&lt;?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>strings on Fellipe Gomes - Data Science Blog</title>
    <link>https://gomesfellipe.github.io/tags/strings/</link>
    <description>√öltimos posts sobre Data Science, Machine Learning e R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <managingEditor>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</managingEditor>
    <webMaster>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</webMaster>
    <lastBuildDate>Fri, 03 Dec 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://gomesfellipe.github.io/tags/strings/" rel="self" type="application/rss+xml" />
    <item>
      <title>Vou te provar que da para fazer Grafos bonitos em R!</title>
      <link>https://gomesfellipe.github.io/post/2021-12-03-grafos-em-r/</link>
      <pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-12-03-grafos-em-r/</guid>
      <description>Neste post vamos coletar not√≠cias via web scrapping, detectar entidades dos textos e criar um grafo utilizando ggplot2</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#introdu%C3%A7%C3%A3o-e-contexto" id="toc-introdu√ß√£o-e-contexto">Introdu√ß√£o e contexto</a>
<ul>
<li><a href="#o-que-s%C3%A3o-grafos" id="toc-o-que-s√£o-grafos">O que s√£o Grafos?</a></li>
<li><a href="#como-contruir-um" id="toc-como-contruir-um">Como contruir um?</a></li>
</ul></li>
<li><a href="#carregar-depend%C3%AAncias" id="toc-carregar-depend√™ncias">Carregar depend√™ncias</a></li>
<li><a href="#fonte-dos-dados" id="toc-fonte-dos-dados">Fonte dos dados</a></li>
<li><a href="#ner---named-entity-recognition" id="toc-ner---named-entity-recognition">NER - Named Entity Recognition</a></li>
<li><a href="#preparar-dados" id="toc-preparar-dados">Preparar dados</a></li>
<li><a href="#b%C3%B4nus" id="toc-b√¥nus">B√¥nus</a></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o</a></li>
<li><a href="#outras-bibliotecas-para-constru%C3%A7%C3%A3o-de-grafos" id="toc-outras-bibliotecas-para-constru√ß√£o-de-grafos">Outras bibliotecas para constru√ß√£o de grafos</a></li>
</ul>
</div>

<div id="introdu√ß√£o-e-contexto" class="section level1">
<h1>Introdu√ß√£o e contexto</h1>
<p>Durante os anos de 2020 e 2021 fiz um <a href="https://educacao-executiva.fgv.br/df/brasilia/cursos/mba-pos-graduacao/mba-presencial/mba-executivo-em-business-analytics-e-big-data">MBA Executivo em Business Analytics e Big Data</a> na FGV e uma das disciplinas que gostei bastante abordou a an√°lise de m√≠dias sociais com t√©cnicas de minera√ß√£o de texto e processamento de linguagem natural.</p>
<p>No trabalho final fomos desafiados a extrair dados da internet via api ou scraping, aplicar a metodologia apropriada para extrair informa√ß√µes de interesse e contruir um Grafo.</p>
<p>Como esse gr√°fico deu mais de trabalho do que eu esperava e fiquei bem satisfeito com o resultado final, resolvi fazer uma nova an√°lise para praticar e publicar aqui no blog, espero que gostem!</p>
<div id="o-que-s√£o-grafos" class="section level2">
<h2>O que s√£o Grafos?</h2>
<p>üìé Segundo o Wikipedia:</p>
<blockquote>
<p>‚ÄúA teoria dos grafos √© um ramo da matem√°tica que estuda as rela√ß√µes entre os objetos de um determinado conjunto‚Äù</p>
</blockquote>
<p>S√£o muito √∫teis para an√°lises de redes sociais, redes de amizades ou qualquer rede com rela√ß√µes de depend√™ncias. Existem muitos tipos de grafos como conectados, desconectados, esparsos, densos, direcionados, n√£o direcionados e por ai vai‚Ä¶</p>
<p>Al√©m disso existe toda uma nomenclatura espec√≠fica, mas n√£o entrarei em detalhes te√≥ricos neste post pois tamb√©m estou estudado sobre o tema! Caso queira aprofundar na teoria por tr√°s recomendo <a href="http://faculty.ucr.edu/~hanneman/nettext/index.html">este material</a> gratuito muito bom!</p>
</div>
<div id="como-contruir-um" class="section level2">
<h2>Como contruir um?</h2>
<p>No curso que fiz aprendemos a mexer no <a href="https://gephi.org/">Gephi</a> para a contru√ß√£o desses Grafos (ferramenta incr√≠vel, diga-se de passagem) por√©m ouvi dizer diversas vezes, tanto dentro quanto fora da FGV, que R e Python eram muito limitados para constru√ß√£o de Grafos bonitos e que esse software sempre a melhor op√ß√£o.</p>
<p>Apesar do enorme potencial do Gephi, fiquei um pouco entediado estudando-o pois n√£o sou grande f√£ de ferramentas <em>point-and-click</em> e quando o professor falou que a escolha da ferramenta para a constru√ß√£o do Grafo era livre, resolvi tentar faz√™-lo em R!</p>
</div>
</div>
<div id="carregar-depend√™ncias" class="section level1">
<h1>Carregar depend√™ncias</h1>
<p>Pacotes utilizados neste post:</p>
<pre class="r"><code>library(rvest)     # web scrapping
library(dplyr)     # manipulate data
library(purrr)     # functional prog
library(stringr)   # str toolkit
library(spacyr)    # ner
library(igraph)    # base graph
library(tidygraph) # tidy graph
library(ggraph)    # plot graph</code></pre>
</div>
<div id="fonte-dos-dados" class="section level1">
<h1>Fonte dos dados</h1>
<p>Os dados utilizados neste post foram coletados via web scrapping do site do <a href="https://g1.globo.com/">G1 - Globo</a>. Optei por trabalhar com textos jornal√≠sticos neste post pois apresentam a vantagem de serem bem escritos, o que facilita na tarefa de minera√ß√£o de texto.</p>
<p>Tamb√©m fiz um grafo analisando tweets sobre a CPI da pandemia <a href=".#b%C3%B4nus">que ser√° apresentado como b√¥nus no final deste post</a> e para quem tiver curiosidade de conferir <a href="https://github.com/gomesfellipe/cpi_da_pandemia">os c√≥digos</a> vai notar que foi necess√°rio um tratamento muito mais extensivo para corrigir os nomes de cada um dos senadores, deputados e personagens pol√≠ticos detectados.</p>
<p>Confira abaixo todos os c√≥digos necess√°rios para realizar tal extra√ß√£o:</p>
<details>
<summary>
(<em>Clique aqui para exibir as fun√ß√µes <code>scrape_post_links</code> e <code>scrape_post_body</code> </em>)
</summary>
<pre class="r"><code># Funcao para coletar os links de cada noticia
scrape_post_links &lt;- function(site) {
  cat(paste0(site, &quot;\n&quot;))
  
  source_html &lt;- read_html(site)
  
  links &lt;- source_html %&gt;%
    html_nodes(&quot;div.widget--info__text-container&quot;) %&gt;%
    html_nodes(&quot;a&quot;) %&gt;%
    html_attr(&quot;href&quot;)
  
  links &lt;- links[!is.na(links)]
  
  return(links)
}

# Funcao para coletar o texto da materia em cada link
scrape_post_body &lt;- function(site) { 
  
  text &lt;- tryCatch({
    cat(paste0(site, &quot;\n&quot;))
    body &lt;- site %&gt;%
      read_html %&gt;%
      html_nodes(&quot;article&quot;) %&gt;%
      html_nodes(&quot;p.content-text__container&quot;)  %&gt;%
      html_text %&gt;% 
      paste(collapse = &#39;&#39;)
    
  }, error = function(e){
    cat(paste(&quot;ERRO 404&quot;, &quot;\n&quot;))
    body &lt;- NA
  })
  
  return(body)
}

# criar matriz de adjacencias
get_adjacent_list &lt;- function(edge_list) {
  gtools::combinations(length(edge_list), 2, edge_list)  
}</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code># raiz
root &lt;- &quot;https://g1.globo.com/busca/?q=economia+brasil&quot;

# gerar links das proximas 100 paginas
all_pages &lt;- c(root, paste0(root, &quot;&amp;page=&quot;, 1:50))

# coletar os links dos posts de cada pagina
all_links &lt;- map(all_pages, scrape_post_links) %&gt;% unlist()

# extrair urls
cleaned_links &lt;- map_chr(all_links, ~{
  .x %&gt;% 
    urltools::param_get() %&gt;% 
    pull(u) %&gt;% 
    urltools::url_decode()
})

# reter apenas links que falam de economia
cleaned_links &lt;- cleaned_links %&gt;% .[str_detect(.,  &quot;g1.globo.com/economia&quot;)]

# nao reter links do globoplay
cleaned_links &lt;- cleaned_links %&gt;% .[!str_detect(.,  &quot;globoplay&quot;)]

# coletar conteudo de cada link
data &lt;- map_chr(cleaned_links, scrape_post_body) %&gt;% unique()</code></pre>
</div>
<div id="ner---named-entity-recognition" class="section level1">
<h1>NER - Named Entity Recognition</h1>
<p>Utilizaremos um modelo de reconhecimento de entidades pr√©-treinado fornecido pela <a href="https://spacy.io/">Spacy</a> (que fornece essa e muitas outras solu√ß√µes interessantes quando se trata de processamento de linguagem natural).</p>
<p>Primeiramente vamos configurar o <code>spacyr</code> na m√°quina para utilizar o modelo pr√© treinado para reconhecimento de entidades em portugu√™s:</p>
<pre class="r"><code># Executar apenas 1 vez
spacyr::spacy_install()
spacy_download_langmodel(&quot;pt_core_news_sm&quot;)</code></pre>
<p>Inicializar modelo pr√©-treinado em portugu√™s:</p>
<pre class="r"><code>spacy_initialize(model=&quot;pt_core_news_sm&quot;)</code></pre>
<p>Aplicar modelo carregado para o reconhecimento de entidades:</p>
<pre class="r"><code>entities &lt;- spacy_extract_entity(data)</code></pre>
<p>Filtrar apenas entidades cujo tipo s√£o <strong>pessoas</strong> ou <strong>organiza√ß√µes</strong>:</p>
<pre class="r"><code>filtered_entities &lt;- 
  entities %&gt;% 
  filter(ent_type==&#39;ORG&#39;| ent_type==&#39;PER&#39;)</code></pre>
</div>
<div id="preparar-dados" class="section level1">
<h1>Preparar dados</h1>
<p>Precisamos criar uma lista de arestas:</p>
<pre class="r"><code>edges &lt;- 
  filtered_entities %&gt;%
  group_by(doc_id) %&gt;%
  summarise(entities = paste(text, collapse = &quot;,&quot;)) %&gt;% 
  pull(entities) %&gt;% 
  str_split(&quot;,&quot;) %&gt;% 
  map(~unique(unlist(.x))) %&gt;% 
  .[map_dbl(., length) != 1]</code></pre>
<p>Agora criaremos a matriz de adjac√™ncias, que envolvem todas as combina√ß√µes 2 a 2 das entidades detectadas em cada not√≠cia:</p>
<pre class="r"><code>adjacent_matrix &lt;-
  map_dfr(edges, ~ as.data.frame(get_adjacent_list(.x))) %&gt;% 
  as_tibble() %&gt;% 
  set_names(c(&#39;item1&#39;, &#39;item2&#39;))</code></pre>
<p>Aplicaremos algum tratamento para padronizar as entidades, reter apenas combina√ß√µes que aconteceram pelo menos 3 vezes e remover algum res√≠duo que veio no processo de NER:</p>
<pre class="r"><code># Padronizar entidades
adjacent_matrix &lt;- adjacent_matrix %&gt;% 
  mutate_all(~.x %&gt;% 
               str_replace_all(&quot;Funda√ß√£o Getulio Vargas&quot;, &quot;FGV&quot;) %&gt;% 
               str_replace_all(&quot;FMI&quot;, &quot;Fundo Monet√°rio Internacional&quot;) %&gt;% 
               str_replace_all(&quot;Paulo Guedes&quot;, &quot;Guedes&quot;) %&gt;% 
               str_replace_all(&quot;Estados Unidos( da Am[√©e]rica)?&quot;, &quot;EUA&quot;) %&gt;% 
               str_replace_all(&quot;Donald Trump&quot;, &quot;Trump&quot;) %&gt;% 
               str_replace_all(&quot;CEF&quot;, &quot;Caixa Econ√¥mica Federal&quot;) %&gt;% 
               str_replace_all(&quot;CMN&quot;, &quot;Conselho Monet√°rio Nacional&quot;) %&gt;% 
               str_replace_all(&quot;Cl[√°a]udio Considera&quot;, &quot;Cl√°udio&quot;) %&gt;% 
               str_replace_all(&quot;OCDE&quot;, &quot;Organiza√ß√£o para a Coopera√ß√£o e
                               Desenvolvimento Econ√¥mico&quot;) %&gt;% 
               str_replace_all(&quot;(Andr√© )?Brand√£o&quot;, &quot;Andr√© Brand√£o&quot;) %&gt;% 
               str_replace_all(&quot;(Maur[i√≠]cio )?Macri&quot;, &quot;Mauricio Macri&quot;) %&gt;% 
               str_remove_all(&quot;^(?i)(no|de)\\s&quot;)
             
             )

# remover residuos
{
  entities_to_drop &lt;- c(&quot;Assine&quot;, &quot;Google Podcasts&quot;, &quot;Spotify&quot;, &quot;Focus do&quot;,
                        &quot;Focus&quot;, &quot;Segundo&quot;, &quot;Ningu√©m&quot;, &quot;Haver√°&quot;, &quot;G1&quot;,
                        &quot;Come√ßa&quot;, &quot;LEIA&quot;, &quot;R$&quot;, &quot;Considera&quot;, &quot;Caixa Aqui&quot;)
  
  weighted_edgelist &lt;- adjacent_matrix %&gt;%
    filter_at(1:2, ~ !.x %in% entities_to_drop) %&gt;% 
    group_by(item1, item2) %&gt;%
    summarise(n=n()) %&gt;% 
    ungroup() %&gt;% 
    filter(n&gt;3) 
}</code></pre>
<p>Definir alguns objetos para o grafo:</p>
<pre class="r"><code># Instanciar objeto das setas
a &lt;- grid::arrow(type = &quot;closed&quot;, length = unit(.15, &quot;inches&quot;))

# Definir pesos conforme numero de ocorrencias
subt &lt;- weighted_edgelist

# Instanciar objeto dos vertices
vert &lt;- subt %&gt;% 
  tidyr::gather(item, word, item1, item2) %&gt;%
  group_by(word) %&gt;% 
  summarise(n = sum(n))

# Obter componentes para colorir os clusters do grafo
tidy_graph_components &lt;- 
  subt  %&gt;%
  select(item1, item2) %&gt;% 
  as.matrix() %&gt;%
  graph.edgelist(directed = FALSE)  %&gt;%
  as_tbl_graph() %&gt;% 
  activate(&quot;edges&quot;) %&gt;% 
  # definir pesos como numero de ocorrencias
  mutate(weight = subt$n) %&gt;% 
  activate(&quot;nodes&quot;) %&gt;% 
  # obter clusters:
  mutate(component = as.factor(tidygraph::group_edge_betweenness()))
  # outros tipos de agrupamentos:
  # tidygraph.data-imaginist.com/reference/group_graph.html 
  
# Atualizar vertice para incluir grupos
vert &lt;- vert %&gt;% 
  left_join( as.data.frame(activate(tidy_graph_components, &quot;nodes&quot;)) %&gt;% 
               rename(word = name))</code></pre>
<p>Finalmente, vamos criar o grafo utilizando <code>ggplot2</code>:</p>
<pre class="r"><code>set.seed(1)
subt %&gt;%
  graph_from_data_frame(vertices = vert) %&gt;%
  # https://www.data-imaginist.com/2017/ggraph-introduction-layouts/ # layouts
  ggraph(layout = &quot;fr&quot;) +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, &#39;inches&#39;), color = &quot;#D9D9D9A0&quot;) +
  geom_node_point() + 
  geom_node_text(aes(label = name, size = n, alpha = n, color = component),# color = &quot;#EAFF00&quot;,
                 repel = TRUE, point.padding = unit(0.2, &quot;lines&quot;),
                 show.legend = F) +
  scale_size(range = c(2,10)) +
  scale_alpha(range = c(0.5,1))+ 
  theme_dark() + 
  theme(
    panel.background = element_rect(fill = &quot;#2D2D2D&quot;),
    legend.key = element_rect(fill = &quot;#2D2D2D&quot;)
  ) +
  theme_graph(background = &quot;black&quot;)</code></pre>
<center>
<img src="/post/2021-12-03-grafos-em-r/grafo.png" style="width:95.0%" />
</center>
<p>üìå Interpreta√ß√£o</p>
<p>Este grafo resume algumas informa√ß√µes interessantes sobre como o cen√°rio da economia no brasil estava no dia 30 de novembro de 2021. Vejamos alguns pontos relevantes que podem ser envontrados no cen√°rio atual:</p>
<div class="w3-panel w3-pale-green w3-border">
<p>¬† ‚òû Bolsa familia</p>
<p>O Aux√≠lio Brasil √© referido como o ‚ÄúNovo Bolsa Fam√≠lia‚Äù pelos jornais e por isso deve ter sido criada tal rela√ß√£o no Grafo. J√° a Caixa Econ√¥mica Federal √© o agente que executa os pagamentos.</p>
</div>
<div class="w3-panel w3-pale-red w3-border">
<p>¬† ‚òû Guedes</p>
<p>Paulo Guedes √© nosso atual ministro da economia e envolta de seu nome aparecem diversos assuntos que est√£o em pauta atualmente como a PEC dos precat√≥rios, (a privatiza√ß√£o da) Petrobr√°s, Copom, IPCA, Aux√≠lio Brasil dentre outros.</p>
</div>
<div class="w3-panel w3-pale-yellow w3-border">
<p>¬† ‚òû Fundo Monet√°rio Internacional</p>
<p>O FMI <a href="https://pt.wikipedia.org/wiki/Fundo_Monet%C3%A1rio_Internacional">trabalha para melhorar as economias dos pa√≠ses</a> e al√©m da Argentina estar endividada e em acordo com o FMI, √© √©poca de elei√ß√£o, o que explica haver alguns personagens de sua pol√≠tica relacionados.</p>
</div>
<p>Salvar localmente em alta resolu√ß√£o:</p>
<pre class="r"><code>ggsave(filename = &#39;grafo.png&#39;, width = 8, height = 6, device=&#39;png&#39;, dpi=700)</code></pre>
<p>O legal de salvar em alta resolu√ß√£o √© poder dar zoom e navegar pelo grafo!</p>
</div>
<div id="b√¥nus" class="section level1">
<h1>B√¥nus</h1>
<p>Antes de criar este post trabalhei em um <a href="https://github.com/gomesfellipe/cpi_da_pandemia">outro grafo</a> com banco de dados de aproximadamente 27GB de tweets coletados e fornecidos gentilmente pelo <a href="https://twitter.com/trifenol">Janderson Toth</a> (Para quem n√£o o conhe√ße, recomendo fortemente <a href="https://br.linkedin.com/in/trifenol">segui-lo no linkedin</a> pois ele tem compartilhado uma s√©rie de posts com insights obtidos destes dados!)</p>
<center>
<img src="/post/2021-12-03-grafos-em-r/grafo2.png" style="width:95.0%" />
</center>
<p>Para quem tiver interesse, o c√≥digo est√° <a href="https://github.com/gomesfellipe/cpi_da_pandemia">dispon√≠vel no github</a>!</p>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o</h1>
<p>Convenhamos que, de fato, criar um grafo no R n√£o √© uma tarefa super simples. No Gelphi √© poss√≠vel criar grafos at√© mais bonitos que este, por√©m, no longo prazo, ganhamos em produtividade e em escalabilidade pois poder√≠amos reaproveitar muito c√≥digo e tranquilamente desenvolver uma rotina para criar novos grafos a partir de dados streaming, por exemplo, automatizando todo o processo!</p>
</div>
<div id="outras-bibliotecas-para-constru√ß√£o-de-grafos" class="section level1">
<h1>Outras bibliotecas para constru√ß√£o de grafos</h1>
<p>Depois de conversar com algumas pessoas que leram o post, achei que merecia um update com mais id√©ias de mais bibliotecas que poderiam ter sido utilizadas:</p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/cheddar/vignettes/PlotsAndStats.pdf">cheddar</a></li>
<li><a href="https://cran.r-project.org/web/packages/bipartite/bipartite.pdf">bipartite</a></li>
<li><a href="https://pedroj.github.io/bipartite_plots/">ggbipart</a></li>
<li><a href="https://rich-iannone.github.io/DiagrammeR/">diagrameR</a></li>
<li><a href="https://cran.r-project.org/web/packages/visNetwork/vignettes/Introduction-to-visNetwork.html">visNetwork</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-12-03-grafos-em-r/">Vou te provar que da para fazer Grafos bonitos em R!</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category>Texto e NLP</category>
      <category domain="tag">data-mining</category>
      <category domain="tag">estatistica</category>
      <category domain="tag">ggplot2</category>
      <category domain="tag">grafo</category>
      <category domain="tag">r</category>
      <category domain="tag">rstudio</category>
      <category domain="tag">strings</category>
      <category domain="tag">text-mining</category>
      <category domain="tag">tidyverse</category>
      <category domain="tag">web-scrappnig</category>
    </item>
    <item>
      <title>Manipula√ß√£o de Strings e Text Mining</title>
      <link>https://gomesfellipe.github.io/post/2017-12-17-string/string/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2017-12-17-string/string/</guid>
      <description>Algumas dicas e truques √∫teis de pacotes especiais para a manipula√ß√£o e tratamento de strings</description>
      <content:encoded>&lt;![CDATA[
        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="manipula√ß√£o-de-strings-e-text-mining" class="section level1">
<h1>Manipula√ß√£o de strings e Text mining</h1>
<!-- ![](/img/2017-12-17-string/imagem2.png) -->
<p>Estudamos n√∫meros e mais n√∫meros na gradua√ß√£o de estat√≠stica (n√£o sei nem se ainda consigo enxergar algarismos gregos como letras) e mesmo assim um problema frequente na vida de quem trabalha com dados √© a manipula√ß√£o de vari√°veis do tipo <em>string</em>.</p>
<p>Uma vari√°vel do tipo <em>string</em> √© uma vari√°vel do tipo texto e esse tipo de objeto costuma causar alguns problemas na an√°lise de dados se n√£o forem devidamente tratados.</p>
<p>Desde modifica√ß√µes em nomes de colunas em data.frames at√© as mais espertas aplica√ß√µes de text mining com corpus, a limpeza e manipula√ß√£o de strings √© quase sempre necess√°ria</p>
</div>
<div id="criando-fun√ß√µes" class="section level1">
<h1>Criando fun√ß√µes</h1>
<p>Antes de apresentar alguns pacotes com fun√ß√µes √∫teis para manipular strings, gostaria de comentar que pode ser bem √∫til desenvolvermos fun√ß√µes para nosso pr√≥prio uso, n√£o √© raro realizarmos o mesmo procedimento em diferentes etapas das an√°lises, o que pode tornar o c√≥digo desorganizado ou polu√≠do com tantas linhas repetidas.</p>
<p>Trago aqui de exemplo uma fun√ß√£o que encontrei recentemente para remover acentos no <a href="https://pt.stackoverflow.com/questions/46473/remover-acentos">stackoverflow</a> que j√° me ajudou bastante, veja a fun√ß√£o:</p>
<pre class="r"><code>rm_accent &lt;- function(str,pattern=&quot;all&quot;) {
  # Rotinas e fun√ß√µes √∫teis V 1.0
  # rm.accent - REMOVE ACENTOS DE PALAVRAS
  # Fun√ß√£o que tira todos os acentos e pontua√ß√µes de um vetor de strings.
  # Par√¢metros:
  # str - vetor de strings que ter√£o seus acentos retirados.
  # patterns - vetor de strings com um ou mais elementos indicando quais acentos dever√£o ser retirados.
  #            Para indicar quais acentos dever√£o ser retirados, um vetor com os s√≠mbolos dever√£o ser passados.
  #            Exemplo: pattern = c(&quot;¬¥&quot;, &quot;^&quot;) retirar√° os acentos agudos e circunflexos apenas.
  #            Outras palavras aceitas: &quot;all&quot; (retira todos os acentos, que s√£o &quot;¬¥&quot;, &quot;`&quot;, &quot;^&quot;, &quot;~&quot;, &quot;¬®&quot;, &quot;√ß&quot;)
  if(!is.character(str))
    str &lt;- as.character(str)
  
  pattern &lt;- unique(pattern)
  
  if(any(pattern==&quot;√á&quot;))
    pattern[pattern==&quot;√á&quot;] &lt;- &quot;√ß&quot;
  
  symbols &lt;- c(
    acute = &quot;√°√©√≠√≥√∫√Å√â√ç√ì√ö√Ω√ù&quot;,
    grave = &quot;√†√®√¨√≤√π√Ä√à√å√í√ô&quot;,
    circunflex = &quot;√¢√™√Æ√¥√ª√Ç√ä√é√î√õ&quot;,
    tilde = &quot;√£√µ√É√ï√±√ë&quot;,
    umlaut = &quot;√§√´√Ø√∂√º√Ñ√ã√è√ñ√ú√ø&quot;,
    cedil = &quot;√ß√á&quot;
  )
  
  nudeSymbols &lt;- c(
    acute = &quot;aeiouAEIOUyY&quot;,
    grave = &quot;aeiouAEIOU&quot;,
    circunflex = &quot;aeiouAEIOU&quot;,
    tilde = &quot;aoAOnN&quot;,
    umlaut = &quot;aeiouAEIOUy&quot;,
    cedil = &quot;cC&quot;
  )
  
  accentTypes &lt;- c(&quot;¬¥&quot;,&quot;`&quot;,&quot;^&quot;,&quot;~&quot;,&quot;¬®&quot;,&quot;√ß&quot;)
  
  if(any(c(&quot;all&quot;,&quot;al&quot;,&quot;a&quot;,&quot;todos&quot;,&quot;t&quot;,&quot;to&quot;,&quot;tod&quot;,&quot;todo&quot;)%in%pattern)) # opcao retirar todos
    return(chartr(paste(symbols, collapse=&quot;&quot;), paste(nudeSymbols, collapse=&quot;&quot;), str))
  
  for(i in which(accentTypes%in%pattern))
    str &lt;- chartr(symbols[i],nudeSymbols[i], str)
  
  return(str)
}</code></pre>
<p>Criar nossas pr√≥prias fun√ß√µes √© muito simples em R e eu encorajo a todos a come√ßarem a trabalhar com fun√ß√µes pr√≥prias tamb√©m (al√©m das nativas do R), pois o programa fica muito mais din√¢mico e limpo.</p>
</div>
<div id="o-pacote-stringr" class="section level1">
<h1>O pacote <code>stringr</code></h1>
<p>Al√©m do pacote <code>dplyr</code>, mais uma vez <a href="https://github.com/hadley">Hadley Wickham</a> tr√°s uma solu√ß√£o bastante √∫til para facilitar nossa vida de programador estat√≠stico (ou cientista de dados se preferir, seguindo as ‚Äútend√™ncias da moda‚Äù de ‚Äúdata scientist‚Äù) com o pacote <code>stringr</code>, que possui uma sintaxe consistente, permitindo a manipula√ß√£o de textos com muito mais facilidade.</p>
<p>Seu uso consiste em uma variedade de utilidades que podem ser consultadas diretamente de dentro do R ao escrever <code>str_</code> (ap√≥s carregar o pacote) e aguardar um instante que a seguinte lista de fun√ß√µes ser√° exibida:</p>
<div class="figure">
<img src="/img/2017-12-17-string/imagem1.png" alt="" />
<p class="caption">Note que essa aplica√ß√£o funciona para qualquer pacote do R</p>
</div>
<p>Portanto, inicialmente vamos carregar o pacote:</p>
<pre class="r"><code>library(stringr)</code></pre>
<p>Com o pacote carregado j√° podemos fazer o uso de algumas das fun√ß√µes que s√£o bem √∫teis.</p>
<div id="arrumando-titulos-de-base-de-dados" class="section level2">
<h2>Arrumando titulos de base de dados</h2>
<p>√â muito comum que os cabe√ßalhos de uma base de dados venha repleta de caracteres especiais como este exemplo:</p>
<pre class="r"><code>nomes=c(&#39;Anivers√°rio&#39;, &#39;Situa√ß√£o&#39;, &#39;Ra√ßa&#39;, &#39;IMC&#39;, &#39;Tipo f√≠sico&#39;, &#39;tabaco por dia (cig/dia)&#39;, &#39;Alcool (dose/semana)&#39;, &#39;Drogas/g&#39;, &#39;Caf√©/dia&#39;, &#39;Suco/dia&#39;);nomes</code></pre>
<pre><code>##  [1] &quot;Anivers√°rio&quot;              &quot;Situa√ß√£o&quot;                
##  [3] &quot;Ra√ßa&quot;                     &quot;IMC&quot;                     
##  [5] &quot;Tipo f√≠sico&quot;              &quot;tabaco por dia (cig/dia)&quot;
##  [7] &quot;Alcool (dose/semana)&quot;     &quot;Drogas/g&quot;                
##  [9] &quot;Caf√©/dia&quot;                 &quot;Suco/dia&quot;</code></pre>
<p>Unindo as fun√ß√µes deste pacote com a sintaxe do pacote <code>dplyr</code> podemos elaborar uma fun√ß√£o que ir√° facilitar bastante nas chamadas das colunas do data.frame na hora da an√°lise, veja:</p>
<pre class="r"><code>ajustar_nomes=function(x){
  x%&gt;%
    stringr::str_trim() %&gt;%                        #Remove espa√ßos em branco sobrando
    stringr::str_to_lower() %&gt;%                    #Converte todas as strings para minusculo
    rm_accent() %&gt;%                                #Remove os acentos com a funcao criada acima
    stringr::str_replace_all(&quot;[/&#39; &#39;.()]&quot;, &quot;_&quot;) %&gt;% #Substitui os caracteres especiais por &quot;_&quot;
    stringr::str_replace_all(&quot;_+&quot;, &quot;_&quot;) %&gt;%        #Substitui os caracteres especiais por &quot;_&quot;   
    stringr::str_replace(&quot;_$&quot;, &quot;&quot;)                 #Substitui o caracter especiais por &quot;_&quot;
}
nomes=ajustar_nomes(nomes)
nomes</code></pre>
<pre><code>##  [1] &quot;aniversario&quot;            &quot;situacao&quot;               &quot;raca&quot;                  
##  [4] &quot;imc&quot;                    &quot;tipo_fisico&quot;            &quot;tabaco_por_dia_cig_dia&quot;
##  [7] &quot;alcool_dose_semana&quot;     &quot;drogas_g&quot;               &quot;cafe_dia&quot;              
## [10] &quot;suco_dia&quot;</code></pre>
<div id="fun√ß√£o-str_replace-e-str_replace_all" class="section level3">
<h3>Fun√ß√£o str_replace() e str_replace_all()</h3>
<p>Esse √© o tipo de fun√ß√£o que √© utilizada com frequ√™ncia. Utilizada para substituir ou remover uma (ou todas) as ocorr√™ncias de determinado car√°cter no objeto, suponha a seguinte situa√ß√£o:</p>
<pre class="r"><code>exemplo &lt;- c(&quot;o esperto&quot;, &quot;o doido&quot;, &quot;o normal&quot;)</code></pre>
<p>Para remover a primeira vogal de cada string:</p>
<pre class="r"><code>str_replace(exemplo, &quot;[aeiou]&quot;, &quot;&quot;) </code></pre>
<pre><code>## [1] &quot; esperto&quot; &quot; doido&quot;   &quot; normal&quot;</code></pre>
<p>Para substitui todas as vogais por "_"</p>
<pre class="r"><code>str_replace_all(exemplo, &quot;[aeiou]&quot;, &quot;_&quot;) </code></pre>
<pre><code>## [1] &quot;_ _sp_rt_&quot; &quot;_ d__d_&quot;   &quot;_ n_rm_l&quot;</code></pre>
<p>Considere este novo exemplo:</p>
<pre class="r"><code>exemplo2 &lt;- &quot;O-    ffffzx2, faifavuvuifoovvv fovvo&quot;</code></pre>
<p>Para substitui o primeiro f (ou f‚Äôs) por ‚Äúv‚Äù:</p>
<pre class="r"><code>exemplo2 &lt;- str_replace(exemplo2, &quot;f+&quot;, &quot;v&quot;)
exemplo2</code></pre>
<pre><code>## [1] &quot;O-    vzx2, faifavuvuifoovvv fovvo&quot;</code></pre>
<p>Para substituir todos os v‚Äôs (em sequ√™ncia ou n√£o) por ‚Äúc‚Äù:</p>
<pre class="r"><code>exemplo2 &lt;- str_replace_all(exemplo2, &quot;v+&quot;, &quot;c&quot;) 
exemplo2</code></pre>
<pre><code>## [1] &quot;O-    czx2, faifacucuifooc foco&quot;</code></pre>
</div>
<div id="fun√ß√£o-str_split-e-str_split_fixed" class="section level3">
<h3>Fun√ß√£o str_split() e str_split_fixed()</h3>
<p>Essas fun√ß√µes separam uma string em v√°rias de acordo com um separador.</p>
<pre class="r"><code>frase &lt;- &#39;Analisar palavras √© muito legal. Apesar de todos os desafios as informa√ß√µes que podemos extrair podem revelar informa√ß√µes incr√≠velmente √∫teis. Esse exemplo esta sendo escrito pois vamos retirar cada frase desse paragrafo separadamente.&#39;

str_split(frase, fixed(&#39;.&#39;))</code></pre>
<pre><code>## [[1]]
## [1] &quot;Analisar palavras √© muito legal&quot;                                                                              
## [2] &quot; Apesar de todos os desafios as informa√ß√µes que podemos extrair podem revelar informa√ß√µes incr√≠velmente √∫teis&quot;
## [3] &quot; Esse exemplo esta sendo escrito pois vamos retirar cada frase desse paragrafo separadamente&quot;                 
## [4] &quot;&quot;</code></pre>
</div>
<div id="fun√ß√£o-str_sub" class="section level3">
<h3>Fun√ß√£o <code>str_sub()</code></h3>
<p>Para obter uma parte fixa de uma string podemos utilizar o comando <code>str_sub()</code> da seguinte maneira:</p>
<pre class="r"><code>#Suponha as seguintes palavras:
words=c(&quot;00-casados&quot;, &quot;01-casamento&quot;, &quot;02-emprego&quot;, &quot;03-empregado&quot;)</code></pre>
<p>Selecionado apenas do quarto at√© o √∫ltimo caracteres da string:</p>
<pre class="r"><code>str_sub(words, start = 4) # come√ßa no 4 caractere</code></pre>
<pre><code>## [1] &quot;casados&quot;   &quot;casamento&quot; &quot;emprego&quot;   &quot;empregado&quot;</code></pre>
<p>Selecionando apenas os dois primeiros caracteres da string:</p>
<pre class="r"><code>str_sub(words, end = 2) # termina no 2 caractere</code></pre>
<pre><code>## [1] &quot;00&quot; &quot;01&quot; &quot;02&quot; &quot;03&quot;</code></pre>
<p>Para obter caracteres utilizando o sinal de nega√ß√£o <code>-</code></p>
<pre class="r"><code>#Suponha:
words &lt;- c(&quot;casamento-01&quot;, &quot;emprego-02&quot;, &quot;empregado-03&quot;)
str_sub(words, end = -4)   #Seleciona todos os valores menos os √∫ltimos 3</code></pre>
<pre><code>## [1] &quot;casamento&quot; &quot;emprego&quot;   &quot;empregado&quot;</code></pre>
<pre class="r"><code>str_sub(words, start = -2) #Seleciona todos os valores at√© o segundo valor</code></pre>
<pre><code>## [1] &quot;01&quot; &quot;02&quot; &quot;03&quot;</code></pre>
<p>Tamb√©m √© poss√≠vel utilizar os argumentos <code>end</code> e <code>start</code> conjuntamente, veja</p>
<pre class="r"><code>#√â poss√≠vel usar os argumentos start e end conjuntamente.
words &lt;- c(&quot;__casamento__&quot;, &quot;__emprego__&quot;, &quot;__empregado__&quot;)
str_sub(words, start=3, end=-3)</code></pre>
<pre><code>## [1] &quot;casamento&quot; &quot;emprego&quot;   &quot;empregado&quot;</code></pre>
<p>A manipula√ß√£o de strings √© uma tarefa bem trabalhosa e algumas vezes at√© complexa por√©m cada desafio que surge ajuda bastante a entender esse mecanismo para manipula√ß√£o de strings.</p>
</div>
</div>
</div>
<div id="pacote-tm" class="section level1">
<h1>Pacote <code>tm</code></h1>
<p>O pacote <code>tm</code> √© um cl√°ssico para o text mining em R, quando os dados se apresentam de forma n√£o estrutura, necessitam de uma prepara√ß√£o pr√©via que pode ser considerada um tipo de pr√©-processamento.</p>
<p>Inicialmente, carregando o pacote:</p>
<pre class="r"><code>library(tm)</code></pre>
<p>Em bases de dados textuais, conhecidos como <em>corpus</em> ou <em>corpora</em> s√£o tratado como ‚Äúdocumentos‚Äù e cada ‚Äúdocumento‚Äù em um <em>corpus</em> pode assumir diferentes caracter√≠sticas em rela√ß√£o ao tamanho do texto (sequ√™ncias de caracteres), tipo de conte√∫do (assunto abordado), l√≠ngua na qual √© escrito ou tipo de linguagem adotada dentro outros exemplos.</p>
<p>A transforma√ß√£o de um <em>corpus</em> em um conjunto de dados que possa ser submetido √† procedimentos de an√°lise consiste em um processo que gera uma representa√ß√£o capaz de descrever cada documento em termos de suas caracter√≠sticas.</p>
<p>Para criar um <em>corpus</em> a partir de um <code>data.frame</code> basta utilizar o seguinte comando:</p>
<pre class="r"><code>#Criando o corpus para o tratamento das variaveis com pacote library(tm): 
corpus &lt;- Corpus(DataframeSource(x))</code></pre>
<p>A seguir veremos algumas dos poss√≠veis procedimentos para a manipula√ß√£o de dados em um <em>corpus</em>.</p>
<div id="limpeza-de-um-corpus" class="section level2">
<h2>Limpeza de um corpus</h2>
<p>Uma sequ√™ncia de comando interessantes para a limpeza de um <em>corpus</em> que j√° utilizei bastante √© a seguinte:</p>
<pre class="r"><code>#Realizando a limpeza da base de dados:
#Acrescentar mais stopwords para retirada;
#novas=c()

#Tratamento do corpus
tratar_corpus=function(x){
  x%&gt;% 
    tm_map(stripWhitespace)%&gt;%                                #remover excessos de espa√ßos em branco
    tm_map(removePunctuation)%&gt;%                              #remover pontuacao
    tm_map(removeNumbers)%&gt;%                                  #remover numeros
    tm_map(removeWords, c(stopwords(&quot;portuguese&quot;),novas))%&gt;%  #remmover as stopwords,crie um vetor chamado &quot;novas&quot; para incluir novas stopwords 
    tm_map(stripWhitespace)%&gt;%                                #remover excessos de espa√ßos em branco novamente
    tm_map(removeNumbers)                                 #remover numeros novamente
  # tm_map(content_transformer(tolower))%&gt;%                   #colocar todos caracteres como minusculo
  #tm_map(stemDocument)                                      #Extraindo os radicais
}                                   
corpus=tratar_corpus(corpus)
#inspect(corpus[[3]]) #Leitura de algum documento espec√≠fico</code></pre>
<p>Para criar a matriz de termos podemos utilizar o comando:</p>
<pre class="r"><code>#Criando a matrix de termos:
corpus_tf=TermDocumentMatrix(corpus, control = list(minWordLength=2,minDocFreq=5))</code></pre>
<p>Caso precise trabalhar com a transforma√ß√£o <code>tf-idf</code> basta utilizar:</p>
<pre class="r"><code>#Caso precise utilizar a medida tf-idf em um corpus:
corpus_tf_idf=weightTfIdf(corpus_tf,normalize=T)</code></pre>
</div>
<div id="obtendo-uma-matriz-de-frequ√™ncias-a-partir-de-um-corpos" class="section level2">
<h2>Obtendo uma matriz de frequ√™ncias a partir de um corpos</h2>
<p>Criando uma matriz para facilitar a manipula√ß√£o dos dados</p>
<pre class="r"><code>#Transformando em matrix para permitir a manipula√ß√£o:
matriz = as.matrix(corpus_tf)

#organizar os dados de forma decrescente
matriz = sort(rowSums(matriz), decreasing=T)

#criando um data.frame para a matriz
matriz = data.frame(word=names(matriz), freq = matriz)</code></pre>
<p>Caso seja necess√°rio conferir visualmente as palavras mais mencionadas, tamb√©m podemos utilizar gr√°ficos, como por exemplo:</p>
<pre class="r"><code>#Vejamos os primeiros 10 registros:
head(matriz, n=10)</code></pre>
<pre><code>##              word freq
## anos         anos  242
## pra           pra  226
## site         site  156
## cadastro cadastro  134
## faz           faz  124
## fazer       fazer  124
## ver           ver  114
## todo         todo  110
## consegue consegue  102
## gente       gente  100</code></pre>
<pre class="r"><code>#Vejamos visualmente:
head(matriz, n=10) %&gt;%
  ggplot(aes(word, freq)) +
  geom_bar(stat = &quot;identity&quot;, color = &quot;black&quot;, fill = &quot;#87CEFA&quot;) +
  geom_text(aes(hjust = 1.3, label = freq)) + 
  coord_flip() + 
  labs(title = &quot;20 Palavras mais mensionadas&quot;,  x = &quot;Palavras&quot;, y = &quot;N√∫mero de usos&quot;)</code></pre>
<p><img src="/post/2017-12-17-string/string_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
</div>
</div>
<div id="n-gram-dictionary-com-rweka" class="section level1">
<h1>N-gram Dictionary com <code>RWeka</code></h1>
<p>Embora a an√°lise de palavras realizada neste documento seja √∫til para a explora√ß√£o inicial, o cientista de dados precisar√° construir um dicion√°rio de bigrams, trigrams e quatro grams, coletivamente chamados de n-grams, que s√£o frases de n palavras.</p>
<p>‚ÄúO <a href="https://www.cs.waikato.ac.nz/ml/weka/">Weka</a> tem como objectivo agregar algoritmos provenientes de diferentes abordagens/paradigmas na sub-√°rea da intelig√™ncia artificial dedicada ao estudo de aprendizagem de m√°quina.‚Äù-<a href="https://pt.wikipedia.org/wiki/Weka">Wikipedia</a></p>
<p>Carregando o pacote <code>RWeka</code>:</p>
<pre class="r"><code>library(rJava)
suppressMessages(library(RWeka)) 
BigramTokenizer &lt;- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
TrigramTokenizer &lt;- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
FourgramTokenizer &lt;- function(x) NGramTokenizer(x, Weka_control(min = 4, max = 4))</code></pre>
<p>Como exemplo, criaremos um dicion√°rio de trigrams (frases de tr√™s palavras) e a fun√ß√£o para construir um dicion√°rio de n-gramas utilizando o pacote <code>tm</code> e o <code>RWeka</code> √©:</p>
<pre class="r"><code># tokenize into tri-grams
trigram.Tdm &lt;- tm::TermDocumentMatrix(corpus, control = list(tokenize = TrigramTokenizer))</code></pre>
<p>Criando uma matriz para facilitar a manipula√ß√£o dos dados</p>
<pre class="r"><code>#Transformando em matrix para permitir a manipula√ß√£o:
matriz = as.matrix(trigram.Tdm)

#organizar os dados de forma decrescente
matriz = sort(rowSums(matriz), decreasing=T)

#criando um data.frame para a matriz
matriz = data.frame(word=names(matriz), freq = matriz)</code></pre>
<pre class="r"><code>#Vejamos os primeiros 20 registros:
head(matriz, n=10)

#Vejamos visualmente:
head(matriz, n=10) %&gt;%
  ggplot(aes(word, freq)) +
  geom_bar(stat = &quot;identity&quot;, color = &quot;black&quot;, fill = &quot;#87CEFA&quot;) +
  geom_text(aes(hjust = 1.3, label = freq)) + 
  coord_flip() + 
  labs(title = &quot;20 frases mais mensionadas&quot;,  x = &quot;Palavras&quot;, y = &quot;N√∫mero de usos&quot;)</code></pre>
<p>Parece que este pacote parou de funcionar temporariamente, uma alternativa a este pacote pode ser o <code>ngram</code> e seu uso pode ser da seguinte forma:</p>
<pre class="r"><code>library(ngram)
ngrams=3
temp=ngram::ngram(ngram::concatenate(corpus),ngrams)      # Objeto temporario recebe objeto que guarda sequencias
temp=get.phrasetable(temp)                                  # Obtendo tabela de sequencias do objeto acima

temp$ngrams=temp$ngrams%&gt;%                                  # Limpeza das sequencias obtidas:
  str_replace_all(pattern = &quot;^([A-Za-z] [A-Za-z])+&quot;,&quot;&quot;)%&gt;%  # Remover sequencias de apenas 1 letras 
  str_replace_all(pattern = &quot;[:punct:]&quot;,&quot;&quot;)%&gt;%              # Remover caracteres especiais
  str_replace_all(pattern = &quot;\n&quot;,&quot;&quot;)%&gt;%                     # Remover o marcador de &quot;nova linha&quot;
  str_trim()                                                # Remover espa√ßos em branco sobrando

#Apos a limpeza..

temp=temp[temp$ngrams!=&quot;&quot;,]                                 # Selecionando apenas as linhas que contenham informacao

temp=temp%&gt;%                                                # Novamente manipulando o objeto que contem a tabela de sequencias
  group_by(ngrams) %&gt;%                                      # Agrupando por &quot;ngrams&quot; (sequencias obtidas)
  summarise(freq=sum(freq))%&gt;%                              # Resumir as linhas repetidas pela soma das frequencias
  arrange(desc(freq))%&gt;%                                    # Organizando da maior para a menos frequencia
  as.matrix()                                               # Alterando o tipo de objeto para matrix

rownames(temp)=str_c(temp[,1])                              # O nome das linhas passa a ser a sequencia correspondente
v=sort(temp[,2],decreasing = T)                               # Retorna um objeto com as frequencias em ordem decrescente e linhas nomeadas
data.frame(words = names(v),freq=v)%&gt;%
  head(n=25)%&gt;%
  ggplot(aes(words, freq)) +
  geom_bar(stat = &quot;identity&quot;, color = &quot;black&quot;, fill = &quot;#87CEFA&quot;) +
  geom_text(aes(hjust = 1.3, label = freq)) + 
  coord_flip() + 
  labs(title = &quot;25 frases mais mensionadas&quot;,  x = &quot;Palavras&quot;, y = &quot;N√∫mero de usos&quot;)</code></pre>
<p><img src="/post/2017-12-17-string/string_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<div id="package-snowballc" class="section level2">
<h2>Package ‚ÄòSnowballC‚Äô</h2>
<p>Caso seja necess√°rio retirar o radical de um vetor de strings podemos utilizar a fun√ß√£o ¬¥wordStem¬¥ do pacote <code>SnowballC</code>, caso queria conferir, existe o <a href="https://cran.r-project.org/web/packages/SnowballC/SnowballC.pdf">manual do pacote</a> no <a href="https://cran.r-project.org/web/packages/SnowballC">CRAN</a></p>
<pre class="r"><code>words=c(&quot;casados&quot;, &quot;casamento&quot;, &quot;emprego&quot;, &quot;empregado&quot;)
SnowballC::getStemLanguages()</code></pre>
<pre><code>##  [1] &quot;arabic&quot;     &quot;basque&quot;     &quot;catalan&quot;    &quot;danish&quot;     &quot;dutch&quot;     
##  [6] &quot;english&quot;    &quot;finnish&quot;    &quot;french&quot;     &quot;german&quot;     &quot;greek&quot;     
## [11] &quot;hindi&quot;      &quot;hungarian&quot;  &quot;indonesian&quot; &quot;irish&quot;      &quot;italian&quot;   
## [16] &quot;lithuanian&quot; &quot;nepali&quot;     &quot;norwegian&quot;  &quot;porter&quot;     &quot;portuguese&quot;
## [21] &quot;romanian&quot;   &quot;russian&quot;    &quot;spanish&quot;    &quot;swedish&quot;    &quot;tamil&quot;     
## [26] &quot;turkish&quot;</code></pre>
<pre class="r"><code>SnowballC::wordStem(words, language = &quot;portuguese&quot;)</code></pre>
<pre><code>## [1] &quot;cas&quot;      &quot;casament&quot; &quot;empreg&quot;   &quot;empreg&quot;</code></pre>
</div>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2017-12-17-string/string/">Manipula√ß√£o de Strings e Text Mining</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>R</category>
      <category>Pr√°tica</category>
      <category>Text Mining</category>
      <category domain="tag">gomesfellipe</category>
      <category domain="tag">R</category>
      <category domain="tag">RStudio</category>
      <category domain="tag">text mining</category>
      <category domain="tag">strings</category>
    </item>
  </channel>
</rss>