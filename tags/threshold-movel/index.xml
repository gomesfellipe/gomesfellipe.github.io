&lt;?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>threshold-movel on Fellipe Gomes - Data Science Blog</title>
    <link>https://gomesfellipe.github.io/tags/threshold-movel/</link>
    <description>√öltimos posts sobre Data Science, Machine Learning e R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <managingEditor>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</managingEditor>
    <webMaster>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</webMaster>
    <lastBuildDate>Mon, 01 Nov 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://gomesfellipe.github.io/tags/threshold-movel/" rel="self" type="application/rss+xml" />
    <item>
      <title>Solu√ß√£o Final - Porto Seguro Data Challenge [3¬∫ lugar]</title>
      <link>https://gomesfellipe.github.io/post/2021-11-01-solucao-final-porto-seguro-data-challenge/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-11-01-solucao-final-porto-seguro-data-challenge/</guid>
      <description>Confira a estrat√©gia aplicada para a competi√ß√£o de machine learning do Porto Seguro hospedada no Kaggle</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#introdu%C3%A7%C3%A3o" id="toc-introdu√ß√£o">Introdu√ß√£o</a></li>
<li><a href="#defini%C3%A7%C3%A3o-do-problema-de-neg%C3%B3cio" id="toc-defini√ß√£o-do-problema-de-neg√≥cio">Defini√ß√£o do problema de neg√≥cio</a></li>
<li><a href="#an%C3%A1lise-explorat%C3%B3ria-em-r" id="toc-an√°lise-explorat√≥ria-em-r">An√°lise Explorat√≥ria (em R)</a></li>
<li><a href="#machine-learning-em-python" id="toc-machine-learning-em-python">Machine Learning (em Python)</a>
<ul>
<li><a href="#importar-depend%C3%AAncias" id="toc-importar-depend√™ncias">Importar depend√™ncias</a></li>
<li><a href="#stage-0-feature-extraction-com-knn" id="toc-stage-0-feature-extraction-com-knn">Stage 0: Feature Extraction com KNN</a></li>
<li><a href="#stage-1-tuning-xgboost-com-optuna" id="toc-stage-1-tuning-xgboost-com-optuna">Stage 1: Tuning XGBoost com Optuna</a></li>
<li><a href="#stage-2-calcular-out-of-fold-shap-values" id="toc-stage-2-calcular-out-of-fold-shap-values">Stage 2: Calcular Out-Of-Fold SHAP values</a></li>
<li><a href="#stage-3-modelo-final-com-autogluon" id="toc-stage-3-modelo-final-com-autogluon">Stage 3: Modelo Final com AutoGluon</a></li>
</ul></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias</a></li>
</ul>
</div>

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 20%;
padding: 10px;
}

.column8 {
float: left;
width: 80%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>
<hr />
<div id="introdu√ß√£o" class="section level1">
<h1>Introdu√ß√£o</h1>
<div class="row">
<div class="column8">
<p>Em Agosto e 2021 a Porto Seguro lan√ßou um desafio no Kaggle que consistia em estimar a propens√£o de aquisi√ß√£o de novos produtos. Tratava-se de um problema de classifica√ß√£o e foi bem desafiador principalmente por 2 motivos:</p>
<ol style="list-style-type: decimal">
<li>Todas as features da base de ddos eram anonimas;</li>
<li>A m√©trica de avalia√ß√£o foi a F1 Score (sens√≠vel √† um ponto de corte)</li>
</ol>
</div>
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/Ie2Hs3A0uJRtK/giphy.gif" alt="Via Giphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/Ie2Hs3A0uJRtK/giphy.gif">Via Giphy</a></div>
</div>
</div>
</div>
<p>Depois de 2 longos meses e dezenas de notebooks desenvolvidos, muitas submiss√µes frustradas e muitas horas a menos de sono, cheguei em uma solu√ß√£o final que envole um <em>blending</em> de modelos e <em>pseudo-labels</em> e quando a competi√ß√£o acabou, percebi que uma solu√ß√£o mais simples de implementar teria um resultado privado ainda maior do que o notebook que selecionei. üòÖ</p>
<div class="w3-panel w3-sand w3-border">
<p>‚ö†Ô∏è Aten√ß√£o!</p>
<p>Neste post abordarei uma solu√ß√£o mais simples e eficiente mas caso tenha interesse em conferir a solu√ß√£o final completa (um grande frankstein), j√° est√° <a href="https://github.com/gomesfellipe/porto_seguro_data_challenge">publica la no github</a>.</p>
</div>
<p>Este notebook √© uma <a href="https://www.kaggle.com/gomes555/3st-place-simplified-solution-0-6967-private">reescritura do meu notebook publicado no Kaggle em linguagem Python</a>. Para quem acompanha meus posts de R pode achar meio estranho este notebook mas convido-o a tentar entender a solu√ß√£o pois foi desenvolvida pela perspectiva de um usu√°rio nativo de R.</p>
<p>Espero que gostem! ü§ò</p>
</div>
<div id="defini√ß√£o-do-problema-de-neg√≥cio" class="section level1">
<h1>Defini√ß√£o do problema de neg√≥cio</h1>
<p>Segundo a descri√ß√£o da competi√ß√£o:</p>
<blockquote>
<p>Voc√™ provavelmente j√° recebeu uma liga√ß√£o de telemarketing oferecendo um produto que voc√™ n√£o precisa. Essa situa√ß√£o de estresse √© minimizada quando voc√™ oferece um produto que o cliente realmente precisa. <br /><br /> Nessa competi√ß√£o voc√™ ser√° desafiado a construir um modelo que prediz a probabilidade de aquisi√ß√£o de um produto.</p>
</blockquote>
<p>Sobre a m√©trica de avalia√ß√£o:</p>
<p>O crit√©rio utilizado para defini√ß√£o da melhor solu√ß√£o ser√° o F1-Score, veja sua formula:</p>
<p><span class="math display">\[
F_1 = 2 \times \frac{precision \times recall}{precision + recall}  
\]</span></p>
<p>Note que tanto a <em>Precision</em> quanto a <em>Recall</em> precisam de um ponto de corte para obter as classes e por isso busquei otmizar as m√©tricas <em>ROC-AUC</em> e <em>Log Loss</em> para obter estimativas de probabilidades com qualidade para finalmente calcular os pontos de corte que maximizam a <em>F1</em>.</p>
</div>
<div id="an√°lise-explorat√≥ria-em-r" class="section level1">
<h1>An√°lise Explorat√≥ria (em R)</h1>
<p>Antes de partir para modelagem fiz uma an√°lise explorat√≥ria utilizando a linguagem R. Neste post tratarei de maneira bem breve e quem tiver interesse em conferir mais detalhes bem como os c√≥digos dos gr√°ficos basta acessar o <a href="https://www.kaggle.com/gomes555/porto-seguro-r-an-lise-explorat-ria-dos-dados">notebook que deixei aberto no Kaggle</a>.</p>
<p>Veja alguns gr√°ficos:</p>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/aed.png" style="width:90.0%" />
</center>
<!-- <div class="w3-panel w3-light-blue w3-border"> -->
<p><strong>üìå Interpreta√ß√£o:</strong> <br></p>
<ul>
<li><strong>Categ√≥ricas</strong>:
<div style="color: rgb(0, 0, 0);">
<ul>
<li>
<strong>Qualitativo nominal</strong>: Possuem muitas classes, poderia ser o nome do produto, regi√£o, um texto o que torna o desafio ainda maior para criar novas features;
</li>
<li>
<strong>Qualitativo ordinal</strong>: Basicamente deixei como veio pois j√° tava como numerico;
</li>
</ul>
</div></li>
<li><strong>Num√©ricas</strong>:
<div style="color: rgb(0, 0, 0);">
<ul>
<li>
<strong>Quantitativo continua</strong>: Todas est√£o normalizadas (0, 1), algumas s√£o bimodais, algumas assim√©tricas a direita (pode ser tempo ate alguma coisa);
</li>
<li>
<strong>Quantitativo discreto</strong>: Sem muito o que fazer, observa√ß√£o apenas a feature <code>var52</code> que parece idade
</li>
</ul>
</div></li>
<li><strong>Dados missing</strong>: Parece haver algum padr√£o na maneira como os dados missing ocorrem e tentei substituir os <code>-999</code> por <code>NaN</code>, imputar a m√©dia, a mediana e via outros modelos
<!-- </div> --></li>
</ul>
<p>N√£o achei que seria muito produtivo ficar adivinhando o que poderia ser cada feature pois praticamente todos as transforma√ß√µes e novas features que gerei n√£o superavam o resultado do modelo ajustado nos dados da maneira que vinham portanto procurei investir mais tempo na modelagem mesmo.</p>
</div>
<div id="machine-learning-em-python" class="section level1">
<h1>Machine Learning (em Python)</h1>
<p>Veja a estrat√©gia de modelagem de maneira visual:</p>
</br>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/final_pipeline.png" style="width:60.0%" />
</center>
<p></br></p>
<div id="importar-depend√™ncias" class="section level2">
<h2>Importar depend√™ncias</h2>
<p>Carregar pacotes do Python</p>
<pre class="python"><code># general packages
import pandas as pd
import numpy as np
import time
# knn features
from gokinjo import knn_kfold_extract
from gokinjo import knn_extract
# ml tools
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.metrics import f1_score, log_loss, roc_auc_score
# models
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
# optimization
import optuna
# interpretable ml
import shap
# automl
from autogluon.tabular import TabularPredictor
# ignore specific warnings
import warnings
warnings.filterwarnings(&quot;ignore&quot;, message=&quot;ntree_limit is deprecated, use `iteration_range` or model slicing instead.&quot;)</code></pre>
<p>Definir fun√ß√µes auxiliares para calcular o ponto de corte que maximiza a F1:</p>
<pre class="python"><code>def get_threshold(y_true, y_pred):
    thresholds = np.arange(0.0, 1.0, 0.01)
    f1_scores = []
    for thresh in thresholds:
        f1_scores.append(
            f1_score(y_true, [1 if m&gt;thresh else 0 for m in y_pred]))
    f1s = np.array(f1_scores)
    return thresholds[f1s.argmax()]
    
def custom_f1(y_true, y_pred):
    max_f1_threshold =  get_threshold(y_true, y_pred)
    y_pred = np.where(y_pred&gt;max_f1_threshold, 1, 0)
    return f1_score(y_true, y_pred) </code></pre>
<p>Carregar <a href="https://www.kaggle.com/c/porto-seguro-data-challenge/data">dados da competi√ß√£o</a>:</p>
<pre class="python"><code># load data
train = pd.read_csv(&#39;../input/porto-seguro-data-challenge/train.csv&#39;).drop(&#39;id&#39;, axis=1)
test = pd.read_csv(&#39;../input/porto-seguro-data-challenge/test.csv&#39;).drop(&#39;id&#39;, axis=1)
sample_submission = pd.read_csv(&#39;../input/porto-seguro-data-challenge/submission_sample.csv&#39;)
meta = pd.read_csv(&#39;../input/porto-seguro-data-challenge/metadata.csv&#39;)

# get data types
cat_nom = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==&quot;Qualitativo nominal&quot;)].iloc[:,0]] 
cat_ord = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==&quot;Qualitativo ordinal&quot;)].iloc[:,0]] 
num_dis = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==&quot;Quantitativo discreto&quot;)].iloc[:,0]] 
num_con = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==&quot;Quantitativo continua&quot;)].iloc[:,0]] </code></pre>
</div>
<div id="stage-0-feature-extraction-com-knn" class="section level2">
<h2>Stage 0: Feature Extraction com KNN</h2>
<p>Esta t√©cnica gera <span class="math inline">\(k \times c\)</span> novas features, onde <span class="math inline">\(c\)</span> √© o n√∫mero de classes da target. As novas features s√£o calculadas a partir das dist√¢ncias entre as observa√ß√µes e seus k vizinhos mais pr√≥ximos dentro de cada classe;</p>
<p>O valor para os <span class="math inline">\(K\)</span> vizinhos mais pr√≥ximos selecionado foi <span class="math inline">\(K=1\)</span> e para isso utilizei a biblioteca
<a href="https://github.com/momijiame/gokinjo"><code>gokinjo</code></a> que foi <a href="https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335">inspirada nas id√©ias apresentadas na solu√ß√£o vencedora do Otto Group Product Classification Challenge.</a></p>
<pre class="python"><code># convert to numpy because gokinjo expects np arrays
X = train[cat_nom+cat_ord+num_dis+num_con].to_numpy()
y = train.y.to_numpy()
X_test = test[cat_nom+cat_ord+num_dis+num_con].to_numpy()

# extract on train data
KNN_feat_train = knn_kfold_extract(X, y, k=1, normalize=&#39;standard&#39;)
print(&quot;KNN features for training set, shape: &quot;, np.shape(KNN_feat_train))

# extract on test data
KNN_feat_test = knn_extract(X, y, X_test, k=1, normalize=&#39;standard&#39;)
print(&quot;KNN features for test set, shape: &quot;, np.shape(KNN_feat_test))

# convert to dataframe
knn_feat_train = pd.DataFrame(KNN_feat_train, columns=[&quot;knn&quot;+str(x) for x in range(knn_feat_train.shape[1])])
knn_feat_test = pd.DataFrame(KNN_feat_test, columns=[&quot;knn&quot;+str(x) for x in range(knn_feat_test.shape[1])])</code></pre>
<pre><code>## KNN features for training set, shape:  (14123, 2)
## KNN features for test set, shape:  (21183, 2)</code></pre>
</div>
<div id="stage-1-tuning-xgboost-com-optuna" class="section level2">
<h2>Stage 1: Tuning XGBoost com Optuna</h2>
<p>Testei e otimizei muitos modelos como XGBoost, NGBoost, LightGBM, CatBoost, TabNet, HistGradientBoosting e algumas DNNs e em todos os casos (exceto DNNs) utilizei o Optuna para a sele√ß√£o dos hiperpar√¢metros.</p>
<p>Tamb√©m inclui nas tentativas iniciais de otimiza√ß√£o alguns m√©todos de remostrarem como Random Under Sampling, Smote, Tomek, Adasyn dentre outros mas n√£o tive muito sucesso.. apenas a combina√ß√£o Tomek + CatBoost pareceu trazer algum ganho.</p>
<p>Claro que minhas tentativas n√£o foram exautivas e devido ao tempo limitado acabei selecionando o XGBoost que foi o que apresentou as melhores m√©tricas depois de otimizado e tamb√©m o CatBoost com alguns hiperpar√¢metros fixos para serem a base deste pipeline.</p>
<p>Principais Informa√ß√µes üìå :</p>
<ul>
<li>Nenhum pr√©-processamento;</li>
<li>KFold K=10;</li>
<li>Otimiza√ß√£o de hiperpar√¢metros com Optuna;</li>
<li>Loss do XGBoost: Log Loss;</li>
<li>Loss do Otimizador: Log Loss;</li>
<li>Sem resampling;</li>
<li>Previs√£o final com a probabilidade m√©dia de 10 seeds diferentes</li>
</ul>
<pre class="python"><code>X_test = test[cat_nom+cat_ord+num_dis+num_con]
X = train[cat_nom+cat_ord+num_dis+num_con]
y = train.y

K=10
SEED=314
kf = KFold(n_splits=K, random_state=SEED, shuffle=True)</code></pre>
<pre class="python"><code>fixed_params = {
    &#39;random_state&#39;: 9,
    &quot;objective&quot;: &quot;binary:logistic&quot;,
    &quot;eval_metric&quot;: &#39;logloss&#39;,
    &#39;use_label_encoder&#39;:False,
    &#39;n_estimators&#39;:10000,
}

def objective(trial):
    
    hyperparams = {
        &#39;clf&#39;:{
        &quot;booster&quot;: trial.suggest_categorical(&quot;booster&quot;, [&quot;gbtree&quot;]),
        &quot;lambda&quot;: trial.suggest_float(&quot;lambda&quot;, 1e-8, 5.0, log=True),
        &quot;alpha&quot;: trial.suggest_float(&quot;alpha&quot;, 1e-8, 5.0, log=True)
        }
    }
    
    if hyperparams[&#39;clf&#39;][&quot;booster&quot;] == &quot;gbtree&quot; or hyperparams[&#39;clf&#39;][&quot;booster&quot;] == &quot;dart&quot;:
        hyperparams[&#39;clf&#39;][&quot;max_depth&quot;] = trial.suggest_int(&quot;max_depth&quot;, 1, 9)
        hyperparams[&#39;clf&#39;][&quot;eta&quot;] = trial.suggest_float(&quot;eta&quot;, 0.01, 0.1, log=True)
        hyperparams[&#39;clf&#39;][&quot;gamma&quot;] = trial.suggest_float(&quot;gamma&quot;, 1e-8, 1.0, log=True)
        hyperparams[&#39;clf&#39;][&quot;grow_policy&quot;] = trial.suggest_categorical(&quot;grow_policy&quot;, [&quot;depthwise&quot;, &quot;lossguide&quot;])
        hyperparams[&#39;clf&#39;][&#39;min_child_weight&#39;] = trial.suggest_int(&#39;min_child_weight&#39;, 5, 20)
        hyperparams[&#39;clf&#39;][&quot;subsample&quot;] = trial.suggest_float(&quot;subsample&quot;, 0.03, 1)
        hyperparams[&#39;clf&#39;][&quot;colsample_bytree&quot;] = trial.suggest_float(&quot;colsample_bytree&quot;, 0.03, 1)
        hyperparams[&#39;clf&#39;][&#39;max_delta_step&#39;] = trial.suggest_float(&#39;max_delta_step&#39;, 0, 10)
        
    if hyperparams[&#39;clf&#39;][&quot;booster&quot;] == &quot;dart&quot;:
        hyperparams[&#39;clf&#39;][&quot;sample_type&quot;] = trial.suggest_categorical(&quot;sample_type&quot;, [&quot;uniform&quot;, &quot;weighted&quot;])
        hyperparams[&#39;clf&#39;][&quot;normalize_type&quot;] = trial.suggest_categorical(&quot;normalize_type&quot;, [&quot;tree&quot;, &quot;forest&quot;])
        hyperparams[&#39;clf&#39;][&quot;rate_drop&quot;] = trial.suggest_float(&quot;rate_drop&quot;, 1e-8, 1.0, log=True)
        hyperparams[&#39;clf&#39;][&quot;skip_drop&quot;] = trial.suggest_float(&quot;skip_drop&quot;, 1e-8, 1.0, log=True)
    
    params = dict(**fixed_params, **hyperparams[&#39;clf&#39;])
    xgb_oof = np.zeros(X.shape[0])

    for fold, (train_idx, val_idx) in enumerate(kf.split(X=X, y=y)):
        X_train = X.iloc[train_idx]
        y_train = y.iloc[train_idx]
        X_val = X.iloc[val_idx]
        y_val = y.iloc[val_idx]
        
        model = XGBClassifier(**params)
        
        model.fit(X_train, y_train,
                  eval_set=[(X_val, y_val)],
                  early_stopping_rounds=150,
                  verbose=False)
    
        xgb_oof[val_idx] = model.predict_proba(X_val)[:,1]

        del model

    return log_loss(y, xgb_oof)</code></pre>
<p>Como no Kaggle existe o limite de aproximadamente 8h para executar um notebook, coloquei um limite de 7.5 horas para a busca de hiperpar√¢metros:</p>
<pre class="python"><code>study_xgb = optuna.create_study(direction=&#39;minimize&#39;)

study_xgb.optimize(objective, 
               timeout=60*60*7.5, 
               gc_after_trial=True)</code></pre>
<p>Resultados da busca:</p>
<pre class="python"><code>print(&#39;-&gt; Number of finished trials: &#39;, len(study_xgb.trials))
print(&#39;-&gt; Best trial:&#39;)
trial = study_xgb.best_trial
print(&#39;\tValue: {}&#39;.format(trial.value))
print(&#39;-&gt; Params: &#39;)
trial.params</code></pre>
<pre><code>## -&gt; Number of finished trials:  197
## -&gt; Best trial:
## 	Value: 0.3028443879614926
## -&gt; Params: 
## {&#39;booster&#39;: &#39;gbtree&#39;,
##  &#39;lambda&#39;: 9.012384508756378e-07,
##  &#39;alpha&#39;: 0.7472040331088792,
##  &#39;max_depth&#39;: 5,
##  &#39;eta&#39;: 0.01507605562231303,
##  &#39;gamma&#39;: 1.0214961302342215e-08,
##  &#39;grow_policy&#39;: &#39;lossguide&#39;,
##  &#39;min_child_weight&#39;: 5,
##  &#39;subsample&#39;: 0.9331005225916879,
##  &#39;colsample_bytree&#39;: 0.25392142363325004,
##  &#39;max_delta_step&#39;: 5.685109389498008}</code></pre>
<p>Acompanhar o hist√≥rico de cada etapa da otimiza√ß√£o:</p>
<pre class="python"><code>plot_optimization_history(study_xgb)</code></pre>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/optimization_hist.png" style="width:90.0%" />
</center>
<p>Avaliar as combina√ß√µes de hiperpar√¢metros mais bem sucedidas:</p>
<pre class="python"><code>optuna.visualization.plot_parallel_coordinate(study_xgb)</code></pre>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/parallel_plot.png" style="width:90.0%" />
</center>
<p>Quais hiperpar√¢metros tiveram mais impacto na modelagem:</p>
<pre class="python"><code>plot_param_importances(study_xgb)</code></pre>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/param_imp.png" style="width:90.0%" />
</center>
<p>Ap√≥s as 7.5 horas de busca, a melhor combina√ß√£o encontrada para o XGBoost foi a seguinte:</p>
<pre class="python"><code># After 7.5 hours...
study_xgb = {&#39;booster&#39;: &#39;gbtree&#39;,
 &#39;lambda&#39;: 9.012384508756378e-07,
 &#39;alpha&#39;: 0.7472040331088792,
 &#39;max_depth&#39;: 5,
 &#39;eta&#39;: 0.01507605562231303,
 &#39;gamma&#39;: 1.0214961302342215e-08,
 &#39;grow_policy&#39;: &#39;lossguide&#39;,
 &#39;min_child_weight&#39;: 5,
 &#39;subsample&#39;: 0.9331005225916879,
 &#39;colsample_bytree&#39;: 0.25392142363325004,
 &#39;max_delta_step&#39;: 5.685109389498008}</code></pre>
<p>Preparar lista de hiperpar√¢metros do XGBoost:</p>
<pre class="python"><code>final_params_xgb = dict()
final_params_xgb[&#39;clf&#39;]=dict(**fixed_params, **study_xgb)</code></pre>
</div>
<div id="stage-2-calcular-out-of-fold-shap-values" class="section level2">
<h2>Stage 2: Calcular Out-Of-Fold SHAP values</h2>
<p>Ap√≥s obter a melhor combina√ß√£o de hiperpar√¢metros para o XGBoost e encontrar resultados formid√°veis com o CatBoost modificando apenas alguns hiperpar√¢metros, resolvi tentar utilizar a informa√ß√£o adquirida pelo <em>SHAP values</em> desses modelos como entrada para novos modelos.</p>
<p>Algumas vantagens de se usar o shap values como um m√©todo de encoder dos dados, <a href="https://www.kaggle.com/pavelvod/gbm-supervised-pretraining">segundo este notebook publicado no Kaggle</a> (muito interessante por sinal):</p>
<ul>
<li>Normaliza os dados;</li>
<li>Mais ou menos Linearizado pois as <em>features</em> s√£o transformadas em suas import√¢ncias;</li>
<li>Recursos categ√≥ricos codificados de maneira mais inteligente (A codifica√ß√£o n√£o √© linear e depende de outros recursos da amostra);</li>
<li>Tratamento mais inteligente para valores <em>missing</em>.</li>
</ul>
<p>Para evitar <em>data leak</em>, o <em>SHAP values</em> foi calculado em cima dos dados <em>out-of-fold</em> para os dados de treino e a m√©dia da previs√£o de todos os <em>fold</em> nos dados de teste.</p>
<p>Definir estrat√©gia de valida√ß√£o cruzada:</p>
<pre class="python"><code>X_test = test[cat_nom+cat_ord+num_dis+num_con]
X = train[cat_nom+cat_ord+num_dis+num_con]
y = train.y

K=15 # number of bins with Sturge‚Äôs rule
SEED=123
kf = StratifiedKFold(n_splits=K, random_state=SEED, shuffle=True)</code></pre>
<div id="xgboost" class="section level3">
<h3>XGBoost</h3>
<p>Obter <em>out-of-fold</em> SHAP do modelo XGBoost tunado:</p>
<pre class="python"><code>shap1_oof = np.zeros((X.shape[0], X.shape[1]))
shap1_test = np.zeros((X_test.shape[0], X_test.shape[1]))
model_shap1_oof = np.zeros(X.shape[0])

for fold, (train_idx, val_idx) in enumerate(kf.split(X=X, y=y)):
    print(f&quot;‚ûú FOLD :{fold}&quot;)
    X_train = X.iloc[train_idx]
    y_train = y.iloc[train_idx]
    X_val = X.iloc[val_idx]
    y_val = y.iloc[val_idx]
    
    start = time.time()
    
    model = XGBClassifier(**final_params_xgb[&#39;clf&#39;])
    
    model.fit(X_train, y_train,
              eval_set=[(X_val, y_val)],
              early_stopping_rounds=150,
              verbose=False)
    
    model_shap1_oof[val_idx] += model.predict_proba(X_val)[:,1]
    
    print(&quot;Final F1     :&quot;, custom_f1(y_val, model_shap1_oof[val_idx]))
    print(&quot;Final AUC    :&quot;, roc_auc_score(y_val, model_shap1_oof[val_idx]))
    print(&quot;Final LogLoss:&quot;, log_loss(y_val, model_shap1_oof[val_idx]))

    explainer = shap.TreeExplainer(model)
    shap1_oof[val_idx] = explainer.shap_values(X_val)
    shap1_test += explainer.shap_values(X_test) / K

    print(f&quot;elapsed: {time.time()-start:.2f} sec\n&quot;)
    
shap1_oof = pd.DataFrame(shap1_oof, columns = [x+&quot;_shap1&quot; for x in X.columns])
shap1_test = pd.DataFrame(shap1_test, columns = [x+&quot;_shap1&quot; for x in X_test.columns])

print(&quot;Final F1     :&quot;, custom_f1(y, model_shap1_oof))
print(&quot;Final AUC    :&quot;, roc_auc_score(y, model_shap1_oof))
print(&quot;Final LogLoss:&quot;, log_loss(y, model_shap1_oof))</code></pre>
<pre><code>## ‚ûú FOLD :0
## Final F1     : 0.7032967032967034
## Final AUC    : 0.902330627099664
## Final LogLoss: 0.2953604946129216
## elapsed: 62.58 sec
## 
## ‚ûú FOLD :1
## Final F1     : 0.6193853427895981
## Final AUC    : 0.8613101903695408
## Final LogLoss: 0.34227429854659686
## elapsed: 45.96 sec
## 
## ‚ûú FOLD :2
## Final F1     : 0.6793478260869567
## Final AUC    : 0.8945898656215007
## Final LogLoss: 0.3085819148842589
## elapsed: 58.84 sec
## 
## ‚ûú FOLD :3
## Final F1     : 0.7073791348600509
## Final AUC    : 0.9058020716685331
## Final LogLoss: 0.2881665477053405
## elapsed: 62.24 sec
## 
## ‚ûú FOLD :4
## Final F1     : 0.7239583333333334
## Final AUC    : 0.9053121500559911
## Final LogLoss: 0.29320601468396107
## elapsed: 93.74 sec
## 
## ‚ûú FOLD :5
## Final F1     : 0.7009803921568627
## Final AUC    : 0.9076567749160134
## Final LogLoss: 0.2872539995859452
## elapsed: 73.34 sec
## 
## ‚ûú FOLD :6
## Final F1     : 0.6736292428198434
## Final AUC    : 0.8822788353863381
## Final LogLoss: 0.320014158050091
## elapsed: 55.16 sec
## 
## ‚ûú FOLD :7
## Final F1     : 0.7135416666666666
## Final AUC    : 0.9016657334826428
## Final LogLoss: 0.29617989833438774
## elapsed: 74.49 sec
## 
## ‚ûú FOLD :8
## Final F1     : 0.7135135135135134
## Final AUC    : 0.8893825776158104
## Final LogLoss: 0.29351621553572266
## elapsed: 93.71 sec
## 
## ‚ûú FOLD :9
## Final F1     : 0.7391304347826086
## Final AUC    : 0.9064054944284814
## Final LogLoss: 0.28033187155768635
## elapsed: 95.65 sec
## 
## ‚ûú FOLD :10
## Final F1     : 0.684863523573201
## Final AUC    : 0.9031046324199313
## Final LogLoss: 0.29823173886367804
## elapsed: 64.70 sec
## 
## ‚ûú FOLD :11
## Final F1     : 0.704225352112676
## Final AUC    : 0.8882052000840984
## Final LogLoss: 0.30525241732057884
## elapsed: 50.06 sec
## 
## ‚ûú FOLD :12
## Final F1     : 0.6666666666666666
## Final AUC    : 0.8905529469479291
## Final LogLoss: 0.313654842143217
## elapsed: 78.45 sec
## 
## ‚ûú FOLD :13
## Final F1     : 0.6500000000000001
## Final AUC    : 0.8745111780783517
## Final LogLoss: 0.3300786509821235
## elapsed: 59.54 sec
## 
## ‚ûú FOLD :14
## Final F1     : 0.7135416666666666
## Final AUC    : 0.9063284042329526
## Final LogLoss: 0.29314716930177404
## elapsed: 70.28 sec
## 
## Final F1     : 0.6822461331540014
## Final AUC    : 0.8945288307257988
## Final LogLoss: 0.30301717097927483</code></pre>
</div>
<div id="catboost" class="section level3">
<h3>CatBoost</h3>
<p>Obter <em>out-of-fold</em> SHAP do modelo CatBoost + features extrat√≠das via KNN:</p>
<pre class="python"><code>X = pd.concat([X, knn_feat_train], axis=1)
X_test = pd.concat([X_test, knn_feat_test], axis=1)</code></pre>
<pre class="python"><code>shap2_oof = np.zeros((X.shape[0], X.shape[1]))
shap2_test = np.zeros((X_test.shape[0], X_test.shape[1]))
model_shap2_oof = np.zeros(X.shape[0])

for fold, (train_idx, val_idx) in enumerate(kf.split(X=X, y=y)):
    print(f&quot;‚ûú FOLD :{fold}&quot;)
    X_train = X.iloc[train_idx]
    y_train = y.iloc[train_idx]
    X_val = X.iloc[val_idx]
    y_val = y.iloc[val_idx]
    
    start = time.time()
    
    model = CatBoostClassifier(random_seed=SEED,
                               verbose = 0,
                               n_estimators=10000,
                               loss_function= &#39;Logloss&#39;,
                               use_best_model=True,
                               eval_metric= &#39;Logloss&#39;)
    
    model.fit(X_train, y_train, 
              eval_set = [(X_val,y_val)], 
              early_stopping_rounds = 100,
              verbose = False)
    
    model_shap2_oof[val_idx] += model.predict_proba(X_val)[:,1]
    
    print(&quot;Final F1     :&quot;, custom_f1(y_val, model_shap2_oof[val_idx]))
    print(&quot;Final AUC    :&quot;, roc_auc_score(y_val, model_shap2_oof[val_idx]))
    print(&quot;Final LogLoss:&quot;, log_loss(y_val, model_shap2_oof[val_idx]))

    explainer = shap.TreeExplainer(model)
    shap2_oof[val_idx] = explainer.shap_values(X_val)
    shap2_test += explainer.shap_values(X_test) / K

    print(f&quot;elapsed: {time.time()-start:.2f} sec\n&quot;)
    
shap2_oof = pd.DataFrame(shap2_oof, columns = [x+&quot;_shap&quot; for x in X.columns])
shap2_test = pd.DataFrame(shap2_test, columns = [x+&quot;_shap&quot; for x in X_test.columns])

print(&quot;Final F1     :&quot;, custom_f1(y, model_shap2_oof))
print(&quot;Final AUC    :&quot;, roc_auc_score(y, model_shap2_oof))
print(&quot;Final LogLoss:&quot;, log_loss(y, model_shap2_oof))</code></pre>
<pre><code>## ‚ûú FOLD :0
## Final F1     : 0.6972010178117048
## Final AUC    : 0.8954157334826428
## Final LogLoss: 0.29952314366911725
## elapsed: 22.84 sec
## 
## ‚ûú FOLD :1
## Final F1     : 0.6348448687350835
## Final AUC    : 0.8628429451287795
## Final LogLoss: 0.3407490151943705
## elapsed: 12.59 sec
## 
## ‚ûú FOLD :2
## Final F1     : 0.6809651474530831
## Final AUC    : 0.8949538073908175
## Final LogLoss: 0.3066089330852162
## elapsed: 18.03 sec
## 
## ‚ûú FOLD :3
## Final F1     : 0.702247191011236
## Final AUC    : 0.9107992721164613
## Final LogLoss: 0.2877216893570601
## elapsed: 15.66 sec
## 
## ‚ûú FOLD :4
## Final F1     : 0.7131367292225201
## Final AUC    : 0.9018687010078387
## Final LogLoss: 0.2976481761596595
## elapsed: 29.35 sec
## 
## ‚ûú FOLD :5
## Final F1     : 0.7055837563451777
## Final AUC    : 0.909231522956327
## Final LogLoss: 0.28834373773423566
## elapsed: 15.35 sec
## 
## ‚ûú FOLD :6
## Final F1     : 0.6631578947368421
## Final AUC    : 0.8796402575587906
## Final LogLoss: 0.32303153676573987
## elapsed: 19.13 sec
## 
## ‚ûú FOLD :7
## Final F1     : 0.6997389033942559
## Final AUC    : 0.901637737961926
## Final LogLoss: 0.2985978485411335
## elapsed: 23.30 sec
## 
## ‚ûú FOLD :8
## Final F1     : 0.6965699208443271
## Final AUC    : 0.8825565912117177
## Final LogLoss: 0.3009859242847037
## elapsed: 20.19 sec
## 
## ‚ûú FOLD :9
## Final F1     : 0.7435897435897436
## Final AUC    : 0.9042469689536757
## Final LogLoss: 0.28276851015512977
## elapsed: 24.39 sec
## 
## ‚ûú FOLD :10
## Final F1     : 0.6767676767676767
## Final AUC    : 0.902712173242694
## Final LogLoss: 0.29999812838692497
## elapsed: 16.14 sec
## 
## ‚ûú FOLD :11
## Final F1     : 0.7013698630136986
## Final AUC    : 0.8865022075828719
## Final LogLoss: 0.3081393413008847
## elapsed: 13.50 sec
## 
## ‚ûú FOLD :12
## Final F1     : 0.6630434782608696
## Final AUC    : 0.8920456934613498
## Final LogLoss: 0.31338640296724246
## elapsed: 24.48 sec
## 
## ‚ûú FOLD :13
## Final F1     : 0.6485148514851485
## Final AUC    : 0.8689887167986544
## Final LogLoss: 0.3369797070301582
## elapsed: 17.17 sec
## 
## ‚ûú FOLD :14
## Final F1     : 0.7108753315649867
## Final AUC    : 0.8994743850304856
## Final LogLoss: 0.301420230674656
## elapsed: 16.51 sec
## 
## Final F1     : 0.6823234134098244
## Final AUC    : 0.892656043550729
## Final LogLoss: 0.305726567456891</code></pre>
<pre class="python"><code>train = pd.concat([train, shap1_oof], axis=1)
test = pd.concat([test, shap1_test], axis=1)

train = pd.concat([train, shap2_oof], axis=1)
test = pd.concat([test, shap2_test], axis=1)</code></pre>
</div>
</div>
<div id="stage-3-modelo-final-com-autogluon" class="section level2">
<h2>Stage 3: Modelo Final com AutoGluon</h2>
<p>AutoGluon √© um <a href="https://github.com/awslabs/autogluon">AutoML desenvolvido pela Amazon</a> muito f√°cil de utilizar (no melhor estilo <code>sklearn</code> com m√©todos <code>.fit()</code> e <code>.predict()</code>).</p>
<p>Principais Informa√ß√µes üìå :</p>
<ul>
<li>Inputs: Dataset original + knn features + Shapt values do XGBoost tunado e do CatBoost;</li>
<li>Loss do XGBoost: Log Loss;</li>
<li>Loss do CatBoost: AUC;</li>
<li>Loss do AutoGluon: Log Loss;</li>
<li>Tempo de processamento: 7h30m</li>
</ul>
<div class="w3-panel w3-pale-green w3-border">
<p><strong>üí° Insight</strong> <br></p>
<p>Um recurso muito √∫til do AutoGluon √© poder acessar as previs√µes out-of-folds, o que facilita no c√°lculo do <em>threshold</em> que maximiza a <em>F1 Score</em>.</p>
</div>
<pre class="python"><code>predictor = TabularPredictor(label=&quot;y&quot;,
                             problem_type=&#39;binary&#39;,
                             eval_metric=&quot;log_loss&quot;,
                             path=&#39;./AutoGlon/&#39;,
                             verbosity=1)

predictor.fit(train, presets=&#39;best_quality&#39;, time_limit=60*60*7.5) 

results = predictor.fit_summary()</code></pre>
<pre><code>## *** Summary of fit() ***
## Estimated performance of each model:
##                       model  score_val  pred_time_val      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
## 0       WeightedEnsemble_L2  -0.299310      30.410467   8888.826963                0.001654           2.456810            2       True         14
## 1           CatBoost_BAG_L1  -0.301038       3.051793   2376.887100                3.051793        2376.887100            1       True          7
## 2       WeightedEnsemble_L3  -0.301722     194.034947  22907.669139                0.001541           2.008858            3       True         26
## 3         LightGBMXT_BAG_L2  -0.302135     131.534432  17201.299530                1.378576         389.400378            2       True         15
## 4         LightGBMXT_BAG_L1  -0.302562       3.570399    969.385833                3.570399         969.385833            1       True          3
## 5           CatBoost_BAG_L2  -0.302646     131.912474  17619.939451                1.756617         808.040299            2       True         19
## 6           LightGBM_BAG_L2  -0.303002     131.422007  17281.518763                1.266150         469.619612            2       True         16
## 7           LightGBM_BAG_L1  -0.303264       2.964433   1038.037160                2.964433        1038.037160            1       True          4
## 8            XGBoost_BAG_L1  -0.303471       4.475003   2036.551052                4.475003        2036.551052            1       True         11
## 9    NeuralNetFastAI_BAG_L1  -0.304455      19.917584   3434.894841               19.917584        3434.894841            1       True         10
## 10           XGBoost_BAG_L2  -0.304499     132.757505  17834.135370                2.601648        1022.236218            2       True         23
## 11   NeuralNetFastAI_BAG_L2  -0.306339     142.018741  18777.287244               11.862885        1965.388093            2       True         22
## 12     LightGBMLarge_BAG_L2  -0.306606     131.701429  18260.504603                1.545573        1448.605452            2       True         25
## 13    NeuralNetMXNet_BAG_L2  -0.308237     177.769179  19273.211899               47.613322        2461.312748            2       True         24
## 14     LightGBMLarge_BAG_L1  -0.309686       3.042399   2629.185346                3.042399        2629.185346            1       True         13
## 15    ExtraTreesEntr_BAG_L2  -0.314045     132.017535  16815.886061                1.861679           3.986910            2       True         21
## 16  RandomForestEntr_BAG_L2  -0.314454     132.061970  16843.769642                1.906114          31.870490            2       True         18
## 17    ExtraTreesGini_BAG_L2  -0.314960     132.123651  16816.087081                1.967794           4.187930            2       True         20
## 18    NeuralNetMXNet_BAG_L1  -0.317156      81.677096   4258.886806               81.677096        4258.886806            1       True         12
## 19  RandomForestGini_BAG_L2  -0.321702     132.035970  16835.326491                1.880114          23.427339            2       True         17
## 20    ExtraTreesEntr_BAG_L1  -0.323283       1.794093      4.051307                1.794093           4.051307            1       True          9
## 21  RandomForestEntr_BAG_L1  -0.324296       1.966043     33.380685                1.966043          33.380685            1       True          6
## 22    ExtraTreesGini_BAG_L1  -0.325897       1.796291      3.748723                1.796291           3.748723            1       True          8
## 23  RandomForestGini_BAG_L1  -0.328218       1.778995     22.705248                1.778995          22.705248            1       True          5
## 24    KNeighborsDist_BAG_L1  -1.070156       2.010938      2.075571                2.010938           2.075571            1       True          2
## 25    KNeighborsUnif_BAG_L1  -1.071373       2.110790      2.109480                2.110790           2.109480            1       True          1
## Number of models trained: 26
## Types of models trained:
## {&#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_NNFastAiTabular&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_XGBoost&#39;, &#39;StackerEnsembleModel_CatBoost&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_XT&#39;, &#39;StackerEnsembleModel_TabularNeuralNet&#39;}
## Bagging used: True  (with 10 folds)
## Multi-layer stack-ensembling used: True  (with 3 levels)
## Feature Metadata (Processed):
## (raw dtype, special dtypes):
## (&#39;float&#39;, [])     : 152 | [&#39;var55&#39;, &#39;var56&#39;, &#39;var57&#39;, &#39;var58&#39;, &#39;var59&#39;, ...]
## (&#39;int&#39;, [])       :  48 | [&#39;var1&#39;, &#39;var2&#39;, &#39;var3&#39;, &#39;var4&#39;, &#39;var5&#39;, ...]
## (&#39;int&#39;, [&#39;bool&#39;]) :   6 | [&#39;var27&#39;, &#39;var31&#39;, &#39;var44&#39;, &#39;var49&#39;, &#39;var50&#39;, ...]
## Plot summary of models saved to file: ./AutoGlon/SummaryOfModels.html
## *** End of fit() summary ***</code></pre>
<p>Nota: Os resultados podem variar devido √† natureza estoc√°stica do algoritmo ou procedimento de avalia√ß√£o.</p>
<pre class="python"><code># get final predictions
y_oof = predictor.get_oof_pred_proba().iloc[:,1]
y_pred = predictor.predict_proba(test).iloc[:,1]</code></pre>
<pre class="python"><code>final_threshold = get_threshold(train.y, y_oof)
final_threshold</code></pre>
<pre><code>## 0.31</code></pre>
<pre class="python"><code>print(&quot;Final F1     :&quot;, custom_f1(y, y_oof))
print(&quot;Final AUC    :&quot;, roc_auc_score(y, y_oof))
print(&quot;Final LogLoss:&quot;, log_loss(y, y_oof))</code></pre>
<pre><code>## Final F1     : 0.6846193682030037
## Final AUC    : 0.8961328807692966
## Final LogLoss: 0.2993098559321765</code></pre>
<p>Ap√≥s submiss√£o:</p>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/final_sub.png" style="width:90.0%" />
</center>
</div>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o</h1>
<p>Gostaria de agradecer imensamente ao time do Porto Seguro pela iniciativa, pois esse tipo de competi√ß√£o (t√£o detalhada e desafiadora) n√£o tem sido muito comum no Brasil e √© muito importante para fomentar a comunidade brasileira de ci√™ncia de dados!</p>
<p>Sabemos que o ‚Äúmundo real‚Äù √© diferente do mundo das competi√ß√µes (onde buscamos o melhor score a todo custo) por√©m, na minha vis√£o, n√£o deixa de ser um √≥timo exerc√≠cio para treinar o racioc√≠nio anal√≠tico.. al√©m de ser muito empolgante e divertido!</p>
<p>Tive o enorme prazer de trocar id√©ias e conhecer pessoas fora da curva bem como me tornar f√£ de alguns competidores! A cada semana q passava o n√≠vel estava cada vez mais alto!</p>
<p>Com certeza este pipeline poderia ser muito melhor, sinto que poderia ter gasto mais tempo com <em>feature engineering</em> e tido mais paciencia com alguns modelos. Tentei fazer o melhor que pude com o tempo dispon√≠vel e me sinto muito grato pela experi√™ncia de apresentar os resultados e aprender bastante com a solu√ß√£o dos top colocados.</p>
<p>N√£o acaba por aqui! Agora √© hora de voltar aos estudos, continuar praticando com as <a href="https://www.kaggle.com/c/tabular-playground-series-nov-2021/overview">TPS‚Äôs do Kaggle</a> e, quem sabe, ir melhor na pr√≥xima!</p>
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias</h1>
<ul>
<li><a href="https://github.com/momijiame/gokinjo" class="uri">https://github.com/momijiame/gokinjo</a></li>
<li><a href="https://www.kaggle.com/melanie7744/tps6-boost-your-score-with-knn-features" class="uri">https://www.kaggle.com/melanie7744/tps6-boost-your-score-with-knn-features</a></li>
<li><a href="https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335" class="uri">https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335</a></li>
<li><a href="https://www.kaggle.com/pavelvod/gbm-supervised-pretraining" class="uri">https://www.kaggle.com/pavelvod/gbm-supervised-pretraining</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-11-01-solucao-final-porto-seguro-data-challenge/">Solu√ß√£o Final - Porto Seguro Data Challenge [3¬∫ lugar]</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">catboost</category>
      <category domain="tag">data-science</category>
      <category domain="tag">kaggle</category>
      <category domain="tag">knn</category>
      <category domain="tag">machine-learning</category>
      <category domain="tag">optuna</category>
      <category domain="tag">pratica</category>
      <category domain="tag">python</category>
      <category domain="tag">shap</category>
      <category domain="tag">threshold-movel</category>
    </item>
    <item>
      <title>Prevendo a qualidade do sono utilizando Machine Learning</title>
      <link>https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/</guid>
      <description>Utilizaremos dados reais coletados pelo celular para gerar previs√µes a partir de uma pequena base de dados com target desbalanceada</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#qualidade-de-sono" id="toc-qualidade-de-sono">Qualidade de sono? ü§®</a></li>
<li><a href="#como-funciona-aplicativo-sleep-cycle" id="toc-como-funciona-aplicativo-sleep-cycle">Como funciona aplicativo Sleep Cycle? <img src="https://www.sleepcycle.com/wp-content/uploads/2020/09/sleep_cycle_app_icon-480x480.png" style="width:3.0%" /></a></li>
<li><a href="#objetivo" id="toc-objetivo">Objetivo üéØ</a></li>
<li><a href="#explorar-dados" id="toc-explorar-dados">Explorar dados üîé</a>
<ul>
<li><a href="#limpeza-e-prepara%C3%A7%C3%A3o-dos-dados" id="toc-limpeza-e-prepara√ß√£o-dos-dados">Limpeza e prepara√ß√£o dos dados</a></li>
<li><a href="#imputar-dados-de-fontes-externas" id="toc-imputar-dados-de-fontes-externas">Imputar dados de fontes externas</a></li>
<li><a href="#insights" id="toc-insights">Insights</a></li>
<li><a href="#reter-dados" id="toc-reter-dados">Reter dados</a></li>
</ul></li>
<li><a href="#modelagem" id="toc-modelagem">Modelagem üöÄ</a>
<ul>
<li><a href="#amostragem" id="toc-amostragem">Amostragem</a></li>
<li><a href="#engenharia-de-recursos" id="toc-engenharia-de-recursos">Engenharia de recursos</a></li>
<li><a href="#modelo-nulo-baseline" id="toc-modelo-nulo-baseline">Modelo Nulo (Baseline)</a></li>
<li><a href="#%C3%A1rvore-de-decis%C3%B5es" id="toc-√°rvore-de-decis√µes">√Årvore de decis√µes</a></li>
<li><a href="#random-forest" id="toc-random-forest">Random Forest</a></li>
<li><a href="#lightgbm" id="toc-lightgbm">LightGBM</a></li>
</ul></li>
<li><a href="#sele%C3%A7%C3%A3o-do-modelo" id="toc-sele√ß√£o-do-modelo">Sele√ß√£o do modelo ü§î</a></li>
<li><a href="#previs%C3%A3o-em-dados-novos" id="toc-previs√£o-em-dados-novos">Previs√£o em dados novos üí´</a></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o üçª</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias üß≥</a></li>
</ul>
</div>

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 33%;
padding: 10px;
}

.column8 {
float: left;
width: 66%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>
<div id="qualidade-de-sono" class="section level1">
<h1>Qualidade de sono? ü§®</h1>
<p>Sim, exatamente! Neste post analisaremos dados de um <em>tracking</em> que venho fazendo desde 2017 com informa√ß√µes relacionadas √† um sono de qualidade.</p>
<div class="row">
<div class="column8">
<p>Boas noites de sono nos tornam mais felizes, mais saud√°veis, mais inteligentes, mais dispostos e evita problemas de cansa√ßo, falta de concentra√ß√£o, depress√£o e ansiedade.</p>
<p>Resumindo, a nossa qualidade de vida est√° diretamente ligada √† qualidade do nosso sono, pois ao dormir nosso corpo realiza fun√ß√µes extremamente importantes como por exemplo o fortalecimento do sistema imunol√≥gico, secre√ß√£o e libera√ß√£o de horm√¥nios, consolida√ß√£o da mem√≥ria, entre outras<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
</div>
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/mguPrVJAnEHIY/giphy.gif" alt="Via Giphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/mguPrVJAnEHIY/giphy.gif">Via Giphy</a></div>
</div>
</div>
</div>
<p>Alguns fatores podem auxiliar a determinar se uma noite foi bem dormida como por exemplo: a regularidade do hor√°rio de dormir e de acordar, a frequ√™ncia card√≠aca (bpm), n√∫mero de passos dados no dia, tempo na cama, tempo antes de dormir, ronco, tipo de clima etc..</p>
<div class="row">
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/xUPJPlFxssGpmLemru/giphy.gif" style="width:80.0%" alt="Via Gyiphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/xUPJPlFxssGpmLemru/giphy.gif">Via Gyiphy</a></div>
</div>
</div>
<div class="column8">
<p>Felizmente, existe um aplicativo chamado <a href="sleepcycle.com/">Sleep Cycle</a> que √© capaz de <em>trackear</em> todas essas informa√ß√µes durante o uso do app, dentre outras funcionalidades. Desde 2017 tenho acompanhado meu sono atrav√©s dele, principalmente pela funcionalidade de <a href="https://www.sleepcycle.com/how-sleep-cycle-works/">rastreio dos padr√µes de sono para despertar durante sua fase mais leve, sem um despertador convencional</a> e tenho curtido bastante!</p>
</div>
</div>
<p>A proposta principal do aplicativo √© monitorar os sinais do corpo para nos despertar suavemente quando estivermos no est√°gio de sono mais leve poss√≠vel, pois acordar durante o sono leve √© como acordar naturalmente descansado!</p>
</div>
<div id="como-funciona-aplicativo-sleep-cycle" class="section level1">
<h1>Como funciona aplicativo Sleep Cycle? <img src="https://www.sleepcycle.com/wp-content/uploads/2020/09/sleep_cycle_app_icon-480x480.png" style="width:3.0%" /></h1>
<p><small>Tradu√ß√£o livre de <a href="https://www.sleepcycle.com/how-sleep-cycle-works/"><em>How Sleep Cycle works</em></a>:</small></p>
<p>‚ÄúO funcionamento b√°sico desse aplicativo se baseia que nos mexemos predominantemente durante o sono leve. J√° durante o sono pesado, os m√∫sculos tendem a permanecer relaxados, e em sono REM a movimenta√ß√£o muscular abaixo do pesco√ßo fica paralizada.</p>
<p>Assim sendo √© poss√≠vel selecionar um hor√°rio que gostaria de acordar, como de 6:30 at√© 7:00, e o aplicativo rastrear√° os movimentos na cama para acordar apenas quando entrar em sono leve durnte este per√≠odo.</p>
<p>Dessa forma, estar√≠amos aumentando as chances de acordar mais bem-disposto, j√° que seu sono foi interrompido em uma fase mais leve de descanso.‚Äù</p>
<p>Vejamos dois gr√°ficos que exemplificam dois dos poss√≠veis cen√°rios de uma noite de sono:</p>
<div class="row">
<div class="column">
<center>
<strong>Exemplo 1 - sono regular</strong>
<img src="https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_regular_sleep.png" style="width:80.0%" alt="via SleepCycle.com" />
</br>
<small>Os picos representam os ciclos do sono, incluindo todas as fases do sono.</small>
</center>
</div>
<div class="column">
<center>
<strong>Exemplo 2 - sono irregular</strong>
<img src="https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_irregular_sleep.png" style="width:80.0%" alt="via SleepCycle.com" />
</br>
<small>Ciclos de sono mais irregulares, onde o usu√°rio provavelmente n√£o dormiu t√£o bem como em nosso primeiro exemplo.</small>
</center>
</div>
</div>
<p>Esta √© a principal informa√ß√£o coletada no aplicativo e que permite um ‚Äúdespertar tranquilo‚Äù!</p>
<!-- Agora que j√° entendemos as benef√≠cios de uma noite bem dormida, de onde v√™m os dados, como o app funciona e quantas horas proporcionam uma boa noite de sono, vamos direto ao objetivo deste post! -->
</div>
<div id="objetivo" class="section level1">
<h1>Objetivo üéØ</h1>
<p>Apesar do aplicativo captar diversos dados sobre a noite de sono, o ‚Äúhumor ao acordar‚Äù √© uma informa√ß√£o fornecida pelo usu√°rio assim que desativa o alarme, quando a seguinte tela √© exibida:</p>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/mood.jpg" style="width:80%;">
</center>
<p>Como houveram diversos dias em que utilizei o aplicativo mas n√£o assinalei o humor (seja por ter desativado o recurso por algum tempo ou simplesmente por ter ignorado üòÖ) vamos trabalhar para responder a seguinte pergunta:</p>
<blockquote>
<p>Qual foi a probabilidade de ter acordado de <strong>mal humor</strong> durante o per√≠odo de <em>tracking</em> do app, nos dias cujo esse dado √© faltante?</p>
</blockquote>
<p>Onde <strong>mal humor</strong> ser√° a classe positiva da <strong>target</strong>, traduzido nos dados da seguinte forma:</p>
<p><span class="math display">\[
mood=
\begin{cases}
Bom, &amp; \text{se}\  mood = Bom \\
Ruim, &amp; \text{c.c}\
\end{cases}
\]</span></p>
<p>Logo, <code>mood</code> ser√° bin√°ria, avaliando se o humor foi <code>Bom</code> ou <code>Ruim</code> ao acordar, onde <code>Ruim</code> a combina√ß√£o do status üòë (Ok) e üò° (Mau) e ser√° a classe mais importante para controlar os erros de previs√£o.</p>
<p>Tomei a liberdade de fazer essa transforma√ß√£o pois desde o in√≠cio do uso do app, marco como <code>Ruim</code> apenas quando realmente n√£o descansei de forma satisfat√≥ria. Isso pode ter ocorrido por diversos fatores, como por exemplo: acordar ap√≥s um pesadelo; acordar com barulho da rua ou de casa; acordar meio doente ou passando mal e por ai vai..</p>
<p>Por enquanto, estas informa√ß√µes ser√£o suficientes. Vejamos na an√°lise explorat√≥ria como se apresenta a vari√°vel target e quais dados dispon√≠veis para atingir tal objetivo.</p>
</div>
<div id="explorar-dados" class="section level1">
<h1>Explorar dados üîé</h1>
<p>Carregar as depend√™ncias:</p>
<pre class="r"><code>library(tidyverse)  # datascience toolkit 
library(lubridate)  # manipule date
library(patchwork)  # grid ggplot
library(tidymodels) # machine learning toolkit
library(reactable)  # print tables 
library(treesnip)   # lightgbm

# Definir tema para ggplot
theme_set(theme_bw()) </code></pre>
<p>Vamos carregar fun√ß√µes que foram desenvolvidas ao longo das an√°lises para facilitar tanto na apresenta√ß√£o dos resultados quanto na portabilidade dos c√≥digos (bastando pequenos ajustes para ‚Äúrecicl√°-los‚Äù ‚ôªÔ∏è):</p>
<details>
<summary>
(<em>Clique aqui para exibir as fun√ß√µes customizadas</em>)
</summary>
<pre class="r"><code># Para o print de tabelas
print_table &lt;- function(x, round=0, evalue_model = F, ...){ 
  
  if(round&gt;0) x &lt;- x %&gt;% mutate_if(is.numeric, ~round(.x, round))
  
  if(evalue_model == T){
    
    reactable::reactable(x, striped = T, bordered = T, 
                         highlight = T, pagination = F,
                         width = 800,
                         defaultColDef = colDef(minWidth = 85),
                         defaultSorted = list(auc_pr = &quot;desc&quot;),
                         columns = list(
                           model = colDef(minWidth = 110),
                           tp = colDef(minWidth = 40),
                           fp = colDef(minWidth = 40),
                           fn = colDef(minWidth = 40),
                           tn = colDef(minWidth = 40)),
                         ...)  
    
  }else{
    reactable::reactable(x, striped = T, bordered = T, width = 800,
                         highlight = T, pagination = F, ...)  
  }
  
  
}

# Graficos de features numericas
plot_num &lt;- function(data, num_feature, 
                     title = NULL, bins = 30, legend = NULL){
  
  if(is.null(title)) title = num_feature
  
  data = data %&gt;% filter(!is.na(mood))
  
  p_shapiro = round(shapiro.test(data$air_pressure_pa)$p.value, 5)
  
  p1 &lt;- 
    data %&gt;% 
    ggplot(aes_string(x = num_feature, fill = &quot;mood&quot;))+
    geom_histogram(aes(y=..density..), bins = bins, alpha = 0.5,
                   show.legend = ifelse(!is.null(legend), T, F))+
    geom_density(alpha = 0.5,
                 show.legend = ifelse(!is.null(legend), T, F))+
    labs(y = &quot;&quot;, x= &quot;&quot;, title = title)+
    scale_fill_viridis_d(end = 0.8, direction = 1)
  
  if(!is.null(legend)){
    p1 = p1 + theme(legend.position = legend)
  }
  
  p2 &lt;- 
    data %&gt;% 
    ggplot(aes_string(x = num_feature))+
    geom_boxplot(aes(y = &quot;&quot;, color = mood), 
                 show.legend = F)+
    labs(y = &quot;&quot;, x= &quot;&quot;, 
         caption = paste0(&quot;Shapiro-Wilk normality test: &quot;,
                          ifelse(p_shapiro == 0, &quot;P&lt;0.05&quot;, p_shapiro) ))+
    scale_color_viridis_d(end = 0.8, direction = 1)
  
  p1 / p2  + plot_layout(heights = c(4/5, 1/5))
}  

# Graficos de features categoricas
plot_cat &lt;- function(data, cat_feature, title = NULL, label = TRUE, legend = NULL){
  
  data = data %&gt;% filter(!is.na(mood))
  
  valor_p = round(chisq.test(data %&gt;% pull(cat_feature), 
                             data$mood, 
                             simulate.p.value = T)$p.value, 5)
  
  to_plot = data %&gt;%
    count(!!as.name(cat_feature), mood) %&gt;% 
    group_by(!!as.name(cat_feature)) 
  
  final_plot = to_plot %&gt;% 
    mutate(prop = n/sum(n),
           lab = paste0(round(prop*100, 2), &quot;%&quot;)) %&gt;% 
    ggplot()+
    geom_bar(aes_string(x = cat_feature, y = &quot;n&quot;, fill = &quot;mood&quot;),
             stat = &quot;identity&quot;, alpha = 0.7, 
             position = position_dodge2(0.9),
             show.legend = ifelse(!is.null(legend), T, F))+
    scale_fill_viridis_d(end = 0.8, direction = 1)+
    labs(title = title, y = &quot;&quot;,
         caption = paste0(&quot;Pearson&#39;s Chi-squared test: &quot;, valor_p))
  
  if(label == TRUE){
    final_plot = final_plot+
      geom_label(aes_string(x = cat_feature, y = &quot;n&quot;, label = &quot;lab&quot;),
                 position = position_dodge2(0.9), show.legend = F)  
  }
  
  if(!is.null(legend)){
    final_plot = final_plot + theme(legend.position = legend)
  }
  
  return(final_plot)
  
}

# Grafico interativo de features temporais
plot_dygraph &lt;- function(x, order.by, feature, title = NULL){
  x %&gt;%  
    xts::xts(order.by = order.by) %&gt;% 
    .[,feature] %&gt;%
    dygraphs::dygraph(main = title) %&gt;% 
    dygraphs::dyRangeSelector()
}

# Calcula o ponto de corte que maximiza a funcao f beta
threshold_max &lt;- function(x){
  
  fbeta &lt;- function(precision, recall){ 
    (beta+1)*(precision*recall)/(beta*(precision+recall))
  }
  
  # https://machinelearningmastery.com/fbeta-measure-for-machine-learning/
  # F05: + precision - recall
  # F1 : + precision + recall
  # F2 : - precision + recall 
  beta = 0.5
  
  x  %&gt;%
    pr_curve(mood, .pred_Ruim) %&gt;% 
    mutate(fbeta = fbeta(precision, recall) ) %&gt;% 
    filter(fbeta == max(fbeta, na.rm = T))
}

# Plot da matriz de confusao e da funcao das funcoes de densidade estimadas
conf_mat_plot &lt;- function(x, null_model = FALSE){
  trs &lt;- threshold_max(x)$.threshold
  
  if(null_model==FALSE){
    x &lt;- x %&gt;% 
      mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs, &quot;Ruim&quot;, &quot;Bom&quot;) %&gt;%
               factor(levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE))  
  }
  
  p1 &lt;- 
    x %&gt;%
    select(.pred_class, mood) %&gt;%
    table() %&gt;% 
    conf_mat() %&gt;% 
    autoplot(type = &quot;heatmap&quot;)+
    labs(title = &quot;Matriz de Confusao&quot;,
         subtitle = paste0(&quot;Threshold max F0.5: &quot;, round(trs, 4)))
  
  p2 &lt;- 
    x  %&gt;%
    ggplot() +
    geom_density(aes(x = .pred_Ruim, fill = mood), 
                 alpha = 0.5)+
    labs(title = &quot;Distribui√ß√µes de probabilidade previstas&quot;,
         subtitle = &quot;por classe&quot;)+ 
    scale_x_continuous(limits = 0:1)+
    geom_vline(aes(xintercept = trs, color = &quot;threshold max F0.5&quot;), linetype = 2) +
    scale_color_manual(name = &quot;&quot;, values = c(`threshold max F0.5` =  &quot;red&quot;))+
    scale_fill_viridis_d(end = 0.7, direction = 1)
  
  p1 | p2
} 

# Conjunto de metricas utilizadas para avaliar os modelos
evalue_model &lt;- function(x, model = &quot;&quot;, null_model=FALSE){
  
  trs &lt;- threshold_max(x)$.threshold
  
  if(null_model==FALSE){
    x &lt;- x %&gt;%
      mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs, &quot;Ruim&quot;, &quot;Bom&quot;) %&gt;% 
               factor(levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE))
  }
  
  cm &lt;- x %&gt;% 
    select(.pred_class, mood) %&gt;% 
    table() 
  
  tibble(
    model = model,
    tp = cm[1,1],
    fp = cm[1,2],
    fn = cm[2,1],
    tn = cm[2,2],
    auc_roc   = yardstick::roc_auc(x, mood, `.pred_Ruim`)$.estimate,
    auc_pr    = yardstick::pr_auc(x, mood, `.pred_Ruim`)$.estimate,
    logloss   = yardstick::mn_log_loss_vec(x$mood, x$.pred_Ruim),
    f1        = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 1),
    f05       = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 0.5),
    f2        = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 2),
    precision = yardstick::precision_vec(x$mood, x$.pred_class),
    recall    = yardstick::recall_vec(x$mood, x$.pred_class),
    trs_fbeta = trs
  ) 
}  

plot_auc &lt;- function(x){
  
  p1 &lt;-  
    x %&gt;% 
    group_by(model) %&gt;%
    roc_curve(mood, .pred_Ruim) %&gt;%
    ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
    geom_line(size = 1, alpha = 0.5, show.legend = F) +
    geom_abline(lty = 2, alpha = 0.5, color = &quot;gray50&quot;, size = 1.3)+
    labs(title = &quot;AUC&quot;)+
    scale_color_viridis_d(direction = 1)
  
  p2 &lt;- 
    x %&gt;%
    group_by(model) %&gt;%
    pr_curve(mood, .pred_Ruim) %&gt;%
    ggplot(aes(x = recall, y = precision, color = model)) +
    geom_line(size = 1.15, alpha = 0.5) +
    # geom_abline(slope = -1, intercept = 1, lty = 2, alpha = 0.5, color = &quot;gray50&quot;, size = 1.2)+
    labs(title = &quot;PR AUC&quot;)+
    theme(legend.position = &quot;right&quot;)+
    scale_color_viridis_d(direction = 1)
  
  (p1 | p2)
}</code></pre>
</details>
<p>¬†</p>
<p>Importar os dados obtidos no app <a href="https://www.sleepcycle.com/">SleepCycle</a> e padronizar nomes das colunas:</p>
<pre class="r"><code>sleep &lt;- read_csv2(&quot;sleepdata.csv&quot;) %&gt;% janitor::clean_names(case = &quot;snake&quot;)</code></pre>
<p>A seguir, uma tabela com uma descri√ß√£o do conte√∫do de cada coluna:</p>
<table>
<colgroup>
<col width="9%" />
<col width="11%" />
<col width="79%" />
</colgroup>
<thead>
<tr class="header">
<th>Coluna</th>
<th>Descri√ß√£o curta</th>
<th>Descri√ß√£o detalhada</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>start</strong></td>
<td>In√≠cio</td>
<td>In√≠cio do monitoramento</td>
</tr>
<tr class="even">
<td><strong>end</strong></td>
<td>Fim</td>
<td>Fim do monitoramento</td>
</tr>
<tr class="odd">
<td><strong>sleep_quality</strong></td>
<td>Qualidade do Sono</td>
<td>Qualidade do sono √© baseada em: tempo que passa a dormir, movimentos durante a noite e momentos em que est√° totalmente desperto</td>
</tr>
<tr class="even">
<td><strong>regularity</strong></td>
<td>Regularidade</td>
<td>Informa sobre a regularidade do hor√°rio de dormir e de acordar durante um per√≠odo de tempo. Quanto maior, mais regular tem sido o hor√°rio de acordar e dormir e isso pode resultar em um sono melhor</td>
</tr>
<tr class="odd">
<td><strong>mood</strong> üéØ</td>
<td>Humor</td>
<td>Humor informado no app ao acordar: üòÉ (Bom), üòë (Ok), üò° (Mau), ‚õî (N√£o informado)</td>
</tr>
<tr class="even">
<td><strong>heart_rate_bpm</strong></td>
<td>Frequ√™ncia card√≠aca (bpm)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>steps</strong></td>
<td>Passos</td>
<td>Quantos passos d√° por dia (bom a partir de 10.000 passos por dia)</td>
</tr>
<tr class="even">
<td><strong>alarm_mode</strong></td>
<td>Modo de alarme</td>
<td>Alarme ligado ou apenas monitoramento</td>
</tr>
<tr class="odd">
<td><strong>air_pressure_pa</strong></td>
<td>Press√£o do Ar (Pa)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>city</strong></td>
<td>Cidade</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>movements_per_hour</strong></td>
<td>Movimentos por hora</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>time_in_bed_seconds</strong></td>
<td>Tempo na cama (segundos)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>time_asleep_seconds</strong></td>
<td>Tempo adormecido (segundos)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>time_before_sleep_seconds</strong></td>
<td>Tempo antes de dormir (segundos)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>window_start</strong></td>
<td>In√≠cio da janela</td>
<td>In√≠cio do modo soneca</td>
</tr>
<tr class="even">
<td><strong>window_stop</strong></td>
<td>Fim da janela</td>
<td>Fim do modo soneca</td>
</tr>
<tr class="odd">
<td><strong>did_snore</strong></td>
<td>Ronco</td>
<td>Detector de ru√≠dos (pode captar outros barulhos que n√£o seja ronco)</td>
</tr>
<tr class="even">
<td><strong>snore_time</strong></td>
<td>Hora do ronco</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>weather_temperature_c</strong></td>
<td>Temperatura (¬∞C)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>weather_type</strong></td>
<td>Tipo de clima</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>notes</strong></td>
<td>Notas</td>
<td>Alguma nota ao acordar</td>
</tr>
</tbody>
</table>
<p>¬†</p>
<div id="limpeza-e-prepara√ß√£o-dos-dados" class="section level2">
<h2>Limpeza e prepara√ß√£o dos dados</h2>
<p>Vamos realizar uma limpeza inicial, preparando os dados para possibilitar as an√°lise em um objeto <code>tibble</code> minimamente arrumado:</p>
<pre class="r"><code>sleep &lt;- sleep %&gt;% 
  # fix target
  mutate(mood = case_when(mood == &quot;Bom&quot; ~ &quot;Bom&quot;,
                          mood == &quot;Mau&quot; ~ &quot;Ruim&quot;,
                          mood == &quot;Ok&quot; ~ &quot;Ruim&quot;,
                          is.na(mood) ~ NA_character_),
         mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;% 
  # fix window
  mutate_at(c(&quot;window_start&quot;, &quot;window_stop&quot;), 
            ~ifelse(is.na(.x), end, .x)) %&gt;% 
  # fix string %
  mutate_at(c(&quot;sleep_quality&quot;, &quot;regularity&quot;),
            ~ .x %&gt;% str_remove(&quot;%&quot;) %&gt;% as.numeric() ) %&gt;% 
  # fix heart_rate_bpm e criar bug indicator 
  mutate(heart_rate_bug = ifelse(heart_rate_bpm == 0, &quot;sim&quot;, &quot;nao&quot;)) %&gt;% 
  mutate(heart_rate_bpm = ifelse(heart_rate_bpm == 0, 
                                 NA_integer_, heart_rate_bpm)) %&gt;% 
  # fix dados de soneca
  mutate(snore_time = as.numeric(snore_time),
         did_snore = ifelse(did_snore == TRUE, &quot;sim&quot;, &quot;nao&quot;)) %&gt;% 
  # fix para numerico
  mutate_at(c(&quot;time_before_sleep_seconds&quot;, 
              &quot;time_asleep_seconds&quot;, 
              &quot;time_in_bed_seconds&quot;),
            ~as.numeric(.x) ) %&gt;% 
  # fix movements_per_hour para double
  mutate(movements_per_hour = as.double(movements_per_hour)) %&gt;% 
  # fix weather_type
  mutate(weather_type = 
           factor(weather_type, 
                  levels = c(&quot;No weather&quot;, &quot;Rain&quot;, &quot;Rainy showers&quot;, &quot;Cloudy&quot;,
                             &quot;Partly cloudy&quot;, &quot;Fair&quot;, &quot;Sunny&quot;),
                  ordered = TRUE))  %&gt;% 
  mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
            ~ as.numeric(.x) %&gt;% if_else(. == 0, NA_real_, .)) %&gt;% 
  # remover unused columns
  select(-one_of(c(&quot;city&quot;, &quot;notes&quot;))) %&gt;% 
  select(mood, everything()) %&gt;% 
  arrange(end)</code></pre>
<p>Qual a estrutura geral dos dados? Ser√° que existe algum padr√£o nos dados ausentes?</p>
<pre class="r"><code>sleep %&gt;% 
  arrange(end) %&gt;% 
  mutate(Date = as.Date(end))%&gt;%
  # complete(Date = seq.Date(min(Date), max(Date), by=&quot;day&quot;))  %&gt;%  
  visdat::vis_dat() </code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-7-1.png" style="width:80.0%" />
</center>
<p>Os dados ausentes ocorrem tanto espalhados (<code>heart_rate_bpm</code>) quanto em sequ√™ncia (<code>air_pressure_pa</code>, <code>weather_temperature_c</code>, <code>mood</code>) portando, adotaremos as seguintes estrat√©gias para inputar dados ausentes:</p>
<ol style="list-style-type: decimal">
<li><code>air_pressure_pa</code>: Ser√° obtidos no site <a href="https://www.data.rio/datasets/dados-hor%C3%A1rios-do-monitoramento-da-qualidade-do-ar-monitorar?selectedAttribute=Pres">data.rio/datasets</a> e caso ainda exista dados ausentes, ser√° preenchido com as m√©dias m√≥veis dos √∫ltimos 7 dias;</li>
<li><code>weather_temperature_c</code>: Mesma estrat√©gia do item (1);</li>
<li><code>heart_rate_bpm</code>: C√°lculo das m√©dias m√≥veis dos √∫ltimos 7 dias;</li>
<li><code>mood</code>: Como √© a <em>target</em>, as inst√¢ncias aonde <code>is.na(mood)</code> ser√£o retidas para estima√ß√£o ap√≥s o ajuste do modelo.</li>
</ol>
</div>
<div id="imputar-dados-de-fontes-externas" class="section level2">
<h2>Imputar dados de fontes externas</h2>
<p>O preenchimento das features <code>air_pressure_pa</code>, <code>weather_temperature_c</code> ser√£o realizados a partir do download de dados p√∫blicos do Rio de Janeiro no link: <a href="https://www.data.rio/datasets/dados-hor%C3%A1rios-do-monitoramento-da-qualidade-do-ar-monitorar?selectedAttribute=Pres">data.rio/datasets</a>. Para obter este dado utilizaremos a fun√ß√£o <code>get_rj_data()</code> desenvolvida para este post, que est√° omitida mas para quem tiver interesse basta conferir clicando no item abaixo:</p>
<details>
<summary>
(<em>C√≥digo da fun√ß√£o <code>get_rj_data()</code></em>)
</summary>
<pre class="r"><code>get_rj_data &lt;- function(){ 
  
  if(!file.exists(&quot;rj_data.rds&quot;)){ 
    
    url &lt;- &quot;https://opendata.arcgis.com/datasets/5b1bf5c3e5114564bbf9b7a372b85e17_2.csv?outSR=%7B%22latestWkid%22%3A4326%2C%22wkid%22%3A4326%7D&quot;
    
    download.file(url, &quot;rj_data.csv&quot;)
    
    rj_data &lt;- readr::read_csv(&quot;rj_data.csv&quot;)
    
    saveRDS(rj_data, &quot;rj_data.rds&quot;)
    
  }else{
    rj_data &lt;- readRDS(&quot;rj_data.rds&quot;)
  }
  
  # preparar dados de pressao atmosferica e temperatura no periodo desejado
  rj_data &lt;- rj_data %&gt;% 
    mutate(Data = ymd_hms(Data)) %&gt;% 
    filter(Data &gt;= min(sleep$start) &amp;  Data &lt;= max(sleep$start)) %&gt;% 
    group_by(Data = as.Date(Data)) %&gt;% 
    summarise(air_pressure_pa = mean(Pres/10, rm.na=T),
              weather_temperature_c = mean(Temp, rm.na=T))
  
  return(rj_data)
  
}</code></pre>
</details>
<!-- &nbsp; -->
<p>Com acesso aos dados, hora de combinar as bases e preencher os dados faltantes:</p>
<pre class="r"><code>sleep &lt;- sleep %&gt;% 
  mutate(Data = as.Date(start)) %&gt;%
  # to numeric
  mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
            ~ as.numeric(.x) %&gt;% if_else(. == 0, NA_real_, .)) %&gt;% 
  # join Rio data
  left_join(get_rj_data() , by = c(&quot;Data&quot;)) %&gt;% 
  # fill with new data
  mutate(air_pressure_pa = ifelse(is.na(air_pressure_pa.x),
                                  air_pressure_pa.y,
                                  air_pressure_pa.x)) %&gt;%
  mutate(weather_temperature_c = ifelse(is.na(weather_temperature_c.x),
                                        weather_temperature_c.y, 
                                        weather_temperature_c.x)) %&gt;%
  # remove aux columns
  select(-air_pressure_pa.x, -air_pressure_pa.y,
         -weather_temperature_c.x, -weather_temperature_c.y,
         -Data)</code></pre>
</div>
<div id="insights" class="section level2">
<h2>Insights</h2>
<p>Nesta se√ß√£o vamos responder algumas perguntas com dados!</p>
<div id="start-e-end" class="section level3">
<h3><code>start</code> e <code>end</code></h3>
<p>Qual a m√©dia mensal de horas dormidas e que horas costumo acordar, em m√©dia, mensalmente ao longo desses anos?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>dy1 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(dif_sleep_hours = as.numeric(end - start)/60) %&gt;% 
  mutate(dif_sleep_hours = zoo::rollmean(dif_sleep_hours, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;dif_sleep_hours&#39;)

dy2 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(end_hour = hour(end)) %&gt;% 
  mutate(end_hour = zoo::rollmean(end_hour, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;end_hour&#39;)</code></pre>
</details>
<p>¬†¬†</p>
<!-- <div class="row"> -->
<!-- <div class="column"> -->
<!-- <center> -->
<!-- **Tempo dormindo (em horas)** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3,echo = F} -->
<!-- dy1 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O tempo que passa dormindo parece variar (em m√©dia) em torno de 6 √† 7 horas</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- <div class="column"> -->
<!-- <center>   -->
<!-- **Hora que acorda** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3,echo = F} -->
<!-- dy2 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O pico no in√≠cio no gr√°fico corresponde ao pen√∫ltimo semestre da facultado. No final de 2017 comecei a trabalhare passei a acordar mais cedo  </small> -->
<!-- </center> -->
<!-- </div> -->
<!-- </div> -->
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img1.png" style="width:80.0%" /></p>
<div class="w3-panel w3-sand w3-border">
<p>‚ö†Ô∏è Note que existem alguns espa√ßos vazios, que correspondem aos dias que o app n√£o foi utilizado.</p>
</div>
</div>
<div id="window_start-e-window_stop" class="section level3">
<h3><code>window_start</code> e <code>window_stop</code></h3>
<p>Quanto tempo costumo usar o modo ‚Äúsoneca‚Äù ao longo da semana? E aos finais de semana?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>p &lt;- sleep %&gt;% 
  mutate(mood = ifelse(is.na(mood), &quot;NA&quot;, as.character(mood)) %&gt;% 
           factor(levels = c(&quot;Ruim&quot;, &quot;NA&quot;, &quot;Bom&quot;))) %&gt;% 
  mutate(nap_minutes = (window_stop - window_start) / 30,
         final_de_semana = lubridate::wday(start) %in% c(1, 7)) %&gt;% 
  count(mood, final_de_semana, nap_minutes) %&gt;% 
  group_by(mood, final_de_semana) %&gt;% 
  mutate(
    fnap_minutes = case_when(
      nap_minutes == 0 ~ &quot;Sem modo soneca&quot;,
      nap_minutes == 20 ~ &quot;20 minutos&quot;,
      nap_minutes == 30 ~ &quot;30 minutos&quot;,
      nap_minutes == 60 ~ &quot;1 hora&quot;),
    fnap_minutes = reorder(fnap_minutes, nap_minutes),
    final_de_semana = ifelse(final_de_semana == T, &quot;Final de semena&quot;, &quot;Dia de semana&quot;),
    label = paste0( n, &quot; (&quot;, round(n/sum(n)*100, 2), &quot;%)&quot;)
  ) %&gt;% 
  ggplot(aes(x = fnap_minutes, y = n, label = label, fill = mood))+
  geom_bar(stat = &quot;identity&quot;, alpha = 0.8)+
  scale_fill_viridis_d(end = 0.7, direction = 1)+
  # ggrepel::geom_label_repel(aes(label = label))+
  labs(x = &quot;&quot;, y = &quot;&quot;)+
  facet_wrap(~final_de_semana)+
  theme(axis.text.x = element_text(angle = 30, hjust=1))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>p %&gt;% plotly::ggplotly() %&gt;% plotly::config(displayModeBar = F)</code></pre>
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img2.png" style="width:80.0%" /></p>
<p>Como era de se esperar, os dias em que <code>mood=="Ruim"</code> ocorrem mais quando o modo soneca n√£o √© ativado pois acaba mesmo sendo menos prop√≠cio a voltar a dormir. Outro detalhe √© que muitas vezes usei o soneca por um tempo muito prolongado! (üò± pelo menos <code>mood=="Bom"</code> na maioria desses casos!)</p>
<p>J√° nos finais de semana, ocorre pouqu√≠ssimo <code>mood== "Ruim"</code> e praticamente n√£o h√° uso do alarme e quando h√°, n√£o utiliza soneca.</p>
</div>
<div id="weather_type-e-alarm_mode" class="section level3">
<h3><code>weather_type</code> e <code>alarm_mode</code></h3>
<p>Ser√° que o humor ao acordar esta relacionado com o tipo de clima ou com o modo utilizado no alarme?</p>
<pre class="r"><code>p1 &lt;- plot_cat(sleep, cat_feature=&quot;weather_type&quot;, 
               title = &quot;Tipo de clima&quot;, label = F)+ 
  theme(axis.text.x = element_text(angle = 30, hjust=1))

p2 &lt;- plot_cat(sleep, cat_feature=&quot;alarm_mode&quot;, 
               title = &quot;Modo de alarme&quot;, label = F, legend = &quot;right&quot;)

p1 | p2</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-15-1.png" style="width:80.0%" />
</center>
<p>Nota-se que n√£o existem evid√™ncias estatisticas para afimar que essas features (sozinhas) est√£o associadas √† target, por√©m como ser√£o utilizados modelos baseados em √°rvores que experimentam diversas combina√ß√µes de features, vamos manter na base e deixar o modelo decidir como usar.</p>
</div>
<div id="sleep_quality-e-time_in_bed_seconds" class="section level3">
<h3><code>sleep_quality</code> e <code>time_in_bed_seconds</code></h3>
<p>A qualidade de sono e o tempo da cama est√£o normalmente distribu√≠dos em torno de uma m√©dia?</p>
<pre class="r"><code>p1 &lt;- sleep %&gt;% plot_num(&quot;sleep_quality&quot;)
p2 &lt;- sleep %&gt;% plot_num(&quot;time_in_bed_seconds&quot;, legend = &quot;right&quot;)

p1 | p2</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-16-1.png" style="width:80.0%" />
</center>
<p>Existem alguns registros em que o tempo na cama √© menor que 10.000 segundos (~3horas) o que corresponde aos pequenos cochilos que registrei no app. N√£o foram muitos registros mas talvez seja √∫til na modelagem pois existem ocorr√™ncias de humor (<code>mood</code>) <code>Bom</code> e <code>Ruim</code> ali.</p>
<p>Como a correla√ß√£o de spearman entre estas duas feautures √© muito alta (0.8705) √© poss√≠vel notar que baixa qualidade do sono esta altamente correlacionada com o tempo na cama.</p>
<p>Mais uma pergunta sobre estas features: Como a m√©dia mensal da qualidade do sono e do tempo na cama em horas est√£o distribu√≠dos ao longo do tempo?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>dy1 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)),
                            max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(sleep_quality = zoo::rollmean(sleep_quality, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;sleep_quality&#39;)

dy2 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), 
                            max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(time_in_bed_seconds = 
           zoo::rollmean(time_in_bed_seconds, k =  30, fill = NA)) %&gt;%
  mutate(time_in_bed_seconds = time_in_bed_seconds / 60 / 60) %&gt;% 
  plot_dygraph(order.by = .$start, feature =  &#39;time_in_bed_seconds&#39;)</code></pre>
</details>
<p>¬†¬†</p>
<!-- <div class="row"> -->
<!-- <div class="column"> -->
<!-- <center> -->
<!-- **Qualidade do sono** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3, echo = F} -->
<!-- dy1 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>Parece que a qualidade do sono vem aumentando desde final de 2019, mantendo um patamar semlhante ao final e 2018.</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- <div class="column"> -->
<!-- <center>   -->
<!-- **Tempo na cama em horas** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3, echo = F} -->
<!-- dy2 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O tempo na cama varia entre 6 √† 7 horas (Apesar de alguns picos em 2020, provavelmente por conta da pandemia do corona virus quando estabeleceu-se o home office)</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- </div> -->
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img3.png" style="width:80.0%" /></p>
</div>
</div>
<div id="reter-dados" class="section level2">
<h2>Reter dados</h2>
<p>Antes de iniciar o processo de modelagem, ser√° necess√°rio reter dados aonde <code>mood</code> √© <code>NA</code>, pois faremos as previs√µes nestes dados apenas ap√≥s o ajuste e sele√ß√£o do modelo final.</p>
<pre class="r"><code>new_sleep &lt;- sleep %&gt;% filter(is.na(mood))
sleep &lt;- sleep %&gt;% filter(!is.na(mood))</code></pre>
</div>
</div>
<div id="modelagem" class="section level1">
<h1>Modelagem üöÄ</h1>
<p>Hora de criar alguns modelos para estimar a probabilidade das classes da target: <code>mood</code>.</p>
Como estamos diante de um cen√°rio onde os dados est√£o desbalanceados, ser√° necess√°rio tomar algumas decis√µes muito importantes (sim, cientistas de dados precisam tomar decis√µes o tempo inteiro).
<div class="row">
<div class="column8">
<div class="center">
<span>
<div>
<p>Neste caso, as quest√µes s√£o as seguintes:</p>
<ol style="list-style-type: decimal">
<li>Qual a classe mais importante?</li>
<li>Qual a m√©trica ser√° utilizada para selecionar os modelos?</li>
<li>Qual ser√° o <em>threshold</em>?</li>
<li>Qual ser√° estrat√©gia para lidar com o desbalanceamento?</li>
<li>Quais m√©tricas ser√£o monitoradas?</li>
</ol>
</div>
<p></span></p>
</div>
</div>
<div class="column4">
<p></br>
<img src="https://media.giphy.com/media/XeH1MFu4x3etVsllUN/giphy.gif" alt="Via Giphy" /></p>
</div>
</div>
<p>A classe mais importante para nossa previs√£o √© a positiva, ou seja, <code>mood=="Ruim"</code>. Sendo assim desejamos <strong>evitar falsos positivos</strong>.</p>
<p>A m√©trica utilizada para selecionar os modelos ser√° a <a href="https://www.kaggle.com/dansbecker/what-is-log-loss"><strong>logloss</strong></a>. Esta √© uma m√©trica probabilistica que foca na incerteza que o modelo tem nas previs√µes e penaliza as previs√µes que est√£o erradas<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>Ap√≥s calibrar a probabilidade, estabeleceremos um ponto de corte que <strong>maximizar a medida F-Beta</strong>, (que √© uma abstra√ß√£o da medida <em>F1</em>, m√©dia harm√¥nica entre <em>Precision</em> e <em>Recall</em>) onde <em>Beta = 0.5</em>. Essa medida tem o efeito de aumentar a import√¢ncia da <em>Precision</em> e diminui a import√¢ncia do <em>Recall</em>. <a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Parra lidar com o desbalanceamento da <em>target</em>, utilizaremos o m√©todo de <em>undersampling</em> chamado ** <em>Tomek Links</em> **<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. Este m√©todo faz uma amostragem da classe majorit√°ria de forma ‚Äúmais esperta‚Äù que uma simples amostragem aleat√≥ria.</p>
<p>Por fim, a principal m√©trica que ser√° monitorada ser√° a <strong><em>AUC-PR</em></strong><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> (<em>Area Under Precision Recall Curve</em>). Ela √© uma esp√©cie de <em>AUC</em> que c√°lculada a √°rea sobre a <em>Precision</em> x <em>Recall</em>. Essa m√©trica √© prefer√≠vel neste caso pois foca maisn na classe positiva e a <em>ROC AUC</em> tente a superestimar os valores nesse caso.</p>
<div id="amostragem" class="section level2">
<h2>Amostragem</h2>
<p>Para preparar os dados para modelagem vamos dividir os dados em treino (70%) e teste (30%).</p>
<pre class="r"><code>set.seed(123456789)

# treino e teste
sleep_split &lt;- initial_split(data = sleep, strata = mood, prop = 0.7)
sleep_train &lt;- training(sleep_split)
sleep_test  &lt;- testing(sleep_split)</code></pre>
<p>Al√©m disso, vamos dividir o conjunto de treino em 4 folds para obter resultados de valida√ß√£o cruzada. Este valor corresponde metade da quantidade em que <code>mood=="Ruim"</code> nos dados teste.</p>
<pre class="r"><code>set.seed(123456789)
k_fold &lt;- sleep_test %&gt;% count(mood) %&gt;% filter(mood==&quot;Ruim&quot;) %&gt;% pull(n)

sleep_folds &lt;- sleep_train %&gt;% 
  rsample::vfold_cv(v = round(k_fold/2), repeats = 10, strata = mood)</code></pre>
<p>A decis√£o de utilizar o valor de <code>k</code> como metade do tamanho da classe minorit√°ria foi uma decis√£o pessoal, n√£o sei se √© √≥tima mas foi conveniente neste caso.</p>
<p>Como ficou dividido:</p>
<details>
<summary>
(<em>C√≥digo para tabela abaixo</em>)
</summary>
<pre class="r"><code>tab &lt;- 
  full_join(sleep_train %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            sleep_test %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            by = &quot;mood&quot;) %&gt;% 
  print_table(round = 2,
              columns = list(
                n.x = colDef(name = &quot;N&quot;),
                prop.x = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n.y = colDef(name = &quot;N&quot;),
                prop.y = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;)
              ), 
              columnGroups = list(
                colGroup(name = &quot;Train&quot;, columns = c(&quot;n.x&quot;, &quot;prop.x&quot;)),
                colGroup(name = &quot;Test&quot;, columns = c(&quot;n.y&quot;, &quot;prop.y&quot;))
              ))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>tab</code></pre>
<div class="w3-panel w3-pale-red w3-border">
<p>‚ò†Ô∏è A quantidade reduzida de dados para teste reflete a baixa quantidade de dados no geral!</p>
</div>
</div>
<div id="engenharia-de-recursos" class="section level2">
<h2>Engenharia de recursos</h2>
<p>Hora de criar o objeto que vai conter todos os passos do pr√©-processamento necess√°rio! Esse passo √© muito importante pois algumas estat√≠sticas precisam ser calculadas nos dados de treino isoladamente para n√£o ‚Äúdar pistas‚Äù para modelo sobre as informa√ß√µes contidas nos dados de teste, comprometendo o desempenho do modelo em novos dados.</p>
<p>De forma semelhante (mas n√£o igual) ao <code>sklearn.pipeline.Pipeline</code>, dispon√≠vel para Python, na linguagem R existe o pacote <code>recipes</code> que permite a cria√ß√£o de ‚Äúreceitas‚Äù com a fun√ß√£o <code>recipe()</code> e que pode ser utilizada em um <code>workflow()</code> para treinar o modelo na sequ√™ncia.</p>
<p>Sendo assim, algumas das opera√ß√µes realizadas no pr√©processamento do modelo:</p>
<ul>
<li>Criar feature: <code>ano</code>;</li>
<li>Criar feature: <code>mes</code>;</li>
<li>Criar feature: <code>dia da semana</code>;</li>
<li>Criar feature: <code>dia do mes</code>;</li>
<li>Criar feature: <code>hora que acordou</code>;</li>
<li>Criar feature: <code>final de semana</code>;</li>
<li>Criar feature: <code>tempo dormindo</code>;;</li>
<li>Criar feature: <code>tempo de soneca</code></li>
<li>Criar feature: <code>quarentena</code>;</li>
<li>Inputar m√©dia movel semanal para preencher as features de <code>weather_temperature_c</code> e <code>air_pressure_pa</code> no RJ;</li>
<li>Transformar categ√≥ricas em dummy;</li>
<li>Remover colunas com dados inv√°lidos para modelo (timestamp);</li>
<li>Preencher os dados faltantes de <code>heart_rate_bpm</code> utilizando o algor√≠tmo <code>knn</code> com 2 vizinhos mais pr√≥ximos;</li>
<li>Aplicar o algoritmo <em>Tomek Links</em>, que √© um m√©todo de <em>undersampling</em>.</li>
</ul>
<p>Caso queira saber mais sobre m√©todos de <em>undersampling</em> para tratar dados desbalanceados sugiro a leitura <a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/">deste excelente post</a>! (Os c√≥digos est√£o em Python por√©m a explica√ß√£o da teoria √© o que importa neste caso)</p>
<p>Preparar objeto <code>recipe</code> que cont√©m um conjunto de etapas para pr√©-processamento de dados:</p>
<pre class="r"><code>sleep_recipe &lt;- 
  recipe(mood~., data = sleep_train) %&gt;%
  step_ordinalscore(weather_type) %&gt;% 
  step_mutate(
    ano = factor(year(end)),
    mes = month(end),
    dia_semana = wday(end) %&gt;% ifelse(. == 7, 0, .),
    dia_mes = mday(end),
    end_hour = hour(end),
    final_de_semana = 
      ifelse(lubridate::wday(start) %in% c(1, 7),  &quot;sim&quot;, &quot;nao&quot;) %&gt;% as.factor(),
    dif_sleep_hours = as.numeric(end - start)/60,
    dif_nap = as.numeric(window_stop - window_start) / 60,
    quarentena = ifelse(start &gt; dmy(&quot;20/03/2020&quot;), &quot;sim&quot;, &quot;nao&quot;) %&gt;% as.factor(),
    nap_minutes = (window_stop - window_start) / 30
  ) %&gt;% 
  step_mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
                 fn = ~ imputeTS::na_ma(.x, k = 7, weighting = &quot;simple&quot;)) %&gt;% 
  step_dummy(all_nominal(), -all_outcomes())  %&gt;% 
  step_mutate_at(starts_with(&quot;ano&quot;), # Fix 2018 nos novos dados
                 fn = ~ ifelse(is.na(.x), 0, .x)) %&gt;% 
  step_rm(start, end, window_start, window_stop)%&gt;%
  step_knnimpute(heart_rate_bpm, neighbors = 2) %&gt;% 
  themis::step_tomek(mood) %&gt;%
  prep()

# bake(sleep_recipe, new_data = NULL)</code></pre>
<p>Finalmente! ü•µ</p>
<p>Com os dados devidamente preparados, vamos ligar as turbinas e partir para modelagem!</p>
<pre class="r"><code>doParallel::registerDoParallel(4)</code></pre>
</div>
<div id="modelo-nulo-baseline" class="section level2">
<h2>Modelo Nulo (Baseline)</h2>
<p>Este n√£o √© o tipo de modelo que serve para resolver problemas reais mas pode servir como um bom baseline (‚Äúpior que isso n√£o fica‚Äù) pois ele vai prever apenas a classe majorit√°ria, e com base nisso, poderemos comparar as m√©tricas de performance do ajuste para saber se nossos modelos est√£o (no m√≠nimo) performando melhor que um modelo que classifica unicamente 1 classe,</p>
<pre class="r"><code>null_model &lt;- null_model(mode = &quot;classification&quot;) %&gt;% 
  set_engine(&quot;parsnip&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>null_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(null_model) </code></pre>
<p>Realizar ajuste final nos dados de treino:</p>
<pre class="r"><code>null_final_fit_bas &lt;- null_wflow_bas %&gt;% last_fit(sleep_split) </code></pre>
<p>Coletar previs√µes nos dados de teste:</p>
<pre class="r"><code>null_test_preds_bas &lt;- collect_predictions(null_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>null_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot(null_model = T)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-31-1.png" style="width:80.0%" />
</center>
<p>Modelo nulo pronto! Vamos para a modelagem propriamente dita!</p>
</div>
<div id="√°rvore-de-decis√µes" class="section level2">
<h2>√Årvore de decis√µes</h2>
<p>Este algor√≠timo √© um √≥timo ponto de partida pois possui alta explicabilidade, gerando um plot intuitivo e muito f√°cil de interpretar. As <em>features</em> que aparecem no topo s√£o as mais importantes e cada n√≥ seguinte √© gerado a partir de regras que otimizam a divis√£o dos dados daquele ramo.</p>
<p>Existem recursos interessantes ao trabalhar com √°rvores, como determinar uma regra de parada ou ainda deixar a √°rvore crescer e depois realizar a poda. Primeiramente vamos ajusta uma √°rvore de decis√µes <em>default</em> e em seguida realizar algum tipo de tunning para tentar obter resultados melhores.</p>
<!-- `gini`: -->
<!-- Se selecionarmos dois itens de uma populacao aleatoriamente, entao eles devem ser da mesma classe e a probabilidade para isto √© 1 se a popula√ß√£o √© pura. -->
<div id="default" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>rpart</code> em <a href="https://cran.r-project.org/web/packages/rpart/rpart.pdf" class="uri">https://cran.r-project.org/web/packages/rpart/rpart.pdf</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do pacote <code>parsnip</code> em <a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="uri">https://parsnip.tidymodels.org/reference/decision_tree.html</a></p>
<pre class="r"><code>tree_model_bas &lt;- decision_tree(
  cost_complexity = 0.01, # cp
  tree_depth = 30,        # maxdepth
  min_n = 20              # minsplit
) %&gt;% 
  set_engine(&quot;rpart&quot;) %&gt;%
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>tree_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(tree_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>tree_res_bas &lt;- fit_resamples(
  tree_wflow_bas,
  sleep_folds,
  metrics = metric_set(pr_auc, roc_auc, mn_log_loss),
  control = control_resamples(save_pred = TRUE)
)
# Salvar &quot;cache&quot; da otimizacao 
saveRDS(tree_res_bas, &quot;tree_res_bas.rds&quot;)</code></pre>
<p>Finalizar o modelo:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
tree_final_wflow_bas &lt;- 
  finalize_workflow(
    tree_wflow_bas,
    select_best(tree_res_bas, metric = &#39;mn_log_loss&#39;) 
  )

# Realizar ajuste final nos dados de treino
tree_final_fit_bas &lt;- tree_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
tree_test_preds_bas &lt;- collect_predictions(tree_final_fit_bas)</code></pre>
<p>Vejamos como ficou o modelo baseline:</p>
<details>
<summary>
(<em>C√≥digo do objeto <code>tre_model_bas</code></em>)
</summary>
<pre class="r"><code>tre_model_bas &lt;- 
  tree_final_fit_bas$.workflow[[1]] %&gt;% 
  pull_workflow_fit()</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>rattle::fancyRpartPlot(tre_model_bas$fit, sub = NULL, cex = 0.6)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-38-1.png" style="width:80.0%" />
</center>
<p>Note que o modelo <em>default</em> se baseia nas features <code>time_before_sleep_seconds</code> e <code>steps</code>. Talvez, com outra combina√ß√£o de par√¢metros seja poss√≠vel conseguir um modelo uma √°rvore um pouco maior com resultado igual/melhor.</p>
<p>Como s√£o apenas duas features, √© poss√≠vel visualizar os regras de classifica√ß√£o a partir de um gr√°fio de dispers√£o</p>
<pre class="r"><code>sleep_train %&gt;%
  ggplot(aes(time_before_sleep_seconds, steps)) +
  parttree::geom_parttree(data = tre_model_bas$fit, alpha = 0.3) +
  geom_jitter(aes(color = mood), alpha = 0.7) +
  scale_color_viridis_d(end = 0.8, direction = 1)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-39-1.png" style="width:80.0%" />
</center>
<p>Vamos avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>tree_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-40-1.png" style="width:80.0%" />
</center>
<p>O modelo n√£o esta muito bom‚Ä¶ mas tamb√©m n√£o esta muito ruim para come√ßar! üòÖ</p>
<p>Coram 5/8 acertos para classe de interesse, vamos tentar fazer o tunning deste modelo!</p>
</div>
<div id="tunning" class="section level3">
<h3>Tunning</h3>
<p>Definir o modelo que ser√° utilizado:</p>
<pre class="r"><code>tree_model_tun &lt;- decision_tree(
  min_n = tune(),
  cost_complexity = tune(), 
  tree_depth = tune()
) %&gt;%
  set_engine(&quot;rpart&quot;) %&gt;%
  set_mode(&quot;classification&quot;)
# tree_model_tun %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>tree_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(tree_model_tun) </code></pre>
<p>O grid utilizado foi alterado para tentar previnir que a √°rvore tenha apenas o n√≥ raiz pois o grid default, combinado com o <em>threshold</em>, estava gerando um ‚Äúcotoco‚Äù.</p>
<ul>
<li><code>min_n</code>: [1, 5]</li>
<li><code>cost_complexity</code>: (transformed scale): [-10, -1]</li>
<li><code>tree_depth</code>: [10, 20]</li>
</ul>
<p>Definir um grid aleat√≥rio para otimiza√ß√£o dos hiperpar√¢metros:</p>
<pre class="r"><code>tree_params &lt;- 
  tree_model_tun %&gt;% 
  parameters() %&gt;%
  update(
    min_n = min_n(c(1, 5)), 
    cost_complexity = cost_complexity(),
    tree_depth = tree_depth(c(10, 20)) 
  )

tree_grid &lt;-grid_regular(tree_params, levels = 3)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>tree_res_tun &lt;- 
  tree_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = tree_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
# saveRDS(tree_res_tun, &quot;tree_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;%
  slice(1) %&gt;% 
  pull(.config)

plot_tree_tun &lt;- 
  tree_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)
         # cost_complexity = log(cost_complexity)-10
  ) %&gt;% 
  select(.metric, mean, best_model,
         cost_complexity:min_n) %&gt;%
  pivot_longer(cost_complexity:min_n,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% 
  mutate(parameter = case_when(
    parameter == &quot;cost_complexity&quot; ~ &quot;Cost-Complexity Parameter&quot;,
    parameter == &quot;tree_depth&quot; ~ &quot;Tree Depth&quot;,
    parameter == &quot;min_n&quot; ~ &quot;Minimal Node Size&quot;,
    
  ))%&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }
# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(tree_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_tree_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img4.png" style="width:80.0%" />
</center>
<p>5 Melhores resultados:</p>
<pre class="r"><code>show_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<pre><code>## # A tibble: 5 x 6
##   cost_complexity tree_depth min_n .metric      mean std_err
##             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1             0.1         10     1 mn_log_loss  1.64   0.212
## 2             0.1         15     1 mn_log_loss  1.64   0.212
## 3             0.1         20     1 mn_log_loss  1.64   0.212
## 4             0.1         10     3 mn_log_loss  1.64   0.212
## 5             0.1         15     3 mn_log_loss  1.64   0.212</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
tree_final_wflow_tun &lt;- 
  finalize_workflow(
    tree_wflow_tun,
    select_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
tree_final_fit_tun &lt;- tree_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
tree_test_preds_tun &lt;- collect_predictions(tree_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>tre_model_tun &lt;- pull_workflow_fit(tree_final_fit_tun$.workflow[[1]])</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>rattle::fancyRpartPlot(tre_model_tun$fit, sub = NULL, cex = 0.6)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-51-1.png" style="width:80.0%" />
</center>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>tree_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-52-1.png" style="width:80.0%" />
</center>
<p>Ao comparar o modelo default com o modelo ap√≥s o <em>tunning</em> √© poss√≠vel notar que o n√∫mero de verdadeiros positivos foi menor por√©m o n√∫mero de fasos positivos tbm foi menor devido ao elevado <code>trs_fbeta</code> encontrado (maximizando F0.5).</p>
<p>No geral, o modelo tunado ficou pior que o modelo default mas como o modelo de √°rvore de deci√µes costuma ser bem inst√°vel, ainda mais em um cen√°rio de dados desbalanceados vamos apenas guardar estes resultados e dar mais um passo, combinando diversas √°rvore de decis√µes!</p>
</div>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<p>O <em>Random Forest</em> √© um algoritmo que (de forma simplificada) realiza bootstrap em cima de √°rvores de decis√µes (modelos que utilizamos anteriormente) construindo modelos de √°rvores de decis√µes em diferentes amostras com diferentes combina√ß√µes de <em>features</em> e assim uma previs√£o final √© feita ap√≥s uma ‚Äúvota√ß√£o entre os modelos‚Äù.</p>
<div id="default-1" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>ranger</code> em <a href="https://cran.r-project.org/web/packages/ranger/ranger.pdf" class="uri">https://cran.r-project.org/web/packages/ranger/ranger.pdf</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do pacote <code>parsnip</code> em <a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="uri">https://parsnip.tidymodels.org/reference/rand_forest.html</a></p>
<pre class="r"><code># raiz quadrada do numero de features 
n_col = ncol(juice(sleep_recipe))

rf_model_bas &lt;- rand_forest(
  mtry = sqrt(n_col) %&gt;% floor(), # mtry
  trees = 500,                    # num.trees
  min_n = 1                       # min.node.size 
) %&gt;% 
  set_engine(&quot;ranger&quot;, num.threads = 4, importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>rf_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(rf_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>rf_res_bas &lt;- fit_resamples(
  rf_wflow_bas,
  sleep_folds,
  metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
  control = control_resamples(save_pred = TRUE)
)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
rf_final_wflow_bas &lt;- 
  finalize_workflow(
    rf_wflow_bas,
    select_best(rf_res_bas, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
rf_final_fit_bas &lt;- rf_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
rf_test_preds_bas &lt;- collect_predictions(rf_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>rf_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-58-1png" style="width:80.0%" />
</center>
<p>Este modelo n√£o fez nenhuma previs√£o de falso positivo! Por√©m note que o <code>trs_fbeta</code> ficou bastante alto, o que deve ter ocorrido como reflexo do elevado <code>logloss</code> que indicaria que a incerteza que o modelo tem nas previs√µes esta alta.</p>
</div>
<div id="tunning-1" class="section level3">
<h3>Tunning</h3>
<p>Definir o modelo que ser√° utilizado:</p>
<pre class="r"><code>rf_model_tun &lt;- rand_forest(
  mtry = tune(),
  trees = tune(), 
  min_n = tune()
) %&gt;% 
  set_engine(&quot;ranger&quot;, num.threads = 4, importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)
# tree_model %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>rf_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(rf_model_tun) </code></pre>
<p>O grid utilizado tentar√° valores superiores e inferiores ao n√∫mero de √°rvores <em>default</em> do algoritmo e vamos incluir o valor 1 ao <code>min_n</code> pois √°rvores mais longas neste m√©todo podem ser √∫teis. O <code>mtry</code> ser√° calculado baseado nas informa√ß√µes do dataset de treino.</p>
<ul>
<li><code>trees</code>: [100, 900]</li>
<li><code>min_n</code>: [1, 40]</li>
<li><code>mtry</code>: [1, 20]</li>
</ul>
<p>Definir t√©cnica de otimiza√ß√£o de hiperpar√¢metros</p>
<pre class="r"><code>rf_grid &lt;-grid_max_entropy(
  trees() %&gt;% range_set(c(100, 900)), # Default Range: [1, 2000]
  min_n() %&gt;% range_set(c(1, 40)),    # Default Range: [2, 40]
  finalize(mtry(), sleep_train),
  size = 30)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>rf_res_tun &lt;- 
  rf_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = rf_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
saveRDS(rf_res_tun, &quot;rf_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;%
  slice(1) %&gt;% 
  pull(.config)

plot_rf_tun &lt;- 
  rf_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)) %&gt;% 
  select(.metric, mean, best_model,
         mtry:min_n) %&gt;%
  pivot_longer(mtry:min_n,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% 
  mutate(parameter = case_when(
    parameter == &quot;mtry&quot; ~ &quot;Randomly Selected Predictors&quot;,
    parameter == &quot;min_n&quot; ~ &quot;Minimal Node Size&quot;,
    parameter == &quot;trees&quot; ~ &quot;# Trees&quot;
  )) %&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }
# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(rf_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_rf_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img5.png" style="width:80.0%" />
</center>
<p>Melhores resultados:</p>
<pre class="r"><code>show_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
rf_final_wflow_tun &lt;- 
  finalize_workflow(
    rf_wflow_tun,
    select_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
rf_final_fit_tun &lt;- rf_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
rf_test_preds_tun &lt;- collect_predictions(rf_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>rf_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-68-1.png" style="width:80.0%" />
</center>
<p>Note que apesar do maior n√∫mero de Verdadeiros Positivos, este modelo apresentou um Falso Positivo. Parece estranho pois √© exatamente o que queriamos evitar por√©m √© poss√≠vel notar que o <code>logloss</code> foi bem inferior e o <code>trs_fbeta</code> est√° bem mais razoavel agora.</p>
<p>Importancia de cada <em>feature</em> conforme o modelo:</p>
<pre class="r"><code>vip::vip(pull_workflow_fit(rf_final_fit_tun$.workflow[[1]]))</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-70-1.png" style="width:80.0%" />
</center>
<p>Diferente do modelo baseado em 1 unica √°rvore de decis√µes, a <em>feature</em> <code>steps</code> n√£o foi t√£o importante assim. A <code>time_asleep_seconds</code> foi a mais importante mas com a ordem de grandeza muito pr√≥xima de <code>time_before_sleep_seconds</code>.</p>
<p><em>Random Forest</em> √© um excelente modelo e poder√≠amos investir mais tempo tentando otimizando sua performance mas para este post acho que j√° esta suficiente. Vamos para o pr√≥ximo modelo! üòç</p>
</div>
</div>
<div id="lightgbm" class="section level2">
<h2>LightGBM</h2>
<p>Este modelo consiste em um m√©todo de <em>boosting</em>. Tamb√©m √© baseado nos modelos de √°rvore de decis√µes, mas, diferentemente do <em>Random Forest</em>, suas √°rvores s√£o calculadas em sequ√™ncia, ‚Äúaprendendo‚Äù com o erro das √°rvores anteriores.</p>
<p>A mec√¢nica do <em>LightGBM</em> √© um pouco diferente do <em>XGBoost.</em> N√£o entrarei em detalhes sobre a teoria neste post at√© porque a documenta√ß√£o oficial no github em <a href="https://github.com/microsoft/LightGBM" class="uri">https://github.com/microsoft/LightGBM</a> √© bastante rica, e seus recursos s√£o muito bem apresentados neste link: <a href="https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst" class="uri">https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst</a></p>
<p>Links √∫teis para consulta ao trabalhar com este algoritmo:</p>
<ul>
<li>Documenta√ß√£o oficial: <a href="https://lightgbm.readthedocs.io/en/latest/" class="uri">https://lightgbm.readthedocs.io/en/latest/</a></li>
<li>Excelente post: <a href="https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/" class="uri">https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/</a></li>
<li>Documenta√ß√£o oficial do pacote <code>treesnip</code>: <a href="https://curso-r.github.io/treesnip/articles/working-with-lightgbm-catboost.html" class="uri">https://curso-r.github.io/treesnip/articles/working-with-lightgbm-catboost.html</a></li>
<li>Reposit√≥rio no github do pacote <code>treesnip</code>: <a href="https://github.com/curso-r/treesnip" class="uri">https://github.com/curso-r/treesnip</a></li>
<li>√ìtimo link para consulta dos par√¢metros: <a href="https://sites.google.com/view/lauraepp/parameters" class="uri">https://sites.google.com/view/lauraepp/parameters</a></li>
</ul>
<div id="default-2" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>lightgbm</code> em <a href="https://lightgbm.readthedocs.io/en/latest/" class="uri">https://lightgbm.readthedocs.io/en/latest/</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do (incr√≠vel ü§©) pacote <code>treesnip</code> em <a href="https://github.com/curso-r/treesnip/blob/master/R/lightgbm.R" class="uri">https://github.com/curso-r/treesnip/blob/master/R/lightgbm.R</a></p>
<pre class="r"><code>lgbm_model_bas &lt;- parsnip::boost_tree(
  mode = &quot;classification&quot;,
  trees = 100,       # num_iterations
  learn_rate = 0.1,  # fixo
  min_n = 20,        # min_data_in_leaf
  tree_depth = 6,    # max_depth
  sample_size = 1,   # bagging_fraction
  mtry = 1,          # feature_fraction
  loss_reduction = 0 # min_gain_to_split
) %&gt;%  
  set_engine(&quot;lightgbm&quot;,
             nthread = 4,
             importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>lgbm_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(lgbm_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>lgbm_res_bas &lt;- fit_resamples(
  lgbm_wflow_bas,
  sleep_folds,
  metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
  control = control_resamples(save_pred = TRUE)
)
saveRDS(lgbm_res_bas, &quot;lgbm_res_bas.rds&quot;)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
lgbm_final_wflow_bas &lt;- 
  finalize_workflow(
    lgbm_wflow_bas,
    select_best(lgbm_res_bas, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
lgbm_final_fit_bas &lt;- lgbm_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
lgbm_test_preds_bas &lt;- collect_predictions(lgbm_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>lgbm_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-76-1.png" style="width:80.0%" />
</center>
</div>
<div id="tunning-2" class="section level3">
<h3>Tunning</h3>
<p>Para o tunning vamos utilizar uma estrat√©gia um pouco diferente. Vamos fixar o n√∫mero de √°rvores <code>trees</code> e a taxa de aprendizado <code>learning_rate</code> pois vamos separar mais uma pequena parte dos dados para usar o recurso <code>early_stopping</code>. Esta op√ß√£o basicamente ‚Äútrava‚Äù o crescimento da √°rvore caso o modelo n√£o melhore a performance a partir da n-√©sima itera√ß√£o.</p>
<pre class="r"><code>lgbm_model_tun &lt;- parsnip::boost_tree(
  mode = &quot;classification&quot;,
  trees = 700,             # autotune com early stopping
  learn_rate = 0.01,       # early stopping
  min_n = tune(),          # min_data_in_leaf
  tree_depth = tune(),     # max_depth
  sample_size = 1,         # bagging_fraction, n funciona com goss
  mtry = tune(),           # feature_fraction
  loss_reduction = tune()  # min_gain_to_split
) %&gt;%  
  set_engine(&quot;lightgbm&quot;, nthread = 4, 
             # parametros para early stopping
             early_stop = 30,
             validation = .20,
             eval_metric = &quot;mn_log_loss&quot;,
             importance = &quot;permutation&quot;
             # feature_fraction = tune(&quot;feature_fraction&quot;)
  ) %&gt;% 
  set_mode(&quot;classification&quot;)
# tree_model %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>lgbm_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(lgbm_model_tun) </code></pre>
<p>Definir grid para otimiza√ß√£o de hiperpar√¢metros baseados nas sugest√µes de <a href="https://github.com/Laurae2">github/Laurae2</a> em uma <a href="https://github.com/microsoft/LightGBM/issues/695">issue</a> no reposit√≥rio <a href="https://github.com/microsoft/LightGBM/issues/695">oficial</a> do modelo</p>
<pre class="r"><code>lightgbm_params &lt;- 
  dials::parameters(
    # learn_rate(),           # learning_rate
    # trees()                 # num_iterations
    min_n(),                  # min_data_in_leaf
    tree_depth(c(2, 63)),     # max_depth
    # sample_prop(c(0.4, 1)), # bagging_fraction (vai para sample_size)
    mtry(),                   # feature_fraction
    loss_reduction()          # min_gain_to_split
  ) 

lgbm_grid &lt;- lightgbm_params %&gt;% 
  finalize(sleep_train) %&gt;% 
  grid_max_entropy(size = 30)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>lgbm_res_tun &lt;- 
  lgbm_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = lgbm_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
saveRDS(lgbm_res_tun, &quot;lgbm_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;)[1, ] %&gt;% 
  pull(.config)

plot_lgbm_tun &lt;- 
  lgbm_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)) %&gt;% 
  select(.metric, mean, best_model,
         mtry:loss_reduction) %&gt;%
  pivot_longer(mtry:loss_reduction,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }

# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(lgbm_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_lgbm_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img6.png" style="width:80.0%" />
</center>
<p>Melhores resultados:</p>
<pre class="r"><code>show_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<pre><code>## # A tibble: 5 x 7
##    mtry min_n tree_depth loss_reduction .metric      mean std_err
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;          &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1     2    35         28 0.000000000108 mn_log_loss 0.259 0.00888
## 2     1    16          5 0.00000160     mn_log_loss 0.267 0.0100 
## 3     4    28         31 0.000507       mn_log_loss 0.272 0.0111 
## 4     5    39         62 0.000164       mn_log_loss 0.273 0.00955
## 5     2    14         19 0.0642         mn_log_loss 0.274 0.0138</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
lgbm_final_wflow_tun &lt;- 
  finalize_workflow(
    lgbm_wflow_tun,
    select_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
lgbm_final_fit_tun &lt;- lgbm_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
lgbm_test_preds_tun &lt;- collect_predictions(lgbm_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>lgbm_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-87-1.png" style="width:80.0%" />
</center>
<p>Que maravilha! Modelos acertaram mais a classe de interesse do que os anteriores (apesar do <em>default</em> ainda apresentar alta propor√ß√£o de falsos positivos). Note ainda que o LightGBM ap√≥s o <em>tunning</em> apresentou as melhores m√©tricas no geral (melhor AUC-PR, menor <em>logloss</em> e um bom equil√≠brio no <em>trade-off</em> de <em>Precision</em> x <em>Recall</em>).</p>
<p>Vejamos quais as <em>features</em> mais importantes no ajuste do modelo:</p>
<pre class="r"><code>lgbm_imp_tun &lt;- lightgbm::lgb.importance(lgbm_final_fit_tun$.workflow[[1]]$fit$fit$fit, percentage = T)

lgbm_imp_tun%&gt;% 
  mutate(Feature = reorder(Feature, Gain)) %&gt;% 
  ggplot(aes(x = Feature, y = Gain))+
  geom_bar(stat = &quot;identity&quot;)+
  labs(y = &quot;Importance&quot;, x= &quot;&quot;)+
  coord_flip()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-89-1.png" style="width:80.0%" />
</center>
</div>
</div>
</div>
<div id="sele√ß√£o-do-modelo" class="section level1">
<h1>Sele√ß√£o do modelo ü§î</h1>
<!-- Curva Roc e Precision-Recall Curve: -->
<!-- ```{r} -->
<!-- bind_rows( -->
<!--   # null_res_bas %>% unnest(.predictions) %>% mutate(model = "null baseline"),   -->
<!--   tree_res_bas %>% unnest(.predictions) %>% mutate(model = "rpart baseline"),   -->
<!--   tree_res_tun %>% unnest(.predictions) %>% mutate(model = "rpart tunning"), -->
<!--   rf_res_bas %>% unnest(.predictions) %>% mutate(model = "rf baseline"), -->
<!--   rf_res_tun %>% unnest(.predictions) %>% mutate(model = "rf tunning"), -->
<!--   lgbm_res_bas %>% unnest(.predictions) %>% mutate(model = "lgbm baseline"), -->
<!--   lgbm_res_tun %>% unnest(.predictions) %>% mutate(model = "lgbm tunning") -->
<!-- ) %>%   -->
<!--   plot_auc() +  -->
<!--   plot_annotation(title = 'Resultados nos dados de treino', -->
<!--                   theme = theme(plot.title = element_text(hjust = 0.4))) -->
<!-- ``` -->
<p>Comparar os modelos de forma visual com os gr√°ficos da ROC AUC e da PR AUC:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>auc_plots &lt;- 
  bind_rows(
    null_test_preds_bas %&gt;% mutate(model = &quot;null baseline&quot;),
    tree_test_preds_bas %&gt;% mutate(model = &quot;rpart default&quot;),
    tree_test_preds_tun %&gt;% mutate(model = &quot;rpart tunning&quot;),
    rf_test_preds_bas %&gt;% mutate(model = &quot;rf default&quot;),
    rf_test_preds_tun %&gt;% mutate(model = &quot;rf tunning&quot;),
    lgbm_test_preds_bas %&gt;% mutate(model = &quot;lgbm default&quot;),
    lgbm_test_preds_tun %&gt;% mutate(model = &quot;lgbm tunning&quot;)
  ) %&gt;% 
  plot_auc() + 
  plot_annotation(title = &#39;Resultados nos dados de teste&#39;,
                  theme = theme(plot.title = element_text(hjust = 0.4)))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>auc_plots</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-91-1.png" style="width:80.0%" />
</center>
<p>Apenas olhando o gr√°fico n√£o da para fazer uma an√°lise conclusiva, vejamos as medidas de qualidade (ordenado por <code>auc_pr</code>):</p>
<details>
<summary>
(<em>C√≥digo da tabela</em>)
</summary>
<pre class="r"><code>test_results &lt;- 
  bind_rows(
    evalue_model(null_test_preds_bas, model = &quot;null baseline&quot;, null_model = TRUE),
    evalue_model(tree_test_preds_bas, model = &quot;rpart default&quot;),
    evalue_model(tree_test_preds_tun, model = &quot;rpart tunning&quot;),
    evalue_model(rf_test_preds_bas, model = &quot;rf default&quot;),
    evalue_model(rf_test_preds_tun, model = &quot;rf tunning&quot;),
    evalue_model(lgbm_test_preds_bas, model = &quot;lgbm default&quot;),
    evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)
  ) %&gt;% print_table(round = 4, evalue_model = T)   </code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>test_results</code></pre>
<table>
<colgroup>
<col width="13%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="10%" />
<col width="7%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th>model</th>
<th>tp</th>
<th>fp</th>
<th>fn</th>
<th>tn</th>
<th>auc_roc</th>
<th>auc_pr</th>
<th>logloss</th>
<th>f1</th>
<th>f05</th>
<th>f2</th>
<th>precision</th>
<th>recall</th>
<th>trs_fbeta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>lgbm tunning</td>
<td>6</td>
<td>1</td>
<td>2</td>
<td>72</td>
<td>0.8699</td>
<td>0.7804</td>
<td>0.2190</td>
<td>0.8000</td>
<td>0.8333</td>
<td>0.7692</td>
<td>0.8571</td>
<td>0.7500</td>
<td>0.5937</td>
</tr>
<tr class="even">
<td>rf default</td>
<td>4</td>
<td>0</td>
<td>4</td>
<td>73</td>
<td>0.8399</td>
<td>0.6916</td>
<td>0.6613</td>
<td>0.6667</td>
<td>0.8333</td>
<td>0.5556</td>
<td>1.0000</td>
<td>0.5000</td>
<td>0.7140</td>
</tr>
<tr class="odd">
<td>rf tunning</td>
<td>5</td>
<td>1</td>
<td>3</td>
<td>72</td>
<td>0.8493</td>
<td>0.6658</td>
<td>0.2722</td>
<td>0.7143</td>
<td>0.7812</td>
<td>0.6579</td>
<td>0.8333</td>
<td>0.6250</td>
<td>0.3888</td>
</tr>
<tr class="even">
<td>null baseline</td>
<td>0</td>
<td>0</td>
<td>8</td>
<td>73</td>
<td>0.5000</td>
<td>0.5494</td>
<td>0.3236</td>
<td></td>
<td></td>
<td></td>
<td>0.0000</td>
<td>0.1141</td>
<td></td>
</tr>
<tr class="odd">
<td>lgbm default</td>
<td>6</td>
<td>3</td>
<td>2</td>
<td>70</td>
<td>0.8527</td>
<td>0.5038</td>
<td>0.2313</td>
<td>0.7059</td>
<td>0.6818</td>
<td>0.7317</td>
<td>0.6667</td>
<td>0.7500</td>
<td>0.4286</td>
</tr>
<tr class="even">
<td>rpart default</td>
<td>5</td>
<td>9</td>
<td>3</td>
<td>64</td>
<td>0.7312</td>
<td>0.4471</td>
<td>0.3267</td>
<td>0.4545</td>
<td>0.3906</td>
<td>0.5435</td>
<td>0.3571</td>
<td>0.6250</td>
<td>0.5714</td>
</tr>
<tr class="odd">
<td>rpart tunning</td>
<td>4</td>
<td>7</td>
<td>4</td>
<td>66</td>
<td>0.7243</td>
<td>0.4390</td>
<td>0.3399</td>
<td>0.4211</td>
<td>0.3846</td>
<td>0.4651</td>
<td>0.3636</td>
<td>0.5000</td>
<td>0.7857</td>
</tr>
</tbody>
</table>
<p>O modelo LightGBM ap√≥s o processo de tunning foi o que apresentou as melhores medidas no geral. Note que o LightGBM com os par√¢metro default ficou pior do que o modelo nulo üò±! Isso mostra como o processo de tunning pode ser importante. Al√©m disso note que o modelo <code>rf baseline</code> apresentou o segundo maior AUC-PR mas o pior logloss (note que o <code>threshold</code> est√° muito alto e as demais m√©tricas n√£o ficaram muito boas).</p>
<p>Portanto, apenas os modelos <em>LightGBM</em> e <em>Random Forest</em> apresentaram resultados melhores que um modelo nulo (sempre estima a classe majorit√°ria) e como o LightGBM foi o mais satisfat√≥rio, este ser√° o modelo selecionado. üòé</p>
</div>
<div id="previs√£o-em-dados-novos" class="section level1">
<h1>Previs√£o em dados novos üí´</h1>
<p>Obter as previs√µes nos novos dados:</p>
<pre class="r"><code>trs_final &lt;- evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$trs_fbeta

final &lt;- 
  predict(lgbm_final_fit_tun$.workflow[[1]], new_sleep, type = &quot;prob&quot;) %&gt;% 
  mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs_final, &quot;Ruim&quot;, &quot;Bom&quot;)) 

# new_sleep %&gt;% filter(final$.pred_class == &quot;Ruim&quot;)</code></pre>
<p>Comparar a quantidade de previs√µes de cada classe com o conjunto de treino/teste:</p>
<details>
<summary>
(<em>C√≥digo para tabela abaixo</em>)
</summary>
<pre class="r"><code>tab &lt;- 
  full_join(sleep_train %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            sleep_test %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            by = &quot;mood&quot;) %&gt;% 
  full_join(final %&gt;% 
              count(mood = .pred_class) %&gt;% mutate(prop = n/sum(n)*100)) %&gt;% 
  print_table(round = 2,
              columns = list(
                n.x = colDef(name = &quot;N&quot;),
                prop.x = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n.y = colDef(name = &quot;N&quot;),
                prop.y = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n = colDef(name = &quot;N&quot;),
                prop = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;)
              ), 
              columnGroups = list(
                colGroup(name = &quot;Train&quot;, columns = c(&quot;n.x&quot;, &quot;prop.x&quot;)),
                colGroup(name = &quot;Test&quot;, columns = c(&quot;n.y&quot;, &quot;prop.y&quot;)),
                colGroup(name = &quot;New Data&quot;, columns = c(&quot;n&quot;, &quot;prop&quot;))
              ))</code></pre>
</details>
<p>¬†¬†</p>
<pre class="r"><code>tab</code></pre>
<details>
<summary>
(<em>C√≥digo do c√°lculo das medidas abaixo</em>)
</summary>
<pre class="r"><code># ref: https://en.wikipedia.org/wiki/Sensitivity_and_specificity

# Obter medidas da matriz de confusao
tp = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$tp
tn = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$tn
fn = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$fn
fp = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$fn

# true positive rate
tpr = tp / (tp + fn)
# false negative rate
fnr = 1 - tpr
#false positive rate
fpr = fp / (fp + tn)</code></pre>
</details>
<p>¬†¬†</p>
<p>Como nosso modelo foi otimizado para ser menos ‚Äúalarmista‚Äù (com uma Taxa de Falso Positivo: 2.7%) √© poss√≠vel que o modelo tenha deixado passar alguns dias em que <code>mood=="Ruim"</code> (Taxa de Falso Negativo: 25%). N√£o vejo isto como um grande problema pois dado a pequena quantidade de dados dispon√≠veis at√© que o resultado para a classe de interesse estava bem razo√°vel (Taxa de Verdadeiro Positivo: 75%).</p>
<p>Para n√£o alongar aida mais o post com an√°lise explorat√≥ria das previs√µes, vamos comparar como foram as previs√µes nestes novos dados em rela√ß√£o aos dados utilizados para treinar o modelo e ver se, pelo menos visualmente, o modelo esteja conseguindo prever de semelhante ao padr√£o de dados conhecidos.</p>
<p>A t√©cnica <a href="https://cran.r-project.org/web/packages/umap/vignettes/umap.html">UMAP</a> ser√° utilizada com a finalidade de reduzir a dimensionalidade para visualiza√ß√£o:</p>
<details>
<summary>
(<em>C√≥digo para gr√°fico abaixo</em>)
</summary>
<pre class="r"><code># Treinar UMAP: 
sleep_umap &lt;-  juice(sleep_recipe) %&gt;% select(-mood) %&gt;% umap::umap()

# Aplicar em novos dados:
new_data &lt;- bake(sleep_recipe, new_sleep) %&gt;% select(-mood)
new_data_umap &lt;- predict(sleep_umap, new_data)

# Preparar plot comparando treino com novos dados:
umap_plot &lt;-
  bind_rows(
    sleep_umap$layout %&gt;% 
      as_tibble() %&gt;% 
      bind_cols(juice(sleep_recipe) %&gt;% select(mood))  %&gt;% 
      bind_cols(dataset =  &quot;Train&quot;)
    ,
    new_data_umap %&gt;% 
      as_tibble() %&gt;% 
      mutate(mood = factor(final$.pred_class,
                           levels = c(&quot;Ruim&quot;, &quot;Bom&quot;)))  %&gt;% 
      bind_cols(dataset =  &quot;New Data&quot;)
  ) %&gt;%
  mutate(dataset = factor(dataset, levels = c(&quot;New Data&quot;, &quot;Train&quot;))) %&gt;% {
    ggplot(., aes(x = V1, y = V2, color = mood, shape = mood))+
      geom_point(show.legend = F)+
      geom_point(aes(x = V1, y = V2, color = mood), 
                 data = subset(., mood == &#39;Ruim&#39;), 
                 size = 2, shape = 3)+
      labs(x = &quot;&quot;, y = &quot;&quot;, 
           title = &quot;UMAP (Uniform Manifold Approximation and Projection)&quot;)+
      scale_color_viridis_d(end = 0.8, direction = 1)+
      # scale_size_manual(values=c(2,5))+
      theme(legend.position = &quot;bottom&quot;)+
      facet_wrap(~dataset)
  }</code></pre>
</details>
<p>¬†¬†</p>
<pre class="r"><code>umap_plot %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<p>Parece que o modelo fez previs√µes nos novos dados em um padr√£o espec√≠fico dos dados (√† direita) enquanto que nos dados de treino podemos observar alguma informa√ß√£o da classe <code>Ruim</code> na massa de dados √† esquerda. Isso pode estar acontecendo devido ao foco que demos para minimizar falsos positivos. √â uma boa indica√ß√£o para analisar melhor o padr√£o que o modelo esta aprendendo em rela√ß√£o aos falsos negativos.</p>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img7.png" style="width:80.0%" />
</center>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o üçª</h1>
<p>Apesar da pequena quantidade dados dados dispon√≠veis, conseguimos ajustar um modelo razo√°vel para prever a qualidade de sono em dias que n√£o foram registrados!</p>
<div class="row">
<div class="column8">
<p>Utilizamos diversas t√©cnicas de <em>Machine Leaning</em> combinadas em dados reais (que n√£o s√£o nada comportados) e, obviamente, para colocar um modelo em produ√ß√£o na vida real seria necess√°rio aplicar mais uma s√©rie de an√°lises, al√©m de entender como o modelo est√° funcionando, aplicando t√©cnicas de <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">XAI</a> (Explainable AI) mas isso pode ser assunto para um futuro <em>post</em>, hora de dormir! üò¥</p>
<p>Espero que este pequeno ‚Äú<em>case</em>‚Äù seja √∫til para voc√™! Para mim foi √≥timo combinar a pr√°tica do uso do pacote <code>tidymodels</code> para resolver um problema com dados reais com um estudo que me trouxe mais auto-conhecmento e um monte de <em>insights</em> pessoais.</p>
</div>
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/U7Lvtcuqh4WZy/giphy.gif" alt="Via Giphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/U7Lvtcuqh4WZy/giphy.gif">Via Giphy</a></div>
</div>
</div>
</div>
<hr />
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias üß≥</h1>
<ul>
<li><a href="https://juliasilge.com/blog/wind-turbine/" class="uri">https://juliasilge.com/blog/wind-turbine/</a></li>
<li><a href="https://juliasilge.com/blog/hotels-recipes/" class="uri">https://juliasilge.com/blog/hotels-recipes/</a></li>
<li><a href="https://juliasilge.com/blog/xgboost-tune-volleyball/" class="uri">https://juliasilge.com/blog/xgboost-tune-volleyball/</a></li>
<li><a href="http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/" class="uri">http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/</a></li>
<li><a href="https://machinelearningmastery.com/imbalanced-classification-with-python/" class="uri">https://machinelearningmastery.com/imbalanced-classification-with-python/</a></li>
<li><a href="https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/fbeta-measure-for-machine-learning/" class="uri">https://machinelearningmastery.com/fbeta-measure-for-machine-learning/</a></li>
<li><a href="https://sites.google.com/view/lauraepp/parameters" class="uri">https://sites.google.com/view/lauraepp/parameters</a></li>
<li><a href="https://github.com/microsoft/LightGBM/issues/695" class="uri">https://github.com/microsoft/LightGBM/issues/695</a></li>
</ul>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p><a href="https://www.usp.br/espacoaberto/?materia=a-importancia-de-dormir-bem" class="uri">https://www.usp.br/espacoaberto/?materia=a-importancia-de-dormir-bem</a><a href="#fnref1" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p><a href="https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/</a><a href="#fnref2" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn3"><p><a href="https://machinelearningmastery.com/fbeta-measure-for-machine-learning/" class="uri">https://machinelearningmastery.com/fbeta-measure-for-machine-learning/</a><a href="#fnref3" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn4"><p><a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/</a><a href="#fnref4" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn5"><p><a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/</a><a href="#fnref5" class="footnote-back">‚Ü©Ô∏é</a></p></li>
</ol>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/">Prevendo a qualidade do sono utilizando Machine Learning</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">imbalanced</category>
      <category domain="tag">imbalanced-data</category>
      <category domain="tag">lightgbm</category>
      <category domain="tag">r</category>
      <category domain="tag">random-forest</category>
      <category domain="tag">threshold-movel</category>
      <category domain="tag">tidymodels</category>
      <category domain="tag">tidyverse</category>
      <category domain="tag">tunning</category>
    </item>
  </channel>
</rss>