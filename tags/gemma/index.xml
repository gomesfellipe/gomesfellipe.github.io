<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gemma on Fellipe Gomes</title>
    <link>https://gomesfellipe.github.io/tags/gemma/</link>
    <description>Recent content in Gemma on Fellipe Gomes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 26 May 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://gomesfellipe.github.io/tags/gemma/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Detecção de Linguagem Tóxica com o LLM Gemma e LangChain</title>
      <link>https://gomesfellipe.github.io/post/2024-05-26-detec-o-de-linguagem-t-xica-com-o-llm-gemma-e-langchain/</link>
      <pubDate>Sun, 26 May 2024 00:00:00 +0000</pubDate>
      
      <guid>https://gomesfellipe.github.io/post/2024-05-26-detec-o-de-linguagem-t-xica-com-o-llm-gemma-e-langchain/</guid>
      <description>Caso de Uso de IA Generativa: Detecção de Linguagem Tóxica em Mídias Sociais Setup Carregar dados Carregar Modelo Prompt Engineering Conclusão Referencias Caso de Uso de IA Generativa: Detecção de Linguagem Tóxica em Mídias Sociais Neste post, realizaremos a tarefa de detecção de linguagem tóxica em mídias sociais usando o modelo Gemma de IA generativa do Google com o framework LangChain. Vamos explorar como o texto de entrada afeta a saída do modelo e faremos alguma engenharia de prompts para direcioná-lo à tarefa necessária.</description>
    </item>
    
  </channel>
</rss>
