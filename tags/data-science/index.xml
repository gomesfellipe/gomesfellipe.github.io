&lt;?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>data-science on Fellipe Gomes - Data Science Blog</title>
    <link>https://gomesfellipe.github.io/tags/data-science/</link>
    <description>√öltimos posts sobre Data Science, Machine Learning e R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <managingEditor>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</managingEditor>
    <webMaster>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</webMaster>
    <lastBuildDate>Fri, 27 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://gomesfellipe.github.io/tags/data-science/" rel="self" type="application/rss+xml" />
    <item>
      <title>Extra√ß√£o de informa√ß√µes de imagens com IA Generativa</title>
      <link>https://gomesfellipe.github.io/post/2024-09-27-image-text-to-text/</link>
      <pubDate>Fri, 27 Sep 2024 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2024-09-27-image-text-to-text/</guid>
      <description>Neste post, exploraremos como utilizar o modelo Llava para gerar r√≥tulos descritivos de imagens, usando dados do conjunto COCO-2017.</description>
      <content:encoded>&lt;![CDATA[
        


<div id="caso-de-uso-de-ia-generativa-extra√ß√£o-de-informa√ß√µes-de-imagens-com-o-modelo-llava" class="section level1">
<h1>Caso de Uso de IA Generativa: Extra√ß√£o de Informa√ß√µes de Imagens com o Modelo Llava</h1>
<p>GenAI refere-se a modelos de intelig√™ncia artificial capazes de gerar conte√∫do novo e criativo a partir de dados de entrada. Seu uso est√° revolucionando a maneira como processamos dados n√£o estruturados, como imagens, √°udios, textos, v√≠deos, etc. Trabalhar com modelos pr√©-treinados (i.e., que j√° foram treinados com grandes conjuntos de dados) e adapt√°-los para necessidades espec√≠ficas tem sido um divisor de √°guas.</p>
<p>Neste post, vamos explorar a utiliza√ß√£o do modelo Llava (Large Language and Vision Assistant) para extrair r√≥tulos descritivos de imagens e tamb√©m discutir como comparar a qualidade das previs√µes geradas com m√©tricas espec√≠ficas para avaliar a performance desse tipo de modelo.</p>
<div id="por-que-o-modelo-llava" class="section level2">
<h2>Por que o Modelo Llava?</h2>
<p>O modelo <a href="https://llava-vl.github.io/">Llava</a> √© uma alternativa de c√≥digo aberto ao <a href="https://chat-gpt-5.ai/capabilities-of-gpt-4v/">GPT-4 Vision</a> da OpenAI (que se destaca neste dom√≠nio, mas sua aplica√ß√£o √© restrita devido sua natureza propriet√°ria e comercial) que foi treinado em grandes conjuntos de dados multimodais, sendo capaz de compreender e gerar descri√ß√µes textuais para imagens.</p>
<p>Essa capacidade de ‚Äúconversar com imagens‚Äù tendo o mesmo ‚Äúpoder‚Äù de um LLM, possibilita seu uso em muitas solu√ß√µes desenvolvidas por cientistas de dados no mundo real, como:</p>
<ol style="list-style-type: decimal">
<li><strong>Classifica√ß√£o de produtos em e-commerce</strong>: gera√ß√£o de descri√ß√µes detalhadas de roupas, acess√≥rios, eletr√¥nicos, etc.</li>
<li><strong>Detec√ß√£o de defeitos em linhas de produ√ß√£o</strong>: identifica√ß√£o de falhas em produtos para automa√ß√£o e controle de qualidade.</li>
<li><strong>Diagn√≥stico m√©dico por imagens</strong>: auxiliar na detec√ß√£o precoce de doen√ßas a partir de descri√ß√µes detalhadas de imagens m√©dicas.</li>
<li><strong>Reconhecimento de placas de carros</strong>: transcri√ß√£o autom√°tica de textos de placas e caracter√≠sticas de ve√≠culos.</li>
<li><strong>Identifica√ß√£o de sinais de tr√¢nsito</strong>: aplica√ß√£o em ve√≠culos aut√¥nomos para navega√ß√£o e identifica√ß√£o de sinais.</li>
<li><strong>An√°lise de alimentos para calcular nutri√ß√£o</strong>: extra√ß√£o autom√°tica de informa√ß√µes nutricionais de fotos ou r√≥tulos de alimentos.</li>
<li><strong>Identifica√ß√£o de animais em c√¢meras de vida selvagem</strong>: gerar descri√ß√µes detalhadas de animais detectados, ajudando pesquisadores a automatizar o monitoramento da vida selvagem.</li>
<li><strong>Detec√ß√£o de aglomera√ß√µes em eventos</strong>: analisar imagens de c√¢meras de seguran√ßa para identificar a presen√ßa de grandes grupos de pessoas em eventos ou lugares p√∫blicos, √∫til em gest√£o de multid√µes ou para quest√µes de seguran√ßa.</li>
</ol>
</div>
<div id="dataset-coco-2017" class="section level2">
<h2>Dataset COCO-2017</h2>
<p>O <a href="https://cocodataset.org/">COCO</a> (Common Objects in Context) √© um dataset amplamente utilizado em vis√£o computacional. Ele √© um dos maiores conjuntos de imagens do dia a dia com objetos em diferentes contextos, com anota√ß√µes detalhadas fornecidas por humanos como tags, caixa delimitadora, pol√≠gono que segmenta a imagem detectando objetos bem como sua descri√ß√£o. Isso o torna ideal para testar o desempenho desse tipo de modelo para gera√ß√£o de legendas.</p>
<center>
<div style="display: flex; width: 100%;">
<div style="width: 50%;">
<p><img src="/post/2024-09-27-image-text-to-text/coco1.png" alt="Imagem 2" style="width: 100%;"></p>
</div>
<div style="width: 50%;">
<p><img src="/post/2024-09-27-image-text-to-text/coco2.png" alt="Imagem 2" style="width: 100%;"></p>
</div>
</div>
<center>
<small>
Imagem do COCO Dataset com e sem anota√ß√£o obtida na <a href="https://cocodataset.org/#explore">se√ß√£o explorat√≥ria</a> das imagens
</small>
</center>
</center>
</div>
</div>
<div id="preparando-o-ambiente" class="section level1">
<h1>Preparando o Ambiente</h1>
<p>Utilizei o ambiente do Kaggle para desenvolvimento deste notebook, que disponibiliza a utiliza√ß√£o de GPUs. Atrav√©s do Hardware Accelerator utilizaremos a <a href="https://www.kaggle.com/docs/efficient-gpu-usage">NVIDIA TESLA P100 GPU</a>.</p>
<details>
<summary>
<em>Expandir c√≥digo</em>
</summary>
<pre><code>%%capture
!pip -qqq install bitsandbytes accelerate rouge-score pycocoevalcap bert_score
!pip install -U nltk

import os
import re
import json
import pandas as pd
import numpy as np
from tqdm import tqdm

import seaborn as sns
import matplotlib.pyplot as plt

from PIL import Image
import requests
from io import BytesIO
from IPython.display import HTML
import base64

import torch
from transformers import pipeline, AutoProcessor, BitsAndBytesConfig

from nltk.translate.bleu_score import sentence_bleu
from rouge_score import rouge_scorer
from bert_score import score as bert_score
from nltk.translate.meteor_score import meteor_score

from transformers import logging
import warnings

logging.set_verbosity_error()
warnings.filterwarnings(&quot;ignore&quot;, &quot;use_inf_as_na&quot;)</code></pre>
</details>
<p><br></p>
</div>
<div id="carregar-dados" class="section level1">
<h1>Carregar dados</h1>
<p>Por fins de praticidade para este post, selecionei uma amostra de 10 imagens aleat√≥rias do dataset COCO - (Common Objects in Context) no site <a href="https://cocodataset.org" class="uri">https://cocodataset.org</a> (onde √© poss√≠vel ter uma descri√ß√£o detalhada do conjunto de dados, incluindo seu <a href="https://arxiv.org/abs/1405.0312">paper</a> para aprofundamento), para avaliar o desempenho do modelo.</p>
<details>
<summary>
<em>Expandir c√≥digo</em>
</summary>
<pre class="python"><code>df_sample = pd.DataFrame({
  &#39;coco_url&#39;: [
    &#39;http://images.cocodataset.org/train2017/000000058822.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000530396.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000097916.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000418492.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000022304.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000295999.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000406616.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000370926.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000005612.jpg&#39;,
    &#39;http://images.cocodataset.org/train2017/000000146436.jpg&#39;
  ],
  &#39;caption&#39;: [
    &#39;A laptop sitting on a desk with a cell phone and mouse.&#39;,
    &#39;A black bear walking through the grass field.&#39;,
    &#39;a person who is surfing in the ocean.&#39;,
    &#39;A young boy standing on a sandy beach holding a flag.&#39;,
    &#39;A man surfing on a wave in the ocean.&#39;,
    &#39;A herd of cows, grazing in a field.&#39;,
    &#39;There is a cutting board and knife with chopped apples and carrots.&#39;,
    &#39;A long yellow school bus is parked on a city street.\n&#39;,
    &#39;A black and white horse standing in the middle of a field.&#39;,
    &#39;A man in a red jacket looking at his phone.&#39;
    ]})
    
# Fun√ß√£o para verificar se o caminho √© uma URL
def is_url(path):
    return path.startswith(&#39;http://&#39;) or path.startswith(&#39;https://&#39;)

# Fun√ß√£o simplificada para gerar o thumbnail e convert√™-lo em base64 diretamente
def process_image(path):
    try:
        if is_url(path):
            # Se for uma URL, baixar a imagem
            response = requests.get(path)
            response.raise_for_status()  # Verifica se houve algum erro no download
            image = Image.open(BytesIO(response.content))  # Abrir a imagem do conte√∫do da resposta
        else:
            # Se for um caminho local, abrir a imagem diretamente
            image = Image.open(path)
        
        # Criar uma miniatura da imagem (thumbnail) com tamanho m√°ximo de 150x150
        image.thumbnail((150, 150), Image.LANCZOS)
        
        # Salvar a imagem em um buffer de mem√≥ria e convert√™-la para base64
        with BytesIO() as buffer:
            image.save(buffer, &#39;jpeg&#39;)
            image_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        # Retornar a string HTML com a imagem embutida no formato base64
        return f&#39;&lt;img src=&quot;data:image/jpeg;base64,{image_base64}&quot;&gt;&#39;
    
    except Exception as e:
        # Em caso de erro, retornar uma string vazia ou uma mensagem de erro
        return f&quot;&lt;p&gt;Erro ao carregar imagem: {e}&lt;/p&gt;&quot;

# Aplicar o processamento de imagens diretamente no DataFrame
df_sample[&#39;image&#39;] = df_sample[&#39;coco_url&#39;].map(process_image)  # Pode ser URL ou caminho local

# Exibir as legendas e imagens formatadas em HTML
HTML(df_sample[[&#39;image&#39;, &#39;coco_url&#39;, &#39;caption&#39;]].head().to_html(escape=False))</code></pre>
</details>
<p><br></p>
<p><img src="/post/2024-09-27-image-text-to-text/df1.png" style="width: 100%;"></p>
<p>Caso voc√™ precise de mais imagens para testar, tamb√©m √© poss√≠vel encontrar uma <a href="https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset/data">vers√£o disponibilizada no Kaggle</a> .</p>
</div>
<div id="carregar-modelo" class="section level1">
<h1>Carregar modelo</h1>
<p>Utilizaremos uma vers√£o de 7 bilh√µes de par√¢metros do modelo <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf">‚ÄúLLaVA 1.5‚Äù</a> (Language and Vision Assistant), dispon√≠vel no HuggingFace (Uma plataforma onde a comunidade de Machine Learning colabora com modelos, dados e aplica√ß√µes) treinada para tarefas de gera√ß√£o de texto a partir de imagens.</p>
<pre class="python"><code>%%time

model_id = &quot;llava-hf/llava-1.5-7b-hf&quot;

# Configura√ß√£o de quantiza√ß√£o do modelo, que permite reduzir o uso de mem√≥ria sem 
# comprometer muito a precis√£o. Aqui estamos configurando para usar quantiza√ß√£o em 4 bits.
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,  
    bnb_4bit_use_double_quant=True,  
    bnb_4bit_quant_type=&quot;nf4&quot;,  
    bnb_4bit_compute_dtype=torch.bfloat16  
)

# Cria√ß√£o de um pipeline de processamento de imagens para gera√ß√£o de texto
# O pipeline √© configurado para a tarefa &quot;image-to-text&quot;
pipe = pipeline(
    &quot;image-to-text&quot;, 
    model=model_id, 
    model_kwargs={
        &quot;quantization_config&quot;: quantization_config,
        &quot;low_cpu_mem_usage&quot;: True
    }
)

# Carregar o processador associado respons√°vel por pr√©-processar
# as imagens de entrada e preparar os dados para serem inseridos no modelo
processor = AutoProcessor.from_pretrained(model_id)</code></pre>
<pre><code>CPU times: user 28.7 s, sys: 28.1 s, total: 56.8 s
Wall time: 6min 26s</code></pre>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† <strong>üìå Nota:</strong> A quantiza√ß√£o √© uma t√©cnica para reduzir o tamanho do modelo, perdendo um pouco de performance para otimizar o desempenho e rodar em m√°quinas com mem√≥ria limitada.</p>
</div>
</div>
<div id="prompt-engineering" class="section level1">
<h1>Prompt Engineering</h1>
<p>Uma ampla variedade de <a href="https://www.promptingguide.ai/pt">t√©cnicas</a> poderiam ser aplicadas para desenvolver <a href="https://python.langchain.com/docs/how_to/multimodal_prompts/">prompts</a> mais eficazes (inclusive com <a href="https://python.langchain.com/docs/introduction/">LangChain</a>, como fiz no <a href="https://gomesfellipe.github.io/post/2024-05-26-detec-o-de-linguagem-t-xica-com-o-llm-gemma-e-langchain/">√∫ltimo post</a>) ou especializar o modelo com ajuste fino visando obter resultados otimizados. No entanto, como este n√£o √© o foco do post, usarei um prompt simples e direto para estabelecer um baseline para avaliar as capacidades do modelo com o m√≠nimo de esfor√ßo.</p>
<pre class="python"><code># Cada valor em &quot;content&quot; tem que ser uma lista de dicion√°rio com os tipos (&quot;text&quot;, &quot;image&quot;) 
conversation = [
    {
      &quot;role&quot;: &quot;user&quot;,
      &quot;content&quot;: [
          {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Describe this image in a few words:&quot;},
          {&quot;type&quot;: &quot;image&quot;},
        ]
    },
]

# Formata a conversa (que pode incluir texto e imagens) no formato correto que o modelo entende.
prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)</code></pre>
<p>O <a href="https://colab.research.google.com/drive/1qsl6cd2c8gGtEW1xV5io7S8NHh-Cp1TV?usp=sharing#scrollTo=JvvtplWDRvfu">prompt</a> deve ser especificado no seguinte formato:</p>
<pre><code>USER: &lt;image&gt;
&lt;prompt&gt;
ASSISTANT:</code></pre>
</div>
<div id="infer√™ncia" class="section level1">
<h1>Infer√™ncia</h1>
<p>Com o modelo devidamente configurado e o prompt ajustado, estamos prontos para executar o pipeline de infer√™ncia. A vantagem de utilizar <a href="https://huggingface.co/docs/transformers/main_classes/pipelines#multimodal">pipelines</a> √© que eles abstraem boa parte da codifica√ß√£o complexa, proporcionando uma interface simples e eficiente. Essa API vers√°til √© dedicada a v√°rias tarefas, como NER (Reconhecimento de Entidades), An√°lise de Sentimentos, Extra√ß√£o de Features e Question Answering.</p>
<pre class="python"><code>for i in tqdm(range(df_sample.shape[0])):
    
    # preparar objetos do loop
    coco_url = df_sample.iloc[i][&#39;coco_url&#39;]
    caption = df_sample.iloc[i][&#39;caption&#39;]
    index = df_sample.iloc[i].name
    
    # Obter imagem
    response = requests.get(coco_url)
    image = Image.open(BytesIO(response.content))
    
    # Realizar a infer√™ncia usando o pipeline e o prompt gerado
    outputs = pipe(image, prompt=prompt, generate_kwargs={&quot;max_new_tokens&quot;: 32})
    
    # Processar o texto gerado para extrair a parte relevante
    result = outputs[0][&#39;generated_text&#39;].split(&#39;ASSISTANT:&#39;, 1)[1].strip()
    
    # Adicionar o resultado da infer√™ncia √† nova coluna &#39;llm&#39; do DataFrame
    df_sample.loc[index, &#39;llm&#39;] = result</code></pre>
<pre><code>100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:41&lt;00:00,  4.20s/it]</code></pre>
<p>Ap√≥s a execu√ß√£o do modelo, veja como ficaram os resultados:</p>
<details>
<summary>
<em>Expandir c√≥digo</em>
</summary>
<pre class="python"><code># Fun√ß√£o para destacar as palavras
def highlight_diff(caption, llm):
    # Divide as frases em palavras
    caption_words = caption.replace(&quot;.&quot;, &quot;&quot;).split()
    llm_words = llm.replace(&quot;.&quot;, &quot;&quot;).split()
    
    # Converte as palavras em conjuntos para encontrar a interse√ß√£o
    caption_set = set(caption_words)
    llm_set = set(llm_words)
    
    # Calcula as palavras que n√£o est√£o na interse√ß√£o
    caption_highlighted = &quot; &quot;.join([f&#39;&lt;span style=&quot;color:red&quot;&gt;{word}&lt;/span&gt;&#39; if word not in llm_set else word for word in caption_words])
    llm_highlighted = &quot; &quot;.join([f&#39;&lt;span style=&quot;color:red&quot;&gt;{word}&lt;/span&gt;&#39; if word not in caption_set else word for word in llm_words])
    
    return caption_highlighted, llm_highlighted

# Aplica a fun√ß√£o a cada linha do DataFrame e cria novas colunas
df_sample[&#39;highlighted_caption&#39;], df_sample[&#39;highlighted_llm&#39;] = zip(*df_sample.apply(lambda row: highlight_diff(row[&#39;caption&#39;], row[&#39;llm&#39;]), axis=1))

# Exibir o DataFrame formatado com HTML
HTML(df_sample[[&#39;image&#39;, &#39;highlighted_caption&#39;, &#39;highlighted_llm&#39;]].to_html(escape=False))</code></pre>
</details>
<p><br></p>
<p><img src="/post/2024-09-27-image-text-to-text/df2.png" alt="extra√ß√£o de r√≥tulos descritivos de imagens com Llava" style="width: 100%;"></p>
<p>Destaquei em vermelho as palavras que diferem entre a legenda original do dataset e a previs√£o gerada pelo nosso modelo de linguagem.</p>
<div class="w3-panel w3-pale-yellow w3-border">
<p>¬† üí≠ Apesar de algumas diferen√ßas sutis entre as duas vers√µes, como ‚Äòlooking at his phone‚Äô e ‚Äòlooking at his <span style="color:red;">cell</span> phone‚Äô, a ideia principal permanece bastante coerente com o que vemos nas imagens. Em alguns casos, como no item 3, a descri√ß√£o gerada pelo modelo, ‚Äòholding a <span style="color:red;">kite</span>‚Äô, parece at√© mais apropriada do que a fornecida pelo dataset, ‚Äòholding a <span style="color:red;">flag</span>‚Äô.</p>
</div>
<p>Agora, o pr√≥ximo passo ser√° quantificar essas diferen√ßas de maneira num√©rica.</p>
</div>
<div id="avaliar-modelo" class="section level1">
<h1>Avaliar modelo</h1>
<p>Para medir a precis√£o das legendas geradas, aplicaremos quatro m√©tricas amplamente usadas:</p>
<ul>
<li><strong><a href="https://aclanthology.org/P02-1040.pdf">BLEU</a> (Bilingual Evaluation Understudy Score)</strong>: Amplamente utilizada para medir a qualidade de tradu√ß√µes autom√°ticas, mede a <strong>sobreposi√ß√£o de n-gramas</strong> entre a tradu√ß√£o gerada por um modelo e as tradu√ß√µes de refer√™ncia, atribuindo uma pontua√ß√£o que varia de 0 a 1 (aplica tamb√©m um fator de penaliza√ß√£o para evitar que tradu√ß√µes curtas sejam favorecidas);</li>
<li><strong><a href="https://aclanthology.org/W04-1013.pdf">ROUGE-L</a> (Recall-Oriented Understudy for Gisting Evaluation)</strong>: Muito utilizado em tarefa de sumariza√ß√£o de textos, considera a sequ√™ncia mais longa de palavras que aparecem em ambas as refer√™ncias e previs√µes, medindo a capacidade de preservar a <strong>ordem das palavras</strong>;</li>
<li><strong><a href="https://www.cs.cmu.edu/~alavie/METEOR/">METEOR</a> (Metric for Evaluation of Translation with Explicit ORdering)</strong>: Baseada na m√©dia harm√¥nica da precis√£o e recall de n-gramas, com recall ponderado mais alto do que a precis√£o. Essa m√©trica METEOR foi projetada para corrigir alguns dos problemas (como encontrar sin√¥nimos) nas m√©tricas BLEU e ROGUE;</li>
<li><strong><a href="https://huggingface.co/spaces/evaluate-metric/bertscore">BERTScore</a></strong>: Usa embeddings (representa√ß√µes sem√¢nticas) obtidas a partir do modelo BERT para comparar a similaridade sem√¢ntica entre as descri√ß√µes geradas e as de refer√™ncia.</li>
</ul>
<details>
<summary>
<em>Expandir c√≥digo</em>
</summary>
<pre class="python"><code># Fun√ß√µes para calcular as m√©tricas
def calcular_bleu(referencias, previsao):
    return sentence_bleu([referencias.split(&quot; &quot;)], previsao.split(&quot; &quot;),weights = [1])

def calcular_rouge(referencias, previsao):
    scorer = rouge_scorer.RougeScorer([&#39;rougeL&#39;], use_stemmer=True)
    return scorer.score(referencias, previsao)[&#39;rougeL&#39;].fmeasure

def calcular_meteor(referencias, previsao):
    return meteor_score([referencias.split(&quot; &quot;)], previsao.split(&quot; &quot;))

def calcular_bertscore(referencias, previsao):
    P, R, F1 = bert_score([previsao], [referencias], lang=&quot;en&quot;, verbose=True)
    return F1.mean().item()</code></pre>
</details>
<p><br></p>
<pre class="python"><code>%%capture

# Avaliar as amostras no DataFrame
resultados = []
for i, row in df_sample.iterrows():
    
    referencias = row[&#39;caption&#39;].replace(&quot;.&quot;, &quot;&quot;)
    previsao = row[&#39;llm&#39;].replace(&quot;.&quot;, &quot;&quot;)
    
    bleu = calcular_bleu(referencias, previsao)
    rouge = calcular_rouge(referencias, previsao)
    meteor = calcular_meteor(referencias, previsao)
    bert = calcular_bertscore(referencias, previsao)
    
    resultados.append([referencias, previsao, bleu, rouge, meteor, bert])

# Converter os resultados para um DataFrame
df_resultados = pd.DataFrame(resultados, columns=[&#39;caption&#39;, &#39;llm&#39;, &#39;BLEU&#39;, &#39;ROUGE&#39;, &#39;METEOR&#39;, &#39;BERTScore&#39;])</code></pre>
<p>Vejamos os resultados:</p>
<details>
<summary>
<em>Expandir c√≥digo</em>
</summary>
<pre class="python"><code># Configurar o tema do Seaborn
sns.set_theme(style=&quot;white&quot;, rc={&quot;axes.facecolor&quot;: (0, 0, 0, 0)})

# Reformatar o DataFrame para o formato long
df_long = df_resultados[[&#39;BLEU&#39;, &#39;ROUGE&#39;, &#39;METEOR&#39;, &#39;BERTScore&#39;]].melt(var_name=&quot;M√©trica&quot;, value_name=&quot;Valor&quot;)

# Calcular a m√©dia de cada m√©trica
mean_values = df_long.groupby(&#39;M√©trica&#39;)[&#39;Valor&#39;].mean().reset_index()

# Inicializar o objeto FacetGrid
pal = sns.cubehelix_palette(len(df_long[&#39;M√©trica&#39;].unique()), rot=-.25, light=.7)
g = sns.FacetGrid(df_long, row=&quot;M√©trica&quot;, hue=&quot;M√©trica&quot;, aspect=6, height=1.5, palette=pal)

# Desenhar as densidades
g.map(sns.kdeplot, &quot;Valor&quot;, 
      bw_adjust=.5, clip_on=False, 
      fill=True, alpha=1, linewidth=1.5)
g.map(sns.kdeplot, &quot;Valor&quot;, clip_on=False, color=&quot;w&quot;, lw=2, bw_adjust=.5)

# Adicionar linha de refer√™ncia
g.refline(y=0, linewidth=2, linestyle=&quot;-&quot;, color=None, clip_on=False)

# Fun√ß√£o para rotular o gr√°fico
def label(x, color, label):
    ax = plt.gca()
    # Localizar a m√©dia correspondente √† m√©trica
    mean_value = mean_values[mean_values[&#39;M√©trica&#39;] == label][&#39;Valor&#39;].values[0]
    ax.text(0, .4, f&quot;{label} (M√©dia: {mean_value:.2f})&quot;, fontweight=&quot;bold&quot;, color=color,
            ha=&quot;left&quot;, va=&quot;center&quot;, transform=ax.transAxes, fontsize=20)

g.map(label, &quot;Valor&quot;)

# Ajustar espa√ßamento entre subplots manualmente
g.figure.subplots_adjust(hspace=0.2)

# Remover detalhes desnecess√°rios dos eixos
g.set_titles(&quot;&quot;)
g.set(yticks=[], ylabel=&quot;&quot;)
g.despine(bottom=True, left=True)

# Configurar o eixo x
g.set(xlim=(0.4, 1), xticks=np.arange(0.4, 1.05, 0.1))  # Limites e ticks do eixo x

# Remover r√≥tulos do eixo x em cada subplot
for ax in g.axes.flat:
    ax.set_xlabel(&quot;&quot;)  # Remover r√≥tulo do eixo x
    ax.tick_params(axis=&#39;x&#39;, labelsize=16)  # Aumentar o tamanho da fonte dos ticks do eixo x

# Exibir o gr√°fico
plt.show()</code></pre>
</details>
<p><br></p>
<center>
<img src="/post/2024-09-27-image-text-to-text/metrics.png" alt="metricas da extra√ß√£o de r√≥tulos descritivos de imagens com Llava" style="width: 80%;">
</center>
<div class="w3-panel w3-pale-yellow w3-border">
<p>¬† <strong>üìå Insights ao Avaliar as M√©tricas do Modelo: </strong></p>
<ul>
<li><p>As m√©tricas baseadas em <strong>n-grams e na correspond√™ncia de palavras</strong> mostraram desempenho <strong>subestimado</strong>. Embora o modelo tenha apresentado algumas varia√ß√µes na escolha das palavras, as frases geradas mantiveram um sentido geral muito semelhante ao que √© retratado nas imagens.</p></li>
<li><p>Por outro lado, a m√©trica baseada em <strong>embeddings</strong>, que avalia o significado <strong>sem√¢ntico</strong> das frases, apresentou resultados <strong>significativamente superiores</strong>. Essa abordagem se mostrou mais congruente em avaliar a similaridade das descri√ß√µes geradas e a descri√ß√£o informada do conte√∫do visual das imagens.</p></li>
<li><p>√â importante ressaltar que nosso <strong>prompt</strong> foi mantido na forma <strong>mais simples poss√≠vel</strong> e que o conjunto de dados abrange um <strong>escopo bastante amplo</strong>. Com isso, acredito que o modelo ainda tem muito potencial para oferecer resultados ainda mais robustos, sem a necessidade de ajustes finos, em tarefas mais espec√≠ficas.</p></li>
</ul>
</div>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o</h1>
<p>O uso da GenAI com o modelo Llava oferece uma solu√ß√£o eficiente para a extra√ß√£o de features de imagens em Python, possibilitando a cria√ß√£o de descri√ß√µes ricas e detalhadas. Ao comparar a qualidade das sa√≠das com m√©tricas como BLEU, podemos garantir que o modelo esteja oferecendo resultados satisfat√≥rios para as necessidades do projeto.</p>
<p>Se voc√™ deseja automatizar processos de an√°lise de imagens, explorar a cria√ß√£o de modelos customizados ou otimizar a organiza√ß√£o de dados visuais, a utiliza√ß√£o de GenAI com modelos como o Llava pode ser um divisor de √°guas em seus projetos.</p>
<p>Se este conte√∫do foi √∫til, continue acompanhando o blog para mais tutoriais sobre intelig√™ncia artificial e Python!</p>
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias</h1>
<ul>
<li><a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" class="uri">https://huggingface.co/llava-hf/llava-1.5-7b-hf</a></li>
<li><a href="https://github.com/haotian-liu/LLaVA" class="uri">https://github.com/haotian-liu/LLaVA</a></li>
<li><a href="https://colab.research.google.com/drive/1qsl6cd2c8gGtEW1xV5io7S8NHh-Cp1TV?usp=sharing#scrollTo=6Bx8iu9jOssW" class="uri">https://colab.research.google.com/drive/1qsl6cd2c8gGtEW1xV5io7S8NHh-Cp1TV?usp=sharing#scrollTo=6Bx8iu9jOssW</a></li>
<li><a href="https://cocodataset.org/#explore" class="uri">https://cocodataset.org/#explore</a></li>
<li><a href="https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset/" class="uri">https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset/</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2024-09-27-image-text-to-text/">Extra√ß√£o de informa√ß√µes de imagens com IA Generativa</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">chatgpt</category>
      <category domain="tag">data-science</category>
      <category domain="tag">genai</category>
      <category domain="tag">ia-generativa</category>
      <category domain="tag">inteligencia-artificial</category>
      <category domain="tag">llama</category>
      <category domain="tag">llama2</category>
      <category domain="tag">llava</category>
      <category domain="tag">llm</category>
      <category domain="tag">lmm</category>
    </item>
    <item>
      <title>Detec√ß√£o de Linguagem T√≥xica com o LLM Gemma e LangChain</title>
      <link>https://gomesfellipe.github.io/post/2024-05-26-detec-o-de-linguagem-t-xica-com-o-llm-gemma-e-langchain/</link>
      <pubDate>Sun, 26 May 2024 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2024-05-26-detec-o-de-linguagem-t-xica-com-o-llm-gemma-e-langchain/</guid>
      <description>Neste post utilizaremos o modelo Gemma de IA generativa do Google com framework LangChain auxiliando na tarefa de prompt engineering</description>
      <content:encoded>&lt;![CDATA[
        


<div id="caso-de-uso-de-ia-generativa-detec√ß√£o-de-linguagem-t√≥xica-em-m√≠dias-sociais" class="section level1">
<h1>Caso de Uso de IA Generativa: Detec√ß√£o de Linguagem T√≥xica em M√≠dias Sociais</h1>
<hr />
<p>Neste post, realizaremos a tarefa de detec√ß√£o de linguagem t√≥xica em m√≠dias sociais usando o modelo <a href="https://ai.google.dev/gemma?hl=pt-br">Gemma</a> de IA generativa do Google com o framework <a href="https://www.langchain.com/">LangChain</a>. Vamos explorar como o texto de entrada afeta a sa√≠da do modelo e faremos alguma engenharia de prompts para direcion√°-lo √† tarefa necess√°ria.</p>
</div>
<div id="setup" class="section level1">
<h1>Setup</h1>
<p>Utilizaremos o ambiente do Kaggle para desenvolvimento deste notebook, que disponibiliza a utiliza√ß√£o de GPUs. Atrav√©s do <em>Hardware Accelerator</em> utilizaremos a <a href="https://www.kaggle.com/docs/efficient-gpu-usage">NVIDIA TESLA P100 GPU</a>.</p>
<div id="instalar-e-carregar-dependencias" class="section level2">
<h2>Instalar e carregar dependencias</h2>
<p>Vamos instalar as bibliotecas <code>accelerate</code> e <code>bitsandbytes</code> que possibilitam a quantiza√ß√£o de LLMs e algumas bibliotecas do framework LangChain</p>
<pre class="python"><code>!pip install accelerate
!pip install -i https://pypi.org/simple/ bitsandbytes
!pip install langchain langchain_huggingface langchain_community langchain_chroma</code></pre>
</div>
<div id="carregar-bibliotecas" class="section level2">
<h2>Carregar bibliotecas</h2>
<pre class="python"><code>import pandas as pd
import torch 
import re

from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline
from langchain_huggingface import HuggingFacePipeline
from langchain_core.prompts.few_shot import PromptTemplate, FewShotPromptTemplate
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_chroma import Chroma</code></pre>
</div>
<div id="carregar-fun√ß√µes-auxiliares" class="section level2">
<h2>Carregar fun√ß√µes auxiliares</h2>
<p>Carregar uma fun√ß√£o para limpeza simples dos tweets.</p>
<details>
<summary>
<em>Clique aqui para ver os c√≥digos</em>
</summary>
<pre class="python"><code>def clean_tweet(text):
    &quot;&quot;&quot;
    src: https://github.com/lrdsouza/told-br-classifier
    &quot;&quot;&quot;
    text = text.replace(&#39;rt @user&#39;, &#39;&#39;)
    text = text.replace(&#39;@user&#39;, &#39;&#39;)
    pattern = re.compile(&#39;[^a-zA-Z0-9\s√°√©√≠√≥√∫√†√®√¨√≤√π√¢√™√Æ√¥√ª√£√µ√ß√Å√â√ç√ì√ö√Ä√à√å√í√ô√Ç√ä√é√î√õ√É√ï√á]&#39;)
    text = re.sub(r&#39;http\S+&#39;, &#39;&#39;, text)
    text = pattern.sub(r&#39; &#39;, text)
    text = text.replace(&#39;\n&#39;, &#39; &#39;)
    text = &#39; &#39;.join(text.split())
    return text</code></pre>
</details>
<p>¬†</p>
</div>
</div>
<div id="carregar-dados" class="section level1">
<h1>Carregar dados</h1>
<hr />
<p>Vamos utilizar o conjunto de dados <a href="https://github.com/JAugusto97/ToLD-Br">TolD-br</a>, um recurso interessante para o estudo da toxicidade em conte√∫dos online em portugu√™s brasileiro. Este dataset foi utilizado na competi√ß√£o <a href="https://www.kaggle.com/competitions/ml-olympiad-toxic-language-ptbr-detection">ML Olympiad - Toxic Language (PTBR) Detection</a>, organizada pelo <a href="https://www.youtube.com/@tensorflowugsp">TensorFlow UGSP</a> no Kaggle este ano. A competi√ß√£o convidou entusiastas de dados, cientistas e pesquisadores a desenvolverem modelos de machine learning capazes de classificar tweets em portugu√™s brasileiro como t√≥xicos ou n√£o t√≥xicos.</p>
<pre class="python"><code>train = pd.read_csv(&quot;/kaggle/input/ml-olympiad-toxic-language-ptbr-detection/train (2).csv&quot;)
test = pd.read_csv(&quot;/kaggle/input/ml-olympiad-toxic-language-ptbr-detection/test (4).csv&quot;)
sub = pd.read_csv(&quot;/kaggle/input/ml-olympiad-toxic-language-ptbr-detection/sample_submission.csv&quot;)</code></pre>
<p>Selecionar uma amostra para auxiliar no desenvolvimento do prompt para utiliza√ß√£o em novos dados:</p>
<pre class="python"><code>valid = train.sample(n=100, random_state=123)</code></pre>
<div id="preparar-dados" class="section level2">
<h2>Preparar dados</h2>
<p>Aplicar limpeza b√°sica para preparar os tweets.</p>
<details>
<summary>
<em>Clique aqui para ver os c√≥digos</em>
</summary>
<pre class="python"><code>train[&#39;text&#39;] = train.text.apply(lambda x: clean_tweet(x))
valid[&#39;text&#39;] = valid.text.apply(lambda x: clean_tweet(x))
test[&#39;text&#39;] = test.text.apply(lambda x: clean_tweet(x))</code></pre>
</details>
<p>¬†</p>
</div>
</div>
<div id="carregar-modelo" class="section level1">
<h1>Carregar Modelo</h1>
<hr />
<p>Neste notebook, faremos uso de um modelo da fam√≠lia <a href="https://ai.google.dev/gemma?hl=pt-br">Gemma</a>, desenvolvida pelo Google, que consiste em modelos leves e de c√≥digo aberto constru√≠dos com base em pesquisas e tecnologias empregadas no desenvolvimento dos modelos <a href="https://gemini.google.com/">Gemini</a></p>
<div class="w3-panel w3-pale-yellow w3-border">
<p>¬† <strong>üìå Nota:</strong> Para utilizar o modelo √© necess√°rio consentir com a <a href="https://www.kaggle.com/models/google/gemma/license/consent?returnUrl=%2Fmodels%2Fgoogle%2Fgemma%2Ftransformers">licen√ßa do Gemma</a> com o preenchimento de um formul√°rio dispon√≠vel na <a href="https://www.kaggle.com/models/google/gemma">p√°gina do modelo</a>.</p>
</div>
<p>Utilizaremos a implementa√ß√£o do <a href="https://huggingface.co/google/gemma-7b-it">Gemma-7b-instruct</a>, que √© uma variante ajustada por instru√ß√£o (IT) que pode ser usada para bate-papo e/ou seguir instru√ß√µes.</p>
<pre class="python"><code># Caminho para o modelo dispon√≠vel pelo ambiente do Kaggle
model_path = &quot;/kaggle/input/gemma/transformers/1.1-7b-it/1/&quot;

# Definir configuracoes de quantizacao para reduzir 
# o tamanho do modelo perdendo pouca performance
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type=&quot;nf4&quot;,
    bnb_4bit_compute_dtype=torch.bfloat16
)

# Instanciar o tokenizador do LLM
tokenizer = AutoTokenizer.from_pretrained(model_path)

# Instanciar o LLM
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    quantization_config=quantization_config,
    low_cpu_mem_usage=True, 
    device_map=&quot;auto&quot;
)</code></pre>
<p>Vamos carregar tamb√©m um modelo de embedding que utilizaremos para auxiliar na constru√ß√£o do nosso prompt:</p>
<pre class="python"><code>embeddings = HuggingFaceEmbeddings(model_name=&quot;all-MiniLM-L6-v2&quot;)</code></pre>
<div id="preparar-modelo" class="section level2">
<h2>Preparar modelo</h2>
<p>Os modelos da Hugging Face podem ser facilmente executados localmente utilizando a classe <code>HuggingFacePipeline</code>. O <a href="https://huggingface.co/models">Hugging Face Model Hub</a> √© um reposit√≥rio que abriga mais de 120 mil modelos, 20 mil conjuntos de dados e 50 mil aplicativos de demonstra√ß√£o (Spaces), todos de c√≥digo aberto e dispon√≠veis publicamente. Esta plataforma online permite que as pessoas colaborem facilmente e construam modelos de machine learning juntas.</p>
<pre class="python"><code># Instanciar um pipeline transformers
pipe = pipeline(
    model=model,
    tokenizer=tokenizer,
    task=&quot;text-generation&quot;,
    max_new_tokens=1,
)

# Passar o pipeline para a classe do LangChain
llm = HuggingFacePipeline(pipeline=pipe)</code></pre>
</div>
</div>
<div id="prompt-engineering" class="section level1">
<h1>Prompt Engineering</h1>
<hr />
<p>Para resolver este problema, criaremos um template de prompt que utiliza a estrat√©gia few-shot, que pode ser constru√≠do a partir de um conjunto de exemplos. O conjunto de exemplos ser√° din√¢mico, sendo constru√≠do com base em tweets que possuem a maior similaridade semantica com o tweet de entrada.</p>
<div id="preparar-exemplos" class="section level2">
<h2>Preparar exemplos</h2>
<p>Selecionaremos os exemplos candidatos do conjunto de dados de treino que n√£o estejam no dataset de valida√ß√£o. Cada exemplo de entrada deve ser um dicion√°rio onde:</p>
<ul>
<li><code>key</code>: o nome das vari√°veis de inputs do prompt;</li>
<li><code>values</code>: os valores dos inputs.</li>
</ul>
<pre class="python"><code># indices de instancias que nao estao no dataset de validacao (evitar leak)
idx_train_examples = train.loc[~train.index.isin(valid.index)].index

# organizar a lista com os exemplos candidatos
examples = [{&#39;tweet&#39;: train.text[i], 
             &#39;label&#39;: str(train.label[i])} for i in idx_train_examples]</code></pre>
</div>
<div id="criar-template-para-os-exemplos-com-prompttemplate" class="section level2">
<h2>Criar template para os exemplos com <code>PromptTemplate</code></h2>
<p>Agora precisamos instanciar um <code>PromptTemplate</code> para nosso prompt, que recebe um template das instru√ß√µes que desejamos passar para o LLM e os inputs que alimentam este template:</p>
<pre class="python"><code>example_template = &quot;&quot;&quot;
Tweet: {tweet}
Label: {label}
&quot;&quot;&quot;

# Instanciar o exemplo de prompt 
example_prompt = PromptTemplate(
    input_variables=[&quot;tweet&quot;, &quot;label&quot;], 
    template=example_template
)</code></pre>
</div>
<div id="inserir-exemplos-com-exampleselector" class="section level2">
<h2>Inserir exemplos com <code>ExampleSelector</code></h2>
<p>Agora vamos instanciar <code>SemanticSimilarityExampleSelector</code> para selecionar exemplos com base em sua semelhan√ßa com a entrada. Ele usa um modelo de embedding para calcular a similaridade entre a entrada e os exemplos de few-shot, bem como um armazenamento de vetores <a href="https://www.trychroma.com/">Chroma</a> para realizar a pesquisa do vizinho mais pr√≥ximo de maneira eficiente.</p>
<pre class="python"><code>example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples = examples,
    embeddings = embeddings,
    vectorstore_cls = Chroma,
    k=3,
)</code></pre>
<p>Aumentar o n√∫mero de vizinhos mais pr√≥ximos n√£o garantir√° necessariamente resultados melhores. Normalmente k=6 no m√°ximo j√° √© suficiente. Se n√£o conseguir bons resultados assim, j√° seria mais indicado realizar um ajuste fino mesmo.</p>
</div>
<div id="preparar-o-fewshotprompttemplate" class="section level2">
<h2>Preparar o <code>FewShotPromptTemplate</code></h2>
<p>Finalmente, vamos definir a formata√ß√£o para a apresenta√ß√£o dos exemplos e, em seguida, usar <code>FewShotPromptTemplate</code> para para gerar o template final que ser√° utilizado como prompt com base nos valores de entrada.</p>
<pre class="python"><code>prefix = &quot;&quot;&quot;The following tweets are written in Brazilian Portuguese. \n\
You are a tweet classifier that identifies \
toxic language as 1 and non-toxic language as 0. \n\
Here are some examples:&quot;&quot;&quot;

suffix = &quot;&quot;&quot;
Tweet: {tweet} 
Label: &quot;&quot;&quot;

prompt = FewShotPromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
    prefix=prefix,
    suffix=suffix,
    example_separator=&#39;\n&#39;,
    input_variables=[&quot;tweet&quot;],
)</code></pre>
<p>Vejamos como ser√° a formata√ß√£o do prompt para a classifica√ß√£o de cada tweet:</p>
<pre class="python"><code>print(prompt.format(tweet=valid.head(1).text.values[0]))</code></pre>
<pre><code>## The following tweets are written in Brazilian Portuguese. 
## You are a tweet classifier that identifies toxic language as 1 and non-toxic language as 0. 
## Here are some examples:
## 
## Tweet: caralho eu tenho q fazer alguma coisa mt importante mas eu esqueci o que √© ent√£o n deve ser importante
## Label: 1
## 
## Tweet: caralho as pessoas fazem me sentir a pessoa mais bosta e odiada poss√≠vel eu t√¥ bem
## Label: 0
## 
## Tweet: tenho quase certeza que isso e um homem escroto fingindo ser mulher kkkkkkkkk por um momento eu tbm pensei nisso
## Label: 0
## 
## Tweet: vei se um filho faz isso cmg eu pego o sandu√≠che e enfio no cu dele
## Label: </code></pre>
</div>
<div id="definir-custom-output-parsers" class="section level2">
<h2>Definir <code>Custom Output Parsers</code></h2>
<p>Para concluir a cadeia, vamos definir uma fun√ß√£o que funcione como um <a href="https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/custom/">Custom Output Parser</a>, que ser√° respons√°vel por pegar a sa√≠da do LLM e transform√°-la no formato mais adequado para nosso caso. Precisamos apenas do √∫ltimo caractere que ser√° retornado pelo LLM.</p>
<pre class="python"><code>def parse(response):
    &quot;&quot;&quot;Retorna apenas o ultimo caracter da sa√≠da do LLM&quot;&quot;&quot;
    return int(response[-1:])</code></pre>
</div>
<div id="definir-cadeira-langchain" class="section level2">
<h2>Definir Cadeira LangChain</h2>
<p><a href="https://python.langchain.com/v0.1/docs/modules/chains/">Chains</a> referem-se √† sequ√™ncias de chamadas - seja para um LLM, uma etapa de pr√©-processamento de dados, <a href="https://python.langchain.com/v0.1/docs/modules/tools/">tools</a>, ou ainda etapas de p√≥s-processamento do output gerado pelo modelo. As cadeias constru√≠das desta forma s√£o boas porque oferecem suporte nativo a streaming, ass√≠ncrono e infer√™ncia em batchs para uso.</p>
<pre class="python"><code>chain = prompt | llm | parse</code></pre>
<p>Vamos testar o comportamento da nossa cadeia em 1 tweet:</p>
<pre class="python"><code>print(f&quot;&quot;&quot;Tweet: {valid.head(1).text.values[0]}
Label: {valid.head(1).label.values[0]}
Predict: {chain.invoke({&#39;tweet&#39;:  valid.head(1).text.values[0]})}&quot;&quot;&quot;)</code></pre>
<pre><code>## Tweet: vei se um filho faz isso cmg eu pego o sandu√≠che e enfio no cu dele
## Label: 1
## Predict: 1</code></pre>
<p>Claramente um conte√∫do t√≥xico e que foi classificado corretamente. Mas como queremos realizar a chamada da nossa cadeia para diversos tweets do dataset de test, utilizaremos o m√©todo <code>.batch()</code> que executa a cadeia para uma lista de entradas:</p>
<pre class="python"><code>%%time
valid[&#39;predict&#39;] = chain.batch([{&#39;tweet&#39;: x} for x in valid.text])</code></pre>
<pre><code>## CPU times: user 1min 26s, sys: 24.8 s, total: 1min 51s
## Wall time: 1min 50s</code></pre>
</div>
<div id="avaliar-resultados" class="section level2">
<h2>Avaliar resultados</h2>
<p>Como a m√©trica de avalia√ß√£o da competi√ß√£o era a acur√°cia, vamos dar uma olhada em como ficou a matriz de confus√£o:</p>
<details>
<summary>
<em>Clique aqui para ver o c√≥digo do gr√°fico</em>
</summary>
<pre class="python"><code># Calcular m√©tricas
cm = confusion_matrix(valid.label, valid.predict)
acc=accuracy_score(valid.label, valid.predict)

# Configura√ß√µes de estilo do seaborn
sns.set(font_scale=1.2)
plt.figure(figsize=(5, 3))

# Plotar Matriz de Confus√£o para o m√©todo Vader em ingl√™s
sns.heatmap(cm, annot=True, fmt=&#39;d&#39;, cmap=&#39;binary&#39;, cbar=False,vmin=0, vmax=50,
            xticklabels=[&#39;N√£o T√≥xico&#39;, &#39;T√≥xico&#39;], yticklabels=[&#39;N√£o T√≥xico&#39;, &#39;T√≥xico&#39;])
plt.title(f&#39;Matriz de Confus√£o\nAcur√°cia: {acc:.0%}&#39;, fontsize=22)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.xlabel(&#39;Previsto&#39;, fontsize=14)
plt.ylabel(&#39;Real&#39;, fontsize=14)
plt.show()</code></pre>
</details>
<p>¬†</p>
<center>
<img src="/post/2024-05-26-detec-o-de-linguagem-t-xica-com-o-llm-gemma-e-langchain/cm.png" />
</center>
</div>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o</h1>
<hr />
<p>Embora nosso objetivo n√£o fosse alcan√ßar a perfei√ß√£o em termos de acur√°cia, at√© que o resultado foi satisfat√≥rio, dado o potencial dessa ferramenta para resolver uma ampla gama de problemas com poucas modifica√ß√µes nos c√≥digos. Existem muitos outros caminhos a serem explorados (inclusive recomendo assistir √† <a href="https://www.youtube.com/watch?v=bzU_STGxj7o&amp;t=6s">live no YouTube</a> em que os vencedores apresentaram solu√ß√µes muito mais eficientes), nosso foco aqui foi praticar, aplicar e documentar alguns conceitos interessantes e √∫teis sobre LLMs e LangChain.</p>
</div>
<div id="referencias" class="section level1">
<h1>Referencias</h1>
<hr />
<ul>
<li><a href="https://www.kaggle.com/competitions/ml-olympiad-toxic-language-ptbr-detection" class="uri">https://www.kaggle.com/competitions/ml-olympiad-toxic-language-ptbr-detection</a></li>
<li><a href="https://www.kaggle.com/models/google/gemma/transformers" class="uri">https://www.kaggle.com/models/google/gemma/transformers</a></li>
<li><a href="https://huggingface.co/google/gemma-1.1-7b-it" class="uri">https://huggingface.co/google/gemma-1.1-7b-it</a></li>
<li><a href="https://python.langchain.com/v0.1/docs/modules/model_io/prompts/few_shot_examples/" class="uri">https://python.langchain.com/v0.1/docs/modules/model_io/prompts/few_shot_examples/</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2024-05-26-detec-o-de-linguagem-t-xica-com-o-llm-gemma-e-langchain/">Detec√ß√£o de Linguagem T√≥xica com o LLM Gemma e LangChain</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category>Texto e NLP</category>
      <category domain="tag">chatgpt</category>
      <category domain="tag">classification</category>
      <category domain="tag">data-science</category>
      <category domain="tag">gemma</category>
      <category domain="tag">google</category>
      <category domain="tag">inteligencia-artificial</category>
      <category domain="tag">kaggle</category>
      <category domain="tag">llm</category>
      <category domain="tag">machine-learning</category>
      <category domain="tag">prophet</category>
    </item>
    <item>
      <title>An√°lise de Sentimentos com um &#34;ChatGPT&#34; de C√≥digo Aberto</title>
      <link>https://gomesfellipe.github.io/post/2024-04-20-sentiment-analysis-llama2/</link>
      <pubDate>Sat, 20 Apr 2024 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2024-04-20-sentiment-analysis-llama2/</guid>
      <description>Como executar localmente o LLM pr√©-treinado de c√≥digo aberto Llama2 para realizar uma an√°lise de sentimentos em Python</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#por-que-an%C3%A1lise-de-sentimentos" id="toc-por-que-an√°lise-de-sentimentos">Por que An√°lise de Sentimentos?</a></li>
<li><a href="#por-que-large-language-models" id="toc-por-que-large-language-models">Por que Large Language Models?</a></li>
<li><a href="#o-que-faremos-aqui" id="toc-o-que-faremos-aqui">O que faremos aqui?</a></li>
<li><a href="#m%C3%A3os-a-obra" id="toc-m√£os-a-obra">M√£os a obra!</a>
<ul>
<li><a href="#iniciar-ambiente-de-trabalho" id="toc-iniciar-ambiente-de-trabalho">Iniciar ambiente de trabalho</a></li>
<li><a href="#carregar-dados" id="toc-carregar-dados">Carregar dados</a></li>
<li><a href="#informa%C3%A7%C3%B5es-gerais" id="toc-informa√ß√µes-gerais">Informa√ß√µes gerais</a></li>
<li><a href="#an%C3%A1lise-explorat%C3%B3ria" id="toc-an√°lise-explorat√≥ria">An√°lise Explorat√≥ria</a></li>
<li><a href="#an%C3%A1lise-de-sentimentos" id="toc-an√°lise-de-sentimentos">An√°lise de Sentimentos</a></li>
</ul></li>
<li><a href="#resultado-final" id="toc-resultado-final">Resultado Final</a></li>
<li><a href="#conclus%C3%A3o-e-discuss%C3%A3o" id="toc-conclus√£o-e-discuss√£o">Conclus√£o e Discuss√£o</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias</a></li>
</ul>
</div>

<style>
.column4 {
  float: left;
  width: 33%;
  padding: 10px;
}
 
.column8 {
  float: left;
  width: 66%;
  padding: 10px;
}

.column6 {
  float: left;
  width: 50%;
  padding: 10px;
}

.row:after {
  content: "";
  display: table;
  clear: both;
}
</style>
<div id="por-que-an√°lise-de-sentimentos" class="section level2">
<h2>Por que An√°lise de Sentimentos?</h2>
<p>Compreender os sentimentos por tr√°s de grandes volumes de texto tornou-se essencial, pois em um mundo cada vez mais digitalizado, a capacidade de compreender as respostas e emo√ß√µes em larga escala das pessoas diante de produtos, eventos ou t√≥picos espec√≠ficos n√£o √© apenas valiosa por fornecer insights, mas tamb√©m se tornou uma necessidade para alavancar neg√≥cios e tornar-se cada vez mais competitivo.</p>
<blockquote>
<p>An√°lise de sentimento, tamb√©m chamada de minera√ß√£o de opini√£o, √© o campo de estudo que analisa as opini√µes, sentimentos, avalia√ß√µes, aprecia√ß√µes, atitudes e emo√ß√µes das pessoas em rela√ß√£o a entidades como produtos, servi√ßos, organiza√ß√µes, indiv√≠duos, quest√µes, eventos, t√≥picos e seus atributos. <a href="https://www.cambridge.org/de/universitypress/subjects/computer-science/artificial-intelligence-and-natural-language-processing/sentiment-analysis-mining-opinions-sentiments-and-emotions-2nd-edition?format=HB&amp;isbn=9781108486378">Liu 2020</a></p>
</blockquote>
</div>
<div id="por-que-large-language-models" class="section level2">
<h2>Por que Large Language Models?</h2>
<p>A abordagem comum para resolver problemas de NLP envolviam a aplica√ß√£o de <em>text mining</em>, <em>embeddings</em> como <em>word2vec</em> e <em>GloVe (Global Vectors for Word Representation)</em> e t√©cnicas de Machine Learning, onde modelos como <em>Random Forest</em>, <em>SVM</em>, <em>Naive Bayes</em>, <em>KNN</em>, <em>Ensembles</em> e at√© mesmo Regress√£o eram frequentemente utilizados para classificar textos. Al√©m disso, o uso de redes neurais recorrentes (<em>RNNs</em>) sempre foi uma alternativa valiosa, especialmente em situa√ß√µes que demandavam o processamento de dados sequenciais, sendo a <em>LSTM (Long Short-Term Memory)</em> uma variante eficaz para lidar com o desafio conhecido como <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem"><em>vanishing gradient</em></a>.</p>
<p>J√° no cen√°rio atual de modelos pr√©-treinados, o <em>BERT (Bidirectional Encoder Representations from Transformers)</em> tamb√©m teve bastante destaque nesse dom√≠nio antes da ascens√£o do <em>ChatGPT</em>, demonstrando a viabilidade como um m√©todo gerador de texto e mostraram o poder que as redes neurais t√™m para gerar longas sequ√™ncias de texto que antes pareciam inating√≠veis.</p>
<center>
<p><img src="/post/2024-04-20-sentiment-analysis-llama2/parameters_transformer_based_language_models.png" style="width:70.0%" /></br>
<small><a href="https://www.techtarget.com/searchenterpriseai/definition/GPT-3">GPT-3 supera seus antecessores em termos de contagem de par√¢metros</a></small></p>
</center>
<p>Embora j√° existam h√° algum tempo, os <em>LLMs</em> ganharam a m√≠dia atrav√©s do <em>ChatGPT</em>, interface de chat da OpenAI para modelos LLM GPT-3 lan√ßado em 2020, com 175 milh√µes de par√¢metros, que j√° teve uma s√©rie de avan√ßos significativos nos √∫ltimos anos como seu irm√£o maior, o GPT-4 lan√ßado em 2023 conta com incr√≠veis 100 <strong>tr√≠lh√µes</strong> de par√¢metros.</p>
<center>
<p><img src="/post/2024-04-20-sentiment-analysis-llama2/comparison-between-GPT-3-and-GPT-4.png" style="width:50.0%" /></br>
<small><a href="https://www.techtarget.com/searchenterpriseai/definition/GPT-3">The comparison between GPT-3 and GPT-4 based on the number of parameters used in their architecture</a></small></p>
</center>
<p>Modelos com mais de 100 bilh√µes de par√¢metros j√° podem ser considerados muito grandes, com conhecimento mundial muito rico. Esses modelos maiores conseguem ‚Äúaprender‚Äù ainda mais informa√ß√µes sobre muitas coisas sobre fisica, filosofia, ci√™ncia, programa√ß√£o, etc sendo cada vez mais √∫teis para ajudar em tarefas que envolvam conhecimento profundo ou raciocinio complexo, sendo um bom ‚Äúparceiro‚Äù para brainstorming.</p>
<div class="w3-panel w3-pale-red w3-border">
<p>¬† <strong>‚ö†Ô∏è Aten√ß√£o!</strong> </br>
Afirmar que maiores modelos s√£o sempre melhores n√£o √© verdade. O tempo de processamento, lat√™ncia e o custo tamb√©m ir√£o aumentar, por isso <a href="https://medium.com/@masteringllm/mistral-7b-is-187x-cheaper-compared-to-gpt-4-b8e5ee1c9fc2">abordagens alternativas</a> tamb√©m devem ser consideradas.</p>
</div>
<div id="como-funcionam-os-llms" class="section level3">
<h3>Como funcionam os LLMs?</h3>
<p>Os <em>LLMs</em> s√£o modelos de <em>Machine Learning</em> que usam algoritmos de <em>Deep Learning</em> para processar e compreender a linguagem natural, gerando texto de maneira eficaz. Esses modelos s√£o treinados com grandes volumes de dados da internet, adquirindo a capacidade de identificar padr√µes na composi√ß√£o de palavras e frases. A id√©ia b√°sica por tr√°s desses modelos √© que s√£o capazes de gerar texto prevendo repetidamente a pr√≥xima palavra oferecendo resultados r√°pidos e diversas aplica√ß√µes pr√°ticas em v√°rias √°reas</p>
<div id="aplica√ß√µes" class="section level4">
<h4>Aplica√ß√µes</h4>
<p>Diferentemente de uma ferramenta de busca como o Google, o ChatGPT n√£o recupera informa√ß√µes, mas cria frases e textos completos em tempo real com base no processamento de um imenso volume de dados, veja alguns exemplos de uso para diferentes tarefas:</p>
<div class="row">
<div id="escrita" class="section level5 column4">
<h5>‚úçÔ∏è <strong>Escrita:</strong></h5>
<ul>
<li>Colabora√ß√£o em brainstorming, sugerindo nomes;</li>
<li>Elabora√ß√£o de templates para comunicados e e-mails;</li>
<li>Tradu√ß√£o autom√°tica.</li>
</ul>
</div>
<div id="leitura" class="section level5 column4">
<h5>üìñ <strong>Leitura</strong>:</h5>
<ul>
<li>Revis√£o de textos;</li>
<li>Sumariza√ß√£o de artigos extensos;</li>
<li>An√°lise de sentimentos, possibilitando a cria√ß√£o de dashboards para acompnhamento ao longo do tempo.</li>
</ul>
</div>
<div id="conversa" class="section level5 column4">
<h5>üí¨ <strong>Conversa</strong>:</h5>
<ul>
<li>Di√°logos e aconselhamentos;</li>
<li>Coaching de carreira;</li>
<li>Planejamento de viagens;
Sugest√µes de receitas;</li>
<li>Conversa√ß√£o interativa com documentos PDF;</li>
<li>Atendimento ao cliente;</li>
<li>Realiza√ß√£o de pedidos.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="o-que-faremos-aqui" class="section level2">
<h2>O que faremos aqui?</h2>
<p>Nosso objetivo aqui √© realizar uma an√°lise de sentimentos para classificar senten√ßas como positivas ou negativas utilizando algum LLM pr√©-treinado. Embora a OpenAI j√° tenha sido uma organiza√ß√£o sem fins lucrativos que lan√ßava seus projetos como c√≥digo aberto, desde o lan√ßamento do ChatGPT ela se tornou uma empresa que mant√©m a propriedade de seus c√≥digos fonte. Isso significa que apesar da facilidade de criar aplica√ß√µes, modelos mais poderosos e relativamente baratos, desenvolvedores de IA n√£o podem modificar o GPT-3 para atender √†s nossa necessidades espec√≠ficas ou incorpor√°-lo em seus pr√≥prios projetos de maneira livre e gratuita. Portanto teremos de recorrer √† alternativas n√£o t√£o(*) <em>open source</em> como o <a href="https://huggingface.co/meta-llama"><em>Llama 2</em> da Meta</a> que permite total controle sobre o modelo, rodar em nosso pr√≥prio computador/servidor e n√≥s d√° o controle sobre a privacidade dos nossos dados.</p>
<div class="w3-panel w3-pale-red w3-border">
<p>(*) ‚ÄúC√≥digo aberto‚Äù ü§î </br>
N√£o √© totalmente c√≥digo aberto pois por mais que a Meta tenha disponibilizado o modelo treinado para uso livre, ele n√£o compartilha os dados de treinamento do modelo ou o c√≥digo usado para trein√°-lo.</p>
</div>
</div>
<div id="m√£os-a-obra" class="section level1">
<h1>M√£os a obra!</h1>
<div id="iniciar-ambiente-de-trabalho" class="section level2">
<h2>Iniciar ambiente de trabalho</h2>
<p>Primeiramente vamos carregar todas as dependencias necess√°rias para executar os c√≥digos a seguir:</p>
<pre class="python"><code>import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from PIL import Image
from nltk.corpus import stopwords
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
from llama_cpp import Llama
from tqdm.notebook import tqdm
tqdm.pandas()</code></pre>
</div>
<div id="carregar-dados" class="section level2">
<h2>Carregar dados</h2>
<p>Utilizaremos uma vers√£o <a href="https://www.kaggle.com/datasets/luisfredgs/imdb-ptbr">traduzida do dataset IMdb para o portugu√™s</a>, um conjunto de dados do Internet Movie Database (IMDB), que √© uma das maiores e mais abrangentes bases de dados online sobre filmes e programas de televis√£o.</p>
<pre class="python"><code> #Importar todo conjunto de dados
df = pd.read_csv(&#39;input/imdb-reviews-pt-br.csv&#39;, index_col=&#39;id&#39;)
# Obter amostra de tamanho 100
_, df = train_test_split(df, test_size=100, random_state=42, shuffle=True)</code></pre>
</div>
<div id="informa√ß√µes-gerais" class="section level2">
<h2>Informa√ß√µes gerais</h2>
<p>Esse dataset inclui avalia√ß√µes e cr√≠ticas de filmes feitas por usu√°rios do IMDB, bem como informa√ß√µes sobre os pr√≥prios filmes, como t√≠tulo, ano de lan√ßamento, g√™nero, etc. Para nossa finalidade para tarefa de an√°lise de sentimentos, utilizaremos os seguintes dados:</p>
<table>
<colgroup>
<col width="6%" />
<col width="41%" />
<col width="40%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">id</th>
<th align="left">text_en</th>
<th align="left">text_pt</th>
<th align="center">sentiment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">12534</td>
<td align="left">This was unusual: a modern-day film which‚Ä¶</td>
<td align="left">Isso era incomum: um filme moderno que era‚Ä¶</td>
<td align="center">pos</td>
</tr>
<tr class="even">
<td align="center">35447</td>
<td align="left">Some of my old friends suggested me to wat‚Ä¶</td>
<td align="left">Alguns dos meus velhos amigos sugeriram qu‚Ä¶</td>
<td align="center">neg</td>
</tr>
<tr class="odd">
<td align="center">20281</td>
<td align="left">What a pleasure. This is really a parody. ‚Ä¶</td>
<td align="left">Que prazer. Isto √© realmente uma par√≥dia. S‚Ä¶</td>
<td align="center">pos</td>
</tr>
<tr class="even">
<td align="center">‚Ä¶</td>
<td align="left">‚Ä¶</td>
<td align="left">‚Ä¶</td>
<td align="center">‚Ä¶</td>
</tr>
<tr class="odd">
<td align="center">34241</td>
<td align="left">WOW!I just was given this film from a frie‚Ä¶</td>
<td align="left">WOW! Acabei de receber este filme de um am‚Ä¶</td>
<td align="center">neg</td>
</tr>
<tr class="even">
<td align="center">12896</td>
<td align="left">This film offers many delights and surprise‚Ä¶</td>
<td align="left">Este filme oferece muitas del√≠cias e surp‚Ä¶</td>
<td align="center">pos</td>
</tr>
<tr class="odd">
<td align="center">19748</td>
<td align="left">Over the years Ive watched this movie many‚Ä¶</td>
<td align="left">Ao longo dos anos, assisti a esse filme mu‚Ä¶</td>
<td align="center">pos</td>
</tr>
</tbody>
</table>
<p>Onde:</p>
<ul>
<li><code>id</code>: Identificador;</li>
<li><code>text_en</code>: texto em ingl√™s;</li>
<li><code>text_pt</code>: texto em portugu√™s;</li>
<li><code>sentiment</code>: r√≥tulo do texto, que pode ser <code>pos</code> ou <code>neg</code>.</li>
</ul>
</div>
<div id="an√°lise-explorat√≥ria" class="section level2">
<h2>An√°lise Explorat√≥ria</h2>
<hr />
<div id="distribui√ß√£o-dos-sentimentos-na-amostra" class="section level3">
<h3>Distribui√ß√£o dos sentimentos na amostra</h3>
<p>Primeiro vamos entender como ficou distribu√≠da a propor√ß√£o dos sentimentos na amostra coletada:</p>
<details>
<summary>
<em>Clique aqui para ver o c√≥digo do gr√°fico</em>
</summary>
<pre class="python"><code># Contagem absoluta
contagem_absoluta = df[&#39;sentiment&#39;].value_counts()

# Contagem relativa
contagem_relativa = df[&#39;sentiment&#39;].value_counts(normalize=True) * 100

# Criar gr√°fico de barras
fig, ax = plt.subplots(figsize=(6, 4))
barras = plt.bar(contagem_absoluta.index, contagem_absoluta, color=[&#39;green&#39;, &#39;red&#39;])

# Adicionar texto nas barras
for barra, abs_value, rel_value in zip(barras, contagem_absoluta, contagem_relativa):
    yval = barra.get_height()
    ax.text(barra.get_x() + barra.get_width()/2, yval, f&#39;{abs_value} ({rel_value:.1f}%)&#39;,
            ha=&#39;center&#39;, va=&#39;bottom&#39;, color=&#39;black&#39;, fontsize=12)

# Adicionar r√≥tulos e t√≠tulo
plt.xlabel(&#39;Sentimento&#39;, fontsize=14)
plt.ylabel(&#39;Frequ√™ncia absoluta&#39;, fontsize=14)
plt.title(&#39;Quantidade de textos de cada sentimento \nem uma amostra de tamanho 100&#39;, fontsize=16, x=0.5, y=1.1)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Remover bordas da parte superior e direita
ax.spines[&#39;top&#39;].set_visible(False)
ax.spines[&#39;right&#39;].set_visible(False)

# Ajustar layout
plt.tight_layout()

# Salvar imagem
plt.savefig(f&quot;img/freq_sentiment.png&quot;, bbox_inches=&#39;tight&#39;)

# Exibir o gr√°fico
plt.show()</code></pre>
</details>
<p>¬†</p>
<center>
<p><img src="/post/2024-04-20-sentiment-analysis-llama2/freq_sentiment.png" /></p>
</center>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† üìå <strong>Interpreta√ß√£o:</strong>
Coletei uma amostra aleat√≥ria simples de tamanho n=100 de todas as reviews que cont√©m aproximadamente metade de cada sentimento para diminuir o tempo computacional de execu√ß√£o no meu computador.</p>
</div>
</div>
<div id="palavras-mais-frequentes-para-cada-sentimento" class="section level3 tabset">
<h3>Palavras mais frequentes para cada sentimento</h3>
<p>N√∫vens de palavras das resenhas dos filmes que foram anotadas como positivos e como negativos nas duas linguas dispon√≠veis no dataset:</p>
<details>
<summary>
<em>Clique aqui para ver o c√≥digo das Wordclouds</em>
</summary>
<pre class="python"><code>def generate_wordcloud(df, language=&#39;en&#39;):
    # Definir stopwords para o idioma escolhido
    if language == &#39;en&#39;:
        stop_words_pos = stop_words_neg = set(stopwords.words(&#39;english&#39;))
        stop_words_pos.update([&quot;film&quot;, &quot;movie&quot;, &quot;one&quot;])
        stop_words_neg.update([&quot;character&quot;, &quot;like&quot;, &quot;really&quot;, &quot;make&quot;, &quot;see&quot;])
    elif language == &#39;pt&#39;:
        stop_words_pos = stop_words_neg = set(stopwords.words(&#39;portuguese&#39;))
        stop_words_pos.update([&quot;filme&quot;, &quot;filmes&quot;, &quot;todo&quot;, &quot;t√£o&quot;, &quot;pode&quot;, &quot;todos&quot;])
        stop_words_neg.update([&quot;filme&quot;, &quot;filmes&quot;, &quot;todo&quot;, &quot;t√£o&quot;, &quot;filme&quot;, &quot;coisa&quot;, &quot;realmente&quot;])
    else:
        raise ValueError(&quot;Language must be &#39;en&#39; or &#39;pt&#39;.&quot;)

    # Concatenar textos positivos e negativos
    txt_pos = &quot; &quot;.join(review for review in df[df.sentiment == &#39;pos&#39;][f&#39;text_{language}&#39;])
    txt_neg = &quot; &quot;.join(review for review in df[df.sentiment == &#39;neg&#39;][f&#39;text_{language}&#39;])

    # Carregar m√°scaras de imagem
    mask_pos = np.array(Image.open(f&quot;img/pos.png&quot;))
    mask_neg = np.array(Image.open(f&quot;img/neg.png&quot;))

    # Gerar nuvens de palavras positivas e negativas
    wordcloud_positivo = WordCloud(
        stopwords=stop_words_pos,
        random_state=42,
        background_color=&quot;white&quot;,
        color_func=lambda *args, **kwargs: &quot;green&quot;,
        contour_color=&#39;black&#39;,
        contour_width=1,
        max_font_size=100,
        min_font_size=15,
        max_words=200,
        mask=mask_pos
    ).generate(txt_pos)

    wordcloud_negativo = WordCloud(
        stopwords=stop_words_neg,
        random_state=42,
        background_color=&quot;white&quot;,
        color_func=lambda *args, **kwargs: &quot;red&quot;,
        contour_color=&#39;black&#39;,
        contour_width=1,
        max_font_size=100,
        min_font_size=15,
        max_words=200,
        mask=mask_neg
    ).generate(txt_neg)

    # Configura√ß√µes do plot
    plt.figure(figsize=(7, 14))

    # Plotar nuvem de palavras positivas
    plt.subplot(1, 2, 1)
    plt.imshow(wordcloud_positivo, interpolation=&#39;bilinear&#39;)
    plt.axis(&#39;off&#39;)
    plt.title(&#39;Positivo&#39;, fontsize=20, color=&#39;green&#39;)

    # Plotar nuvem de palavras negativas
    plt.subplot(1, 2, 2)
    plt.imshow(wordcloud_negativo, interpolation=&#39;bilinear&#39;)
    plt.axis(&#39;off&#39;)
    plt.title(&#39;Negativo&#39;, fontsize=20, color=&#39;red&#39;)

    # Ajustar layout
    plt.tight_layout()

    # Salvar a nuvem de palavras como imagem
    plt.savefig(f&quot;img/wordcloud_{language}.png&quot;, bbox_inches=&#39;tight&#39;)

    # Exibir a nuvem de palavras
    plt.show()
    
# Exemplo de uso para o idioma ingl√™s
generate_wordcloud(df, language=&#39;en&#39;)

# Exemplo de uso para o idioma portugu√™s
generate_wordcloud(df, language=&#39;pt&#39;)</code></pre>
</details>
<p>¬†</p>
<center>
<p><img src="/post/2024-04-20-sentiment-analysis-llama2/wordcloud_en.png" /></p>
<p>N√∫vem de palavras mais frequentes das resenhas em <strong>üá∫üá≤ Ingl√™s</strong></p>
</center>
<center>
<p><img src="/post/2024-04-20-sentiment-analysis-llama2/wordcloud_pt.png" /></p>
<p>N√∫vem de palavras mais frequentes das resenhas em <strong>üáßüá∑ Portugu√™s</strong></p>
</center>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† <strong>üìå Interpreta√ß√£o:</strong>
Como esperado, mesmo com a mudan√ßa na l√≠ngua, a frequ√™ncia das palavras √© exibida de maneira muito similar de acordo com cada sentimento.</p>
</div>
</div>
</div>
<div id="an√°lise-de-sentimentos" class="section level2">
<h2>An√°lise de Sentimentos</h2>
<hr />
<div id="fam√≠lia-llama-2-de-large-language-models-llms" class="section level3">
<h3>Fam√≠lia <em>Llama 2</em> de <em>Large Language Models</em> (<em>LLMs</em>)</h3>
<p>Nesta se√ß√£o, exploraremos o <a href="https://llama.meta.com/"><em>Llama 2</em></a>, um modelo de c√≥digo aberto, e discutiremos as vantagens e desvantagens em rela√ß√£o aos LLMs de c√≥digo fechado ou remotos.</p>
<div id="tamanho-do-modelo" class="section level4">
<h4>Tamanho do modelo</h4>
<p>Para saber qual modelo utilizar, primeiramente precisamos ter em mente algumas no√ß√µes sobre a quantidade de par√¢metros e tamanhos dos LLM. No geral:</p>
<div class="row">
<div class="column4">
<p><big><strong>1 Bilh√£o</strong>:</big></p>
<p>Bons em correspond√™ncia de padr√µes e algum conhecimento b√°sico do mundo (como por exemplo classificar avalia√ß√µes por sentimento)</p>
</div>
<div class="column4">
<p><big><strong>10 Bilh√µes</strong>:</big></p>
<p>Maior conhecimento mundial, conhecem mais fatos esot√©ricos sobre o mundo e melhoram em seguir instru√ß√µes b√°sicas (bom para chatbot para pedidos de comida);</p>
</div>
<div class="column4">
<p><big><strong>100+ Bilh√µes</strong>: </big></p>
<p>Muito grandes, com conhecimento mundial muito rico, saber√£o coisas sobre f√≠sica, filosofia, ci√™ncia e assim por diante e ser√£o melhores em racioc√≠nios complexos (tarefas que envolvem conhecimento profundo ou racioc√≠nio complexo, parceiro para brainstorming)</p>
</div>
</div>
<p>Para uma an√°lise de sentimentos simples, n√£o √© necess√°rio um modelo com 100 bilh√µes de par√¢metros. Modelos menores, como os com 7 bilh√µes de par√¢metros, podem ser suficientes e menos computacionalmente exigentes.</p>
</div>
<div id="c√≥digo-aberto-ou-fechado" class="section level4">
<h4>C√≥digo aberto ou fechado</h4>
<p>Embora pr√≥ximos, os LLMs de c√≥digo aberto ainda n√£o conseguem igualar o poder e a precis√£o dos aplicativos de c√≥digo fechado dispon√≠veis comercialmente, como <a href="https://openai.com/gpt-4">GPT-4</a> e <a href="https://gemini.google.com/app">Bard (Gemini)</a>. Mesmo sendo menos poderosos, existem alguns pr√≥s e contras pelos quais podemos pesar na hora de escolher a melhor op√ß√£o:</p>
<div class="row">
<div class="column6">
<p><big><strong>Open Source</strong></big></p>
<ul>
<li>Total controle sobre o modelo</li>
<li>Pode rodar em nosso pr√≥prio computador/servidor</li>
<li>Controle sobre a privacidade dos dados</li>
</ul>
</div>
<div class="column6">
<p><big><strong>Closed</strong></big></p>
<ul>
<li>F√°cil de criar aplica√ß√µes</li>
<li>Maiores e mais poderosos</li>
<li>Relativamente barato</li>
<li>Existe um certo risco de depender do fornecedor</li>
</ul>
</div>
</div>
<p>Utilizaremos a abordagem de c√≥digo aberto por ser mais pr√°tica para fins de estudos, pois al√©m de gratuita, n√£o exige internet, registros ou chaves de API.</p>
</div>
<div id="uso-remoto-ou-local" class="section level4">
<h4>Uso remoto ou local</h4>
<p>Podemos interagir com o modelo de linguagem grande (LLM) do Llama 2 via API da <a href="https://huggingface.co/">Hugging Face</a>, seguindo as instru√ß√µes do <a href="https://huggingface.co/meta-llama">reposit√≥rio oficial da Meta</a> ou podemos baixar os arquivos do modelo em formato GGML para o <a href="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf">Llama 2 7B Chat do Meta Llama 2</a>. Os formatos GGML s√£o utilizados para infer√™ncia de CPU + GPU usando o principamente o pacote <a href="https://pypi.org/project/llama-cpp-python/">llama-cpp-python</a>.</p>
<p>Para mais informa√ß√µes sobre como configurar o modelo consulte <a href="https://swharden.com/blog/2023-07-29-ai-chat-locally-with-python/">este link</a></p>
<pre class="python"><code>def load_llama_model(model_path=&quot;./input/llama-2-7b-chat.ggmlv3.q2_K.bin&quot;, language=&#39;en&#39;, seed=42):
    # Determinar o tamanho da janela de contexto com base no idioma
    if language == &#39;en&#39;:
        context_window = df.text_en.map(len).max()
    elif language == &#39;pt&#39;:
        context_window = df.text_pt.map(len).max()
    else:
        raise ValueError(&quot;Language must be &#39;en&#39; or &#39;pt&#39;.&quot;)

    # Carregar o modelo Llama
    return Llama(model_path=model_path,
                 verbose=False,
                 n_ctx=context_window,
                 seed=seed)</code></pre>
<p>Para obter os melhores resultados, devemos ser o mais claro e espec√≠ficos poss√≠vel nas intera√ß√µes. Por√©m devemos iniciar com um prompt simples e r√°pido para ir direcionando o modelo na dire√ß√£o desejada e avaliando os resultados obtidos e ajustando gradualmente o prompt para refinar e aprimorar a resposta desejada</p>
<pre class="python"><code>def classify_sentiment_llama(text, llama_model):
    # Construir a prompt para o modelo Llama
    prompt = f&#39;&#39;&#39; \
    Q: Answer with just one word, \
    does the following text express a \
    positive or negative feeling? \
    {text} \
    A:&#39;&#39;&#39;
    # Obter a sa√≠da do modelo Llama
    output = llama_model(prompt, max_tokens=3)
    return output[&quot;choices&quot;][0][&quot;text&quot;]</code></pre>
<p>Com nosso prompt definido, j√° podemos carregar o modelo:</p>
<pre class="python"><code># Carregar o modelo Llama para o idioma desejado
llama_model = load_llama_model(language=&#39;en&#39;)</code></pre>
<pre><code>## llama.cpp: loading model from ./llama-2-7b-chat.ggmlv3.q2_K.bin
## llama_model_load_internal: format     = ggjt v3 (latest)
## llama_model_load_internal: n_vocab    = 32000
## llama_model_load_internal: n_ctx      = 4320
## llama_model_load_internal: n_embd     = 4096
## llama_model_load_internal: n_mult     = 256
## llama_model_load_internal: n_head     = 32
## llama_model_load_internal: n_head_kv  = 32
## llama_model_load_internal: n_layer    = 32
## llama_model_load_internal: n_rot      = 128
## llama_model_load_internal: n_gqa      = 1
## llama_model_load_internal: rnorm_eps  = 5.0e-06
## llama_model_load_internal: n_ff       = 11008
## llama_model_load_internal: freq_base  = 10000.0
## llama_model_load_internal: freq_scale = 1
## llama_model_load_internal: ftype      = 10 (mostly Q2_K)
## llama_model_load_internal: model size = 7B
## llama_model_load_internal: ggml ctx size =    0.08 MB
## llama_model_load_internal: mem required  = 2733.66 MB (+ 2160.00 MB per state)
## llama_new_context_with_model: kv self size  = 2160.00 MB
## llama_new_context_with_model: compute buffer total size =  295.35 MB</code></pre>
<p>Ap√≥s instanciar o modelo, basta aplic√°-lo em nossa base de dados. (apliquei o mesmo modelo tanto para as reviews e portugu√™s quanto em ingl√™s).</p>
<pre class="python"><code>df[&#39;sentiment_llm_en&#39;] = df.text_en.progress_apply(lambda x: classify_sentiment_llama(x, llama_model))</code></pre>
<p><img src="/post/2024-04-20-sentiment-analysis-llama2/load_en.png" /></p>
<p>Como este modelo √© o mais b√°sico e n√£o alteramos nenhum par√¢metro (como por exemplo <code>temperature</code>, que determina se o output ser√° mais aleat√≥rio ou mais previs√≠vel) pode ser que a sa√≠da n√£o saia padronizada e necessite de algum p√≥s-processamento. Vejamos como foram os outputs do LLM:</p>
<details>
<summary>
<em>Clique aqui para ver o c√≥digo do gr√°fico</em>
</summary>
<pre class="python"><code># Contagem da frequ√™ncia das classifica√ß√µes
sentiment_llm_counts = df.groupby(&#39;sentiment&#39;).sentiment_llm_en.value_counts().reset_index(name=&#39;n&#39;)

# Organizar as categorias pela frequ√™ncia total
order = df.sentiment_llm_en.value_counts().reset_index(name=&#39;n&#39;)
order = order.sort_values(by=&#39;n&#39;, ascending=False)[&#39;index&#39;]

# Configura√ß√µes de estilo do seaborn
sns.set(style=&quot;whitegrid&quot;)

# Criar o gr√°fico de barras
plt.figure(figsize=(12, 4))
ax = sns.barplot(x=sentiment_llm_counts.sentiment_llm_en, y=sentiment_llm_counts.n, hue=sentiment_llm_counts.sentiment, order=order, palette=[&quot;red&quot;, &quot;green&quot;])

# Adicionar r√≥tulos e t√≠tulo
plt.ylim([0, 25])
plt.xticks(fontsize=12, rotation=90)
plt.yticks(fontsize=12)
ax.set_xlabel(&#39;Anota√ß√£o de sentimento das resenhas&#39;, fontsize=14)
ax.set_ylabel(&#39;Frequ√™ncia&#39;, fontsize=14)
ax.set_title(&#39;Frequ√™ncia dos sentimentos classificados pelo LLM em Ingl√™s\nem rela√ß√£o aos sentimentos j√° anotados da base&#39;, fontsize=20)

# Adicionar anota√ß√µes nas barras
for p in ax.patches:
    ax.annotate(f&#39;{p.get_height()}&#39;, (p.get_x() + p.get_width() / 2., p.get_height()),
                ha=&#39;center&#39;, va=&#39;baseline&#39;, fontsize=10, color=&#39;black&#39;, xytext=(0, 5),
                textcoords=&#39;offset points&#39;)

plt.legend(loc=&quot;upper right&quot;, title = &quot;Label real&quot;)

# Remover bordas da parte superior e direita
ax.spines[&#39;top&#39;].set_visible(False)
ax.spines[&#39;right&#39;].set_visible(False)
ax.grid(False)

# Salvar a nuvem de palavras como imagem
plt.savefig(f&quot;img/freq_class_llm_en.png&quot;, bbox_inches=&#39;tight&#39;)

# Exibir o gr√°fico
plt.show()</code></pre>
</details>
<!-- &nbsp; -->
<center>
<img src="/post/2024-04-20-sentiment-analysis-llama2/freq_class_llm_en.png" />
</center>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† <strong>üìå Interpreta√ß√£o:</strong>
√â poss√≠vel observar que o modelo pr√©-treinado conseguiu reconhecer de maneira bastante coerente o sentimento dos trechos para as categorias <code>pos</code> e <code>neg</code>, por√©m, n√£o vieram padronizadas exatamente como solicitamos ao modelo.</p>
</div>
<p>Como a sa√≠da n√£o foi padronizada, vamos realizar algum p√≥s-processamento para padronizar as classes como <code>pos</code> ou <code>neg</code> para possibilitar avaliar o desempenho do modelo com base em m√©tricas de classifica√ß√£o.</p>
<pre class="python"><code>conditions = [
    (df.sentiment_llm_en.str.contains(&#39;(?i)(?:pos|fun)&#39;)),
    (df.sentiment_llm_en.str.contains(&#39;(?i)(?:neg|horrible|melanchol)&#39;))
]
pd.crosstab(df.sentiment, np.select(conditions, [&#39;pos&#39;, &#39;neg&#39;], default=&#39;other&#39;))</code></pre>
<p>Com os outputs padronizados em duas classes, podemos verificar como foi a acur√°cia do modelo.</p>
</div>
<div id="desempenho" class="section level4">
<h4>Desempenho</h4>
<p>Como estamos diante de um problema de classifica√ß√£o, avaliaremos o desempenho do modelo com matrizes de confus√£o para entender a as taxas de acerto e calcular a acur√°cia pois o dataset √© balanceado.</p>
<details>
<summary>
<em>Clique aqui para ver o c√≥digo do gr√°fico</em>
</summary>
<pre class="python"><code># Matrizes de Confus√£o
conditions = [
    (df.sentiment_llm_en.str.contains(&#39;(?i)(?:pos|fun|good|comedy)&#39;)),
    (df.sentiment_llm_en.str.contains(&#39;(?i)(?:neg|melanchol|absurd|horrible)&#39;))
]
cm_llm_en = confusion_matrix(df.sentiment, np.select(conditions, [&#39;pos&#39;, &#39;neg&#39;], default=&#39;other&#39;))
accuracy_llm_en = accuracy_score(df.sentiment, np.select(conditions, [&#39;pos&#39;, &#39;neg&#39;], default=&#39;other&#39;))

conditions = [
    (df.sentiment_llm_pt.str.contains(&#39;(?i)(?:pos)&#39;)),
    (df.sentiment_llm_pt.str.contains(&#39;(?i)(?:neg|horr√≠vel)&#39;))
]
cm_llm_pt = confusion_matrix(df.sentiment, np.select(conditions, [&#39;pos&#39;, &#39;neg&#39;], default=&#39;other&#39;))
accuracy_llm_pt = accuracy_score(df.sentiment, np.select(conditions, [&#39;pos&#39;, &#39;neg&#39;], default=&#39;other&#39;))

# Configura√ß√µes de estilo do seaborn
sns.set(font_scale=1.2)
plt.figure(figsize=(12, 5))

# Plotar Matriz de Confus√£o para o modelo de LLM em ingl√™s
plt.subplot(1, 2, 1)
sns.heatmap(cm_llm_en, annot=True, fmt=&#39;d&#39;, cmap=&#39;binary&#39;, cbar=False, vmin=0, vmax=50,
            xticklabels=[&#39;Negativo&#39;, &#39;Neutro&#39;, &#39;Positivo&#39;], yticklabels=[&#39;Negativo&#39;, &#39;Neutro&#39;, &#39;Positivo&#39;])
plt.title(f&#39;Matriz de Confus√£o (Vader - Ingl√™s)\nAcur√°cia: {accuracy_llm_en:.0%}&#39;, fontsize=22)
plt.xlabel(&#39;Previsto&#39;, fontsize=14)
plt.ylabel(&#39;Real&#39;, fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Plotar Matriz de Confus√£o para o modelo de LLM em portugu√™s
plt.subplot(1, 2, 2)
sns.heatmap(cm_llm_pt, annot=True, fmt=&#39;d&#39;, cmap=&#39;binary&#39;, cbar=False,vmin=0, vmax=50,
            xticklabels=[&#39;Negativo&#39;, &#39;Neutro&#39;, &#39;Positivo&#39;], yticklabels=[&#39;Negativo&#39;, &#39;Neutro&#39;, &#39;Positivo&#39;])
plt.title(f&#39;Matriz de Confus√£o (Vader - Portugu√™s)\nAcur√°cia: {accuracy_llm_pt:.0%}&#39;, fontsize=22)
plt.xlabel(&#39;Previsto&#39;, fontsize=14)
plt.ylabel(&#39;Real&#39;, fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Ajustar layout
plt.tight_layout()

# Salvar a nuvem de palavras como imagem
plt.savefig(f&quot;img/cm_llm.png&quot;, bbox_inches=&#39;tight&#39;)

# Exibir o gr√°fico
plt.show()</code></pre>
</details>
<!-- &nbsp; -->
<center>
<img src="/post/2024-04-20-sentiment-analysis-llama2/cm_llm2.png" />
</center>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† <strong>üìå Interpreta√ß√£o:</strong>
A acur√°cia geral para a l√≠ngua Inglesa foi superior quando aplicado o mesmo modelo para a l√≠ngua portuguesa. Vale lembrar que este modelo foi treinado em Ingl√™s e estamos utilizado a menor das op√ß√µes.</p>
</div>
<p>O desempenho deste modelo √© muito interessante, principalmente por j√° ser pr√© treinado, n√£o sendo necess√°rio gastar tanto tempo na sua constru√ß√£o mas para afirmar que este modelo √© bom precisamos entender qual seria o resultado para resolver este problemas se utilizassemos a abordagem mais simples poss√≠vel.</p>
</div>
</div>
<div id="vader" class="section level3">
<h3>Vader</h3>
<!-- ## Baseline -->
<p>O <em><strong>VADER</strong> (Valence Aware Dictionary and sEntiment Reasoner)</em> √© uma abordagem mais simples e r√°pida em compara√ß√£o aos LLMs. N√£o requer o treinamento de um modelo, mas depende de l√©xicos de palavras relacionadas a sentimentos. Pode ser facilmente utilizado via bibliotecas de c√≥digo aberto em Python, como <a href="https://pypi.org/project/vaderSentiment/">vaderSentiment</a> para ingl√™s e <a href="https://github.com/rafjaa/LeIA">LeIA (L√©xico para Infer√™ncia Adaptada)</a> para portugu√™s.</p>
<p>A abordagem √© direta: no l√©xico (uma cole√ß√£o de palavras), cada palavra j√° possui uma nota atribu√≠da. Ao passar um documento (frase), retorna um dicion√°rio com o escore de polaridade com base no escore das palavras no texto. O dicion√°rio inclui o valor do sentimento geral normalizado (<code>compound</code>), variando de -1 (extremamente negativo) a +1 (extremamente positivo). Esse valor pode ser usado para descrever o sentimento predominante no texto, considerando os seguintes limites:</p>
<ul>
<li>Sentimento <span style="color: green;">positivo</span>: <code>compound</code> &gt;= 0.05</li>
<li>Sentimento <span style="color: red;">negativo</span>: <code>compound</code> &lt;= -0.05</li>
<li>Sentimento <span style="color: orange;">neutro</span>: (<code>compound</code> &gt; -0.05) e (<code>compound</code> &lt; 0.05)</li>
</ul>
<details>
<summary>
<em>Clique aqui para ver a fun√ß√£o utilizada para classificar o sentimento com base no escore <code>compound</code></em>
</summary>
<pre class="python"><code># Fun√ß√£o para classificar o sentimento com base no compound score
def classify_sentiment_vader(text, language=&#39;en&#39;):

    # Definir m√©todo que ser√° utilizado
    if language==&#39;en&#39;:
        from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    elif language == &#39;pt&#39;:
        from leia import SentimentIntensityAnalyzer
    else:
        raise ValueError(&quot;Language must be &#39;en&#39; or &#39;pt&#39;.&quot;)

    # Instanciar a ferramenta para an√°lise de sentimentos
    analyzer = SentimentIntensityAnalyzer()
    # Realiza a an√°lise de sentimentos e obt√©m o compound score
    compound_score = analyzer.polarity_scores(text)[&#39;compound&#39;]
    # Classifica o sentimento com base no compound score
    if compound_score &gt;= 0.05:
        return &#39;pos&#39;
    elif compound_score &lt;= -0.05:
        return &#39;neg&#39;
    else:
        return &#39;neu&#39;

# Criando uma nova coluna &#39;sentimento_vader&#39;
df[&#39;sentiment_vader_en&#39;] = df.text_en.apply(lambda x: classify_sentiment_vader(x, &#39;en&#39;))
df[&#39;sentiment_vader_pt&#39;] = df.text_pt.apply(lambda x: classify_sentiment_vader(x, &#39;pt&#39;))</code></pre>
</details>
<!-- &nbsp; -->
<p>A execu√ß√£o do c√≥digo √© bem r√°pida, sendo √∫til para refer√™ncia como baseline ou em casos em que temos baixo recurso computacional e um grande volume de dados para classificar.</p>
<div id="desempenho-1" class="section level4">
<h4>Desempenho</h4>
<p>Como estamos diante de um problema de classifica√ß√£o, avaliaremos o desempenho do modelo com matrizes de confus√£o para entender a as taxas de acerto e calcular a acur√°cia pois o dataset √© balanceado.</p>
<details>
<summary>
<em>Clique aqui para ver o c√≥digo do gr√°fico</em>
</summary>
<pre class="python"><code># Matrizes de Confus√£o
cm_vader_en = confusion_matrix(df.sentiment, df.sentiment_vader_en)
cm_vader_pt = confusion_matrix(df.sentiment, df.sentiment_vader_pt)

# Acur√°cias
accuracy_vader_en = accuracy_score(df.sentiment, df.sentiment_vader_en)
accuracy_vader_pt = accuracy_score(df.sentiment, df.sentiment_vader_pt)

# Configura√ß√µes de estilo do seaborn
sns.set(font_scale=1.2)
plt.figure(figsize=(12, 5))

# Plotar Matriz de Confus√£o para o m√©todo Vader em ingl√™s
plt.subplot(1, 2, 1)
sns.heatmap(cm_vader_en, annot=True, fmt=&#39;d&#39;, cmap=&#39;binary&#39;, cbar=False,vmin=0, vmax=50,
            xticklabels=[&#39;Negativo&#39;, &#39;Neutro&#39;, &#39;Positivo&#39;], yticklabels=[&#39;Negativo&#39;, &#39;Neutro&#39;, &#39;Positivo&#39;])
plt.title(f&#39;Matriz de Confus√£o (Vader - Ingl√™s)\nAcur√°cia: {accuracy_vader_en:.0%}&#39;, fontsize=22)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.xlabel(&#39;Previsto&#39;, fontsize=14)
plt.ylabel(&#39;Real&#39;, fontsize=14)

# Plotar Matriz de Confus√£o para o m√©todo Vader em portugu√™s
plt.subplot(1, 2, 2)
sns.heatmap(cm_vader_pt, annot=True, fmt=&#39;d&#39;, cmap=&#39;binary&#39;, cbar=False,vmin=0, vmax=50,
            xticklabels=[&#39;Negativo&#39;, &#39;Neutro&#39;, &#39;Positivo&#39;], yticklabels=[&#39;Negativo&#39;, &#39;Neutro&#39;, &#39;Positivo&#39;])
plt.title(f&#39;Matriz de Confus√£o (Vader - Portugu√™s)\nAcur√°cia: {accuracy_vader_pt:.0%}&#39;, fontsize=22)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.xlabel(&#39;Previsto&#39;, fontsize=14)
plt.ylabel(&#39;Real&#39;, fontsize=14)

# Ajustar layout
plt.tight_layout()

# Salvar a nuvem de palavras como imagem
plt.savefig(f&quot;img/cm_vader.png&quot;, bbox_inches=&#39;tight&#39;)

# Exibir o gr√°fico
plt.show()</code></pre>
</details>
<!-- &nbsp; -->
<center>
<img src="/post/2024-04-20-sentiment-analysis-llama2/cm_vader.png" />
</center>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† <strong>üìå Interpreta√ß√£o:</strong> A acur√°cia geral do m√©todo foi praticamente o mesmo para ambas as linguas. Na lingua inglesa observamos mais casos de falsos positivos (22%), j√° na lingua portuguesa observamos mais casos de falsos negativos (14%).</p>
</div>
<p>Essa abordagem √© boa para ser utilizada como baseline pois quase todas as abordagens tradicionais de Machine Learning para a tarefa de an√°lise de sentimentos necessitam de tempo para desenvolvimento, treino, valida√ß√£o e sustenta√ß√£o de modelos.</p>
</div>
</div>
</div>
</div>
<div id="resultado-final" class="section level1">
<h1>Resultado Final</h1>
<hr />
<p>Avaliamos o desempenho de ambas as abordagens para determinar se o uso do LLM justificou-se em compara√ß√£o com a abordagem mais simples para a execu√ß√£o da tarefa de an√°lise de sentimentos.</p>
<details>
<summary>
<em>Clique aqui para ver o c√≥digo do gr√°fico</em>
</summary>
<pre class="python"><code>models = (
    &quot;Ingl√™s&quot;,
    &quot;Portugu√™s&quot;,
)
weight_counts = {
    &quot;Vader&quot;: np.array([accuracy_vader_en,
                       accuracy_vader_pt]),
    &quot;LLM&quot;: np.array([accuracy_llm_en-accuracy_vader_en,
                     accuracy_llm_pt-accuracy_vader_pt]),
}

fig, ax = plt.subplots()
bottom = np.zeros(2)
colors=[&quot;#b4dbe6&quot;, &quot;#024b7a&quot;]
for (boolean, weight_count), col in zip(weight_counts.items(), colors):
    p = ax.bar(models, weight_count, width=0.5, label=boolean, bottom=bottom, color=col)
    bottom += weight_count

# Formatar eixos
plt.ylim([0, 1.1])
plt.xlabel(&#39;Idioma das resenhas dos filmes&#39;, fontsize=14)
plt.ylabel(&#39;Ganho de Acur√°cia&#39;, fontsize=14)
plt.title(&quot;Compara√ß√£o do ganho de acur√°cia \ndo LLM em rela√ß√£o ao Vader&quot;, fontsize=16, x=0.5)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Legenda
ax.legend(loc=&quot;upper right&quot;, title=&#39;M√©todo utilizado&#39;)
#specify order of items in legend
handles, labels = plt.gca().get_legend_handles_labels()
order = [1, 0]
plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order])

accs=[x*100 for x in [accuracy_vader_en, accuracy_vader_pt, accuracy_llm_en, accuracy_llm_pt]]
for p, acc in zip(ax.patches, accs):
    width, height = p.get_width(), p.get_height()
    x, y = p.get_xy()
    ax.text(x+width/2,
            y+(height/2) - 0.01,
            &#39;{:.0f} %&#39;.format(acc),
            horizontalalignment=&#39;center&#39;,
            verticalalignment=&#39;center&#39;,
            color=&#39;white&#39;, fontsize=18)

# Adicionar setas e textos na figura
plt.arrow(0.3, 0.62, 0, 0.16,
          head_width = 0.05,
          width = 0.015,
          color=&#39;black&#39;)
plt.text(0.2, 0.9, &#39;+20,0%&#39;, fontsize = 20)

plt.arrow(0.7, 0.63, 0, 0.09,
          head_width = 0.05,
          width = 0.015,
          color=&#39;black&#39;)
plt.text(0.6, 0.84, &#39;+11,53%&#39;, fontsize = 20)

# Remover bordas da parte superior e direita
ax.spines[&#39;top&#39;].set_visible(False)
ax.spines[&#39;right&#39;].set_visible(False)
ax.spines[&#39;bottom&#39;].set_visible(True)
ax.spines[&#39;left&#39;].set_visible(True)
ax.grid(visible=None)
ax.set_facecolor(&#39;white&#39;)

# Ajustar layout
plt.tight_layout()

# Salvar a nuvem de palavras como imagem
plt.savefig(f&quot;img/acc_comparation.png&quot;, bbox_inches=&#39;tight&#39;)

# Exibir o gr√°fico
plt.show()</code></pre>
</details>
<!-- &nbsp; -->
<center>
<img src="/post/2024-04-20-sentiment-analysis-llama2/acc_comparation.png" />
</center>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† <strong>üìå Interpreta√ß√£o:</strong> A acur√°cia geral foi consideravelmente maior para o modelo Llama2 em ambas as l√≠nguas, mesmo sendo treinado principalmente em dados da l√≠ngua inglesa.</p>
</div>
</div>
<div id="conclus√£o-e-discuss√£o" class="section level1">
<h1>Conclus√£o e Discuss√£o</h1>
<hr />
<p>Os avan√ßos tecnol√≥gicos na √°rea s√£o verdadeiramente impressionantes e evidenciam a r√°pida evolu√ß√£o da intelig√™ncia artificial. √â importante estarmos sempre atentos a essas mudan√ßas, pois a √°rea de LLMs est√° em constante crescimento e melhorias significativas s√£o desenvolvidas diariamente.</p>
<p>Em meio a tantos avan√ßos, tamb√©m √© importante reconhecer as limita√ß√µes desses modelos. Um dos desafios √© o corte de conhecimento (knowledge cutoffs), o que significa que o modelo √© treinado at√© uma determinada data, como 2022, portanto n√£o possui conhecimento sobre eventos ou desenvolvimentos que ocorreram ap√≥s essa data. Al√©m disso, os LLMs est√£o sujeitos a ‚Äúhallucinations‚Äù, ou seja, podem inventar informa√ß√µes em um tom muito confiante, o que pode levar a resultados imprecisos ou at√© mesmo prejudiciais.</p>
<p>Outras limita√ß√µes incluem restri√ß√µes no input e output dos modelos, o que pode tornar dif√≠cil lidar com grandes volumes de dados ou fornecer resultados completos de uma s√≥ vez. Al√©m disso, os LLMs geralmente n√£o funcionam bem com dados estruturados, como tabelas, e podem reproduzir vieses e toxicidade presentes na sociedade, o que levanta preocupa√ß√µes √©ticas e sociais importantes.</p>
<p>Portanto, enquanto exploramos esse vasto campo das redes neurais, √© essencial abordar essas limita√ß√µes e desenvolver solu√ß√µes que permitam o uso √©tico e respons√°vel dessas poderosas ferramentas de IA.</p>
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias</h1>
<hr />
<ul>
<li><a href="https://medium.com/mapegy-tech/large-scale-language-models-for-innovation-and-technology-intelligence-sentiment-analysis-on-news-2c1ed1f6f2ad">Large-scale language models for innovation and technology intelligence: sentiment analysis on news articles</a></li>
<li><a href="https://medium.com/luisfredgs/an%C3%A1lise-de-sentimentos-com-redes-neurais-recorrentes-lstm-a5352b21e6aa">An√°lise de sentimentos com redes neurais recorrentes LSTM</a></li>
<li><a href="https://www.coursera.org/programs/applied-intelligence-workera-vshgt/learn/generative-ai-for-everyone?authProvider=accenture-main">Generative AI for Everyone - Andrew Ng - Coursera Course</a></li>
<li><a href="https://swharden.com/blog/2023-07-29-ai-chat-locally-with-python/">Run Llama 2 Locally with Python</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2024-04-20-sentiment-analysis-llama2/">An√°lise de Sentimentos com um &#34;ChatGPT&#34; de C√≥digo Aberto</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category>Texto e NLP</category>
      <category domain="tag">chatgpt</category>
      <category domain="tag">data-science</category>
      <category domain="tag">gam</category>
      <category domain="tag">inteligencia-artificial</category>
      <category domain="tag">llama2</category>
      <category domain="tag">llm</category>
      <category domain="tag">python</category>
      <category domain="tag">redes-neurais</category>
      <category domain="tag">sentiment-analysis</category>
    </item>
    <item>
      <title>Solu√ß√£o Final - ML Olympiad [1¬∫ lugar]</title>
      <link>https://gomesfellipe.github.io/post/2023-05-30-solucao-final-ensure-healthy-lives-kaggle-competition/</link>
      <pubDate>Tue, 30 May 2023 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2023-05-30-solucao-final-ensure-healthy-lives-kaggle-competition/</guid>
      <description>Confira a estrat√©gia aplicada para esta competi√ß√£o</description>
      <content:encoded>&lt;![CDATA[
        
<link href="https://gomesfellipe.github.io/post/2023-05-30-solucao-final-ensure-healthy-lives-kaggle-competition/index_files/vembedr/css/vembedr.css" rel="stylesheet" />

<div id="TOC">
<ul>
<li><a href="#introdu%C3%A7%C3%A3o" id="toc-introdu√ß√£o">Introdu√ß√£o</a></li>
<li><a href="#defini%C3%A7%C3%A3o-do-problema-de-neg%C3%B3cio" id="toc-defini√ß√£o-do-problema-de-neg√≥cio">Defini√ß√£o do problema de neg√≥cio</a></li>
<li><a href="#solu%C3%A7%C3%B5es" id="toc-solu√ß√µes">Solu√ß√µes</a></li>
<li><a href="#estrat%C3%A9gia-anal%C3%ADtica" id="toc-estrat√©gia-anal√≠tica">Estrat√©gia anal√≠tica</a>
<ul>
<li><a href="#decis%C3%B5es-sobre-a-target" id="toc-decis√µes-sobre-a-target">Decis√µes sobre a target</a></li>
<li><a href="#processamento-dos-dados" id="toc-processamento-dos-dados">Processamento dos Dados</a></li>
<li><a href="#dados-externos" id="toc-dados-externos">Dados Externos</a></li>
<li><a href="#feature-engineering" id="toc-feature-engineering">Feature Engineering</a></li>
<li><a href="#modelos" id="toc-modelos">Modelos</a></li>
<li><a href="#ensemble" id="toc-ensemble">Ensemble</a></li>
<li><a href="#post-processing" id="toc-post-processing">Post Processing</a></li>
</ul></li>
<li><a href="#considera%C3%A7%C3%B5es-finais" id="toc-considera√ß√µes-finais">Considera√ß√µes Finais</a></li>
<li><a href="#sobre-o-autor" id="toc-sobre-o-autor">Sobre o Autor</a></li>
</ul>
</div>

<div id="introdu√ß√£o" class="section level1">
<h1>Introdu√ß√£o</h1>
<p>O <a href="https://www.meetup.com/TensorFlowSP/events/284607061/">TFUG - TensorFlow Users Group de S√£o Paulo</a> lan√ßou uma nova <a href="https://www.kaggle.com/competitions/ml-olympiad-ensure-healthy-lives">competi√ß√£o no Kaggle</a> onde o objetivo era desenvolver modelos para previs√£o de diagn√≥stico de s√≠ndromes respirat√≥rias, que √© um tema relacionado com um dos 17 t√≥picos de Desenvolvimento Sustent√°vel das Na√ß√µes Unidas - <em>Boa sa√∫de e bem-estar</em>.</p>
<p>Como um cientista de dados, acredito que seja muito importante continuarmos aprimorando nossas habilidades e conhecimentos. Competi√ß√µes como essa s√£o muito divertidas e possibilitam que testemos nossos limites em um ambiente competitivo e colaborativo, al√©m de ser uma grande oportunidade para nos desafiarmos e aprender uns com os outros.</p>
<p>Tive o enorme prazer de conquistar o primeiro lugar, dessa vez com meu grande amigo <a href="https://www.linkedin.com/in/kaike-wesley-reis">Kaike</a>, parceiro de competi√ß√µes de longa data que trouxe grande sinergia para a <a href="https://www.kaggle.com/code/gomes555/ml-olypiads-1-lugar-blending">solu√ß√£o final</a> com a contribui√ß√£o de seu modelo (compartilhado abertamente no Kaggle).</p>
<p>Aqui est√£o alguns dos pr√™mios recebidos:</p>
<center>
<img src="/post/2023-05-30-solucao-final-ensure-healthy-lives-kaggle-competition/premio2.png" style="width:80.0%" />
</center>
<p>Como nesta competi√ß√£o havia bastante trabalho a ser feito e tivemos apenas 1 m√™s para trabalhar na solu√ß√£o, foi preciso fazer uma boa gest√£o do c√≥digo e do tempo de desenvolvimento.</p>
</div>
<div id="defini√ß√£o-do-problema-de-neg√≥cio" class="section level1">
<h1>Defini√ß√£o do problema de neg√≥cio</h1>
<p>O objetivo desta competi√ß√£o consistiu em predizer qual o agente causador da s√≠ndrome respirat√≥ria aguda grave com base nos dados e sintomas dos pacientes.</p>
<p>Esta tarefa pode ser enquadrada como um problema supervisionado de classifica√ß√£o multinomial (com m√∫ltiplos outputs) na qual as previs√µes s√£o, de certa forma, dependentes da entrada umas das outras (o paciente s√≥ pode ter registrado uma das doen√ßas).</p>
<p>A valida√ß√£o da solu√ß√£o foi feita utilizando a m√©trica Macro (or Mean) F1-Score, que √© basicamente a m√©dia do F1 calculado sobre as previs√µes de cada nota.</p>
</div>
<div id="solu√ß√µes" class="section level1">
<h1>Solu√ß√µes</h1>
<p>Ambas solu√ß√µes (minha e do Kaike) foram compartilhadas no Kaggle:</p>
<ul>
<li><a href="https://www.kaggle.com/code/gomes555/ml-olympiad-1-lugar-catboost-pos-process">ML Olympiad - 1¬∫ Lugar - Catboost + Pos Process</a> (Fellipe)</li>
<li><a href="https://www.kaggle.com/code/kaikewreis/ml-olypiads-1-lugar-lightgbm-binary-ensemble">ML Olypiads - 1¬∫ Lugar - LightGBM Binary Ensemble</a> (Kaike)</li>
<li><a href="https://www.kaggle.com/code/gomes555/ml-olympiad-1-lugar-blending">ML Olympiad - 1¬∫ Lugar - Blending</a> (combina√ß√£o das solu√ß√µes em um emsemble)</li>
</ul>
<p>Disponibilizamos tamb√©m a solu√ß√£o em formato de v√≠deo, gravado em um meetup com dura√ß√£o de 1 hora e meia para o canal do <a href="https://www.youtube.com/@tensorflowugsp">TensorFlow UGSP</a> no Youtube no link: <a href="https://youtu.be/6HPJn38NF3w" class="uri">https://youtu.be/6HPJn38NF3w</a></p>
<center>
<div class="vembedr">
<div>
<iframe src="https://www.youtube.com/embed/6HPJn38NF3w" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"></iframe>
</div>
</div>
</center>
</div>
<div id="estrat√©gia-anal√≠tica" class="section level1">
<h1>Estrat√©gia anal√≠tica</h1>
<p>Nas se√ß√µes abaixo apresento o racional por tr√°s da minha solu√ß√£o, como chegamos nos 5 melhores modelos individuais (para cada doen√ßa respirat√≥ria) que utilizei em um ensemble para chegar ao primeiro lugar, bem como a estrat√©gia de p√≥s processamento que com que o score melhorasse significativamente.</p>
<div id="decis√µes-sobre-a-target" class="section level2">
<h2>Decis√µes sobre a target</h2>
<p>A primeira decis√£o importante era definir como enquadrar o problema; se utilizar√≠amos 1 modelo multiclasse ou diferentes modelos para cada classe.</p>
<p>Em todos os testes que fizemos, os modelos individuais superaram o F1-Score Macro de um modelo √∫nico. Como 3 das classes eram bastante desbalanceadas, acredito que modelos especializados nesses casos conseguiram captar melhor suas nuances.</p>
</div>
<div id="processamento-dos-dados" class="section level2">
<h2>Processamento dos Dados</h2>
<p>Como optamos por unificar os resultados apenas na reta final, meu pr√©-processamento foi muito diferente do feito pelo Kaike e isso foi fundamental para que as estimativas dos nossos modelos tivessem baixa correla√ß√£o. N√£o focarei aqui no meu pr√©-processamento, pois n√£o acho que foi o diferencial para atingir um score superior a 0.6 (quem tiver curiosidade est√° tudo bem documentado nos notebooks compartilhados).</p>
</div>
<div id="dados-externos" class="section level2">
<h2>Dados Externos</h2>
<p>O fato de n√£o termos as informa√ß√µes do ano em que esses dados foram coletados dificultou na busca de bases externas, pois indicadores socioecon√¥micos e de sa√∫de variam bastante ao longo do tempo.</p>
<p>Fizemos alguns testes utilizando o <a href="https://basedosdados.org/dataset/mundo-onu-adh">Atlas do Desenvolvimento Humano (ADH)</a>, mas n√£o tivemos muito sucesso, pois esses dados est√£o muito defasados (1991-2010). Tamb√©m tentamos acrescentar a informa√ß√£o de <a href="https://github.com/kelvins/Municipios-Brasileiros/">latitude e longitude de cada munic√≠pio</a>, mas isso n√£o trouxe uma melhora substancial no nosso score.</p>
</div>
<div id="feature-engineering" class="section level2">
<h2>Feature Engineering</h2>
<p>Outra etapa em que investimos bastante tempo foi para criar novas vari√°veis.</p>
<p>Novamente, nossa engenharia de recursos foi feita de maneira separada para que nossos modelos aprendessem aspectos diferentes dos dados. Abaixo, compartilho algumas das features que desenvolvi apenas para o meu modelo:</p>
<ul>
<li>Presen√ßa de sintomas relacionados √† Target;</li>
<li>Se tomografia era t√≠pica do COVID;</li>
<li>Intervalo de idade com mais casos;</li>
<li>Idade discretizada;</li>
<li>Diferen√ßa entre a semana de notifica√ß√£o e primeiros sintomas;</li>
<li>Novas features baseadas nas contagens de algumas features categ√≥ricas;</li>
<li>etc.</li>
</ul>
</div>
<div id="modelos" class="section level2">
<h2>Modelos</h2>
<p>Al√©m de pr√©-processamentos e feature engineering diferentes, tamb√©m utilizamos modelos e mecanismos de tunning diferentes, o que ajudou para que nossas estimativas tivessem baixa correla√ß√£o. Eu usei o Catboost como modelo final, j√° o Kaike optou por um LightGBM com tuning de hiperparametros.</p>
</div>
<div id="ensemble" class="section level2">
<h2>Ensemble</h2>
<p>Calculamos a m√©dia das probabilidades previstas de cada modelo para cada classe antes de selecionar a classe que tivesse a maior probabilidade.</p>
<p>Como nossas previs√µes tinham baixa correla√ß√£o, conseguimos ser bem sucedidos no ensemble combinando nossas submiss√µes com score ~0.6 alcan√ßando ~0.61 na tabela p√∫blica.</p>
</div>
<div id="post-processing" class="section level2">
<h2>Post Processing</h2>
<p>Acredito que o <strong>diferencial</strong> dessa competi√ß√£o estava no p√≥s processamento.</p>
<p>Quando avaliamos o score do modelo de cada classe, tamb√©m calculamos um threshold que maximizava os respectivos F1.</p>
<p>Observamos que nosso modelo para a classe 5 apresentava um F1 muito superior √†s demais classes com esse threshold otimizado, ent√£o fizemos o seguinte:</p>
<ol style="list-style-type: decimal">
<li>Calculamos as probabilidades individuais para cada classe;</li>
<li>Selecionamos a classe que tinha maior probabilidade estimada em cada inst√¢ncia;</li>
<li>Pegamos a classifica√ß√£o bin√°ria da classe 5 com o threshold otimizado e aplicamos a seguinte condi√ß√£o: Se o modelo da classe 5 estimou que y5[i]==1, ent√£o yfinal[i] √© 5, caso contr√°rio, use a classe de maior probabilidade entre as outras 4. (Em outras palavras: <code>np.where(y5_test_class==1, 5, sub.CLASSI_FIN)</code>)</li>
</ol>
</div>
</div>
<div id="considera√ß√µes-finais" class="section level1">
<h1>Considera√ß√µes Finais</h1>
<p>Foi uma competi√ß√£o muito interessante e desafiadora. Agrade√ßo imensamente ao <a href="https://www.meetup.com/TensorFlowSP/events/284607061/">TFUG</a> por organizar o evento e a todos os participantes que contribu√≠ram para o aprendizado coletivo.Foi uma √≥tima oportunidade de aprendizado e troca de experi√™ncias.</p>
<p>Espero que minha solu√ß√£o possa ser √∫til para outros projetos e desafios futuros.</p>
</div>
<div id="sobre-o-autor" class="section level1">
<h1>Sobre o Autor</h1>
<p>Me chamo Fellipe Gomes, sou cientista de dados e apaixonado por aprendizado de m√°quina. Compartilho meu conhecimento por meio de artigos, tutoriais e projetos de c√≥digo aberto. Se quiser saber mais sobre meu trabalho, sinta-se √† vontade para conferir meu <a href="https://www.linkedin.com/in/fellipe-gomes-06943264/">LinkedIn</a> e <a href="https://github.com/fellipe-gomes">GitHub</a>.</p>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2023-05-30-solucao-final-ensure-healthy-lives-kaggle-competition/">Solu√ß√£o Final - ML Olympiad [1¬∫ lugar]</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">catboost</category>
      <category domain="tag">classification</category>
      <category domain="tag">data-mining</category>
      <category domain="tag">data-science</category>
      <category domain="tag">kaggle</category>
      <category domain="tag">machine-learning</category>
      <category domain="tag">modelagem</category>
      <category domain="tag">pratica</category>
      <category domain="tag">r</category>
    </item>
    <item>
      <title>Gerando arte com Intelig√™ncia Artificial</title>
      <link>https://gomesfellipe.github.io/post/2022-08-08-dataart-primeiros-passos/</link>
      <pubDate>Mon, 08 Aug 2022 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2022-08-08-dataart-primeiros-passos/</guid>
      <description>Veja como usar, op√ß√µes, dicas e truques de modelos de intelig√™ncia artificial para criar arte sem escrever uma linha de c√≥digo (a n√£o ser que voc√™ queira).</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#introdu%C3%A7%C3%A3o" id="toc-introdu√ß√£o">Introdu√ß√£o</a></li>
<li><a href="#dalle-2" id="toc-dalle-2">DALL¬∑E 2</a></li>
<li><a href="#instru%C3%A7%C3%B5es-de-uso" id="toc-instru√ß√µes-de-uso">Instru√ß√µes de Uso</a>
<ul>
<li><a href="#par%C3%A2metros" id="toc-par√¢metros">Par√¢metros</a></li>
<li><a href="#exemplos" id="toc-exemplos">Exemplos</a></li>
</ul></li>
<li><a href="#dalle-mini-e-stable-diffusion" id="toc-dalle-mini-e-stable-diffusion">DALL¬∑E Mini e Stable Diffusion</a>
<ul>
<li><a href="#exemplos-1" id="toc-exemplos-1">Exemplos</a></li>
</ul></li>
<li><a href="#op%C3%A7%C3%B5es-alternativas" id="toc-op√ß√µes-alternativas">Op√ß√µes Alternativas</a>
<ul>
<li><a href="#vqganclip" id="toc-vqganclip">VQGAN+CLIP</a></li>
<li><a href="#mais-par%C3%A2metros" id="toc-mais-par√¢metros">Mais Par√¢metros</a></li>
<li><a href="#mais-exemplos" id="toc-mais-exemplos">Mais Exemplos</a></li>
</ul></li>
<li><a href="#discuss%C3%A3o-filos%C3%B3fica" id="toc-discuss√£o-filos√≥fica">Discuss√£o Filos√≥fica</a></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias</a></li>
</ul>
</div>

<style>
.column4 {
  float: left;
  width: 33%;
  padding: 10px;
}

.column8 {
  float: left;
  width: 66%;
  padding: 10px;
}

.column6 {
  float: left;
  width: 50%;
  padding: 10px;
}

.row:after {
  content: "";
  display: table;
  clear: both;
}
</style>
<div id="introdu√ß√£o" class="section level1">
<h1>Introdu√ß√£o</h1>
<p>Voc√™ j√° deve ter ouvido falar sobre uma <a href="https://canaltech.com.br/inteligencia-artificial/inteligencia-artificial-gera-artes-super-realistas-a-partir-de-textos-e-imagens-213520/#:~:text=A%20empresa%20norte%2Damericana%20de,que%20tinha%20a%20mesma%20fun%C3%A7%C3%A3o.">intelig√™ncia artificial que gera artes super-realistas a partir de textos e imagens</a>. Hoje em dia j√° existem algumas op√ß√µes como <a href="https://openai.com/DALL%C2%B7E-2/">DALL¬∑E 2</a> (da OpenAI/Google) e a <a href="https://arxiv.org/abs/2203.13131">Make-A-Scene</a> (da Meta), e essas ferramentas s√£o capazes de gerar vers√µes e estilos diferentes de uma dada imagem ou ainda criar uma imagem com apenas uma breve descri√ß√£o do resultado desejado. As imagens podem ser t√£o aleat√≥rias quanto um ‚Äúgato de √≥culos e uma coroa‚Äù (em homenagem ao dia dos gatos):</p>
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/gato%20de%20oculos2.png" style="width:90.0%" /> </br>
Imagem gerada por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://openai.com/dall-e-2/">DALL¬∑E 2</a>
</center>
<p>N√£o vou entrar na teoria por tr√°s dos algoritmos pois al√©m do <a href="https://arxiv.org/abs/2204.06125">artigo oficial</a>, existe bastante conte√∫do sobre o assunto dispon√≠vel na internet. Neste post focarei mais em fazer alguns coment√°rios sobre o que andei estudando e compartilhar algumas dicas √∫teis sobre como escrever os ‚Äúpar√¢metros‚Äù ou ‚Äúqueries‚Äù para sistemas DALL¬∑E 2 (ou alternativos).</p>
<p>N√£o posso prometer que depois de ler este post voc√™ estar√° imediatamente capaz de criar artes incr√≠veis utilizando IA at√© porque eu tamb√©m sou iniciante no assunto, mas ter√° algum conhecimento b√°sico para poder trabalhar e desenvolver ainda mais suas habilidades. Para ser honesto, uma vez que acostumamos, n√£o √© muito dif√≠cil de usar. N√£o h√° necessidade de escrever nenhuma linha de c√≥digo para utilizar a DALL¬∑E 2 nem as outras arquiteturas que apresentarei neste post (no m√°ximo ajustar alguns hiperpar√¢metros, caso queira).</p>
</div>
<div id="dalle-2" class="section level1">
<h1>DALL¬∑E 2</h1>
<p>A OpenAI lan√ßou em Janeiro de 2021 o DALL¬∑E e um ano depois, sua segunda gera√ß√£o que constr√≥i imagens mais realistas e precisas, com resolu√ß√£o 4x maior. DALL¬∑E 2 come√ßou como um projeto de pesquisa e agora est√° dispon√≠vel em vers√£o beta para aqueles que entrarem na <a href="https://labs.openai.com/waitlist">waitlist</a>. Eles pedem algumas informa√ß√µes como redes sociais e inten√ß√µes de uso. No meu caso, demorou uns 2/3 meses para libera√ß√£o, quando recebi um e-mail com meu acesso:</p>
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/dalle_bem_vindo.png" style="width:80.0%" />
</center>
<p>O modelo n√£o est√° finalizado pois existem diversas mitiga√ß√µes de seguran√ßa que a equipe da OpenAI ainda vem trabalhando:</p>
<ul>
<li>Previnir gera√ß√£o de imagens violentas, limitando a capacidade do DALL¬∑E 2 ao remover conte√∫do explicito dos dados de treinamento e minimizando a exposi√ß√£o do algoritmo √† estes conceitos;</li>
<li>Restringir conte√∫dos pol√≠ticos evitando seu uso indevido (ex.: fake news);</li>
<li>Implanta√ß√£o em fases, limitando o n√∫mero de acessos para usu√°rios confi√°veis e a medida que ganharem confian√ßa, liberam a vers√£o beta para mais pessoas.</li>
</ul>
<div class="w3-panel w3-pale-red w3-border">
<p>¬† üö® <strong>Aten√ß√£o</strong></p>
<p>Para quem quiser ir brincando com esse tipo de rede neural enquanto n√£o recebe o acesso, leia at√© o final pois apresentarei algumas alternativas!</p>
</div>
</div>
<div id="instru√ß√µes-de-uso" class="section level1">
<h1>Instru√ß√µes de Uso</h1>
<p>Ainda existe muita discuss√£o sobre o assunto na comunidade e ainda n√£o consolidou-se um ‚Äúguia definitivo de como usar a ferramenta‚Äù, as dicas que darei aqui foram baseadas em experimentos que fiz e pesquisas na internet (refer√™ncias no final do post). Tentarei fornecer uma boa quantidade de informa√ß√µes organizadas que sejam f√°ceis de entender, mas tamb√©m √∫til para ajud√°-lo a entender como a IA interpreta a frase que voc√™ escreve como input.</p>
<div id="par√¢metros" class="section level2">
<h2>Par√¢metros</h2>
<p>Os ‚Äúpar√¢metros‚Äù que usamos para definir e descrever os detalhes/estilos/objetos/ambiente etc que est√£o na imagem s√£o a chave. Essas s√£o as instru√ß√µes ou descri√ß√µes que ‚Äúdizem‚Äù ao algoritmo o que voc√™ deseja ver na imagem.</p>
<p>√â preciso escrever a frase de uma maneira que a IA entenda claramente. Voc√™ se familiarizar√° com a maneira de escrever par√¢metros ao longo do tempo com a pr√°tica (caso tenha tempo, veja este v√≠deo de <a href="https://www.youtube.com/watch?v=pdhqwbUWf4U">como ensinar linguagem de programa√ß√£o para uma crian√ßa</a>, que da uma bela intui√ß√£o de como devemos pensar).</p>
<p>Para come√ßar, precisamos decidir qual √© a imagem. √â uma pintura? uma fotografia? um desenho de uma linha? Primeiro decidimos o meio da imagem e depois o assunto da imagem. O que vai ter na pintura? Existe uma hist√≥ria a ser contada para descrever visualmente para a IA para que ela esteja na imagem? De que √© a imagem?</p>
<p>Se a imagem que voc√™ deseja produzir for replicar uma arte (um desenho, pintura, etc. de algo), ent√£o voc√™ deve pensar no estilo de arte de um artista que voc√™ gosta ou qual estilo de arte se adequaria ao tema ou sentimento da pe√ßa de arte voc√™ est√° tentando criar.</p>
</div>
<div id="exemplos" class="section level2">
<h2>Exemplos</h2>
<p>A seguir veremos alguns exemplos de como fazer e como n√£o fazer a ‚Äúquery para gerar as imagens.‚Äù</p>
<div class="row">
<div class="column8">
<p>Para criar uma pintura no estilo de algu√©m voc√™ escreveria algo assim nos par√¢metros :‚ÄúA digital art of a happy dog in a desert with pyramids in the background and planets in the sky‚Äù (Uma arte digital de um cachorro feliz em um deserto com pir√¢mides ao fundo e planetas no c√©u):</p>
<p>Note que o modelo entende bem o que s√£o os elementos e como eles se posicionam (√† frente, atr√°s, acima, abaixo, direita, esquerda, etc). Al√©m disso, como n√£o especifiquei se era dia/noite nem se o fundo seria um universo, as cores ficaram confusas. Um azul escuro (quase preto) onde est√£o os planetas e um azul claro (como dia) para o fundo do deserto.</p>
</div>
<div class="column4">
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/dog.png" style="width:90.0%" />
</br>
Imagem gerada por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://openai.com/dall-e-2/">DALL¬∑E 2</a>
</center>
</div>
</div>
<p>Se a imagem n√£o for de uma obra de arte/pintura, n√£o iniciamos a frase com o meio (esbo√ßo/pintura/qualquer que seja), em vez disso, come√ßamos a frase descrevendo imediatamente a cena da maneira mais gramaticalmente correta poss√≠vel (que seja dif√≠cil de entender errado).</p>
<p>Veja um exemplo que vi na internet, dizer algo como ‚ÄúUm homem e uma mulher de vestido vermelho ao lado de um cavalo‚Äù pode ser mal interpretado pela IA, pois o homem e a mulher podem estar no vestido vermelho ou com roupas vermelhas, al√©m de faltar mais detalhes do que estamos imaginando. Veja como ficou o exemplo gerado:</p>
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/homem_mulher_1.png" style="width:90.0%" />
</br>
Imagem gerada por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://openai.com/dall-e-2/">DALL¬∑E 2</a>
</center>
<p>At√© que o resultado n√£o ficou t√£o ruim, com pelo menos uma imagem com o rapaz de camisa branca. Mas n√£o era exatamente essa cena que tinha em mente, vamos tentar descrever melhor a cena que gostariamos de ver: ‚ÄúUm homem de terno preto e uma mulher de lindo vestido vermelho ao lado de seu majestoso cavalo marrom enquanto observam o p√¥r do sol‚Äù:</p>
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/homem_mulher_2.png" style="width:90.0%" />
</br>
Imagem gerada por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://openai.com/dall-e-2/">DALL¬∑E 2</a>
</center>
<p>N√≥s j√° estavamos vendo essa cena mentalmente, mas simplesmente n√£o a hav√≠amos descrito bem o suficiente. Ent√£o sempre pense nas descri√ß√µes dessa maneira, tentando explicar uma fotografia para uma crian√ßa de dez anos de uma forma que provavelmente seria capaz de desenh√°-la ou algo muito parecido sem ver a foto.</p>
<p>Al√©m de descrever bem as fotos, existem alguns tipos de palavras-chave que podem ajudar a melhorar os detalhes, veja alguns bastante populares que criam resultados surpreendentes: ‚Äú4k‚Äù, ‚ÄúUnreal engine‚Äù, ‚ÄúRay tracing‚Äù, ‚ÄúFotorrealismo‚Äù, ‚ÄúHiper-realismo‚Äù.</p>
<div class="w3-panel w3-pale-green w3-border">
<p>¬† ‚≠êÔ∏è Sucesso!</p>
<p>Agora, juntando todas essas dicas, acho que voc√™ est√° pronto para tentar construir seus pr√≥prios ‚Äúpar√¢metros‚Äù.</p>
</div>
</div>
</div>
<div id="dalle-mini-e-stable-diffusion" class="section level1">
<h1>DALL¬∑E Mini e Stable Diffusion</h1>
<blockquote>
<p>Ainda n√£o tenho acesso ao DALL¬∑E 2 e agora?</p>
</blockquote>
<p>Bom, a OpenAI apresentou o primeiro (e impressionante) modelo para gerar imagens com DALL¬∑E, certo? A partir da√≠ a comunidade ficou enlouquecida e muitos cientistas de dados tentaram reproduzir os resultados inspirados no <a href="https://arxiv.org/abs/%202204.06125">artigo oficial</a>.</p>
<p>A vers√£o mais promissora que encontrei foi a <a href="https://huggingface.co/spaces/dalle-mini/dalle-mini">DALL¬∑E mini</a>, desenvolvida por <a href="https://www.craiyon.com/">craiyon.com</a> que √© √© um modelo de IA capaz de gerar figuras formid√°veis a partir de qualquer input de texto. Al√©m disso eles est√£o trabalhando na vers√£o <a href="https://wandb.ai/dalle-mini/dalle-mini/reports/DALL%C2%B7E-mini-Generate-images-from-any-text-prompt--VmlldzoyMDE4NDAy">‚ÄúDALL¬∑E mega‚Äù</a> que possui diversas melhorias nos otimizadores, na arquitetura em geral e treinada em datasets maiores (uma vers√£o beta ja pode ser <a href="https://github.com/borisdayma/dalle-mini">importada via Python</a>).</p>
<p>Al√©m desta, outro lan√ßamento p√∫blico anunciado recentemente (e muito promissor) foi o <a href="https://stability.ai/blog/stable-diffusion-public-release">Stable Difusion</a>, que ap√≥s incans√°veis revis√µes jur√≠dicas, √©ticas e de tecnologia, lan√ßaram o modelo e um
<a href="https://huggingface.co/spaces/stabilityai/stable-diffusion">aplicativo web</a> pronto para uso, com licen√ßa permissiva para uso comercial e n√£o comercial.</p>
<p>√â muito legal ver nestas ferramentas, o fruto de muitas horas de esfor√ßo coletivo para criar um √∫nico arquivo que comprime a ‚Äúinforma√ß√£o visual da humanidade‚Äù em alguns gigabytes!</p>
<div id="exemplos-1" class="section level2">
<h2>Exemplos</h2>
<p>Veja algumas imagens geradas tentando descrever sentimentos:</p>
<div class="row">
<div class="column4">
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/sentimento_felicidade.png" style="width:90.0%" />
</br>
‚ÄúFelicidade‚Äù
</center>
</div>
<div class="column4">
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/sentimento_amor.png" style="width:90.0%" />
</br>
‚ÄúAmor‚Äù
</center>
</div>
<div class="column4">
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/sentimento_solidao.png" style="width:90.0%" />
</br>
‚ÄúSolid√£o‚Äù
</center>
</div>
</div>
<div style="text-align:center">
<p>Imagens geradas por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://huggingface.co/spaces/dalle-mini/dalle-mini">DALL¬∑E Mini</a></p>
</div>
<p>A id√©ia de gerar estas imagens era tentar entender como uma IA ‚Äúpensaria‚Äù sobre estes termos mas, para surpresa de ningu√©m, os resultados foram muito pr√≥ximos de uma busca no Google (dado que o modelo foi treinado em conjuntos de dados p√∫blicos). √â poss√≠vel notar tamb√©m alguns ‚Äúbugs‚Äù como o √∫ltimo smile e um ‚Äúcora√ß√£o duplo‚Äù.</p>
<p>Mesmo assim, achei interessante as paletas de cores apresentadas com cores mais ‚Äúalegres‚Äù para felicidade (como verde, azul, branco e o amarelo dos ‚Äúsmiles‚Äù), um vermelho/rosa para amor e solid√£o em tons de cinza.</p>
<p>Essa rede tem algumas limita√ß√µes com rostos e acabam sendo meio distorcidas (segundo os desenvolvedores, √© uma limita√ß√£o atual do codificador de imagem mas eles j√° est√£o trabalhando nisso). Veja a seguir uma compara√ß√£o do resultado da DALL¬∑E 2 vs DALL mini para a frase ‚ÄúUma sereia nadando em um mar de fogo‚Äù:</p>
<div class="row">
<div class="column6">
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/sereia_1.jpg" style="width:90.0%" />
</center>
</div>
<div class="column6">
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/sereia_2.jpg" style="width:90.0%" />
</br>
</center>
</div>
</div>
<div style="text-align:center">
<p>Imagens geradas por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://huggingface.co/spaces/dalle-mini/dalle-mini">DALL¬∑E Mini</a></p>
</div>
<p>A imagem gerada pela DALL¬∑E mini tem uma resolu√ß√£o mais baixa e demorou um pouco mais para ser processada. Um ponto interessante √© como mesmo esse modelo ‚Äúmenor‚Äù j√° √© capaz de entender um ‚Äúmar‚Äù e gerar o reflexo na √°gua. Os ‚Äúrostos‚Äù gerados pela DALL¬∑E mini muitas vezes s√£o comparados com ‚Äúsonhos‚Äù e at√© mesmo meio assustadores enquanto que a DALL¬∑E 2 conseguiu entregar uma imagem que, apesar de meio ‚Äúcaricata‚Äù, at√© que ficou bastante detalhada.</p>
</div>
</div>
<div id="op√ß√µes-alternativas" class="section level1">
<h1>Op√ß√µes Alternativas</h1>
<p>Depois que o artigo com a ideia principal foi divulgado, a comunidade come√ßou a desenvolver diversas redes que trabalhassem de forma semelhante. Nenhuma das redes conseguiu ser t√£o realistas quando a DALL¬∑E mas fica aquela coisa meio psicodelica que se parece mesmo com um sonho.</p>
<p>Existem diversas vers√µes, como por exemplo:</p>
<ul>
<li><a href="https://colab.research.google.com/drive/1go6YwMFe5MX6XM9tv-cnQiSTU50N9EeT#scrollTo=g7EDme5RYCrt">VQGAN+CLIP</a> (focaremos nesta);</li>
<li><a href="https://colab.research.google.com/drive/1fWka_U56NhCegbbrQPt4PWpHPtNRdU49?usp=sharing#scrollTo=zvZFRZtcv8Mp">CLIP-GLaSS</a>;</li>
<li><a href="https://colab.research.google.com/github/eyaler/clip_biggan/blob/main/WanderCLIP.ipynb#scrollTo=lT3rLJx4VjlD">BigGAN + CLIP + CMA-ES</a>;</li>
<li><a href="https://www.artstation.com/blogs/stijn/B276/ai-sketches-with-vqgan-and-clip-for-concept-art">Disco Diffusion v4.1</a>;</li>
<li><a href="https://grisk.itch.io/clip-app">Um app para Windows que usa a pr√≥pria RAM do pc</a>;</li>
<li><a href="https://www.midjourney.com/home/">Midjourney</a>;</li>
<li><a href="https://www.reddit.com/r/learnmachinelearning/comments/l4qhnp/openais_dalle_alternatives_with_colab_code_deep/">Dentre outras‚Ä¶</a></li>
</ul>
<p>Todos os notebooks que est√£o na lista acima s√£o hospedados no Google Collab e podem ser executados sem nenhum tipo de pr√©-configura√ß√£o de ambiente. O modelo mais popular (e o que eu utilizei mais) acabou sendo a VQGAN+CLIP que foi inicialmente escrito em espanhol e depois em ingl√™s.</p>
<div id="vqganclip" class="section level2">
<h2>VQGAN+CLIP</h2>
<p>Apesar de muito democr√°tica, o problema de hospedar esses notebooks no Google Collab √© que se voc√™ estiver usando um usu√°rio gratuito, descobrir√° que a GPU e RAM s√£o bem limitada. Algumas imagens precisavam de at√© 5h para serem geradas e mesmo assim o resultado n√£o ficava bom (ri muito com alguns resultados üòÇ), enquanto que as imagens geradas com o uso da GPU rodavam em alguns minutos e dava para ver que a rede conseguia ‚Äúir mais longe‚Äù, alcan√ßando imagens com resolu√ß√£o melhor.</p>
<p>Veja a seguir uma imagem que criei a partir de uma foto da Amora (minha cachorrinha) como ‚Äúchute inicial‚Äù:</p>
<p>‚Äù A happy dog in the desert:200 | sunset in the background:100 | planets in the sky:100 | by Salvador Dali:100 | turtle:-100 | city:-100 | buildings:-200‚Äù</p>
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/bafo_surrealista.png" style="width:80.0%" />
</br>
Imagem gerada por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://colab.research.google.com/drive/1go6YwMFe5MX6XM9tv-cnQiSTU50N9EeT#scrollTo=ZdlpRFL8UAlW">VQGAN+CLIP</a>
</center>
<p>Particularmente, gostei bastante do resultado final mas n√£o foi t√£o f√°cil utilizando esta rede. Antes de submeter a imagem no notebook, precisei remover o fundo para remover qualquer tipo de ru√≠do pois a rede n√£o √© capaz de distinguir o que √© um cachorro, o que √© meu bra√ßo ou o arm√°rio ao fundo e os resultados ficavam muito estranhas. Al√©m disso fiz uma colagem (no Power Point mesmo) com alguns elementos que eu gostaria que estivessem na imagem data determinar suas posi√ß√µes.</p>
<div class="w3-panel w3-pale-yellow w3-border">
<p>¬† ‚ö†Ô∏è Alerta!</p>
<p>Eu tinha muito claro em minha mente aonde gostaria que os elementos estivessem posicionados, por√©m, esta etapa de colagem dos elementos √© completamente opcional! √â uma forma de ‚Äúguiar‚Äù a rede para resultados que estamos procurando, parando em determinada intera√ß√£o e ajustando a posi√ß√£o de elementos (muito √∫til para arrumar algumas estranhezas que aparecem em rostos) e inputando novamente como imagem inicial.</p>
</div>
<p>Al√©m disso, voc√™ deve ter notado a presen√ßa de pipes ‚Äú|‚Äù e uns valores (como dicion√°rios do Python). A id√©ia √© que as palavras-chave que voc√™ colocar entre cada um desses pipes influenciar√° bastante na imagem final e at√© mesmo remover coisas que n√£o desejamos.</p>
<p>A primeira senten√ßa √© definida automaticamente como 100 ‚Äúunidades‚Äù. Logo em seguida, as pr√≥ximas senten√ßas receber√£o apenas 1 ‚Äúunidade‚Äù. O ideal √© colocar o ‚Äúvalor‚Äù associado aquela ‚Äúchave‚Äù que representa o qu√£o ‚Äúproeminente‚Äù ser√° aquele elemento na imagem.</p>
<p>Note ainda que eu tentei evitar que o modelo inclu√≠-se novos elementos como uma cidade que estava se formando ao fundo ou uma tartaruga no canto esquerdo informando valores negativos para estes elementos que n√£a gostaria que aparecessem.</p>
<p>Estes notebooks n√£o salvam seus resultados, quando voc√™ atualizar a p√°gina, outra se√ß√£o ser√° iniciada e todo o trabalho ser√° perdido! Ent√£o quando gostar de alguma imagem, n√£o esque√ßa de salv√°-la!</p>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† üí° Dica</p>
<p>Nem sempre a √∫ltima imagem gerada no processo √© a que n√≥s mais gostamos, ent√£o vale a pena conferir como foi o processo de aprendizagem em ‚Äú√©pocas‚Äù anteriores.</p>
</div>
</div>
<div id="mais-par√¢metros" class="section level2">
<h2>Mais Par√¢metros</h2>
<p>Praticamente todos esses notebooks possuem os mesmos par√¢metros ent√£o passarei por alguns que considero interessantes para se ter uma no√ß√£o geral de como funciona:</p>
<ul>
<li><p><code>model</code>: h√° v√°rias op√ß√µes de modelos treinados em conjuntos de dados espec√≠ficos para diferentes tarefas, como por exemplo:</p>
<ul>
<li>Imagens com diferentes texturas: <code>imagenet_1024</code>, <code>imagenet_16384</code>, <code>sflckr</code>, <code>coco</code>;</li>
<li>Imagens com estilos de arte: <code>wikiart_1024</code>, <code>wikiart_16384</code>;</li>
<li>Rostos com diferentes tra√ßos: <code>faceshq</code>, <code>ffhq</code>, <code>celebahq</code>;</li>
</ul></li>
<li><p><code>inicial_image</code>: podemos ter uma id√©ia de elementos que gostar√≠amos que estivesse na imagem e ent√£o criar uma imagem para usar como ‚Äúchute inicial‚Äù para direcionar o trabalho da rede;</p></li>
<li><p><code>seed</code>: √© bom colocar um n√∫mero aleat√≥rio (maior que zero) para garantir que o desenvolvimento da imagem seja reprodut√≠vel;</p></li>
<li><p><code>max_interactions</code>: √© o n√∫mero de vezes que o modelo vai ‚Äútrabalhar‚Äù na imagem. Pode ser limitado, a menos que voc√™ pague pelo Google Collab Pro (a√≠ da para colocar um valor bem alto e avaliar um bom ponto de parada ap√≥s alguns experimentos).</p></li>
<li><p><code>height</code> e <code>width</code>: a altura e a largura s√£o colocadas automaticamente em 600 e 600. Pode ser que demore um pouco ent√£o para quem estiver usando a vers√£o free pode ser √∫til abaixar para cerca de 200 de largura e altura para aliviar no processamento da imagem e permitir mais itera√ß√µes.</p></li>
</ul>
</div>
<div id="mais-exemplos" class="section level2">
<h2>Mais Exemplos</h2>
<div class="row">
<div class="column8">
<p>Veja um exemplo de arte gerada a partir de um quadro, onde a tecnologia atua como um colaborador criativo em vez de uma ferramenta b√°sica:</p>
<p>Esta pintura √© intitulada como ‚ÄúDesolate Civilisation‚Äù e √© composta por 9 pinturas futuristas criadas e montadas utilizando VQGAN+CLIP para se assemelhar √† Mona Lisa (via <a href="https://creator.nightcafe.studio/create">NightCafe Studio</a>).</p>
<p>Interessante como o autor divide a tarefa em 9 ‚Äúminitarefas‚Äù, facilitando assim a produ√ß√£o da imagem toda (al√©m de dar um toque art√≠stico bem interessante).</p>
</div>
<div class="column4">
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/monalisa_nightcafe.png" style="width:90.0%" />
</br>
<em>Desolate Civilisation</em> - <a href="https://creator.nightcafe.studio/create">NightCafe Studio</a>
</center>
</div>
</div>
</div>
</div>
<div id="discuss√£o-filos√≥fica" class="section level1">
<h1>Discuss√£o Filos√≥fica</h1>
<p>Estas novas abordagens est√£o mudando definitivamente a natureza dos processos criativos. Al√©m de n√≥s, meros mortais n√£o-desenhistas, os artistas tamb√©m podem se beneficiar destas tecnologias como fonte de inspira√ß√£o, seja gerando imagens aleat√≥rias sobre coisas que v√™m em mente ou ainda ‚Äútunar‚Äù suas obras, mesclando com diferentes elementos ou tipos de estilos.</p>
<div class="row">
<div class="column8">
<p>Apesar de interessante, para pessoas questionadoras, pode surgir alguma quest√£o filos√≥fica como: <strong>ser√° que isto √© arte</strong>? Existem muitas defini√ß√µes de arte e seu significado varia conforme a √©poca ou cultura.</p>
<p>Li diferentes defini√ß√µes e refleti bastante sobre o assunto, e a defini√ß√£o que mais me agradou foi a de <strong>Immanuel Kant</strong> (um dos meus fil√≥sofos favoritos), que sugere que: ‚Äúa arte diferencia-se da natureza por ser uma atividade racional e livre. Assim, uma teia de aranha, embora possa parecer bela, n√£o √© uma obra de arte, j√° que se trata de uma tarefa mec√¢nica e natural. A arte tamb√©m se diferencia da ci√™ncia, j√° que para se produzir uma obra de arte n√£o basta ter conhecimento sobre um determinado assunto - √© preciso ter habilidade para fazer. Kant define a arte est√©tica como aquela cuja finalidade imediata √© o sentimento do prazer, n√£o apenas o prazer ligado √†s sensa√ß√µes, mas tamb√©m o prazer da reflex√£o.‚Äù</p>
</div>
<div class="column4">
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/arte_dalle.png" style="width:90.0%" />
</br>
Imagem gerada por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://openai.com/dall-e-2/">DALL¬∑E 2</a>
</center>
</div>
</div>
<p>Imagino que, pelo menos hoje em dia e por um bom tempo, a IA por si s√≥ n√£o conseguir√° produzir arte, pois at√© ent√£o todos esses modelos est√£o ‚Äúaprendendo‚Äù com os inputs que fornecemos e produzindo outputs que pedimos. Isso √© uma limita√ß√£o de uma ‚Äúintelig√™ncia artificial fraca‚Äù n√£o sendo capaz de executar a atividade art√≠stica ‚Äúlivremente‚Äù, al√©m de que sua finalidade imediata n√£o tem haver com prazer de reflex√£o nenhuma.</p>
<p>Enquanto continuamos a filosofar e especular sobre a defini√ß√£o de arte, podemos usar estes modelos para ajudar na cria√ß√£o de valor com as ‚Äúartes‚Äù mais necess√°rias no mundo capitalista que vivemos. Veja como fica ‚ÄúUma foto em 4k de um carro futurista em um sal√£o todo branco e vazio‚Äù:</p>
<center>
<img src="/post/2022-08-08-dataart-primeiros-passos/dalle_car.png" style="width:90.0%" />
</br>
Imagem gerada por <a href="https://gomesfellipe.github.io/">gomesfellipe</a> utilizando <a href="https://openai.com/dall-e-2/">DALL¬∑E 2</a>
</center>
<p>Essas imagens mostram como podemos usar estes modelos para produzir prot√≥tipos de bens de consumo, p√°ginas iniciais de sites ou at√© p√¥steres de filmes (imagina ‚ÄúFuturistic Fast and Furious‚Äù üòÖ üòÇ).</p>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o</h1>
<p>Todos esses experimentos me fizeram entender melhor o que √© poss√≠vel e o que n√£o √© poss√≠vel de fazer, mas me deixaram com muitas d√∫vidas de quest√µes filos√≥ficas sobre o que √© a arte em si no sentido mais amplo ü§Ø.</p>
<p>No futuro, gostaria de explorar novas formas de me divertir, criar arte e encontrar caminhos para usar essa nova tecnologia para facilitar o trabalho das pessoas e, quem sabe, at√© monetizar!</p>
<p>Espero que tenham gostado, qualquer cr√≠tica ou sugest√£o ser√° muito bem vinda!</p>
<p>Abra√ßos!</p>
<p><a href="https://gomesfellipe.github.io/about/">Fellipe Gomes</a></p>
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias</h1>
<ul>
<li><a href="https://www.reddit.com/r/bigsleep/comments/p15fis/tutorial_an_introduction_for_newbies_to_using_the/" class="uri">https://www.reddit.com/r/bigsleep/comments/p15fis/tutorial_an_introduction_for_newbies_to_using_the/</a></li>
<li><a href="https://openai.com/dall-e-2/" class="uri">https://openai.com/dall-e-2/</a></li>
<li><a href="https://github.com/openai/DALL-E/blob/master/notebooks/usage.ipynb" class="uri">https://github.com/openai/DALL-E/blob/master/notebooks/usage.ipynb</a></li>
<li><a href="https://colab.research.google.com/drive/1go6YwMFe5MX6XM9tv-cnQiSTU50N9EeT#scrollTo=ZdlpRFL8UAlW" class="uri">https://colab.research.google.com/drive/1go6YwMFe5MX6XM9tv-cnQiSTU50N9EeT#scrollTo=ZdlpRFL8UAlW</a></li>
<li><a href="https://www.artstation.com/blogs/stijn/B276/ai-sketches-with-vqgan-and-clip-for-concept-art" class="uri">https://www.artstation.com/blogs/stijn/B276/ai-sketches-with-vqgan-and-clip-for-concept-art</a></li>
<li><a href="https://arxiv.org/abs/2204.06125" class="uri">https://arxiv.org/abs/2204.06125</a></li>
<li><a href="https://arxiv.org/abs/2203.13131" class="uri">https://arxiv.org/abs/2203.13131</a></li>
<li><a href="https://www.artstation.com/blogs/stijn/B276/ai-sketches-with-vqgan-and-clip-for-concept-art" class="uri">https://www.artstation.com/blogs/stijn/B276/ai-sketches-with-vqgan-and-clip-for-concept-art</a></li>
<li><a href="https://huggingface.co/spaces/dalle-mini/dalle-mini" class="uri">https://huggingface.co/spaces/dalle-mini/dalle-mini</a></li>
<li><a href="https://github.com/borisdayma/dalle-mini" class="uri">https://github.com/borisdayma/dalle-mini</a></li>
<li><a href="https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini-Generate-images-from-any-text-prompt--VmlldzoyMDE4NDAy" class="uri">https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini-Generate-images-from-any-text-prompt--VmlldzoyMDE4NDAy</a></li>
<li><a href="https://stability.ai/blog/stable-diffusion-announcement" class="uri">https://stability.ai/blog/stable-diffusion-announcement</a></li>
<li><a href="https://siliconangle.com/2022/07/14/metas-latest-generative-ai-system-creates-stunning-images-sketches-text/" class="uri">https://siliconangle.com/2022/07/14/metas-latest-generative-ai-system-creates-stunning-images-sketches-text/</a></li>
<li><a href="https://creator.nightcafe.studio/create" class="uri">https://creator.nightcafe.studio/create</a></li>
<li><a href="https://michaelis.uol.com.br/moderno-portugues/busca/portugues-brasileiro/arte" class="uri">https://michaelis.uol.com.br/moderno-portugues/busca/portugues-brasileiro/arte</a></li>
<li><a href="https://www.significados.com.br/arte/" class="uri">https://www.significados.com.br/arte/</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2022-08-08-dataart-primeiros-passos/">Gerando arte com Intelig√™ncia Artificial</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">dalle2</category>
      <category domain="tag">data-science</category>
      <category domain="tag">dataart</category>
      <category domain="tag">gan</category>
      <category domain="tag">inteligencia-artificial</category>
      <category domain="tag">python</category>
      <category domain="tag">redes-neurais</category>
      <category domain="tag">vqgan&#43;clip</category>
    </item>
    <item>
      <title>Solu√ß√£o Final - ML Olympiad [2¬∫ lugar]</title>
      <link>https://gomesfellipe.github.io/post/2022-04-20-solucao-final-education-quality-kaggle-competition/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2022-04-20-solucao-final-education-quality-kaggle-competition/</guid>
      <description>Confira a estrat√©gia aplicada para esta competi√ß√£o</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#introdu%C3%A7%C3%A3o" id="toc-introdu√ß√£o">Introdu√ß√£o</a></li>
<li><a href="#defini%C3%A7%C3%A3o-do-problema-de-neg%C3%B3cio" id="toc-defini√ß√£o-do-problema-de-neg√≥cio">Defini√ß√£o do problema de neg√≥cio</a></li>
<li><a href="#an%C3%A1lise-explorat%C3%B3ria-em-r" id="toc-an√°lise-explorat√≥ria-em-r">An√°lise Explorat√≥ria (em R)</a>
<ul>
<li><a href="#estrutura-da-base" id="toc-estrutura-da-base">Estrutura da base</a></li>
<li><a href="#ano-da-base-de-dados" id="toc-ano-da-base-de-dados">Ano da base de dados</a></li>
<li><a href="#target" id="toc-target">Target</a></li>
</ul></li>
<li><a href="#machine-learning-em-python" id="toc-machine-learning-em-python">Machine Learning (em Python)</a>
<ul>
<li><a href="#importar-dependencias" id="toc-importar-dependencias">Importar dependencias</a></li>
<li><a href="#carregar-dados" id="toc-carregar-dados">Carregar dados</a></li>
<li><a href="#modelagem" id="toc-modelagem">Modelagem</a></li>
</ul></li>
<li><a href="#submiss%C3%A3o" id="toc-submiss√£o">Submiss√£o</a></li>
<li><a href="#considera%C3%A7%C3%B5es-finais" id="toc-considera√ß√µes-finais">Considera√ß√µes Finais</a></li>
</ul>
</div>

<div id="introdu√ß√£o" class="section level1">
<h1>Introdu√ß√£o</h1>
<p>No final de Janeiro desde ano (2022) o <a href="https://www.meetup.com/TensorFlowSP/events/284607061/">TFUG - TensorFlow Users Group de S√£o Paulo</a> lan√ßou uma competi√ß√£o no Kaggle para prever as notas do enem que tem rela√ß√£o com um dos 17 t√≥picos de Desenvolvimento Sustent√°vel das Na√ß√µes Unidas - <em>Educa√ß√£o de Qualidade</em>.</p>
<p>Al√©m de divertido, o desafio foi repleto de possibilidades e bastante desafiador! Todos os competidores que trabalharam duro em pleno m√™s de carnaval est√£o de parab√©ns! üòÖ üòÇ</p>
<p>Aqui est√£o alguns dos pr√™mios recebidos:</p>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/premio.png" style="width:80.0%" />
</center>
<p>Como nesta competi√ß√£o havia bastante trabalho a ser feito e tivemos apenas 1 m√™s para trabalhar na solu√ß√£o, foi preciso fazer uma boa gest√£o do c√≥digo e do tempo de desenvolvimento.</p>
<p>Nas se√ß√µes abaixo apresento o racional por tr√°s da minha solu√ß√£o bem como os 5 melhores modelos individuais (para cada nota) que utilizei em um ensemble para chegar ao segundo lugar.</p>
</div>
<div id="defini√ß√£o-do-problema-de-neg√≥cio" class="section level1">
<h1>Defini√ß√£o do problema de neg√≥cio</h1>
<p>O objetivo desta competi√ß√£o consistiu em prever as notas dos alunos(as) nas provas: Ci√™ncias da Natureza, Ci√™ncias Humanas, Linguagens e C√≥digos, Matem√°tica e Reda√ß√£o.</p>
<p>Apesar das notas serem calculadas de maneira independente, a partir de modelos de <a href="http://portal.mec.gov.br/ultimas-noticias/389-ensino-medio-2092297298/17319-teoria-de-resposta-ao-item-avalia-habilidade-e-minimiza-o-chute">TRI (Teoria de Resposta ao Item)</a> que levam em considera√ß√£o a performance em um caderno espec√≠fico e na dificuldade de cada quest√£o, o mesmo aluno realiza todas as provas em um curto per√≠odo de tempo.</p>
<p>Portanto, esta tarefa pode ser enquadrada como um problema supervisionado de regress√£o com m√∫ltiplos outputs na qual as previs√µes s√£o, de certa forma, dependentes da entrada umas das outras.</p>
<p>A valida√ß√£o da solu√ß√£o foi feita utilizando a m√©trica Mean Columnwise Root Mean Squared Error ‚Äì MCRMSE, que √© basicamente a m√©dia do RMSE calculado sobre as previs√µes de cada nota.</p>
</div>
<div id="an√°lise-explorat√≥ria-em-r" class="section level1">
<h1>An√°lise Explorat√≥ria (em R)</h1>
<p>Convido o leitor a conferir o <a href="https://gomesfellipe.github.io/post/2021-11-01-solucao-final-porto-seguro-data-challenge/">notebook publicado no Kaggle</a> com a an√°lise explorat√≥ria completa. Aqui irei trazer apenas alguns dos principais insights que encontrei durante a etapa de an√°lise explorat√≥ria.</p>
<div id="estrutura-da-base" class="section level2">
<h2>Estrutura da base</h2>
<p>Veja a seguir qual a estrutura geral da base de dados:</p>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/02_df_status.png" style="width:95.0%" />
</center>
<p>√â not√≥rio que existem dados faltantes e que parece haver algum padr√£o. Vejamos com mais detalhse:</p>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/03_missing.png" style="width:95.0%" />
</center>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† üí° Insights!</p>
<p>Existem dados <em>missing</em> nas 5 targets que queremos prever e note que existe uma rela√ß√£o tanto entre as provas de Matem√°tica e Ci√™ncias da Natuerza quanto nas de Ci√™ncias Humanas, Linguagens e C√≥digos e Reda√ß√£o, o que parece ocorrer devido a aus√™ncia do aluno incrito em comparecer a realiza√ß√£o da prova no respectivo dia.</p>
</div>
</div>
<div id="ano-da-base-de-dados" class="section level2">
<h2>Ano da base de dados</h2>
<p>Essa informa√ß√£o n√£o estava explicitamente dispon√≠vel, mas ap√≥s analisar a idade dos participantes em rela√ß√£o ao ano em que conclu√≠ram o ensino m√©dio, foi poss√≠vel identificar que tratavam-se dos dados de 2019, veja:</p>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/05_ano_concluiu.png" style="width:95.0%" />
</center>
<p>Essa informa√ß√£o poderia ser √∫til na hora de buscar dados externos (permitido nesta competi√ß√£o).</p>
<div class="w3-panel w3-pale-blue w3-border">
<p>¬† üí° Insights!</p>
<p>‚Üí Aten√ß√£o aos outliers: √â no m√≠nimo estranho uma pessoa que formou em 2007 ter 17 anos;</p>
<p>‚Üí Como ningu√©m concluiu a escola no ano de 2019 e a m√©dia das idades vai diminuindo quanto mais pr√≥ximo de 2018, parece que estes dados s√£o de 2019. Essa inform√ß√£o poderia ser √∫til na hora de procurar por bases externas.</p>
</div>
</div>
<div id="target" class="section level2">
<h2>Target</h2>
<p>A primeira decis√£o importante era definir como enquadrar o problema; se seriam m√∫ltiplos modelos independentes ou modelos com sa√≠das dependentes.</p>
<p>Primeiramente vejamos como eram as distribui√ß√µes das notas por caderno:</p>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/07_distribuicao_target.png" style="width:95.0%" />
</center>
<p>Ao olhar estas distribui√ß√µes foram surgindo v√°rias id√©ias! Cheguei at√© a tentar modelos estat√≠sticos GAM considerando a resposta como uma distribui√ß√£o Beta (transformando as targets no intervalo [0,1]) mas acabou n√£o apresentando bons resultados para a competi√ß√£o.. acho que seria necess√°rio um pouco mais de prepara√ß√£o nos dados.</p>
<p>Apesar das notas do enem serem calculadas via TRI (Teoria de Resposta ao Item) que considera as notas independentes, parece existir alguma correla√ß√£o entre as notas, veja:</p>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/08_correlacao_notas.png" style="width:95.0%" />
</center>
<p>As targets da nota de L√≠nguas e C√≥digos e Ci√™ncias Humanas pareciam possuir uma correla√ß√£o ‚Äúinteressante‚Äù, mas, ap√≥s testar modelos de m√∫ltiplas respostas dependentes para cada dia (com e sem a nota da reda√ß√£o), em nenhum de meus testes superou (de maneira consistente) o desempenho de modelos que considerassem as sa√≠das independentes. Portanto foquei em criar 5 modelos independentes.</p>
</div>
</div>
<div id="machine-learning-em-python" class="section level1">
<h1>Machine Learning (em Python)</h1>
<p>Toda a rotina de pr√©-processamento dos dados, feature engineering, modelagem, ensamble e p√≥s-processamento foi realizada utilizando a linguagem Python para cada uma das 5 notas. Trouxe apenas o modelo final neste post mas, para chegar at√© aqui foram necess√°rio muitos testes!</p>
<div id="importar-dependencias" class="section level2">
<h2>Importar dependencias</h2>
<p>Carregar pacotes Python:</p>
<pre class="python"><code># data prep
import numpy as np 
import pandas as pd 
# pre process
from sklearn.preprocessing import MinMaxScaler
# modeling
from sklearn.model_selection import train_test_split
from catboost import CatBoostRegressor
# plots
import seaborn as sns
import matplotlib.pyplot as plt</code></pre>
<p>Confira a baixo as fun√ß√µes desenvolvidas para a solu√ß√£o deste problema</p>
<details>
<summary>
(<em>Clique aqui para expandir as fun√ß√µes</em>)
</summary>
<pre class="python"><code>def prep_data_questionarios(df):
  &#39;&#39;&#39;
  Converte dados de questionario para ordinal
  &#39;&#39;&#39;
    # escolaridade pai
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;: 5, &#39;G&#39;: 6, &#39;H&#39;: -1}
    df.loc[:, &#39;Q001&#39;] = df.loc[:, &#39;Q001&#39;].map(to_map).astype(int)

    # escolaridade mae
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;: 5, &#39;G&#39;: 6, &#39;H&#39;: -1}
    df.loc[:, &#39;Q002&#39;] = df.loc[:, &#39;Q002&#39;].map(to_map).astype(int) 

    # ocupacao pai
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;: -1}
    df.loc[:, &#39;Q003&#39;] = df.loc[:, &#39;Q003&#39;].map(to_map).astype(int) 

    # ocupacao mae
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;: -1}
    df.loc[:, &#39;Q004&#39;] = df.loc[:, &#39;Q004&#39;].map(to_map).astype(int) 

    # renda da familia
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;:5, &#39;G&#39;:6, &#39;H&#39;:7, &#39;I&#39;:8,
              &#39;J&#39;:9, &#39;K&#39;:10,&#39;L&#39;:11, &#39;M&#39;:12, &#39;N&#39;:13, &#39;O&#39;:14, &#39;P&#39;:15, &#39;Q&#39;:16}
    df.loc[:, &#39;Q006&#39;] = df.loc[:, &#39;Q006&#39;].map(to_map).astype(int) 

    # empregado domestico
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3}
    df.loc[:, &#39;Q007&#39;] = df.loc[:, &#39;Q007&#39;].map(to_map).astype(int) 

    # banheiro
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q008&#39;] = df.loc[:, &#39;Q008&#39;].map(to_map).astype(int) 

    # qnt de quartos
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q009&#39;] = df.loc[:, &#39;Q009&#39;].map(to_map).astype(int) 

    # qnt de carros
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q010&#39;] = df.loc[:, &#39;Q010&#39;].map(to_map).astype(int) 

    # qnt de motocicleta
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q011&#39;] = df.loc[:, &#39;Q011&#39;].map(to_map).astype(int) 

    # qnt de geladeira
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q012&#39;] = df.loc[:, &#39;Q012&#39;].map(to_map).astype(int) 

    # qnt de freezer
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q013&#39;] = df.loc[:, &#39;Q013&#39;].map(to_map).astype(int) 

    # qnt de maquina de lavar roupa
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q014&#39;] = df.loc[:, &#39;Q014&#39;].map(to_map).astype(int) 

    # qnt de maquina de secar roupa
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q015&#39;] = df.loc[:, &#39;Q015&#39;].map(to_map).astype(int) 

    # qnt de microondas
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q016&#39;] = df.loc[:, &#39;Q016&#39;].map(to_map).astype(int) 

    # qnt de maquina de lavar louca
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q017&#39;] = df.loc[:, &#39;Q017&#39;].map(to_map).astype(int) 

    # tem aspirador de po
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1}
    df.loc[:, &#39;Q018&#39;] = df.loc[:, &#39;Q018&#39;].map(to_map).astype(int) 

    # qtd tv colorida
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q019&#39;] = df.loc[:, &#39;Q019&#39;].map(to_map).astype(int) 

    # tem dvd
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1}
    df.loc[:, &#39;Q020&#39;] = df.loc[:, &#39;Q020&#39;].map(to_map).astype(int) 

    # tem tv por assinatura
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1}
    df.loc[:, &#39;Q021&#39;] = df.loc[:, &#39;Q021&#39;].map(to_map).astype(int) 

    # qtd telefone celular
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q022&#39;] = df.loc[:, &#39;Q022&#39;].map(to_map).astype(int) 

    # qtd telefone fixo
    to_map = {&#39;A&#39;:0, &#39;B&#39;:1}
    df.loc[:, &#39;Q023&#39;] = df.loc[:, &#39;Q023&#39;].map(to_map).astype(int) 

    # qtd computador
    to_map =  {&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}
    df.loc[:, &#39;Q024&#39;] = df.loc[:, &#39;Q024&#39;].map(to_map).astype(int) 

    # tem acesso a internet
    to_map =  {&#39;A&#39;:0, &#39;B&#39;:1}
    df.loc[:, &#39;Q025&#39;] = df.loc[:, &#39;Q025&#39;].map(to_map).astype(int) 
    
    return(df)
  
def fe_questionario(df):
  &#39;&#39;&#39;
  Gerar novas features artificiais baseadas nos dados de questionario
  &#39;&#39;&#39;
    df.loc[:, &quot;Q021+Q006&quot;] = df[&quot;Q021&quot;] + df[&quot;Q006&quot;]
    df.loc[:, &quot;Q018+Q006&quot;] = df[&quot;Q018&quot;] + df[&quot;Q006&quot;]
    df.loc[:, &quot;Q018+Q008&quot;] = df[&quot;Q018&quot;] + df[&quot;Q008&quot;]
    df.loc[:, &quot;Q010+Q018&quot;] = df[&quot;Q010&quot;] + df[&quot;Q018&quot;]
    df.loc[:, &quot;Q018+Q024&quot;] = df[&quot;Q018&quot;] + df[&quot;Q024&quot;]
    
    df.loc[:, &quot;Q018*Q006&quot;] = df[&quot;Q018&quot;] * df[&quot;Q006&quot;]
    df.loc[:, &quot;Q010*Q018&quot;] = df[&quot;Q010&quot;] * df[&quot;Q018&quot;]
    
    return df
  
def fe_mun(data):
    &#39;&#39;&#39;
    Gerar novas features a partir das localizacoes de municipio
    &#39;&#39;&#39;
    for c in list(data.columns[data.dtypes==&#39;category&#39;]):
        data.loc[:, c] = data.loc[:, c].astype(&#39;object&#39;)
    
    data.loc[:, &#39;FE_MUNICIPIO_PROVA_x_MUNICIPIO_RESIDENCIA&#39;] = np.where(data.NO_MUNICIPIO_PROVA == data.NO_MUNICIPIO_RESIDENCIA , 1, 0)
    data.loc[:, &#39;FE_MUNICIPIO_PROVA_x_MUNICIPIO_NASCIMENTO&#39;] = np.where(data.NO_MUNICIPIO_PROVA == data.NO_MUNICIPIO_NASCIMENTO , 1, 0)
    data.loc[:, &#39;FE_MUNICIPIO_PROVA_x_MUNICIPIO_ESC&#39;] = np.where(data.NO_MUNICIPIO_PROVA == data.NO_MUNICIPIO_ESC , 1, 0)
    data.loc[:, &#39;FE_MUNICIPIO_RESIDENCIA_x_MUNICIPIO_NASCIMENTO&#39;] = np.where(data.NO_MUNICIPIO_RESIDENCIA == data.NO_MUNICIPIO_NASCIMENTO , 1, 0)
    data.loc[:, &#39;FE_MUNICIPIO_RESIDENCIA_x_MUNICIPIO_ESC&#39;] = np.where(data.NO_MUNICIPIO_RESIDENCIA == data.NO_MUNICIPIO_ESC , 1, 0)
    data.loc[:, &#39;FE_MUNICIPIO_NASCIMENTO_x_MUNICIPIO_ESC&#39;] = np.where(data.NO_MUNICIPIO_RESIDENCIA == data.NO_MUNICIPIO_ESC , 1, 0)
    
    for c in list(data.columns[data.dtypes==&#39;object&#39;]):
        data.loc[:, c] = data.loc[:, c].astype(&#39;category&#39;)
    
    return data
  
def fe_in(df):
    &#39;&#39;&#39;
    Gerar features a partir das indicadoras
    &#39;&#39;&#39;
    df.loc[:, &#39;IN_DEFICIT_ATENCAO+IN_TEMPO_ADICIONAL&#39;] = df[&quot;IN_DEFICIT_ATENCAO&quot;] + df[&quot;IN_TEMPO_ADICIONAL&quot;]
    df.loc[:, &#39;IN_LEDOR+IN_TRANSCRICAO&#39;] = df[&quot;IN_LEDOR&quot;] + df[&quot;IN_TRANSCRICAO&quot;]

    return df
  
def prep_co_escola(df):
    &#39;&#39;&#39;
    Converter codigo da escola para categorico
    &#39;&#39;&#39;
    df.loc[:, &#39;CO_ESCOLA&#39;] = [str(x) for x in df.CO_ESCOLA]
    df.loc[:, &#39;CO_ESCOLA&#39;] = np.where(df[&#39;CO_ESCOLA&#39;]==&#39;nan&#39;, np.nan, df[&#39;CO_ESCOLA&#39;])
    df.loc[:, &#39;CO_ESCOLA&#39;] = df.loc[:, &#39;CO_ESCOLA&#39;].astype(&#39;category&#39;)
    
    return df
  
def fe_extra(df):
    &#39;&#39;&#39;
    Gerar novas features 
    &#39;&#39;&#39;
    df.loc[:, &quot;FE_IDADE_DISCRETA&quot;] = pd.cut(df.NU_IDADE, (0, 15, 18, 23, 36, 60, 120), labels=[&#39;ADOLESCENTE&#39;,&#39;ADOLESCENTE_2&#39;, &#39;JOVEM&#39;,&#39;JOVEM_2&#39;, &#39;ADULTO&#39;, &#39;IDOSO&#39;]).astype(&#39;category&#39;)
    df.loc[:, &#39;FE_OCUPACAO_PAIS&#39;] = df.Q003 + df.Q004
    df.loc[:, &#39;FE_ESCOLARIDADE_PAIS&#39;] = df.Q001 + df.Q002
    df.loc[:, &#39;FE_RENDA_POR_PESSOA&#39;] = df.Q006 / df.Q005
    df.loc[:, &#39;FE_CELULAR_POR_PESSOA&#39;] = df.Q022 / df.Q005
    df.loc[:, &#39;FE_COMPUTADOR_POR_PESSOA&#39;] = df.Q024 / df.Q005
    df.loc[:, &#39;FE_VISAO_RUIM&#39;] = df[[&#39;IN_BAIXA_VISAO&#39;, &#39;IN_CEGUEIRA&#39;, &#39;IN_VISAO_MONOCULAR&#39;, &#39;IN_SURDO_CEGUEIRA&#39;]].max(axis=1)
    df.loc[:, &#39;FE_AUDICAO_RUIM&#39;] = df[[&#39;IN_SURDEZ&#39;, &#39;IN_DEFICIENCIA_AUDITIVA&#39;, &#39;IN_SURDO_CEGUEIRA&#39;]].max(axis=1)
    df.loc[:, &#39;FE_TDAH_MAIS_TEMPO&#39;] = df.IN_TEMPO_ADICIONAL + df.IN_DEFICIT_ATENCAO
    df.loc[:, &#39;FE_TDAH_MEDICADO&#39;] = np.where((df.IN_DEFICIT_ATENCAO==1)&amp;(df.IN_MEDICAMENTOS==1), 1, 0)
    df.loc[:, &#39;FE_RECURSO_VISAO&#39;] =  df[[&#39;IN_BRAILLE&#39;, &#39;IN_AMPLIADA_24&#39;, &#39;IN_AMPLIADA_18&#39;, &#39;IN_LEDOR&#39;, &#39;IN_MAQUINA_BRAILE&#39;, &#39;IN_LAMINA_OVERLAY&#39;]].max(axis=1)
    df.loc[:, &#39;FE_RECURSO_SURDEZ&#39;] =  df[[&#39;IN_LIBRAS&#39;, &#39;IN_LEITURA_LABIAL&#39;, &#39;IN_TRANSCRICAO&#39;]].max(axis=1)
    acess = [&#39;IN_ACESSO&#39;, &#39;IN_MESA_CADEIRA_RODAS&#39;, &#39;IN_MESA_CADEIRA_SEPARADA&#39;, &#39;IN_APOIO_PERNA&#39;, &#39;IN_CADEIRA_ESPECIAL&#39;, &#39;IN_CADEIRA_CANHOTO&#39;, &#39;IN_CADEIRA_ACOLCHOADA&#39;, &#39;IN_MOBILIARIO_OBESO&#39;, &#39;IN_SALA_INDIVIDUAL&#39;, &#39;IN_SALA_ESPECIAL&#39;, &#39;IN_SALA_ACOMPANHANTE&#39;, &#39;IN_MOBILIARIO_ESPECIFICO&#39;, &#39;IN_MATERIAL_ESPECIFICO&#39;]
    df.loc[:, &#39;FE_ACESSIBILIDADE&#39;] =  df[acess].max(axis=1)

    return df</code></pre>
</details>
<p>¬†</p>
<p>Carregar features artificiais extra√≠das atrav√©s de um modelo KNN. N√£o apresentarei o c√≥digo aqui (talvez fique para um pr√≥ximo post) mas a id√©ia √© basicamente a seguinte:</p>
<div class="w3-panel w3-pale-yellow w3-border">
<p>¬† üß™ Feature Extraction com KNN</p>
<p>Ajuste um <code>KNeighborsRegressor</code> encontrando os K-vizinhos mais pr√≥ximos de cada inst√¢ncia out-of-fold via valida√ß√£o cruzada (para evitar data leak) nos dados de treino e depois ajuste um modelo em todos os dados de treino para obter os K-vizinhos mais pr√≥ximos nos dados de teste.</p>
</div>
<p>Quem sabe no futuro fa√ßo um post compartilhando esta estrat√©gia com mais detalhes.</p>
<pre class="python"><code>knn_train = pd.read_csv(&quot;../input/knn/KNN_feat_train_CH_LC.csv&quot;)
knn_test = pd.read_csv(&quot;../input/knn/KNN_feat_test_CH_LC.csv&quot;)

knn_train_cn_mt = pd.read_csv(&quot;../input/knn/KNN_feat_train_CN_MT.csv&quot;)
knn_test_cn_mt = pd.read_csv(&quot;../input/knn/KNN_feat_test_CN_MT.csv&quot;)

knn_train_rd = pd.read_csv(&quot;../input/knn/KNN_feat_train_RD.csv&quot;)
knn_test_rd = pd.read_csv(&quot;../input/knn/KNN_feat_test_RD.csv&quot;)</code></pre>
</div>
<div id="carregar-dados" class="section level2">
<h2>Carregar dados</h2>
<p>Importar uma vers√£o do dataset no formato <code>.parquet</code> que foi compactada com um truque para otimizar o consumo de mem√≥ria disponibilizada pelos organizadores <a href="https://www.kaggle.com/code/caneiro/mlo-make-parquet">neste notebook</a>.</p>
<pre class="python"><code>train = pd.read_parquet(&#39;train.parquet&#39;)
test = pd.read_parquet(&#39;test.parquet&#39;)
sub = pd.read_csv(&#39;../input/qualityeducation/sample_submission.csv&#39;)</code></pre>
<p>Definir objetos com targets</p>
<pre class="python"><code>targets = [&#39;NU_NOTA_LC&#39;, &#39;NU_NOTA_CH&#39;, &#39;NU_NOTA_CN&#39;,  &#39;NU_NOTA_MT&#39;, &#39;NU_NOTA_REDACAO&#39;]
presencas = [&#39;TP_PRESENCA_LC&#39;, &#39;TP_PRESENCA_CH&#39;, &#39;TP_PRESENCA_CN&#39;, &#39;TP_PRESENCA_MT&#39;, &#39;TP_STATUS_REDACAO&#39;]</code></pre>
<div class="w3-panel w3-pale-yellow w3-border">
<p>¬† ‚ö†Ô∏è Aten√ß√£o:</p>
<p>A feature de presen√ßa √© muito importante no p√≥s-processamento para atribuir nota zero aos alunos que n√£o foram realizar a prova mas n√£o faz sentido mant√™-la nos dados de treino pois ser√° sempre constante.</p>
</div>
<div id="dados-externos" class="section level3">
<h3>Dados externos</h3>
<p>Dados Externos utilizados:</p>
<ol style="list-style-type: decimal">
<li><a href="https://basedosdados.org/dataset/mundo-onu-adh">Atlas do Desenvolvimento Humano (ADH)</a></li>
</ol>
<p>Esta base tinha muita informa√ß√£o legal mas sua cobertura temporal estava bastante defasada (1991 - 2010) o que pode adicionar algum ru√≠do ao modelo.</p>
<p>As features selecionadas (sem muito crit√©rio) desta base foram:</p>
<pre class="python"><code>extra1 = pd.read_csv(&quot;municipio.csv&quot;)

extra1 = extra1[extra1.ano==2010]

features_extra1 = [&#39;expectativa_vida&#39;, &#39;razao_dependencia&#39;, &#39;expectativa_anos_estudo&#39;,
&#39;taxa_analfabetismo_11_a_14&#39;, &#39;taxa_analfabetismo_15_a_17&#39;, &#39;taxa_analfabetismo_18_mais&#39;,
&#39;taxa_atraso_0_basico&#39;, &#39;taxa_atraso_0_fundamental&#39;, &#39;taxa_atraso_0_medio&#39;,
&#39;taxa_freq_bruta_medio&#39;, &#39;taxa_freq_liquida_medio&#39;,
&#39;taxa_freq_medio_18_24&#39;, &#39;taxa_freq_medio_6_14&#39;, &#39;indice_gini&#39;,&#39;prop_pobreza_extrema&#39;, &#39;prop_pobreza&#39;,
&#39;prop_renda_10_ricos&#39;, &#39;prop_renda_20_pobres&#39;, &#39;razao_10_ricos_40_pobres&#39;,&#39;renda_pc&#39; , &#39;renda_pc_quintil_1&#39;,
&#39;indice_theil&#39;, &#39;prop_trabalhadores_conta_proria&#39;, 
&#39;prop_empregadores&#39;, &#39;prop_ocupados_agropecuaria&#39;, &#39;prop_ocupados_comercio&#39;,
&#39;prop_ocupados_construcao&#39;, &#39;prop_ocupados_formalizacao&#39;, &#39;prop_ocupados_medio&#39;,
&#39;prop_ocupados_servicos&#39;, &#39;prop_ocupados_superior&#39;,
&#39;prop_ocupados_renda_0&#39;, &#39;renda_media_ocupados&#39;, &#39;indice_treil_trabalho&#39;,
&#39;taxa_ocupados_carteira&#39;, &#39;taxa_agua_encanada&#39;, 
&#39;taxa_banheiro_agua_encanada&#39;, &#39;taxa_coleta_lixo&#39;, &#39;taxa_energia_eletrica&#39;,
&#39;taxa_agua_esgoto_inadequados&#39;, &#39;taxa_criancas_dom_sem_fund&#39;,
&#39;pea&#39;, &#39;indice_escolaridade&#39;, &#39;indice_frequencia_escolar&#39;, 
&#39;idhm&#39;, &#39;idhm_e&#39;, &#39;idhm_l&#39;, &#39;idhm_r&#39;]
extra1 = extra1[[&#39;id_municipio&#39;]+features_extra1]

train = pd.merge(train, extra1, how=&#39;left&#39;, left_on=&#39;CO_MUNICIPIO_RESIDENCIA&#39;, right_on=&#39;id_municipio&#39;)
test = pd.merge(test, extra1, how=&#39;left&#39;, left_on=&#39;CO_MUNICIPIO_RESIDENCIA&#39;, right_on=&#39;id_municipio&#39;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><a href="https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/censo-escolar">Microdados do Censo Escolar da Educaca√ß√£o B√°sica</a></li>
</ol>
<p>Base dispon√≠vel no mesmo site dos dados da competi√ß√£o e que tr√°s informa√ß√µes muito ricas das escolas do Brasil. Infelizmente quase 75% da informa√ß√£o da escola do aluno era missing ent√£o esta base n√£o conseguiu alavancar os ganhos do modelo de maneira consider√°vel.</p>
<p>Nesta base foquei principalmente nas features utilizadas para calcular o IIE (√çndice de Estrutura da Escola) que se baseia nos seguintes componentes:</p>
<table>
<colgroup>
<col width="32%" />
<col width="24%" />
<col width="42%" />
</colgroup>
<thead>
<tr class="header">
<th>Componente 1: Pedag√≥gica (IEE_Pedag√≥gico):</th>
<th>Componente 2: B√°sica (IEE_B√°sico):</th>
<th>Componente 3: Tecnol√≥gica (IEE_Tecnol√≥gico):</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Qualifica√ß√£o do docente (forma√ß√£o acad√™mica dos professores)</td>
<td>√Ågua filtrada (bin√°ria)</td>
<td>N√∫mero de computadores por aluno (computadores dispon√≠veis para uso dos alunos)</td>
</tr>
<tr class="even">
<td>N√∫mero de alunos por sala</td>
<td>Acesso √† rede p√∫blica de energia (bin√°ria)</td>
<td>N√∫mero de equipamentos multim√≠dia por aluno</td>
</tr>
<tr class="odd">
<td>N√∫mero de funcion√°rios por aluno</td>
<td>Acesso √† rede p√∫blica de esgoto (bin√°ria)</td>
<td>Acesso a internet (bin√°ria)</td>
</tr>
<tr class="even">
<td>Quadra de esportes coberta (bin√°ria)</td>
<td>Coleta peri√≥dica de lixo (bin√°ria)</td>
<td>Laborat√≥rio de Ci√™ncias (bin√°ria)</td>
</tr>
<tr class="odd">
<td>Biblioteca (bin√°ria)</td>
<td>Banheiro dentro do pr√©dio (bin√°ria)</td>
<td>Laborat√≥rio de Inform√°tica (bin√°ria)</td>
</tr>
</tbody>
</table>
<ul>
<li><a href="https://leosalesblog.wordpress.com/2018/02/03/escola-ruim-aluno-ruim-entendendo-a-relacao-entre-estrutura-escolar-e-desempenho-no-enem/">Fonte</a></li>
</ul>
<pre class="python"><code># Importar dados
extra2 = pd.read_csv(&#39;microdados_ed_basica_2021.csv&#39;, error_bad_lines=False, sep=&#39;;&#39;, encoding=&#39;latin1&#39;, dtype={&#39;CO_ORGAO_REGIONAL&#39;: &#39;str&#39;})
extra2 = extra2[extra2.isnull().sum(axis=1) / extra2.shape[1] &lt; .9]

# Tratamento nas features
extra2.loc[:, &#39;QT_TOTAL_ALUNOS&#39;] = extra2[[&#39;QT_MAT_BAS_ND&#39;, &#39;QT_MAT_BAS_BRANCA&#39;, &#39;QT_MAT_BAS_PRETA&#39;, &#39;QT_MAT_BAS_PARDA&#39;, &#39;QT_MAT_BAS_AMARELA&#39;, &#39;QT_MAT_BAS_INDIGENA&#39;]].sum(axis=1).fillna(0)
extra2.loc[:, &#39;QT_TOTAL_PROFESSORES&#39;] = (extra2.QT_DOC_BAS + extra2.QT_DOC_INF + extra2.QT_DOC_INF_CRE + extra2.QT_DOC_INF_PRE + extra2.QT_DOC_FUND + extra2.QT_DOC_FUND_AI + extra2.QT_DOC_FUND_AF + extra2.QT_DOC_MED + extra2.QT_DOC_PROF + extra2.QT_DOC_PROF_TEC + extra2.QT_DOC_EJA + extra2.QT_DOC_EJA_FUND + extra2.QT_DOC_EJA_MED + extra2.QT_DOC_ESP + extra2.QT_DOC_ESP_CC + extra2.QT_DOC_ESP_CE).fillna(0)
extra2.loc[:, &#39;QT_SALAS_UTILIZADAS&#39;] = (extra2.loc[:, &#39;QT_TOTAL_ALUNOS&#39;] / extra2.QT_SALAS_UTILIZADAS).fillna(0)
extra2.loc[:, &#39;QT_COMP_DISP_ALUNO&#39;] = extra2.QT_DESKTOP_ALUNO + extra2.QT_COMP_PORTATIL_ALUNO + extra2.QT_TABLET_ALUNO

# Selecao de faetures importantes
features_extra2 = [&#39;CO_ENTIDADE&#39;, &#39;QT_SALAS_UTILIZADAS&#39;, &#39;QT_TOTAL_PROFESSORES&#39;, &#39;IN_QUADRA_ESPORTES_COBERTA&#39;, &#39;IN_BIBLIOTECA&#39;,
       &#39;IN_AGUA_POTAVEL&#39;, &#39;IN_ENERGIA_REDE_PUBLICA&#39;, &#39;IN_ESGOTO_REDE_PUBLICA&#39;, &#39;IN_LIXO_SERVICO_COLETA&#39;, &#39;IN_BANHEIRO&#39;,
       &#39;QT_COMP_DISP_ALUNO&#39;, &#39;QT_EQUIP_MULTIMIDIA&#39;, &#39;IN_INTERNET&#39;, &#39;IN_LABORATORIO_CIENCIAS&#39;, &#39;IN_LABORATORIO_INFORMATICA&#39;]
extra2 = extra2[features_extra2]

# Remover outliers
for c in list(extra2.iloc[:, 1:].columns):
    trs = extra2.loc[extra2[c]!=88888, c].quantile(.99)
    extra2.loc[(extra2[c]==88888)|(extra2[c]&gt;trs), c] = trs
    
#Normalizar para calcular IEE
scaler = MinMaxScaler()
to_iee = scaler.fit_transform(extra2.iloc[:, 1:])
to_iee = pd.DataFrame(to_iee, columns=extra2.iloc[:, 1:].columns)

# Calcular IEE e componentes
extra2.loc[:, &#39;COMP1&#39;] = to_iee[[&#39;QT_SALAS_UTILIZADAS&#39;, &#39;QT_TOTAL_PROFESSORES&#39;, &#39;IN_QUADRA_ESPORTES_COBERTA&#39;, &#39;IN_BIBLIOTECA&#39;]].sum(axis=1)
extra2.loc[:, &#39;COMP2&#39;] = to_iee[[&#39;IN_AGUA_POTAVEL&#39;, &#39;IN_ENERGIA_REDE_PUBLICA&#39;, &#39;IN_ESGOTO_REDE_PUBLICA&#39;, &#39;IN_LIXO_SERVICO_COLETA&#39;, &#39;IN_BANHEIRO&#39;]].sum(axis=1)
extra2.loc[:, &#39;COMP3&#39;] = to_iee[[&#39;QT_COMP_DISP_ALUNO&#39;, &#39;QT_EQUIP_MULTIMIDIA&#39;, &#39;IN_INTERNET&#39;, &#39;IN_LABORATORIO_CIENCIAS&#39;, &#39;IN_LABORATORIO_INFORMATICA&#39;]].sum(axis=1)
extra2.loc[:, &#39;IEE&#39;] = extra2.COMP1 + extra2.COMP2 + extra2.COMP3

train = pd.merge(train, extra2, how=&#39;left&#39;, left_on=&#39;CO_ESCOLA&#39;, right_on=&#39;CO_ENTIDADE&#39;).drop(&#39;CO_ENTIDADE&#39;, axis=1)
test = pd.merge(test, extra2, how=&#39;left&#39;, left_on=&#39;CO_ESCOLA&#39;, right_on=&#39;CO_ENTIDADE&#39;).drop(&#39;CO_ENTIDADE&#39;, axis=1)</code></pre>
</div>
</div>
<div id="modelagem" class="section level2">
<h2>Modelagem</h2>
<p>Testei muitos modelos e muitas abordagens (inclusive com finalidade de estudo). Foram modelos estat√≠sticos (GAM considerando a distribui√ß√£o Beta(0,1)), redes neurais (TabNet) e √°rvores mas no final das contas os que tiveram melhor custo/benef√≠cio foram o LightGBM e o CatBoost.</p>
<p>Sobre o tuning, tomei a decis√£o de n√£o investir muito em otimiza√ß√£o autom√°tica de hiperpar√¢metros pois o tempo era curto e os ganhos seriam pequenos comparados com o potencial ganho com a variedade de features que poderiam ser geradas, ent√£o fiz apenas alguns testes manuais conforme via necessidade.</p>
<div id="pre-processing" class="section level4">
<h4>Pre processing</h4>
<p>A etapa que investi bastante tempo foi para criar novas vari√°veis. A seguir trago algumas features constru√≠das que foram utilizadas em determinados modelos, a partir dos dados dispon√≠veis:</p>
<ul>
<li>Renda somada dos pais;</li>
<li>N√≠vel de ocupa√ß√£o somado dos pais;</li>
<li>Renda dividido pelo n√∫mero de pessoas na casa;</li>
<li>Quantidade de celulares por pessoa na casa;</li>
<li>Quantidade de computadores por pessoa na casa;</li>
<li>Se a pessoa possui vis√£o ruim (se possui baixa vis√£o, cegueira ou monocular);</li>
<li>Se a pessoa possui audi√ß√£o ruim (Surdez, defici√™ncia auditiva);</li>
<li>Se o aluno possui TDAH e toma medicamento controlado;</li>
<li>Se o aluno possui TDAH e teve mais tempo de prova;</li>
<li>Se precisou de recurso de vis√£o ou audi√ß√£o (libras, baile, etc);</li>
<li>Se o munic√≠pio que nasceu √© o mesmo da escola;</li>
<li>Se o munic√≠pio que fez a prova √© o mesmo da escola;</li>
<li>Se o munic√≠pio da prova √© o mesmo da resid√™ncia;</li>
<li>Nota m√©dia dos alunos da respectiva escola nas outras provas (*);</li>
<li>Renda m√©dia dos alunos da respectiva escola (*).</li>
</ul>
<p>(*) Estas features precisaram ser calculadas de maneira muito cuidadosa para n√£o causar algum tipo de data leak!</p>
</div>
<div id="post-processing" class="section level4">
<h4>Post Processing</h4>
<p>Essa base tinha uma pegadinha que fazia muita diferen√ßa no resultado final. Existem duas possibilidades de um aluno tirar zero em uma prova: errar tudo ou n√£o comparecer.</p>
<p>Como temos a informa√ß√£o da presen√ßa do aluno na prova (o que na pr√°tica seria meio estranho) bastava dar zero para os alunos faltantes na hora de prever nos dados de teste para submeter.</p>
</div>
<div id="linguagens-e-c√≥digos" class="section level3">
<h3>Linguagens e C√≥digos</h3>
<p>Definir finalidade de algumas colunas:</p>
<pre class="python"><code># colunas que serao dropadas
to_drop = [&#39;IN_PROVA_DEITADO&#39;,
            &#39;NU_INSCRICAO&#39;,
            &#39;CO_MUNICIPIO_ESC&#39;,
            &#39;CO_UF_NASCIMENTO&#39;,
            &#39;CO_UF_RESIDENCIA&#39;,
            &#39;CO_UF_ESC&#39;,
            &#39;CO_UF_PROVA&#39;,
            &#39;CO_MUNICIPIO_PROVA&#39;,
            &#39;CO_MUNICIPIO_RESIDENCIA&#39;,
            &#39;CO_MUNICIPIO_NASCIMENTO&#39;]

# definir target e presenca
target = &quot;NU_NOTA_LC&quot;
presenca = &quot;TP_PRESENCA_LC&quot;

# demais notas para dropar (menos ch)
notas = list(set(targets)-set([target, &#39;NU_NOTA_CH&#39;]))</code></pre>
<p>Pr√©-processamento nos dados de treino</p>
<pre class="python"><code>X = train.copy()
X.loc[:, &#39;knn_feature&#39;] = knn_train.knn_oof
X = X.drop(to_drop, axis=1) 
X = X[X[presenca]==1]
X = X[~X[target].isnull()]

X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X.loc[:, &#39;FE_RENDA&#39;] = X.loc[:, &#39;Q006&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1000, &#39;C&#39;:1500, &#39;D&#39;:2000,
&#39;E&#39;:2500, &#39;F&#39;:3000, &#39;G&#39;:4000, &#39;H&#39;:5000, &#39;I&#39;:6000, &#39;J&#39;:7000,&#39;K&#39;:8000,&#39;L&#39;:9000,
&#39;M&#39;:10000, &#39;N&#39;:12000, &#39;O&#39;:15000, &#39;P&#39;:20000, &#39;Q&#39;:30000}).astype(int) 
X = prep_data_questionarios(X)
X = fe_mun(X)
X = fe_questionario(X)
X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&amp;(~train[target].isnull()), target].astype(np.float64)</code></pre>
<p>Pr√©-processamento nos dados de teste</p>
<pre class="python"><code>X_test = test.copy()
X_test.loc[:, &#39;knn_feature&#39;] = knn_test.knn_test
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test.loc[:, &#39;FE_RENDA&#39;] = X_test.loc[:, &#39;Q006&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1000, &#39;C&#39;:1500, &#39;D&#39;:2000,
&#39;E&#39;:2500, &#39;F&#39;:3000, &#39;G&#39;:4000, &#39;H&#39;:5000, &#39;I&#39;:6000, &#39;J&#39;:7000, &#39;K&#39;:8000,&#39;L&#39;:9000,
&#39;M&#39;:10000, &#39;N&#39;:12000, &#39;O&#39;:15000, &#39;P&#39;:20000, &#39;Q&#39;:30000}).astype(int) 
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
X_test = fe_questionario(X_test)
X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)</code></pre>
<p>Feature engineering separada para evitar data leak:</p>
<pre class="python"><code># calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby(&#39;CO_ESCOLA&#39;).FE_RENDA.mean()
co_escola_idade_media = X.groupby(&#39;CO_ESCOLA&#39;).NU_IDADE.mean()
co_escola_nota_ch = X.groupby(&#39;CO_ESCOLA&#39;).NU_NOTA_CH.mean()
X = X.drop(&#39;NU_NOTA_CH&#39;, axis=1)

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    &#39;CO_ESCOLA&#39;: co_escola_renda_media.index,
    &#39;FE_ESCOLA_RENDA_MEDIA&#39;: co_escola_renda_media,
    &#39;FE_IDADE_MEDIA&#39;: co_escola_idade_media,
    &#39;FE_NOTA_CH&#39;: co_escola_nota_ch
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)
X_test = pd.merge(X_test, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)

# Codigo da escola para categorico
X.loc[:, &#39;CO_ESCOLA&#39;] = X.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)
X_test.loc[:, &#39;CO_ESCOLA&#39;] = X_test.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)

# Features de contagem
X.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})</code></pre>
<p>Ajustar modelo:</p>
<pre class="python"><code>cat_feat = X.columns[X.dtypes==&#39;category&#39;]
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)
    
clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = &quot;RMSE&quot;,
                            od_type = &quot;Iter&quot;,
                            od_wait = 100,
                            iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/lc_catboost.png" style="width:95.0%" />
</center>
<p>Salvar previs√µes:</p>
<pre class="python"><code>sub.loc[:, &#39;NU_NOTA_LC&#39;] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_PRESENCA_LC!=1, &#39;NU_NOTA_LC&#39;] = 0</code></pre>
<p>Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:</p>
<pre class="python"><code>sns.kdeplot(train.loc[:, target], shade=True, color=&#39;r&#39;, clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color=&#39;b&#39;, clip=[0,1000])
plt.legend(labels=[&#39;train&#39;, &#39;predict&#39;])
plt.title(target)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/lc_pred.png" style="width:50.0%" />
</center>
</div>
<div id="ci√™ncias-humanas" class="section level3">
<h3>Ci√™ncias Humanas</h3>
<p>Novas features desenvolvidas especificamente para este modelo:</p>
<pre class="python"><code>def fe_ch(df):
    
    df.loc[:, &#39;FE_RENDA&#39;] = df.loc[:, &#39;Q006&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1000,
    &#39;C&#39;:1500, &#39;D&#39;:2000, &#39;E&#39;:2500, &#39;F&#39;:3000, &#39;G&#39;:4000, &#39;H&#39;:5000, &#39;I&#39;:6000,
    &#39;J&#39;:7000, &#39;K&#39;:8000,&#39;L&#39;:9000, &#39;M&#39;:10000, &#39;N&#39;:12000, &#39;O&#39;:15000, 
    &#39;P&#39;:20000, &#39;Q&#39;:30000}).astype(int) 
    df.loc[:, &#39;FE_NU_IDADE*TP_ANO_CONCLUIU&#39;] = df.TP_ANO_CONCLUIU * df.NU_IDADE
    df.loc[:, &#39;FE_Q002+Q024&#39;] = df.loc[:, &#39;Q002&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, 
    &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;: 5, &#39;G&#39;: 6, &#39;H&#39;: -1}).astype(int) + 
    df.loc[:, &#39;Q024&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}).astype(int) 
    df.loc[:, &#39;FE_SCORE&#39;] = (1/df.TP_ANO_CONCLUIU) + np.sqrt(df.NU_IDADE) +
    np.where(df.TP_ESCOLA==3, 1, 0)
    
    return df</code></pre>
<p>Definir finalidade de algumas colunas:</p>
<pre class="python"><code># colunas que serao dropadas
to_drop = [&#39;IN_PROVA_DEITADO&#39;,
           &#39;NU_INSCRICAO&#39;,
           &#39;CO_MUNICIPIO_ESC&#39;,
           &#39;CO_UF_NASCIMENTO&#39;,
           &#39;CO_UF_RESIDENCIA&#39;,
           &#39;CO_UF_ESC&#39;,
           &#39;CO_UF_PROVA&#39;,
           &#39;CO_MUNICIPIO_PROVA&#39;,
           &#39;CO_MUNICIPIO_RESIDENCIA&#39;,
          &#39;CO_MUNICIPIO_NASCIMENTO&#39;]

# definir target e presenca
target = &quot;NU_NOTA_CH&quot;
presenca = &quot;TP_PRESENCA_CH&quot;

# demais notas para dropar (menos lc)
notas = list(set(targets)-set([target, &#39;NU_NOTA_LC&#39;]))</code></pre>
<p>Pr√©-processamento nos dados de treino</p>
<pre class="python"><code>X = train.copy()
X.loc[:, &#39;knn_feature&#39;] = knn_train.knn_oof
X = X.drop(to_drop, axis=1)
X = X[X[presenca]==1]
X = X[~X[target].isnull()]

X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X = fe_ch(X)
X = prep_data_questionarios(X)
X = fe_mun(X)
X = fe_questionario(X)
#X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&amp;(~train[target].isnull()), target].astype(np.float64)</code></pre>
<p>Pr√©-processamento nos dados de teste</p>
<pre class="python"><code>X_test = test.copy()
X_test.loc[:, &#39;knn_feature&#39;] = knn_test.knn_test
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test = fe_ch(X_test)
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
X_test = fe_questionario(X_test)
#X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)</code></pre>
<p>Feature engineering separada para evitar data leak:</p>
<pre class="python"><code># calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby(&#39;CO_ESCOLA&#39;).FE_RENDA.mean()
co_escola_idade_media = X.groupby(&#39;CO_ESCOLA&#39;).NU_IDADE.mean()
co_escola_nota_lc = X.groupby(&#39;CO_ESCOLA&#39;).NU_NOTA_LC.mean()
X = X.drop(&#39;NU_NOTA_LC&#39;, axis=1)

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    &#39;CO_ESCOLA&#39;: co_escola_renda_media.index,
    &#39;FE_ESCOLA_RENDA_MEDIA&#39;: co_escola_renda_media,
    &#39;FE_IDADE_MEDIA&#39;: co_escola_idade_media,
    &#39;FE_NOTA_LC&#39;: co_escola_nota_lc
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)
X_test = pd.merge(X_test, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)

# Codigo da escola para categorico
X.loc[:, &#39;CO_ESCOLA&#39;] = X.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)
X_test.loc[:, &#39;CO_ESCOLA&#39;] = X_test.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)

# Features de contagem
X.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})</code></pre>
<p>Ajustar modelo:</p>
<pre class="python"><code>%%time

cat_feat = X.columns[X.dtypes==&#39;category&#39;]
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)

clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = &quot;RMSE&quot;,
                            od_type = &quot;Iter&quot;,
                            od_wait = 100,iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/ch_catboost.png" style="width:95.0%" />
</center>
<p>Salvar previs√µes:</p>
<pre class="python"><code>sub.loc[:, &#39;NU_NOTA_CH&#39;] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_PRESENCA_CH!=1, &#39;NU_NOTA_CH&#39;] = 0</code></pre>
<p>Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:</p>
<pre class="python"><code>sns.kdeplot(train.loc[:, target], shade=True, color=&#39;r&#39;, clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color=&#39;b&#39;, clip=[0,1000])
plt.legend(labels=[&#39;train&#39;, &#39;predict&#39;])
plt.title(target)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/ch_pred.png" style="width:50.0%" />
</center>
</div>
<div id="ci√™ncias-da-natureza" class="section level3">
<h3>Ci√™ncias da Natureza</h3>
<p>Novas features desenvolvidas especificamente para este modelo:</p>
<pre class="python"><code>def fe_cn(df):
    df.loc[:, &#39;FE_RENDA&#39;] = df.loc[:, &#39;Q006&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1000,
    &#39;C&#39;:1500, &#39;D&#39;:2000, &#39;E&#39;:2500, &#39;F&#39;:3000, &#39;G&#39;:4000, &#39;H&#39;:5000, 
    &#39;I&#39;:6000, &#39;J&#39;:7000, &#39;K&#39;:8000,&#39;L&#39;:9000, &#39;M&#39;:10000, &#39;N&#39;:12000, 
    &#39;O&#39;:15000, &#39;P&#39;:20000, &#39;Q&#39;:30000}).astype(int) 
    df.loc[:, &#39;FE_NU_IDADE*TP_ANO_CONCLUIU&#39;] = df.TP_ANO_CONCLUIU * df.NU_IDADE
    df.loc[:, &#39;FE_Q002+Q024&#39;] = df.loc[:, &#39;Q002&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2,
    &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;: 5, &#39;G&#39;: 6, &#39;H&#39;: -1}).astype(int) + 
    df.loc[:, &#39;Q024&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}).astype(int) 
    df.loc[:, &#39;FE_SCORE&#39;] = (1/df.TP_ANO_CONCLUIU) + np.sqrt(df.NU_IDADE) + np.where(df.TP_ESCOLA==3, 1, 0)
    
    df.loc[:, &#39;FE_UF_ESCOLA&#39;] = df.SG_UF_ESC.map({
      &#39;AM&#39;:&#39;Norte&#39;, &#39;RR&#39;:&#39;Norte&#39;, &#39;AP&#39;:&#39;Norte&#39;, &#39;PA&#39;:&#39;Norte&#39;, &#39;TO&#39;:&#39;Norte&#39;, &#39;RO&#39;:&#39;Norte&#39;, &#39;AC&#39;:&#39;Norte&#39;,
      &#39;MA&#39;:&#39;Nordeste&#39;, &#39;PI&#39;:&#39;Nordeste&#39;, &#39;CE&#39;:&#39;Nordeste&#39;, &#39;RN&#39;:&#39;Nordeste&#39;, &#39;PE&#39;:&#39;Nordeste&#39;, &#39;PB&#39;:&#39;Nordeste&#39;, &#39;SE&#39;:&#39;Nordeste&#39;, &#39;AL&#39;:&#39;Nordeste&#39;, &#39;BA&#39;:&#39;Nordeste&#39;,
      &#39;MT&#39;: &#39;CentroOeste&#39;, &#39;MS&#39;: &#39;CentroOeste&#39;, &#39;GO&#39;: &#39;CentroOeste&#39;,
      &#39;SP&#39;: &#39;Sudeste&#39;, &#39;RJ&#39;: &#39;Sudeste&#39;, &#39;ES&#39;: &#39;Sudeste&#39;, &#39;MG&#39;: &#39;Sudeste&#39;,
      &#39;PR&#39;: &#39;Sul&#39;, &#39;RS&#39;: &#39;Sul&#39;, &#39;SC&#39;: &#39;Sul&#39;}).astype(&#39;category&#39;)
    return df</code></pre>
<p>Definir finalidade de algumas colunas:</p>
<pre class="python"><code># colunas que serao dropadas
to_drop = [&#39;IN_PROVA_DEITADO&#39;,
           &#39;NU_INSCRICAO&#39;,
           &#39;CO_MUNICIPIO_ESC&#39;,
           &#39;CO_UF_NASCIMENTO&#39;,
           &#39;CO_UF_RESIDENCIA&#39;,
           &#39;CO_UF_ESC&#39;,
           &#39;CO_UF_PROVA&#39;,
           &#39;CO_MUNICIPIO_PROVA&#39;,
           &#39;CO_MUNICIPIO_RESIDENCIA&#39;,
          &#39;CO_MUNICIPIO_NASCIMENTO&#39;]

# definir target e presenca
target = &quot;NU_NOTA_CN&quot;
presenca = &quot;TP_PRESENCA_CN&quot;

# demais notas para dropar (menos mt)
notas = list(set(targets)-set([target, &#39;NU_NOTA_MT&#39;]))</code></pre>
<p>Pr√©-processamento nos dados de treino</p>
<pre class="python"><code>X = train.copy()
X = X.drop(to_drop, axis=1) 
X = X[X[presenca]==1]
X = X[~X[target].isnull()]

X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X = fe_cn(X)
X = prep_data_questionarios(X)
X = fe_mun(X)
X = fe_questionario(X)
X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&amp;(~train[target].isnull()), target].astype(np.float64)</code></pre>
<p>Pr√©-processamento nos dados de teste</p>
<pre class="python"><code>X_test = test.copy()
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test = fe_cn(X_test)
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
X_test = fe_questionario(X_test)
X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)</code></pre>
<p>Feature engineering separada para evitar data leak:</p>
<pre class="python"><code># calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby(&#39;CO_ESCOLA&#39;).FE_RENDA.mean()
co_escola_idade_media = X.groupby(&#39;CO_ESCOLA&#39;).NU_IDADE.mean()
co_escola_nota_mt = X.groupby(&#39;CO_ESCOLA&#39;).NU_NOTA_MT.mean()
X = X.drop(&#39;NU_NOTA_MT&#39;, axis=1)

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    &#39;CO_ESCOLA&#39;: co_escola_renda_media.index,
    &#39;FE_ESCOLA_RENDA_MEDIA&#39;: co_escola_renda_media,
    &#39;FE_IDADE_MEDIA&#39;: co_escola_idade_media,
    &#39;FE_NOTA_MT&#39;: co_escola_nota_mt
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)
X_test = pd.merge(X_test, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)

# Codigo da escola para categorico
X.loc[:, &#39;CO_ESCOLA&#39;] = X.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)
X_test.loc[:, &#39;CO_ESCOLA&#39;] = X_test.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)

# Features de contagem
X.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})</code></pre>
<p>Ajustar modelo:</p>
<pre class="python"><code>%%time

cat_feat = X.columns[X.dtypes==&#39;category&#39;]
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)

clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = &quot;RMSE&quot;,
                            od_type = &quot;Iter&quot;,
                            od_wait = 100,iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/cn_catboost.png" style="width:95.0%" />
</center>
<p>Salvar previs√µes:</p>
<pre class="python"><code>sub.loc[:, &#39;NU_NOTA_CN&#39;] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_PRESENCA_CN!=1, &#39;NU_NOTA_CN&#39;] = 0</code></pre>
<p>Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:</p>
<pre class="python"><code>sns.kdeplot(train.loc[:, target], shade=True, color=&#39;r&#39;, clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color=&#39;b&#39;, clip=[0,1000])
plt.legend(labels=[&#39;train&#39;, &#39;predict&#39;])
plt.title(target)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/cn_pred.png" style="width:50.0%" />
</center>
</div>
<div id="matem√°tica" class="section level3">
<h3>Matem√°tica</h3>
<p>Novas features desenvolvidas especificamente para este modelo:</p>
<pre class="python"><code>def fe_mt(df):
    
    df.loc[:, &#39;FE_RENDA&#39;] = df.loc[:, &#39;Q006&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1000, &#39;C&#39;:1500, &#39;D&#39;:2000, &#39;E&#39;:2500, &#39;F&#39;:3000, &#39;G&#39;:4000, &#39;H&#39;:5000, &#39;I&#39;:6000, &#39;J&#39;:7000, &#39;K&#39;:8000,&#39;L&#39;:9000, &#39;M&#39;:10000, &#39;N&#39;:12000, &#39;O&#39;:15000, &#39;P&#39;:20000, &#39;Q&#39;:30000}).astype(int) 
    df.loc[:, &#39;FE_NU_IDADE*TP_ANO_CONCLUIU&#39;] = df.TP_ANO_CONCLUIU * df.NU_IDADE
    df.loc[:, &#39;FE_Q002+Q024&#39;] = df.loc[:, &#39;Q002&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;: 5, &#39;G&#39;: 6, &#39;H&#39;: -1}).astype(int) + df.loc[:, &#39;Q024&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}).astype(int) 
    df.loc[:, &#39;FE_SCORE&#39;] = (1/df.TP_ANO_CONCLUIU) + np.sqrt(df.NU_IDADE) + np.where(df.TP_ESCOLA==3, 1, 0)
    
    df.loc[:, &#39;FE_UF_ESCOLA&#39;] = df.SG_UF_ESC.map({&#39;AM&#39;:&#39;Norte&#39;, &#39;RR&#39;:&#39;Norte&#39;, &#39;AP&#39;:&#39;Norte&#39;, &#39;PA&#39;:&#39;Norte&#39;, &#39;TO&#39;:&#39;Norte&#39;, &#39;RO&#39;:&#39;Norte&#39;, &#39;AC&#39;:&#39;Norte&#39;,
                &#39;MA&#39;:&#39;Nordeste&#39;, &#39;PI&#39;:&#39;Nordeste&#39;, &#39;CE&#39;:&#39;Nordeste&#39;, &#39;RN&#39;:&#39;Nordeste&#39;, &#39;PE&#39;:&#39;Nordeste&#39;, &#39;PB&#39;:&#39;Nordeste&#39;, &#39;SE&#39;:&#39;Nordeste&#39;, &#39;AL&#39;:&#39;Nordeste&#39;, &#39;BA&#39;:&#39;Nordeste&#39;,
                &#39;MT&#39;: &#39;CentroOeste&#39;, &#39;MS&#39;: &#39;CentroOeste&#39;, &#39;GO&#39;: &#39;CentroOeste&#39;,
                &#39;SP&#39;: &#39;Sudeste&#39;, &#39;RJ&#39;: &#39;Sudeste&#39;, &#39;ES&#39;: &#39;Sudeste&#39;, &#39;MG&#39;: &#39;Sudeste&#39;,
                &#39;PR&#39;: &#39;Sul&#39;, &#39;RS&#39;: &#39;Sul&#39;, &#39;SC&#39;: &#39;Sul&#39;}).astype(&#39;category&#39;)
    
    
    return df</code></pre>
<p>Definir finalidade de algumas colunas:</p>
<pre class="python"><code># colunas que serao dropadas
to_drop = [&#39;IN_PROVA_DEITADO&#39;,
           &#39;NU_INSCRICAO&#39;,
           &#39;CO_MUNICIPIO_ESC&#39;,
           &#39;CO_UF_NASCIMENTO&#39;,
           &#39;CO_UF_RESIDENCIA&#39;,
           &#39;CO_UF_ESC&#39;,
           &#39;CO_UF_PROVA&#39;,
           &#39;CO_MUNICIPIO_PROVA&#39;,
           &#39;CO_MUNICIPIO_RESIDENCIA&#39;,
          &#39;CO_MUNICIPIO_NASCIMENTO&#39;]

# definir target e presenca
target = &quot;NU_NOTA_MT&quot;
presenca = &quot;TP_PRESENCA_MT&quot;

# demais notas para dropar (menos cn)
notas = list(set(targets)-set([target, &#39;NU_NOTA_CN&#39;]))</code></pre>
<p>Pr√©-processamento nos dados de treino</p>
<pre class="python"><code>X = train.copy()
X = X.drop(to_drop, axis=1) 
X = X[X[presenca]==1]
X = X[~X[target].isnull()]

X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X = fe_mt(X)
X = prep_data_questionarios(X)
X = fe_mun(X)
#X = fe_questionario(X)
#X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&amp;(~train[target].isnull()), target].astype(np.float64)</code></pre>
<p>Pr√©-processamento nos dados de teste</p>
<pre class="python"><code>X_test = test.copy()
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test = fe_mt(X_test)
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
#X_test = fe_questionario(X_test)
#X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)</code></pre>
<p>Feature engineering separada para evitar data leak:</p>
<pre class="python"><code># calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby(&#39;CO_ESCOLA&#39;).FE_RENDA.mean()
co_escola_idade_media = X.groupby(&#39;CO_ESCOLA&#39;).NU_IDADE.mean()
co_escola_nota_cn = X.groupby(&#39;CO_ESCOLA&#39;).NU_NOTA_CN.mean()
X = X.drop(&#39;NU_NOTA_CN&#39;, axis=1)

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    &#39;CO_ESCOLA&#39;: co_escola_renda_media.index,
    &#39;FE_ESCOLA_RENDA_MEDIA&#39;: co_escola_renda_media,
    &#39;FE_IDADE_MEDIA&#39;: co_escola_idade_media,
    &#39;FE_NOTA_CN&#39;: co_escola_nota_cn
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)
X_test = pd.merge(X_test, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)

# Codigo da escola para categorico
X.loc[:, &#39;CO_ESCOLA&#39;] = X.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)
X_test.loc[:, &#39;CO_ESCOLA&#39;] = X_test.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)

# Features de contagem
X.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})</code></pre>
<p>Ajustar modelo:</p>
<pre class="python"><code>%%time

cat_feat = X.columns[X.dtypes==&#39;category&#39;]
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)
    
clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = &quot;RMSE&quot;,
                            od_type = &quot;Iter&quot;,
                            od_wait = 100,iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/mt_catboost.png" style="width:95.0%" />
</center>
<p>Salvar previs√µes:</p>
<pre class="python"><code>sub.loc[:, &#39;NU_NOTA_MT&#39;] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_PRESENCA_CN!=1, &#39;NU_NOTA_MT&#39;] = 0</code></pre>
<p>Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:</p>
<pre class="python"><code>sns.kdeplot(train.loc[:, target], shade=True, color=&#39;r&#39;, clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color=&#39;b&#39;, clip=[0,1000])
plt.legend(labels=[&#39;train&#39;, &#39;predict&#39;])
plt.title(target)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/mt_pred.png" style="width:50.0%" />
</center>
</div>
<div id="reda√ß√£o" class="section level3">
<h3>Reda√ß√£o</h3>
<p>Novas features desenvolvidas especificamente para este modelo:</p>
<pre class="python"><code>def fe_rd(df):
    
    df.loc[:, &#39;FE_RENDA&#39;] = df.loc[:, &#39;Q006&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1000, &#39;C&#39;:1500, &#39;D&#39;:2000, &#39;E&#39;:2500, &#39;F&#39;:3000, &#39;G&#39;:4000, &#39;H&#39;:5000, &#39;I&#39;:6000, &#39;J&#39;:7000, &#39;K&#39;:8000,&#39;L&#39;:9000, &#39;M&#39;:10000, &#39;N&#39;:12000, &#39;O&#39;:15000, &#39;P&#39;:20000, &#39;Q&#39;:30000}).astype(int) 
    df.loc[:, &#39;FE_NU_IDADE*TP_ANO_CONCLUIU&#39;] = df.TP_ANO_CONCLUIU * df.NU_IDADE
    df.loc[:, &#39;FE_Q002+Q024&#39;] = df.loc[:, &#39;Q002&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;: 5, &#39;G&#39;: 6, &#39;H&#39;: -1}).astype(int) + df.loc[:, &#39;Q024&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4}).astype(int) 
    df.loc[:, &#39;FE_SCORE&#39;] = (1/df.TP_ANO_CONCLUIU) + np.sqrt(df.NU_IDADE) + np.where(df.TP_ESCOLA==3, 1, 0)
    
    df.loc[:, &#39;FE_RENDA_FAMILIA_+_IDADE&#39;] = df.loc[:, &#39;Q006&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;:5, &#39;G&#39;:6, &#39;H&#39;:7, &#39;I&#39;:8, &#39;J&#39;:9, &#39;K&#39;:10,&#39;L&#39;:11, &#39;M&#39;:12, &#39;N&#39;:13, &#39;O&#39;:14, &#39;P&#39;:15, &#39;Q&#39;:16}).astype(int) + df.NU_IDADE        
    df.loc[:, &#39;FE_RENDA_FAMILIA_+_ANO_CONCLUIU&#39;] = df.loc[:, &#39;Q006&#39;].map({&#39;A&#39;:0, &#39;B&#39;:1, &#39;C&#39;:2, &#39;D&#39;:3, &#39;E&#39;:4, &#39;F&#39;:5, &#39;G&#39;:6, &#39;H&#39;:7, &#39;I&#39;:8, &#39;J&#39;:9, &#39;K&#39;:10,&#39;L&#39;:11, &#39;M&#39;:12, &#39;N&#39;:13, &#39;O&#39;:14, &#39;P&#39;:15, &#39;Q&#39;:16}).astype(int)+ df.TP_ANO_CONCLUIU  
    
    return df</code></pre>
<p>Definir finalidade de algumas colunas:</p>
<pre class="python"><code># colunas que serao dropadas
to_drop = [&#39;IN_PROVA_DEITADO&#39;,
           &#39;NU_INSCRICAO&#39;,
           &#39;CO_MUNICIPIO_ESC&#39;,
           &#39;CO_UF_NASCIMENTO&#39;,
           &#39;CO_UF_RESIDENCIA&#39;,
           &#39;CO_UF_ESC&#39;,
           &#39;CO_UF_PROVA&#39;,
           &#39;CO_MUNICIPIO_PROVA&#39;,
           &#39;CO_MUNICIPIO_RESIDENCIA&#39;,
          &#39;CO_MUNICIPIO_NASCIMENTO&#39;]

# definir target e presenca
target = &quot;NU_NOTA_REDACAO&quot;
presenca = &quot;TP_STATUS_REDACAO&quot;

# demais notas para dropar 
notas = list(set(targets)-set([target]))</code></pre>
<p>Pr√©-processamento nos dados de treino</p>
<pre class="python"><code>X = train.copy()
X = X.drop(to_drop, axis=1) 
X = X[X[presenca]==1]
X = X[~X[target].isnull()]


X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X = fe_rd(X)
X = prep_data_questionarios(X)
X = fe_mun(X)
#X = fe_questionario(X)
X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&amp;(~train[target].isnull()), target].astype(np.float64)</code></pre>
<p>Pr√©-processamento nos dados de teste</p>
<pre class="python"><code>X_test = test.copy()
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test = fe_rd(X_test)
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
#X_test = fe_questionario(X_test)
X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)</code></pre>
<p>Feature engineering separada para evitar data leak:</p>
<pre class="python"><code># calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby(&#39;CO_ESCOLA&#39;).FE_RENDA.mean()
co_escola_idade_media = X.groupby(&#39;CO_ESCOLA&#39;).NU_IDADE.mean()

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    &#39;CO_ESCOLA&#39;: co_escola_renda_media.index,
    &#39;FE_ESCOLA_RENDA_MEDIA&#39;: co_escola_renda_media,
    &#39;FE_IDADE_MEDIA&#39;: co_escola_idade_media
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)
X_test = pd.merge(X_test, co_escola_aux, how=&#39;left&#39;, on=&#39;CO_ESCOLA&#39;)

# Codigo da escola para categorico
X.loc[:, &#39;CO_ESCOLA&#39;] = X.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)
X_test.loc[:, &#39;CO_ESCOLA&#39;] = X_test.CO_ESCOLA.astype(&#39;object&#39;).astype(&#39;category&#39;)

# Features de contagem
X.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_PROVA&#39;] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_RESIDENCIA&#39;] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_MUNICIPIO_NASCIMENTO&#39;] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, &#39;FE_COUNT_ESCOLA&#39;] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})</code></pre>
<p>Ajustar modelo:</p>
<pre class="python"><code>%%time

cat_feat = X.columns[X.dtypes==&#39;category&#39;]
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna(&quot;XXX&quot;).astype(&quot;category&quot;)

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)

clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = &quot;RMSE&quot;,
                            od_type = &quot;Iter&quot;,
                            od_wait = 100,iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/redacao_catboost.png" style="width:95.0%" />
</center>
<p>Salvar previs√µes:</p>
<pre class="python"><code>sub.loc[:, &#39;NU_NOTA_REDACAO&#39;] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_STATUS_REDACAO!=1, &#39;NU_NOTA_REDACAO&#39;] = 0</code></pre>
<p>Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:</p>
<pre class="python"><code>sns.kdeplot(train.loc[:, target], shade=True, color=&#39;r&#39;, clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color=&#39;b&#39;, clip=[0,1000])
plt.legend(labels=[&#39;train&#39;, &#39;predict&#39;])
plt.title(target)</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/redacao_pred.png" style="width:50.0%" />
</center>
</div>
</div>
</div>
<div id="submiss√£o" class="section level1">
<h1>Submiss√£o</h1>
<p>Veja a seguir como ficou a distribui√ß√£o das previs√µes comparada √† distribui√ß√£o da target nos dados de treino:</p>
<pre class="python"><code>plt.figure(figsize=(16, 5))

notas = [&#39;NU_NOTA_CH&#39;, &#39;NU_NOTA_CN&#39;, &#39;NU_NOTA_MT&#39;, &#39;NU_NOTA_LC&#39;, &#39;NU_NOTA_REDACAO&#39;]

for i in range(len(notas)):

    plt.subplot(1, 5, i+1)
    sns.kdeplot(train.loc[:, notas[i]], shade=True, color=&#39;r&#39;, clip=[0,1000])
    sns.kdeplot(sub.loc[:, notas[i]], shade=True, color=&#39;b&#39;, clip=[0,1000])
    plt.legend(labels=[&#39;train&#39;, &#39;predict&#39;])
    plt.title(notas[i])
plt.tight_layout()
plt.show()</code></pre>
<center>
<img src="/post/2022-04-20-solucao-final-education-quality-kaggle-competition/all_pred.png" style="width:95.0%" />
</center>
<p>Acredito que talvez um tuning do modelo poderia trazer mais qualidade √†s previs√µes mas com o tempo limitado n√£o pude investir muito nesta etapa.</p>
</div>
<div id="considera√ß√µes-finais" class="section level1">
<h1>Considera√ß√µes Finais</h1>
<p>Em resumo, essas foram as principais id√©ias para a solu√ß√£o da competi√ß√£o e acredito que um dos segredos era focar em feature engineering por 2 motivos:</p>
<ul>
<li>A base era muito grande e o processo de tuning seria muito custoso (a n√£o ser que tenha um √≥timo computador a disposi√ß√£o);</li>
<li>Os atributos n√£o eram an√¥nimos, o que d√° muita informa√ß√£o de contexto.</li>
</ul>
<p>Agrade√ßo aos organizadores e √† todos os participantes que tornaram esta competi√ß√£o t√£o divertida! Por mais competi√ß√µes como esta, que valorizam a comunidade brasileira de Data Science!</p>
<p>Espero que tenham gostado e at√© logo!</p>
<p>Abra√ßos!</p>
<p>Fellipe Gomes</p>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2022-04-20-solucao-final-education-quality-kaggle-competition/">Solu√ß√£o Final - ML Olympiad [2¬∫ lugar]</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">catboost</category>
      <category domain="tag">data-mining</category>
      <category domain="tag">data-science</category>
      <category domain="tag">kaggle</category>
      <category domain="tag">machine-learning</category>
      <category domain="tag">modelagem</category>
      <category domain="tag">pratica</category>
      <category domain="tag">r</category>
      <category domain="tag">regressao</category>
    </item>
    <item>
      <title>Solu√ß√£o Final - Porto Seguro Data Challenge [3¬∫ lugar]</title>
      <link>https://gomesfellipe.github.io/post/2021-11-01-solucao-final-porto-seguro-data-challenge/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-11-01-solucao-final-porto-seguro-data-challenge/</guid>
      <description>Confira a estrat√©gia aplicada para a competi√ß√£o de machine learning do Porto Seguro hospedada no Kaggle</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#introdu%C3%A7%C3%A3o" id="toc-introdu√ß√£o">Introdu√ß√£o</a></li>
<li><a href="#defini%C3%A7%C3%A3o-do-problema-de-neg%C3%B3cio" id="toc-defini√ß√£o-do-problema-de-neg√≥cio">Defini√ß√£o do problema de neg√≥cio</a></li>
<li><a href="#an%C3%A1lise-explorat%C3%B3ria-em-r" id="toc-an√°lise-explorat√≥ria-em-r">An√°lise Explorat√≥ria (em R)</a></li>
<li><a href="#machine-learning-em-python" id="toc-machine-learning-em-python">Machine Learning (em Python)</a>
<ul>
<li><a href="#importar-depend%C3%AAncias" id="toc-importar-depend√™ncias">Importar depend√™ncias</a></li>
<li><a href="#stage-0-feature-extraction-com-knn" id="toc-stage-0-feature-extraction-com-knn">Stage 0: Feature Extraction com KNN</a></li>
<li><a href="#stage-1-tuning-xgboost-com-optuna" id="toc-stage-1-tuning-xgboost-com-optuna">Stage 1: Tuning XGBoost com Optuna</a></li>
<li><a href="#stage-2-calcular-out-of-fold-shap-values" id="toc-stage-2-calcular-out-of-fold-shap-values">Stage 2: Calcular Out-Of-Fold SHAP values</a></li>
<li><a href="#stage-3-modelo-final-com-autogluon" id="toc-stage-3-modelo-final-com-autogluon">Stage 3: Modelo Final com AutoGluon</a></li>
</ul></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias</a></li>
</ul>
</div>

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 20%;
padding: 10px;
}

.column8 {
float: left;
width: 80%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>
<hr />
<div id="introdu√ß√£o" class="section level1">
<h1>Introdu√ß√£o</h1>
<div class="row">
<div class="column8">
<p>Em Agosto e 2021 a Porto Seguro lan√ßou um desafio no Kaggle que consistia em estimar a propens√£o de aquisi√ß√£o de novos produtos. Tratava-se de um problema de classifica√ß√£o e foi bem desafiador principalmente por 2 motivos:</p>
<ol style="list-style-type: decimal">
<li>Todas as features da base de ddos eram anonimas;</li>
<li>A m√©trica de avalia√ß√£o foi a F1 Score (sens√≠vel √† um ponto de corte)</li>
</ol>
</div>
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/Ie2Hs3A0uJRtK/giphy.gif" alt="Via Giphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/Ie2Hs3A0uJRtK/giphy.gif">Via Giphy</a></div>
</div>
</div>
</div>
<p>Depois de 2 longos meses e dezenas de notebooks desenvolvidos, muitas submiss√µes frustradas e muitas horas a menos de sono, cheguei em uma solu√ß√£o final que envole um <em>blending</em> de modelos e <em>pseudo-labels</em> e quando a competi√ß√£o acabou, percebi que uma solu√ß√£o mais simples de implementar teria um resultado privado ainda maior do que o notebook que selecionei. üòÖ</p>
<div class="w3-panel w3-sand w3-border">
<p>‚ö†Ô∏è Aten√ß√£o!</p>
<p>Neste post abordarei uma solu√ß√£o mais simples e eficiente mas caso tenha interesse em conferir a solu√ß√£o final completa (um grande frankstein), j√° est√° <a href="https://github.com/gomesfellipe/porto_seguro_data_challenge">publica la no github</a>.</p>
</div>
<p>Este notebook √© uma <a href="https://www.kaggle.com/gomes555/3st-place-simplified-solution-0-6967-private">reescritura do meu notebook publicado no Kaggle em linguagem Python</a>. Para quem acompanha meus posts de R pode achar meio estranho este notebook mas convido-o a tentar entender a solu√ß√£o pois foi desenvolvida pela perspectiva de um usu√°rio nativo de R.</p>
<p>Espero que gostem! ü§ò</p>
</div>
<div id="defini√ß√£o-do-problema-de-neg√≥cio" class="section level1">
<h1>Defini√ß√£o do problema de neg√≥cio</h1>
<p>Segundo a descri√ß√£o da competi√ß√£o:</p>
<blockquote>
<p>Voc√™ provavelmente j√° recebeu uma liga√ß√£o de telemarketing oferecendo um produto que voc√™ n√£o precisa. Essa situa√ß√£o de estresse √© minimizada quando voc√™ oferece um produto que o cliente realmente precisa. <br /><br /> Nessa competi√ß√£o voc√™ ser√° desafiado a construir um modelo que prediz a probabilidade de aquisi√ß√£o de um produto.</p>
</blockquote>
<p>Sobre a m√©trica de avalia√ß√£o:</p>
<p>O crit√©rio utilizado para defini√ß√£o da melhor solu√ß√£o ser√° o F1-Score, veja sua formula:</p>
<p><span class="math display">\[
F_1 = 2 \times \frac{precision \times recall}{precision + recall}  
\]</span></p>
<p>Note que tanto a <em>Precision</em> quanto a <em>Recall</em> precisam de um ponto de corte para obter as classes e por isso busquei otmizar as m√©tricas <em>ROC-AUC</em> e <em>Log Loss</em> para obter estimativas de probabilidades com qualidade para finalmente calcular os pontos de corte que maximizam a <em>F1</em>.</p>
</div>
<div id="an√°lise-explorat√≥ria-em-r" class="section level1">
<h1>An√°lise Explorat√≥ria (em R)</h1>
<p>Antes de partir para modelagem fiz uma an√°lise explorat√≥ria utilizando a linguagem R. Neste post tratarei de maneira bem breve e quem tiver interesse em conferir mais detalhes bem como os c√≥digos dos gr√°ficos basta acessar o <a href="https://www.kaggle.com/gomes555/porto-seguro-r-an-lise-explorat-ria-dos-dados">notebook que deixei aberto no Kaggle</a>.</p>
<p>Veja alguns gr√°ficos:</p>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/aed.png" style="width:90.0%" />
</center>
<!-- <div class="w3-panel w3-light-blue w3-border"> -->
<p><strong>üìå Interpreta√ß√£o:</strong> <br></p>
<ul>
<li><strong>Categ√≥ricas</strong>:
<div style="color: rgb(0, 0, 0);">
<ul>
<li>
<strong>Qualitativo nominal</strong>: Possuem muitas classes, poderia ser o nome do produto, regi√£o, um texto o que torna o desafio ainda maior para criar novas features;
</li>
<li>
<strong>Qualitativo ordinal</strong>: Basicamente deixei como veio pois j√° tava como numerico;
</li>
</ul>
</div></li>
<li><strong>Num√©ricas</strong>:
<div style="color: rgb(0, 0, 0);">
<ul>
<li>
<strong>Quantitativo continua</strong>: Todas est√£o normalizadas (0, 1), algumas s√£o bimodais, algumas assim√©tricas a direita (pode ser tempo ate alguma coisa);
</li>
<li>
<strong>Quantitativo discreto</strong>: Sem muito o que fazer, observa√ß√£o apenas a feature <code>var52</code> que parece idade
</li>
</ul>
</div></li>
<li><strong>Dados missing</strong>: Parece haver algum padr√£o na maneira como os dados missing ocorrem e tentei substituir os <code>-999</code> por <code>NaN</code>, imputar a m√©dia, a mediana e via outros modelos
<!-- </div> --></li>
</ul>
<p>N√£o achei que seria muito produtivo ficar adivinhando o que poderia ser cada feature pois praticamente todos as transforma√ß√µes e novas features que gerei n√£o superavam o resultado do modelo ajustado nos dados da maneira que vinham portanto procurei investir mais tempo na modelagem mesmo.</p>
</div>
<div id="machine-learning-em-python" class="section level1">
<h1>Machine Learning (em Python)</h1>
<p>Veja a estrat√©gia de modelagem de maneira visual:</p>
</br>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/final_pipeline.png" style="width:60.0%" />
</center>
<p></br></p>
<div id="importar-depend√™ncias" class="section level2">
<h2>Importar depend√™ncias</h2>
<p>Carregar pacotes do Python</p>
<pre class="python"><code># general packages
import pandas as pd
import numpy as np
import time
# knn features
from gokinjo import knn_kfold_extract
from gokinjo import knn_extract
# ml tools
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.metrics import f1_score, log_loss, roc_auc_score
# models
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
# optimization
import optuna
# interpretable ml
import shap
# automl
from autogluon.tabular import TabularPredictor
# ignore specific warnings
import warnings
warnings.filterwarnings(&quot;ignore&quot;, message=&quot;ntree_limit is deprecated, use `iteration_range` or model slicing instead.&quot;)</code></pre>
<p>Definir fun√ß√µes auxiliares para calcular o ponto de corte que maximiza a F1:</p>
<pre class="python"><code>def get_threshold(y_true, y_pred):
    thresholds = np.arange(0.0, 1.0, 0.01)
    f1_scores = []
    for thresh in thresholds:
        f1_scores.append(
            f1_score(y_true, [1 if m&gt;thresh else 0 for m in y_pred]))
    f1s = np.array(f1_scores)
    return thresholds[f1s.argmax()]
    
def custom_f1(y_true, y_pred):
    max_f1_threshold =  get_threshold(y_true, y_pred)
    y_pred = np.where(y_pred&gt;max_f1_threshold, 1, 0)
    return f1_score(y_true, y_pred) </code></pre>
<p>Carregar <a href="https://www.kaggle.com/c/porto-seguro-data-challenge/data">dados da competi√ß√£o</a>:</p>
<pre class="python"><code># load data
train = pd.read_csv(&#39;../input/porto-seguro-data-challenge/train.csv&#39;).drop(&#39;id&#39;, axis=1)
test = pd.read_csv(&#39;../input/porto-seguro-data-challenge/test.csv&#39;).drop(&#39;id&#39;, axis=1)
sample_submission = pd.read_csv(&#39;../input/porto-seguro-data-challenge/submission_sample.csv&#39;)
meta = pd.read_csv(&#39;../input/porto-seguro-data-challenge/metadata.csv&#39;)

# get data types
cat_nom = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==&quot;Qualitativo nominal&quot;)].iloc[:,0]] 
cat_ord = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==&quot;Qualitativo ordinal&quot;)].iloc[:,0]] 
num_dis = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==&quot;Quantitativo discreto&quot;)].iloc[:,0]] 
num_con = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==&quot;Quantitativo continua&quot;)].iloc[:,0]] </code></pre>
</div>
<div id="stage-0-feature-extraction-com-knn" class="section level2">
<h2>Stage 0: Feature Extraction com KNN</h2>
<p>Esta t√©cnica gera <span class="math inline">\(k \times c\)</span> novas features, onde <span class="math inline">\(c\)</span> √© o n√∫mero de classes da target. As novas features s√£o calculadas a partir das dist√¢ncias entre as observa√ß√µes e seus k vizinhos mais pr√≥ximos dentro de cada classe;</p>
<p>O valor para os <span class="math inline">\(K\)</span> vizinhos mais pr√≥ximos selecionado foi <span class="math inline">\(K=1\)</span> e para isso utilizei a biblioteca
<a href="https://github.com/momijiame/gokinjo"><code>gokinjo</code></a> que foi <a href="https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335">inspirada nas id√©ias apresentadas na solu√ß√£o vencedora do Otto Group Product Classification Challenge.</a></p>
<pre class="python"><code># convert to numpy because gokinjo expects np arrays
X = train[cat_nom+cat_ord+num_dis+num_con].to_numpy()
y = train.y.to_numpy()
X_test = test[cat_nom+cat_ord+num_dis+num_con].to_numpy()

# extract on train data
KNN_feat_train = knn_kfold_extract(X, y, k=1, normalize=&#39;standard&#39;)
print(&quot;KNN features for training set, shape: &quot;, np.shape(KNN_feat_train))

# extract on test data
KNN_feat_test = knn_extract(X, y, X_test, k=1, normalize=&#39;standard&#39;)
print(&quot;KNN features for test set, shape: &quot;, np.shape(KNN_feat_test))

# convert to dataframe
knn_feat_train = pd.DataFrame(KNN_feat_train, columns=[&quot;knn&quot;+str(x) for x in range(knn_feat_train.shape[1])])
knn_feat_test = pd.DataFrame(KNN_feat_test, columns=[&quot;knn&quot;+str(x) for x in range(knn_feat_test.shape[1])])</code></pre>
<pre><code>## KNN features for training set, shape:  (14123, 2)
## KNN features for test set, shape:  (21183, 2)</code></pre>
</div>
<div id="stage-1-tuning-xgboost-com-optuna" class="section level2">
<h2>Stage 1: Tuning XGBoost com Optuna</h2>
<p>Testei e otimizei muitos modelos como XGBoost, NGBoost, LightGBM, CatBoost, TabNet, HistGradientBoosting e algumas DNNs e em todos os casos (exceto DNNs) utilizei o Optuna para a sele√ß√£o dos hiperpar√¢metros.</p>
<p>Tamb√©m inclui nas tentativas iniciais de otimiza√ß√£o alguns m√©todos de remostrarem como Random Under Sampling, Smote, Tomek, Adasyn dentre outros mas n√£o tive muito sucesso.. apenas a combina√ß√£o Tomek + CatBoost pareceu trazer algum ganho.</p>
<p>Claro que minhas tentativas n√£o foram exautivas e devido ao tempo limitado acabei selecionando o XGBoost que foi o que apresentou as melhores m√©tricas depois de otimizado e tamb√©m o CatBoost com alguns hiperpar√¢metros fixos para serem a base deste pipeline.</p>
<p>Principais Informa√ß√µes üìå :</p>
<ul>
<li>Nenhum pr√©-processamento;</li>
<li>KFold K=10;</li>
<li>Otimiza√ß√£o de hiperpar√¢metros com Optuna;</li>
<li>Loss do XGBoost: Log Loss;</li>
<li>Loss do Otimizador: Log Loss;</li>
<li>Sem resampling;</li>
<li>Previs√£o final com a probabilidade m√©dia de 10 seeds diferentes</li>
</ul>
<pre class="python"><code>X_test = test[cat_nom+cat_ord+num_dis+num_con]
X = train[cat_nom+cat_ord+num_dis+num_con]
y = train.y

K=10
SEED=314
kf = KFold(n_splits=K, random_state=SEED, shuffle=True)</code></pre>
<pre class="python"><code>fixed_params = {
    &#39;random_state&#39;: 9,
    &quot;objective&quot;: &quot;binary:logistic&quot;,
    &quot;eval_metric&quot;: &#39;logloss&#39;,
    &#39;use_label_encoder&#39;:False,
    &#39;n_estimators&#39;:10000,
}

def objective(trial):
    
    hyperparams = {
        &#39;clf&#39;:{
        &quot;booster&quot;: trial.suggest_categorical(&quot;booster&quot;, [&quot;gbtree&quot;]),
        &quot;lambda&quot;: trial.suggest_float(&quot;lambda&quot;, 1e-8, 5.0, log=True),
        &quot;alpha&quot;: trial.suggest_float(&quot;alpha&quot;, 1e-8, 5.0, log=True)
        }
    }
    
    if hyperparams[&#39;clf&#39;][&quot;booster&quot;] == &quot;gbtree&quot; or hyperparams[&#39;clf&#39;][&quot;booster&quot;] == &quot;dart&quot;:
        hyperparams[&#39;clf&#39;][&quot;max_depth&quot;] = trial.suggest_int(&quot;max_depth&quot;, 1, 9)
        hyperparams[&#39;clf&#39;][&quot;eta&quot;] = trial.suggest_float(&quot;eta&quot;, 0.01, 0.1, log=True)
        hyperparams[&#39;clf&#39;][&quot;gamma&quot;] = trial.suggest_float(&quot;gamma&quot;, 1e-8, 1.0, log=True)
        hyperparams[&#39;clf&#39;][&quot;grow_policy&quot;] = trial.suggest_categorical(&quot;grow_policy&quot;, [&quot;depthwise&quot;, &quot;lossguide&quot;])
        hyperparams[&#39;clf&#39;][&#39;min_child_weight&#39;] = trial.suggest_int(&#39;min_child_weight&#39;, 5, 20)
        hyperparams[&#39;clf&#39;][&quot;subsample&quot;] = trial.suggest_float(&quot;subsample&quot;, 0.03, 1)
        hyperparams[&#39;clf&#39;][&quot;colsample_bytree&quot;] = trial.suggest_float(&quot;colsample_bytree&quot;, 0.03, 1)
        hyperparams[&#39;clf&#39;][&#39;max_delta_step&#39;] = trial.suggest_float(&#39;max_delta_step&#39;, 0, 10)
        
    if hyperparams[&#39;clf&#39;][&quot;booster&quot;] == &quot;dart&quot;:
        hyperparams[&#39;clf&#39;][&quot;sample_type&quot;] = trial.suggest_categorical(&quot;sample_type&quot;, [&quot;uniform&quot;, &quot;weighted&quot;])
        hyperparams[&#39;clf&#39;][&quot;normalize_type&quot;] = trial.suggest_categorical(&quot;normalize_type&quot;, [&quot;tree&quot;, &quot;forest&quot;])
        hyperparams[&#39;clf&#39;][&quot;rate_drop&quot;] = trial.suggest_float(&quot;rate_drop&quot;, 1e-8, 1.0, log=True)
        hyperparams[&#39;clf&#39;][&quot;skip_drop&quot;] = trial.suggest_float(&quot;skip_drop&quot;, 1e-8, 1.0, log=True)
    
    params = dict(**fixed_params, **hyperparams[&#39;clf&#39;])
    xgb_oof = np.zeros(X.shape[0])

    for fold, (train_idx, val_idx) in enumerate(kf.split(X=X, y=y)):
        X_train = X.iloc[train_idx]
        y_train = y.iloc[train_idx]
        X_val = X.iloc[val_idx]
        y_val = y.iloc[val_idx]
        
        model = XGBClassifier(**params)
        
        model.fit(X_train, y_train,
                  eval_set=[(X_val, y_val)],
                  early_stopping_rounds=150,
                  verbose=False)
    
        xgb_oof[val_idx] = model.predict_proba(X_val)[:,1]

        del model

    return log_loss(y, xgb_oof)</code></pre>
<p>Como no Kaggle existe o limite de aproximadamente 8h para executar um notebook, coloquei um limite de 7.5 horas para a busca de hiperpar√¢metros:</p>
<pre class="python"><code>study_xgb = optuna.create_study(direction=&#39;minimize&#39;)

study_xgb.optimize(objective, 
               timeout=60*60*7.5, 
               gc_after_trial=True)</code></pre>
<p>Resultados da busca:</p>
<pre class="python"><code>print(&#39;-&gt; Number of finished trials: &#39;, len(study_xgb.trials))
print(&#39;-&gt; Best trial:&#39;)
trial = study_xgb.best_trial
print(&#39;\tValue: {}&#39;.format(trial.value))
print(&#39;-&gt; Params: &#39;)
trial.params</code></pre>
<pre><code>## -&gt; Number of finished trials:  197
## -&gt; Best trial:
## 	Value: 0.3028443879614926
## -&gt; Params: 
## {&#39;booster&#39;: &#39;gbtree&#39;,
##  &#39;lambda&#39;: 9.012384508756378e-07,
##  &#39;alpha&#39;: 0.7472040331088792,
##  &#39;max_depth&#39;: 5,
##  &#39;eta&#39;: 0.01507605562231303,
##  &#39;gamma&#39;: 1.0214961302342215e-08,
##  &#39;grow_policy&#39;: &#39;lossguide&#39;,
##  &#39;min_child_weight&#39;: 5,
##  &#39;subsample&#39;: 0.9331005225916879,
##  &#39;colsample_bytree&#39;: 0.25392142363325004,
##  &#39;max_delta_step&#39;: 5.685109389498008}</code></pre>
<p>Acompanhar o hist√≥rico de cada etapa da otimiza√ß√£o:</p>
<pre class="python"><code>plot_optimization_history(study_xgb)</code></pre>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/optimization_hist.png" style="width:90.0%" />
</center>
<p>Avaliar as combina√ß√µes de hiperpar√¢metros mais bem sucedidas:</p>
<pre class="python"><code>optuna.visualization.plot_parallel_coordinate(study_xgb)</code></pre>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/parallel_plot.png" style="width:90.0%" />
</center>
<p>Quais hiperpar√¢metros tiveram mais impacto na modelagem:</p>
<pre class="python"><code>plot_param_importances(study_xgb)</code></pre>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/param_imp.png" style="width:90.0%" />
</center>
<p>Ap√≥s as 7.5 horas de busca, a melhor combina√ß√£o encontrada para o XGBoost foi a seguinte:</p>
<pre class="python"><code># After 7.5 hours...
study_xgb = {&#39;booster&#39;: &#39;gbtree&#39;,
 &#39;lambda&#39;: 9.012384508756378e-07,
 &#39;alpha&#39;: 0.7472040331088792,
 &#39;max_depth&#39;: 5,
 &#39;eta&#39;: 0.01507605562231303,
 &#39;gamma&#39;: 1.0214961302342215e-08,
 &#39;grow_policy&#39;: &#39;lossguide&#39;,
 &#39;min_child_weight&#39;: 5,
 &#39;subsample&#39;: 0.9331005225916879,
 &#39;colsample_bytree&#39;: 0.25392142363325004,
 &#39;max_delta_step&#39;: 5.685109389498008}</code></pre>
<p>Preparar lista de hiperpar√¢metros do XGBoost:</p>
<pre class="python"><code>final_params_xgb = dict()
final_params_xgb[&#39;clf&#39;]=dict(**fixed_params, **study_xgb)</code></pre>
</div>
<div id="stage-2-calcular-out-of-fold-shap-values" class="section level2">
<h2>Stage 2: Calcular Out-Of-Fold SHAP values</h2>
<p>Ap√≥s obter a melhor combina√ß√£o de hiperpar√¢metros para o XGBoost e encontrar resultados formid√°veis com o CatBoost modificando apenas alguns hiperpar√¢metros, resolvi tentar utilizar a informa√ß√£o adquirida pelo <em>SHAP values</em> desses modelos como entrada para novos modelos.</p>
<p>Algumas vantagens de se usar o shap values como um m√©todo de encoder dos dados, <a href="https://www.kaggle.com/pavelvod/gbm-supervised-pretraining">segundo este notebook publicado no Kaggle</a> (muito interessante por sinal):</p>
<ul>
<li>Normaliza os dados;</li>
<li>Mais ou menos Linearizado pois as <em>features</em> s√£o transformadas em suas import√¢ncias;</li>
<li>Recursos categ√≥ricos codificados de maneira mais inteligente (A codifica√ß√£o n√£o √© linear e depende de outros recursos da amostra);</li>
<li>Tratamento mais inteligente para valores <em>missing</em>.</li>
</ul>
<p>Para evitar <em>data leak</em>, o <em>SHAP values</em> foi calculado em cima dos dados <em>out-of-fold</em> para os dados de treino e a m√©dia da previs√£o de todos os <em>fold</em> nos dados de teste.</p>
<p>Definir estrat√©gia de valida√ß√£o cruzada:</p>
<pre class="python"><code>X_test = test[cat_nom+cat_ord+num_dis+num_con]
X = train[cat_nom+cat_ord+num_dis+num_con]
y = train.y

K=15 # number of bins with Sturge‚Äôs rule
SEED=123
kf = StratifiedKFold(n_splits=K, random_state=SEED, shuffle=True)</code></pre>
<div id="xgboost" class="section level3">
<h3>XGBoost</h3>
<p>Obter <em>out-of-fold</em> SHAP do modelo XGBoost tunado:</p>
<pre class="python"><code>shap1_oof = np.zeros((X.shape[0], X.shape[1]))
shap1_test = np.zeros((X_test.shape[0], X_test.shape[1]))
model_shap1_oof = np.zeros(X.shape[0])

for fold, (train_idx, val_idx) in enumerate(kf.split(X=X, y=y)):
    print(f&quot;‚ûú FOLD :{fold}&quot;)
    X_train = X.iloc[train_idx]
    y_train = y.iloc[train_idx]
    X_val = X.iloc[val_idx]
    y_val = y.iloc[val_idx]
    
    start = time.time()
    
    model = XGBClassifier(**final_params_xgb[&#39;clf&#39;])
    
    model.fit(X_train, y_train,
              eval_set=[(X_val, y_val)],
              early_stopping_rounds=150,
              verbose=False)
    
    model_shap1_oof[val_idx] += model.predict_proba(X_val)[:,1]
    
    print(&quot;Final F1     :&quot;, custom_f1(y_val, model_shap1_oof[val_idx]))
    print(&quot;Final AUC    :&quot;, roc_auc_score(y_val, model_shap1_oof[val_idx]))
    print(&quot;Final LogLoss:&quot;, log_loss(y_val, model_shap1_oof[val_idx]))

    explainer = shap.TreeExplainer(model)
    shap1_oof[val_idx] = explainer.shap_values(X_val)
    shap1_test += explainer.shap_values(X_test) / K

    print(f&quot;elapsed: {time.time()-start:.2f} sec\n&quot;)
    
shap1_oof = pd.DataFrame(shap1_oof, columns = [x+&quot;_shap1&quot; for x in X.columns])
shap1_test = pd.DataFrame(shap1_test, columns = [x+&quot;_shap1&quot; for x in X_test.columns])

print(&quot;Final F1     :&quot;, custom_f1(y, model_shap1_oof))
print(&quot;Final AUC    :&quot;, roc_auc_score(y, model_shap1_oof))
print(&quot;Final LogLoss:&quot;, log_loss(y, model_shap1_oof))</code></pre>
<pre><code>## ‚ûú FOLD :0
## Final F1     : 0.7032967032967034
## Final AUC    : 0.902330627099664
## Final LogLoss: 0.2953604946129216
## elapsed: 62.58 sec
## 
## ‚ûú FOLD :1
## Final F1     : 0.6193853427895981
## Final AUC    : 0.8613101903695408
## Final LogLoss: 0.34227429854659686
## elapsed: 45.96 sec
## 
## ‚ûú FOLD :2
## Final F1     : 0.6793478260869567
## Final AUC    : 0.8945898656215007
## Final LogLoss: 0.3085819148842589
## elapsed: 58.84 sec
## 
## ‚ûú FOLD :3
## Final F1     : 0.7073791348600509
## Final AUC    : 0.9058020716685331
## Final LogLoss: 0.2881665477053405
## elapsed: 62.24 sec
## 
## ‚ûú FOLD :4
## Final F1     : 0.7239583333333334
## Final AUC    : 0.9053121500559911
## Final LogLoss: 0.29320601468396107
## elapsed: 93.74 sec
## 
## ‚ûú FOLD :5
## Final F1     : 0.7009803921568627
## Final AUC    : 0.9076567749160134
## Final LogLoss: 0.2872539995859452
## elapsed: 73.34 sec
## 
## ‚ûú FOLD :6
## Final F1     : 0.6736292428198434
## Final AUC    : 0.8822788353863381
## Final LogLoss: 0.320014158050091
## elapsed: 55.16 sec
## 
## ‚ûú FOLD :7
## Final F1     : 0.7135416666666666
## Final AUC    : 0.9016657334826428
## Final LogLoss: 0.29617989833438774
## elapsed: 74.49 sec
## 
## ‚ûú FOLD :8
## Final F1     : 0.7135135135135134
## Final AUC    : 0.8893825776158104
## Final LogLoss: 0.29351621553572266
## elapsed: 93.71 sec
## 
## ‚ûú FOLD :9
## Final F1     : 0.7391304347826086
## Final AUC    : 0.9064054944284814
## Final LogLoss: 0.28033187155768635
## elapsed: 95.65 sec
## 
## ‚ûú FOLD :10
## Final F1     : 0.684863523573201
## Final AUC    : 0.9031046324199313
## Final LogLoss: 0.29823173886367804
## elapsed: 64.70 sec
## 
## ‚ûú FOLD :11
## Final F1     : 0.704225352112676
## Final AUC    : 0.8882052000840984
## Final LogLoss: 0.30525241732057884
## elapsed: 50.06 sec
## 
## ‚ûú FOLD :12
## Final F1     : 0.6666666666666666
## Final AUC    : 0.8905529469479291
## Final LogLoss: 0.313654842143217
## elapsed: 78.45 sec
## 
## ‚ûú FOLD :13
## Final F1     : 0.6500000000000001
## Final AUC    : 0.8745111780783517
## Final LogLoss: 0.3300786509821235
## elapsed: 59.54 sec
## 
## ‚ûú FOLD :14
## Final F1     : 0.7135416666666666
## Final AUC    : 0.9063284042329526
## Final LogLoss: 0.29314716930177404
## elapsed: 70.28 sec
## 
## Final F1     : 0.6822461331540014
## Final AUC    : 0.8945288307257988
## Final LogLoss: 0.30301717097927483</code></pre>
</div>
<div id="catboost" class="section level3">
<h3>CatBoost</h3>
<p>Obter <em>out-of-fold</em> SHAP do modelo CatBoost + features extrat√≠das via KNN:</p>
<pre class="python"><code>X = pd.concat([X, knn_feat_train], axis=1)
X_test = pd.concat([X_test, knn_feat_test], axis=1)</code></pre>
<pre class="python"><code>shap2_oof = np.zeros((X.shape[0], X.shape[1]))
shap2_test = np.zeros((X_test.shape[0], X_test.shape[1]))
model_shap2_oof = np.zeros(X.shape[0])

for fold, (train_idx, val_idx) in enumerate(kf.split(X=X, y=y)):
    print(f&quot;‚ûú FOLD :{fold}&quot;)
    X_train = X.iloc[train_idx]
    y_train = y.iloc[train_idx]
    X_val = X.iloc[val_idx]
    y_val = y.iloc[val_idx]
    
    start = time.time()
    
    model = CatBoostClassifier(random_seed=SEED,
                               verbose = 0,
                               n_estimators=10000,
                               loss_function= &#39;Logloss&#39;,
                               use_best_model=True,
                               eval_metric= &#39;Logloss&#39;)
    
    model.fit(X_train, y_train, 
              eval_set = [(X_val,y_val)], 
              early_stopping_rounds = 100,
              verbose = False)
    
    model_shap2_oof[val_idx] += model.predict_proba(X_val)[:,1]
    
    print(&quot;Final F1     :&quot;, custom_f1(y_val, model_shap2_oof[val_idx]))
    print(&quot;Final AUC    :&quot;, roc_auc_score(y_val, model_shap2_oof[val_idx]))
    print(&quot;Final LogLoss:&quot;, log_loss(y_val, model_shap2_oof[val_idx]))

    explainer = shap.TreeExplainer(model)
    shap2_oof[val_idx] = explainer.shap_values(X_val)
    shap2_test += explainer.shap_values(X_test) / K

    print(f&quot;elapsed: {time.time()-start:.2f} sec\n&quot;)
    
shap2_oof = pd.DataFrame(shap2_oof, columns = [x+&quot;_shap&quot; for x in X.columns])
shap2_test = pd.DataFrame(shap2_test, columns = [x+&quot;_shap&quot; for x in X_test.columns])

print(&quot;Final F1     :&quot;, custom_f1(y, model_shap2_oof))
print(&quot;Final AUC    :&quot;, roc_auc_score(y, model_shap2_oof))
print(&quot;Final LogLoss:&quot;, log_loss(y, model_shap2_oof))</code></pre>
<pre><code>## ‚ûú FOLD :0
## Final F1     : 0.6972010178117048
## Final AUC    : 0.8954157334826428
## Final LogLoss: 0.29952314366911725
## elapsed: 22.84 sec
## 
## ‚ûú FOLD :1
## Final F1     : 0.6348448687350835
## Final AUC    : 0.8628429451287795
## Final LogLoss: 0.3407490151943705
## elapsed: 12.59 sec
## 
## ‚ûú FOLD :2
## Final F1     : 0.6809651474530831
## Final AUC    : 0.8949538073908175
## Final LogLoss: 0.3066089330852162
## elapsed: 18.03 sec
## 
## ‚ûú FOLD :3
## Final F1     : 0.702247191011236
## Final AUC    : 0.9107992721164613
## Final LogLoss: 0.2877216893570601
## elapsed: 15.66 sec
## 
## ‚ûú FOLD :4
## Final F1     : 0.7131367292225201
## Final AUC    : 0.9018687010078387
## Final LogLoss: 0.2976481761596595
## elapsed: 29.35 sec
## 
## ‚ûú FOLD :5
## Final F1     : 0.7055837563451777
## Final AUC    : 0.909231522956327
## Final LogLoss: 0.28834373773423566
## elapsed: 15.35 sec
## 
## ‚ûú FOLD :6
## Final F1     : 0.6631578947368421
## Final AUC    : 0.8796402575587906
## Final LogLoss: 0.32303153676573987
## elapsed: 19.13 sec
## 
## ‚ûú FOLD :7
## Final F1     : 0.6997389033942559
## Final AUC    : 0.901637737961926
## Final LogLoss: 0.2985978485411335
## elapsed: 23.30 sec
## 
## ‚ûú FOLD :8
## Final F1     : 0.6965699208443271
## Final AUC    : 0.8825565912117177
## Final LogLoss: 0.3009859242847037
## elapsed: 20.19 sec
## 
## ‚ûú FOLD :9
## Final F1     : 0.7435897435897436
## Final AUC    : 0.9042469689536757
## Final LogLoss: 0.28276851015512977
## elapsed: 24.39 sec
## 
## ‚ûú FOLD :10
## Final F1     : 0.6767676767676767
## Final AUC    : 0.902712173242694
## Final LogLoss: 0.29999812838692497
## elapsed: 16.14 sec
## 
## ‚ûú FOLD :11
## Final F1     : 0.7013698630136986
## Final AUC    : 0.8865022075828719
## Final LogLoss: 0.3081393413008847
## elapsed: 13.50 sec
## 
## ‚ûú FOLD :12
## Final F1     : 0.6630434782608696
## Final AUC    : 0.8920456934613498
## Final LogLoss: 0.31338640296724246
## elapsed: 24.48 sec
## 
## ‚ûú FOLD :13
## Final F1     : 0.6485148514851485
## Final AUC    : 0.8689887167986544
## Final LogLoss: 0.3369797070301582
## elapsed: 17.17 sec
## 
## ‚ûú FOLD :14
## Final F1     : 0.7108753315649867
## Final AUC    : 0.8994743850304856
## Final LogLoss: 0.301420230674656
## elapsed: 16.51 sec
## 
## Final F1     : 0.6823234134098244
## Final AUC    : 0.892656043550729
## Final LogLoss: 0.305726567456891</code></pre>
<pre class="python"><code>train = pd.concat([train, shap1_oof], axis=1)
test = pd.concat([test, shap1_test], axis=1)

train = pd.concat([train, shap2_oof], axis=1)
test = pd.concat([test, shap2_test], axis=1)</code></pre>
</div>
</div>
<div id="stage-3-modelo-final-com-autogluon" class="section level2">
<h2>Stage 3: Modelo Final com AutoGluon</h2>
<p>AutoGluon √© um <a href="https://github.com/awslabs/autogluon">AutoML desenvolvido pela Amazon</a> muito f√°cil de utilizar (no melhor estilo <code>sklearn</code> com m√©todos <code>.fit()</code> e <code>.predict()</code>).</p>
<p>Principais Informa√ß√µes üìå :</p>
<ul>
<li>Inputs: Dataset original + knn features + Shapt values do XGBoost tunado e do CatBoost;</li>
<li>Loss do XGBoost: Log Loss;</li>
<li>Loss do CatBoost: AUC;</li>
<li>Loss do AutoGluon: Log Loss;</li>
<li>Tempo de processamento: 7h30m</li>
</ul>
<div class="w3-panel w3-pale-green w3-border">
<p><strong>üí° Insight</strong> <br></p>
<p>Um recurso muito √∫til do AutoGluon √© poder acessar as previs√µes out-of-folds, o que facilita no c√°lculo do <em>threshold</em> que maximiza a <em>F1 Score</em>.</p>
</div>
<pre class="python"><code>predictor = TabularPredictor(label=&quot;y&quot;,
                             problem_type=&#39;binary&#39;,
                             eval_metric=&quot;log_loss&quot;,
                             path=&#39;./AutoGlon/&#39;,
                             verbosity=1)

predictor.fit(train, presets=&#39;best_quality&#39;, time_limit=60*60*7.5) 

results = predictor.fit_summary()</code></pre>
<pre><code>## *** Summary of fit() ***
## Estimated performance of each model:
##                       model  score_val  pred_time_val      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order
## 0       WeightedEnsemble_L2  -0.299310      30.410467   8888.826963                0.001654           2.456810            2       True         14
## 1           CatBoost_BAG_L1  -0.301038       3.051793   2376.887100                3.051793        2376.887100            1       True          7
## 2       WeightedEnsemble_L3  -0.301722     194.034947  22907.669139                0.001541           2.008858            3       True         26
## 3         LightGBMXT_BAG_L2  -0.302135     131.534432  17201.299530                1.378576         389.400378            2       True         15
## 4         LightGBMXT_BAG_L1  -0.302562       3.570399    969.385833                3.570399         969.385833            1       True          3
## 5           CatBoost_BAG_L2  -0.302646     131.912474  17619.939451                1.756617         808.040299            2       True         19
## 6           LightGBM_BAG_L2  -0.303002     131.422007  17281.518763                1.266150         469.619612            2       True         16
## 7           LightGBM_BAG_L1  -0.303264       2.964433   1038.037160                2.964433        1038.037160            1       True          4
## 8            XGBoost_BAG_L1  -0.303471       4.475003   2036.551052                4.475003        2036.551052            1       True         11
## 9    NeuralNetFastAI_BAG_L1  -0.304455      19.917584   3434.894841               19.917584        3434.894841            1       True         10
## 10           XGBoost_BAG_L2  -0.304499     132.757505  17834.135370                2.601648        1022.236218            2       True         23
## 11   NeuralNetFastAI_BAG_L2  -0.306339     142.018741  18777.287244               11.862885        1965.388093            2       True         22
## 12     LightGBMLarge_BAG_L2  -0.306606     131.701429  18260.504603                1.545573        1448.605452            2       True         25
## 13    NeuralNetMXNet_BAG_L2  -0.308237     177.769179  19273.211899               47.613322        2461.312748            2       True         24
## 14     LightGBMLarge_BAG_L1  -0.309686       3.042399   2629.185346                3.042399        2629.185346            1       True         13
## 15    ExtraTreesEntr_BAG_L2  -0.314045     132.017535  16815.886061                1.861679           3.986910            2       True         21
## 16  RandomForestEntr_BAG_L2  -0.314454     132.061970  16843.769642                1.906114          31.870490            2       True         18
## 17    ExtraTreesGini_BAG_L2  -0.314960     132.123651  16816.087081                1.967794           4.187930            2       True         20
## 18    NeuralNetMXNet_BAG_L1  -0.317156      81.677096   4258.886806               81.677096        4258.886806            1       True         12
## 19  RandomForestGini_BAG_L2  -0.321702     132.035970  16835.326491                1.880114          23.427339            2       True         17
## 20    ExtraTreesEntr_BAG_L1  -0.323283       1.794093      4.051307                1.794093           4.051307            1       True          9
## 21  RandomForestEntr_BAG_L1  -0.324296       1.966043     33.380685                1.966043          33.380685            1       True          6
## 22    ExtraTreesGini_BAG_L1  -0.325897       1.796291      3.748723                1.796291           3.748723            1       True          8
## 23  RandomForestGini_BAG_L1  -0.328218       1.778995     22.705248                1.778995          22.705248            1       True          5
## 24    KNeighborsDist_BAG_L1  -1.070156       2.010938      2.075571                2.010938           2.075571            1       True          2
## 25    KNeighborsUnif_BAG_L1  -1.071373       2.110790      2.109480                2.110790           2.109480            1       True          1
## Number of models trained: 26
## Types of models trained:
## {&#39;StackerEnsembleModel_RF&#39;, &#39;StackerEnsembleModel_NNFastAiTabular&#39;, &#39;WeightedEnsembleModel&#39;, &#39;StackerEnsembleModel_XGBoost&#39;, &#39;StackerEnsembleModel_CatBoost&#39;, &#39;StackerEnsembleModel_KNN&#39;, &#39;StackerEnsembleModel_LGB&#39;, &#39;StackerEnsembleModel_XT&#39;, &#39;StackerEnsembleModel_TabularNeuralNet&#39;}
## Bagging used: True  (with 10 folds)
## Multi-layer stack-ensembling used: True  (with 3 levels)
## Feature Metadata (Processed):
## (raw dtype, special dtypes):
## (&#39;float&#39;, [])     : 152 | [&#39;var55&#39;, &#39;var56&#39;, &#39;var57&#39;, &#39;var58&#39;, &#39;var59&#39;, ...]
## (&#39;int&#39;, [])       :  48 | [&#39;var1&#39;, &#39;var2&#39;, &#39;var3&#39;, &#39;var4&#39;, &#39;var5&#39;, ...]
## (&#39;int&#39;, [&#39;bool&#39;]) :   6 | [&#39;var27&#39;, &#39;var31&#39;, &#39;var44&#39;, &#39;var49&#39;, &#39;var50&#39;, ...]
## Plot summary of models saved to file: ./AutoGlon/SummaryOfModels.html
## *** End of fit() summary ***</code></pre>
<p>Nota: Os resultados podem variar devido √† natureza estoc√°stica do algoritmo ou procedimento de avalia√ß√£o.</p>
<pre class="python"><code># get final predictions
y_oof = predictor.get_oof_pred_proba().iloc[:,1]
y_pred = predictor.predict_proba(test).iloc[:,1]</code></pre>
<pre class="python"><code>final_threshold = get_threshold(train.y, y_oof)
final_threshold</code></pre>
<pre><code>## 0.31</code></pre>
<pre class="python"><code>print(&quot;Final F1     :&quot;, custom_f1(y, y_oof))
print(&quot;Final AUC    :&quot;, roc_auc_score(y, y_oof))
print(&quot;Final LogLoss:&quot;, log_loss(y, y_oof))</code></pre>
<pre><code>## Final F1     : 0.6846193682030037
## Final AUC    : 0.8961328807692966
## Final LogLoss: 0.2993098559321765</code></pre>
<p>Ap√≥s submiss√£o:</p>
<center>
<img src="/post/2021-11-01-solucao-final-porto-seguro-data-challenge/final_sub.png" style="width:90.0%" />
</center>
</div>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o</h1>
<p>Gostaria de agradecer imensamente ao time do Porto Seguro pela iniciativa, pois esse tipo de competi√ß√£o (t√£o detalhada e desafiadora) n√£o tem sido muito comum no Brasil e √© muito importante para fomentar a comunidade brasileira de ci√™ncia de dados!</p>
<p>Sabemos que o ‚Äúmundo real‚Äù √© diferente do mundo das competi√ß√µes (onde buscamos o melhor score a todo custo) por√©m, na minha vis√£o, n√£o deixa de ser um √≥timo exerc√≠cio para treinar o racioc√≠nio anal√≠tico.. al√©m de ser muito empolgante e divertido!</p>
<p>Tive o enorme prazer de trocar id√©ias e conhecer pessoas fora da curva bem como me tornar f√£ de alguns competidores! A cada semana q passava o n√≠vel estava cada vez mais alto!</p>
<p>Com certeza este pipeline poderia ser muito melhor, sinto que poderia ter gasto mais tempo com <em>feature engineering</em> e tido mais paciencia com alguns modelos. Tentei fazer o melhor que pude com o tempo dispon√≠vel e me sinto muito grato pela experi√™ncia de apresentar os resultados e aprender bastante com a solu√ß√£o dos top colocados.</p>
<p>N√£o acaba por aqui! Agora √© hora de voltar aos estudos, continuar praticando com as <a href="https://www.kaggle.com/c/tabular-playground-series-nov-2021/overview">TPS‚Äôs do Kaggle</a> e, quem sabe, ir melhor na pr√≥xima!</p>
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias</h1>
<ul>
<li><a href="https://github.com/momijiame/gokinjo" class="uri">https://github.com/momijiame/gokinjo</a></li>
<li><a href="https://www.kaggle.com/melanie7744/tps6-boost-your-score-with-knn-features" class="uri">https://www.kaggle.com/melanie7744/tps6-boost-your-score-with-knn-features</a></li>
<li><a href="https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335" class="uri">https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14335</a></li>
<li><a href="https://www.kaggle.com/pavelvod/gbm-supervised-pretraining" class="uri">https://www.kaggle.com/pavelvod/gbm-supervised-pretraining</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-11-01-solucao-final-porto-seguro-data-challenge/">Solu√ß√£o Final - Porto Seguro Data Challenge [3¬∫ lugar]</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">catboost</category>
      <category domain="tag">data-science</category>
      <category domain="tag">kaggle</category>
      <category domain="tag">knn</category>
      <category domain="tag">machine-learning</category>
      <category domain="tag">optuna</category>
      <category domain="tag">pratica</category>
      <category domain="tag">python</category>
      <category domain="tag">shap</category>
      <category domain="tag">threshold-movel</category>
    </item>
    <item>
      <title>Ci√™ncia de Dados - Uma vis√£o geral</title>
      <link>https://gomesfellipe.github.io/post/2021-05-24-ciencia-de-dados-uma-visao-geral/</link>
      <pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-05-24-ciencia-de-dados-uma-visao-geral/</guid>
      <description>Nesta apresenta√ß√£o tive a oportunidade de falar um pouco sobre a minha vis√£o e cases relacionados a esta √°rea t√£o extensa e incr√≠vel que √© a ci√™ncia de dados!</description>
      <content:encoded>&lt;![CDATA[
        


<p>Com a elevada quantidade de dados sendo produzidos a todo instante e o poder computacional cada vez maior, a ci√™ncia de dados tem ganhado muito espa√ßo no mercado. Isso ocorre pois suas ferramentas nos permitem descobrir solu√ß√µes ocultas a partir de enormes massas de dados desorganizados combinando programa√ß√£o, matem√°tica, estat√≠stica e compreens√£o contextual.</p>
<div id="o-bom-filho-√†-casa-torna" class="section level1">
<h1>O bom filho √† casa torna!</h1>
<p>No dia 23 de abr. de 2021 tive o enorme prazer de apresentar no <a href="https://edu.ieee.org/br-uff/ramo-uff/">Ramo Estudantil IEEE UFF</a> um pouco sobre a minha vis√£o sobre √°reas que comp√µe a ci√™ncia de dados e apresentar alguns cases relacionados!</p>
<p>Sou muito grato √† organiza√ß√£o por todo o cuidado e capricho do evento e muito satisfeito de poder retornar (apesar das circunst√¢ncias do momento de pandemia) a esta universidade que mudou minha vida e poder contribuir um pouquinho para o desenvolvimento de alunos interessados em seguir na √°rea.</p>
<p>Conte√∫dos que foram (brevemente) abordados:</p>
<ul>
<li>O que √© ci√™ncia de dados</li>
<li>Estat√≠stica e Ci√™ncia de dados</li>
<li>Big Data</li>
<li>Machine Learning</li>
<li>Aplica√ß√µes (e cases)</li>
<li>Dicas de Carreira</li>
</ul>
<p>Foi uma apresenta√ß√£o de 1 hora e esta gravada no canal do Ramo Estudantil IEEE - UFF no Youtube no link: <a href="https://www.youtube.com/watch?v=9UWhZ1s3Ybc" class="uri">https://www.youtube.com/watch?v=9UWhZ1s3Ybc</a></p>
<div style="text-align:center;">
<p><iframe width="560" height="315"
    src="https://www.youtube.com/embed/9UWhZ1s3Ybc"
    title="YouTube video player"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowfullscreen>
</iframe></p>
</div>
<p>Tentei tratar o assunto de forma mais leve poss√≠vel, recheada de memes e linguagem acess√≠vel, espero que gostem do conte√∫do!</p>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-05-24-ciencia-de-dados-uma-visao-geral/">Ci√™ncia de Dados - Uma vis√£o geral</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">big-data</category>
      <category domain="tag">carreira</category>
      <category domain="tag">data-science</category>
      <category domain="tag">estatistica</category>
      <category domain="tag">machine-learning</category>
    </item>
  </channel>
</rss>