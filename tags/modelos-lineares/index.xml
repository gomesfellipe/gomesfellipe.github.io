&lt;?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>modelos lineares on Fellipe Gomes - Data Science Blog</title>
    <link>https://gomesfellipe.github.io/tags/modelos-lineares/</link>
    <description>Últimos posts sobre Data Science, Machine Learning e R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <managingEditor>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</managingEditor>
    <webMaster>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</webMaster>
    <lastBuildDate>Sat, 28 Jul 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://gomesfellipe.github.io/tags/modelos-lineares/" rel="self" type="application/rss+xml" />
    <item>
      <title>modelo bayesiano do zero</title>
      <link>https://gomesfellipe.github.io/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero/</guid>
      <description>Um pouco sobre as duas grandes escolas de inferência, contas e implementação de um modelo linear bayesiano na mão para dados simulados e para dados reais</description>
      <content:encoded>&lt;![CDATA[
        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/plotly-binding/plotly.js"></script>
<script src="/rmarkdown-libs/typedarray/typedarray.min.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>
<link href="/rmarkdown-libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="/rmarkdown-libs/plotly-main/plotly-latest.min.js"></script>


<div id="modelagem-estatística-e-as-duas-grandes-escolas-de-inferência" class="section level1">
<h1>Modelagem estatística e as duas grandes escolas de inferência</h1>
<p>Através da modelagem estatística é possível tomar decisões sobre diversos assuntos de interesse como por exemplo na análise de risco de crédito, previsões de quantidade de chuva em um dado local, estimativas de erros ou falhas de um novo produto ou serviço além de diversas áreas como na Educação, Economia, nas Ciências Sociais, Saúde etc.</p>
<p>Muitas vezes os parâmetros das distribuições em estudo podem ser desconhecidos e existe o desejo de se inferir sobre eles. Existem duas grandes escolas de inferência: a clássica e a bayesiana. A clássica trata esses parâmetros como quantidades fixas e não atribui distribuição a eles, a estimação desses parâmetros é dada através da função de verossimilhança, enquanto que na escola bayesiana atribui-se uma distribuição, chamada de distribuição a priori, ao conjunto de parâmetros desconhecidos quantificando a sua crença sobre esse conjunto e a estimação dos parâmetros é dada através da distribuição à posteriori, que é proporcional ao produto da função de verossimilhança com a distribuição a priori.</p>
<p>O interesse pela modelagem estatística através da abordagem bayesiana surgiu a partir de um projeto de iniciação científica quando cursava o 6º período do curso de Graduação em Estatística que tinha como objetivo o cálculo e apresentação de estatísticas descritivas para ajudar uma pesquisadora. Após obter os resultados da análise exploratória e descritiva, notei, junto com meu orientador, que havia possibilidade de dar continuidade ao estudo a partir de uma abordagem estatística mais elaborada. Sendo assim, outro projeto de iniciação científica foi iniciado em seguida com a finalidade de me preparar para utilizar um modelo linear hierárquico bayesiano sob os dados disponibilizados pela pesquisadora em minha monografia.</p>
<p>Caso tenha interesse em conferir o projeto com o estudo sobre modelos hierárquicos bayesianos, disponibilizei os resultados e os códigos em meu github <a href="https://github.com/gomesfellipe/projeto_modelos_hierarquicos_bayesianos">neste repositório</a>. Neste post farei uma breve introdução sobre o ajuste de um modelo linear bayesiano simples e os resultados obtidos (utilizando uma distribuição a priori não informativa). Os resultados obtidos serão comparados com os resultados obtidos com o ajuste de um modelo de regressão linear através da abordagem clássica.</p>
<div id="distribuição-a-priori" class="section level2">
<h2>Distribuição a priori</h2>
<p>Para o estudo, optou-se pela utilização de valores elevados para variância a priori (também consideradas como “não informativas”, fazendo uma analogia à modelos clássicos) obtendo ajustes que atribuem maior importância à informação provinda da amostra.</p>
<p>Portanto com valores elevados para variância da distribuição a priori (consideradas como “não informativas”) foram obtida a distribuição a posteriori de um parâmetro <span class="math inline">\(\theta\)</span> que contém toda a informação probabilística a respeito deste parâmetro e quando a forma analítica dessa distribuição é conhecida o gráfico da <a href="https://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_densidade">fdp</a> pode ilustrar o comportamento probabilístico do parâmetro de interesse e auxiliar em alguma tomada de decisão, porém, quando a forma analítica não é conhecida ou é muito custosa de ser obtida, pode-se recorrer a métodos de simulação tais como os métodos MCMC.</p>
</div>
<div id="amostrador-de-gibbs---método-mcmc" class="section level2">
<h2>Amostrador de Gibbs - método MCMC</h2>
<p>Com os avanços dos métodos de MCMC, surgiu o amostrador de Gibbs, proposto por <span class="citation">@GemanGeman</span> e tornou-se popular por <span class="citation">@GelfandSmith</span>, falo um pouco mais sobre o algoritmo no <a href="https://github.com/gomesfellipe/projeto_modelos_hierarquicos_bayesianos/blob/master/texto.pdf">texto do projeto</a>.</p>
<p>Como a convergência ocorre após o aquecimento (ou burn-in), é comum usar os valores de <span class="math inline">\(\theta^{(a)}\)</span>, <span class="math inline">\(\theta^{(a+t)}\)</span>, <span class="math inline">\(\theta^{(a+2t)}\)</span>,… para compor a amostra de <span class="math inline">\(\theta\)</span>, sendo <span class="math inline">\(a-1\)</span> o número de iterações iniciais do aquecimento e <span class="math inline">\(t\)</span> o espaçamento utilizado para diminuir a autocorrelação dos parâmetros. Maiores detalhes podem ser vistos em <span class="citation">@Gamerman06</span>.</p>
</div>
</div>
<div id="ao-que-interessa" class="section level1">
<h1>Ao que interessa</h1>
<p>O objetivo deste post é apresentar e comparar os resultados do ajuste de um modelo linear bayesiano simples utilizando uma distribuição a priori não informativa com o modelo de regressão linear simples para dados simulados e para dados reais.</p>
<p>Diversas funções foram criadas ao longo o estudo para conferir o comportamento das cadeias geradas e os resultados do ajuste do modelo, aproveitarei essas funções para este post importando do <a href="https://github.com/gomesfellipe/projeto_modelos_hierarquicos_bayesianos/blob/master/dependencies.R">repositório no github</a> da seguinte maneira:</p>
<pre class="r"><code>path_to_dep &lt;- &quot;https://raw.githubusercontent.com/gomesfellipe/projeto_modelos_hierarquicos_bayesianos/master/dependencies.R&quot;
devtools::source_url(path_to_dep, encoding=&quot;UTF-8&quot;)</code></pre>
</div>
<div id="ajuste-do-modelo-para-dados-simulados" class="section level1">
<h1>Ajuste do modelo para dados simulados</h1>
<p>Suponha então um exemplo em que a população de interesse tenha distribuição normal com média <span class="math inline">\(\beta_0 + \beta_1 X\)</span>, sendo <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> desconhecidos e variância <span class="math inline">\(\sigma^2\)</span> desconhecida. Seja <span class="math inline">\(\tau=\frac{1}{\sigma^2}\)</span> o parâmetro chamado de precisão.</p>
<p>O parâmetro <span class="math inline">\(\beta_0\)</span> é conhecido como intercepto ou coeficiente linear e o <span class="math inline">\(\beta_1\)</span> como coeficiente angular. Além disso, suponha que as unidades dessa população sejam iid. Dessa forma, tem-se que as unidades dessa população tem a seguinte distribuição:</p>
<p><span class="math display">\[
Y_i \stackrel{iid}{\sim} N(\beta_0 + \beta_1 X_i,\frac{1}{\tau}), 
\]</span></p>
<p>onde <span class="math inline">\(i=1,...,N\)</span>.</p>
<p>Para o estudo do modelo primeiramente foi utilizado um conjunto de dados simulados utilizando uma amostra de tamanho <span class="math inline">\(N=1000\)</span> e com os seguintes parâmetros “desconhecidos” dos quais desejamos estimar: <span class="math inline">\(\beta_0 = 1\)</span>, <span class="math inline">\(\beta_1 = 0,5\)</span>, <span class="math inline">\(\tau = 2\)</span>. A amostra será simulada segundo a variável aleatória: <span class="math inline">\(X_i ~ N(0,1)\)</span> e em seguida os parâmetros deste modelo, denotados por <span class="math inline">\(\theta = (\beta_0, \beta_1, \tau)\)</span> foram estimados usando o paradigma Bayesiano.</p>
<div id="gerando-a-amostra" class="section level2">
<h2>Gerando a amostra</h2>
<p>A amostra que foi simulada foi obtida da seguinte maneira:</p>
<pre class="r"><code># Amostra que sera utilizada:

set.seed(12)
n   &lt;- 1000                 # N=1000
b0  &lt;- 1                    # \beta_0 = 1
b1  &lt;- 0.5                  # \beta_1 = 0,5
tau &lt;- 2                    # \tau = 2 e 
x   &lt;- rnorm(n)             # X_i ~ N(0,1), logo:
y   &lt;- b0 + b1 * x + rnorm(n,0,sqrt(1/tau))</code></pre>
<p>Obtendo-se uma amostra de tamanho <span class="math inline">\(n\)</span>, pode-se inferir sob os parâmetros desconhecidos <span class="math inline">\(\theta = (\beta_0, \beta_1, \tau)\)</span> através da distribuição a posteriori e para obter essa distribuição faz-se necessário calcular a função de verossimilhança, que pode ser obtida da seguinte forma:</p>
<p><span class="math display">\[
p(y| \beta_0, \beta_1 , \tau) =\prod^n_{i=1} p(y_i | \beta_0, \beta_1, \tau )  
\]</span></p>
<p>portanto</p>
<p><span class="math display">\[
p(y| \beta_0, \beta_1 , \tau) = \prod_{i=1}^n \frac{ \sqrt{\tau} }{ \sqrt{2\pi} } exp { - \frac{\tau}{2} ( y_i - \beta_0 - \beta_1 x_i )^2 }
\]</span></p>
<p>onde <span class="math inline">\(y = (y_1, ..., y_n)\)</span> é a amostra coletada. O valor p para o teste de Shapiro para conferir a suposição de normalidade da variável resposta foi de 0.6181791 enquanto que o valor p para conferir a normalidade da variável explicativa foi de 0.7413229.</p>
</div>
<div id="distribuição-a-priori-1" class="section level2">
<h2>Distribuição a priori</h2>
<p>Durante o estudo diversos valores os parâmetros a priori foram selecionados para que fosse possível avaliar a sensibilidade da qualidade da escolha da distribuição priori, aqui será apresentado os resultados obtidos com valores elevados para variância a priori (também consideradas como “não informativas”, fazendo uma analogia à modelos clássicos) que ajusta o modelo atribuindo maior importância à informação provinda da amostra.</p>
<p>Considere a priori que os parâmetros sejam independentes e que</p>
<p><span class="math display">\[
\beta_0 \sim N(m_0,\sigma_0^2),  \\
\beta_1 \sim N(m_1,\sigma_1^2) \mbox{ e }  \\
\tau    \sim G(a,b).
\]</span></p>
<p>Portanto, para a estimação foram utilizados os seguintes hiperparâmetros : <span class="math inline">\(m_0 = m_1 = 0\)</span>, <span class="math inline">\(\sigma_0^2 = \sigma_1^2 = 100\)</span>, <span class="math inline">\(a=0,1\)</span> e <span class="math inline">\(b=0,1\)</span></p>
<p>No R:</p>
<pre class="r"><code>#Parametros para b0 ~ N(mu0, sig0)
mu0 &lt;-  0
sig0 &lt;-  1000

#Parametros para b1 ~ N(mu1, sig1)
mu1 &lt;-  0
sig1 &lt;-  1000

#Parametros para tau ~ G(a,b)
a &lt;-  0.1
b &lt;-  0.1</code></pre>
<p>Dessa forma, tem-se que a distribuição conjunta a priori possui a seguinte forma:</p>
<p><span class="math display">\[
 p(\beta_0, \beta_1 , \tau) \propto exp\Big\{-\frac{1}{2\sigma_0^2}( \beta_0 - m_0)^2\Big\} exp\Big\{-\frac{1}{2\sigma_1^2}( \beta_1 - m_1)^2\Big\} \tau^{a-1}exp \{-b \tau\}.
\]</span></p>
</div>
<div id="distribuição-a-posteriori" class="section level2">
<h2>Distribuição a posteriori</h2>
<p>Combinando a função de verossimilhança com a distribuição a priori, obtêm-se a distribuição a posteriori que é proporcional a:</p>
<p><span class="math display">\[
p(\beta_0, \beta_1 , \tau|y) \propto \tau^{\frac{n}{2}+a-1} exp \left\{ -\frac{\tau}{2} \sum^n_{i=1} (y_i - \beta_0 - \beta_1 x_i)^2 - b\tau  - \frac{1}{2\sigma_0^2}(\beta_0-m_0)^2  \right\} \times   exp\left\{- \frac{1}{2\sigma_1^2}(\beta_1-m_1)^2  \right\} . 
\]</span></p>
<p>Note que essa distribuição é multivariada e não possui forma analítica conhecida. Sendo assim, recorre-se aos métodos de MCMC para se obter amostras dessa distribuição. E então faz-se necessário obter as DCCP de <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> e <span class="math inline">\(\tau\)</span>.</p>
</div>
<div id="implementando-o-amostrador-de-gibbs" class="section level2">
<h2>Implementando o amostrador de Gibbs</h2>
<p>O tamanho da cadeia foi de 30000 simulações e o <em>burn-in</em> (ou amostra de aquecimento) utilizado considerada após o ajuste foi de 15000. no R:</p>
<pre class="r"><code>nsim           &lt;-  3*10000
burnin         &lt;-  nsim / 2 
cadeia.b0      &lt;-  rep(0,nsim)
cadeia.b1      &lt;-  rep(0,nsim)
cadeia.tau     &lt;-  rep(0,nsim)

# Chutes iniciais: 
cadeia.b0[1]    &lt;-  0
cadeia.b1[1]    &lt;-  0
cadeia.tau[1]   &lt;-  1</code></pre>
<div id="calculos-para-implementar-o-algoritimo-na-mão" class="section level3">
<h3>Calculos para implementar o algoritimo na mão</h3>
<p>Para a implementação do algoritmo, fez-se necessário o cálculo das distribuições condicionais completas a posteriori (DCCP), primeiramente veja os resultados obtidos para <span class="math inline">\(\tau\)</span>:</p>
<ul>
<li>DCCP de <span class="math inline">\(\tau\)</span>:</li>
</ul>
<p><span class="math display">\[
\tau|y_1, ...,y_n,\beta_0, \beta_1 \sim Gama ( \frac{n}{2}+a,b+\frac{1}{2} \sum^n_{i=1}(y_i-\beta_0-\beta_1 x_i)^2 ) 
\]</span></p>
<p>Em seguida, veja o resultado obtido para <span class="math inline">\(\beta_0\)</span>, o coeficiente linear da reta, isto é, a altura em que a reta de regressão intercepta o eixo dos <span class="math inline">\(Y\)</span>’s:</p>
<ul>
<li>DCCP de <span class="math inline">\(\beta_0\)</span>:</li>
</ul>
<p><span class="math display">\[
\beta_0 | y_1,...,y_n , \tau,\beta_1 \sim N(\dfrac{(\tau\sum^n_{i=1}y_i - \tau\beta_1\sum^n_{i=1}x_i  +\frac{m_0}{\sigma_0^2})}{ \tau n + \frac{1}{\sigma_0^2}},  (n\tau +   \frac{1}{\sigma_0^2} )^{-1})
\]</span></p>
<p>Por fim, veja o resultado obtido para <span class="math inline">\(\beta_1\)</span>, é o coeficiente angular da reta, ou seja, é o a variação esperada na variável <span class="math inline">\(Y\)</span> quando a variável explicativa é acrescida de 1 unidade:</p>
<ul>
<li>DCCP de <span class="math inline">\(\beta_1\)</span>:</li>
</ul>
<p><span class="math display">\[
\beta_1 | y_1,...,y_n , \tau,\beta_0 \sim N(\frac{\tau\sum^n_{i=1}x_i y_i  - \tau\beta_0\sum^n_{i=1}x_i + \frac{m_1}{\sigma_1^2}}{\tau \sum^n_{i=1}x_i^2 + \frac{1}{\sigma_1^2}}, ( \tau \sum^n_{i=1}x_i^2 + \frac{1}{\sigma_1^2} )^{-1})
\]</span></p>
<p>Agora que todas as distribuições condicionais completas estão calculadas o algorítimo já pode ser implementado, no R foi feito da seguinte maneira: (note que as linhas que foram comentadas executariam uma barra de carregamento, com ilustrado em seguida)</p>
<pre class="r"><code># pb &lt;- txtProgressBar(min = 0, max = nsim, style = 3) # iniciando barra de processo
for (k in 2:nsim){
  
  #Cadeia tau
  cadeia.tau[k]   &lt;-  rgamma(1, (n/2) + a, b + (sum((y - cadeia.b0[k-1] - (cadeia.b1[k-1]*x))^2)/2))
  
  # Cadeia B0
  c0              &lt;-  (n*cadeia.tau[k]) + (1/sig0)
  m0              &lt;-  (cadeia.tau[k]*sum(y) - (cadeia.tau[k]*cadeia.b1[k-1]*sum(x)) + (mu0/sig0))/c0
  cadeia.b0[k]    &lt;-  rnorm(1, m0, 1/sqrt(c0))
  
  # Cadeia B1
  c1              &lt;-   (sum(x^2)*cadeia.tau[k]) + (1/sig1)
  m1              &lt;-   ((cadeia.tau[k]*sum(x*y)) - (cadeia.tau[k]*cadeia.b0[k]*sum(x)) + (mu1/sig1))/c1
  cadeia.b1[k]    &lt;-   rnorm(1, m1, 1/sqrt(c1))
  
  # setTxtProgressBar(pb, k)
  
}# ;close(pb) #Encerrando barra de processo</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/loading.png" /></p>
</div>
<div id="resultados-da-cadeia" class="section level3">
<h3>Resultados da cadeia</h3>
<p>A seguir definiremos a variável <code>inds</code> que indica os valores após a amostra de aquecimento (ou <em>burn-in</em>), a variável <code>real</code> que contém os valores reais utilizados para gerar a amostra para conferir se o modelo foi capaz de recuperá-los, os nomes dos parâmetros e os resultados das cadeias foram agregados em uma matriz:</p>
<pre class="r"><code># Juntando resultados:
inds    &lt;- seq(burnin, nsim) # Definindo os indices
real    &lt;- c(b0, b1, tau)
name    &lt;- c(expression(beta[0]), expression(beta[1]), expression(tau))
results &lt;- cbind(cadeia.b0, cadeia.b1, cadeia.tau) %&gt;% as.data.frame() %&gt;% .[inds, ] %T&gt;% head</code></pre>
<div id="histograma-e-densidade" class="section level4">
<h4>Histograma e densidade</h4>
<p>A figura abaixo apresenta os histogramas junto com as densidades de três cadeias obtidas ao se inicializar o amostrador em pontos diferentes de todos os parâmetros contidos em <span class="math inline">\(\theta\)</span> e uma linha vermelha indicará o valor do real parâmetro utilizado para estimar a cadeia.</p>
<pre class="r"><code>g1 &lt;- hist_den(results[,1],name = name[1], p = real[1])
g2 &lt;- hist_den(results[,2],name = name[2], p = real[2])
g3 &lt;- hist_den(results[,3],name = name[3], p = real[3])
grid.arrange(g1,g2,g3,ncol=1)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="cadeia" class="section level4">
<h4>Cadeia</h4>
<p>A figura abaixo apresenta os traços das cadeias dos parâmetros amostrados exibindo o intervalo de credibilidade com a linha pontilhada em azul e o valor verdadeiro do parâmetro em vermelho. Note que há indícios de convergência.</p>
<pre class="r"><code># Cadeia
cadeia(results, name, real)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>é possível notar que todos os intervalos de credibilidade contêm o parâmetro populacional real utilizado para gerar a amostra.</p>
</div>
<div id="autocorrelação" class="section level4">
<h4>Autocorrelação</h4>
<p>A figura abaixo apresenta os gráficos de autocorrelação, que indicam se houve a influência dos “valores vizinhos” dos parâmetros amostrados. Note que parece haver independência entre as interações.</p>
<pre class="r"><code># ACF
FAC(results)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>é possível notar que nenhuma das cadeias apresentaram estimativas autocorrelacionada</p>
</div>
<div id="estimativas" class="section level4">
<h4>Estimativas</h4>
<p>Agora que já foi verificado que a cadeia se comportou de maneira satisfatória, veja os resultados obtidos sobre as estimativas dos parâmetros através do algoritmo. apresenta os resumos a posteriori dos parâmetros amostrados.</p>
<pre class="r"><code>coef &lt;- coeficientes(results, real = real) %&gt;% as.data.frame()

tabela_coeficientes(coef)</code></pre>
<div id="htmlwidget-1" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"visdat":{"11b9832b6bfa0":["function () ","plotlyVisDat"]},"cur_data":"11b9832b6bfa0","attrs":{"11b9832b6bfa0":{"columnorder":[1,2,3,4,5],"columnwidth":[80,80,80,80,80],"header":{"values":["Média","Desv. Pad.","IC inf","IC sup","Real"],"line":{"color":"#506784"},"fill":{"color":"#1F8FFFB4"},"align":["center","center","center","center","center"],"font":{"color":"white","size":15},"height":40},"cells":{"values":[[1.0244,0.4933,1.9001],[0.023,0.0241,0.085],[0.9792,0.4464,1.7371],[1.0697,0.5409,2.0695],[1,0.5,2]],"line":{"color":"#506784"},"fill":{"color":["#1F8FFF58","white","white","white","#1F8FFF58"]},"align":["center","center","center","center","center"],"font":{"color":["white","#506784","#506784","#506784","white"],"size":12},"height":30},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"table"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"hovermode":"closest","showlegend":false},"source":"A","config":{"showSendToCloud":false},"data":[{"columnorder":[1,2,3,4,5],"columnwidth":[80,80,80,80,80],"header":{"values":["Média","Desv. Pad.","IC inf","IC sup","Real"],"line":{"color":"#506784"},"fill":{"color":"#1F8FFFB4"},"align":["center","center","center","center","center"],"font":{"color":"white","size":15},"height":40},"cells":{"values":[[1.0244,0.4933,1.9001],[0.023,0.0241,0.085],[0.9792,0.4464,1.7371],[1.0697,0.5409,2.0695],[1,0.5,2]],"line":{"color":"#506784"},"fill":{"color":["#1F8FFF58","white","white","white","#1F8FFF58"]},"align":["center","center","center","center","center"],"font":{"color":["white","#506784","#506784","#506784","white"],"size":12},"height":30},"type":"table","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Como se trata de uma amostra simulada é possível comparar as estimativas com os valores reais que geraram a amostra e os valores estão muito próximos da média (todos eles estão incluídos no intervalo de credibilidade).</p>
</div>
</div>
<div id="comparando-com-o-modelo-linear-clássico" class="section level3">
<h3>Comparando com o modelo linear clássico</h3>
<p>Agora que os resultados sob o paradigma bayesiano já foram conferidos será ajustado um modelo de regressão linear simples pelo método dos mínimos quadrados através da função <code>lm()</code> sob o paradigma clássico para comparar com os resultados de um modelo de regressão linear simples sob o paradigma bayesiano utilizando os resultados calculados.</p>
<pre class="r"><code># Reta do modelo classico
plot(x, y)
modelo.classico &lt;- lm(y ~ 1 + x)
a.classico      &lt;- modelo.classico$coefficients[1]
b.classico      &lt;- modelo.classico$coefficients[2]
abline(a        &lt;- a.classico, b = b.classico, col = &quot;blue&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>O modelo estimado para estes dados sob o paradigma da inferência clássica foi o seguinte: <span class="math inline">\(\hat{y} = 1.0245 x + 0,4933\)</span>, o que mostra que as estimativas de <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> foram muito parecidas com as estimativas sob o paradigma da inferência bayesiana.</p>
<pre class="r"><code># Reta do modelo bayesiano
plot(x, y)
a.bayes  &lt;-  mean(results[, 1])
b.bayes  &lt;-  mean(results[, 2])
abline(a = a.bayes, b = b.bayes, col = &quot;red&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>A figura apresenta o gráfico de dispersão entre as variáveis da amostra simulada e as retas dos ajustes de ambos os modelos:</p>
<pre class="r"><code>library(stringr)
library(ggplot2)
library(ggExtra)

# Texto da imagem
text.classico &lt;- str_c(&quot;Modelo Classico: &quot;,&quot;y = &quot;,round(a.classico,4),&quot; x + &quot;,round(b.classico,4))
text.bayes    &lt;- str_c(&quot;Modelo Bayesiano: &quot;,&quot;y = &quot;,round(a.bayes,4),&quot; x + &quot;,round(b.bayes,4))

# Gerando o e ambos:
cbind(y, x) %&gt;%
  as.data.frame %&gt;%
    ggplot(aes(y = y, x = x)) +
    geom_point() +
    geom_smooth(method = &quot;lm&quot;, se = F, col = &quot;red&quot;) +
    theme_classic() +
    geom_abline(slope = b.bayes,
    intercept = a.bayes,
    col = &quot;blue&quot;) +
    labs(title = &quot;&quot;,
    x = &quot;Covariável&quot;,
    y = &quot;Reposta&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Agora que os resultados no algoritmo já foram conferidos e avaliados de maneira satisfatória utilizando os dados simulados, é a vez de fazer o ajuste para dados reais.</p>
</div>
</div>
</div>
<div id="ajuste-do-modelo-para-dados-reais" class="section level1">
<h1>Ajuste do modelo para dados reais</h1>
<p>O conjunto de dados que será utilizado como exemplo foi disponibilizado por <span class="citation">@Ezekiel_cars</span> e hoje faz parte do conjunto de banco de dados nativos do R (a base de dados pode ser obtida ao escrever <code>cars</code> no console). Os dados informam a velocidade dos carros e as distâncias tomadas para parar, esses dados foram registrados na década de 1920 e são de grande utilidade didática até os dias de hoje.</p>
<p>Considere que deseja-se modelar a velocidade dos carros de acordo com as distâncias tomadas para parar, portanto a variável resposta será a velocidade e a variável explicativa do modelo será a distância tomada para parar.</p>
<div id="amostra-utilizada" class="section level2">
<h2>Amostra utilizada</h2>
<pre class="r"><code>y    &lt;-  cars$speed
x    &lt;-  cars$dist
n    &lt;-  nrow(cars)</code></pre>
<p>o valor p para o teste de Shapiro para conferir a suposição de normalidade da variável resposta foi de 0.4576319 enquanto que o valor p para conferir a normalidade da variável explicativa foi de 0.0390997</p>
</div>
<div id="distribuição-a-priori-2" class="section level2">
<h2>Distribuição a priori</h2>
<p>Serão utilizados os mesmos valores que foram propostos na simulação como hiperparametros e chutes iniciais para a cadeia, o código usado foi exatamente o mesmo.</p>
</div>
<div id="resultados-da-cadeia-1" class="section level2">
<h2>Resultados da cadeia</h2>
<p>Definiremos novamente a variável <code>inds</code> que indica os valores após a amostra de aquecimento (ou <em>burn-in</em>), desta vez não haverá a variável <code>real</code> pois não conhecemos os valores reais utilizados para gerar a amostra para conferir se o modelo foi capaz de recuperá-los. Desta vez utilizaremos a variável <code>classico</code>, que guarda os valores obtidos com o ajuste do modelo linear pela abordagem clássica.</p>
<pre class="r"><code># Juntando resultados:
inds     &lt;- seq(burnin, nsim) # Definindo os indices
results  &lt;- cbind(cadeia.b0, cadeia.b1, cadeia.tau) %&gt;% as.data.frame() %&gt;% .[inds, ]
classico &lt;- c(coefficients(lm(cars)), 1 / var(lm(cars)$residuals))
name     &lt;- c(expression(beta[0]), expression(beta[1]), expression(tau))</code></pre>
<div id="histograma-e-densidade-1" class="section level4">
<h4>Histograma e densidade</h4>
<p>A figura abaixo exibe os histogramas com as densidades de três cadeias obtidas ao se iniciar o amostrador em pontos diferentes de todos os parâmetros <span class="math inline">\(\theta\)</span> mas dessa vez sem a linha vermelha que indicava o valor do parâmetro real pois agora ele é desconhecido.</p>
<pre class="r"><code>g1 &lt;- hist_den(results[, 1], name = name[1])
g2 &lt;- hist_den(results[, 2], name = name[2])
g3 &lt;- hist_den(results[, 3], name = name[3])
grid.arrange(g1, g2, g3, ncol = 1)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Nota-se que ambas as cadeias convergiram uma mesma distribuição e que as últimas três cadeias apresentaram valores próximos.</p>
</div>
<div id="cadeias" class="section level4">
<h4>Cadeias</h4>
<p>A figura abaixo apresenta os traços das cadeias dos parâmetros amostrados. Note que há indícios de convergência.</p>
<pre class="r"><code>cadeia(results,name)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
</div>
<div id="autocorrelação-1" class="section level4">
<h4>Autocorrelação</h4>
<p>A Figura abaixo apresenta os gráficos de autocorrelação dos parâmetros amostrados.</p>
<pre class="r"><code>FAC(results)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>É possível notar que apenas nas primeiras defasagens das cadeias das estimativas para os parâmetros <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> se apresentaram de forma autocorrelacionada e que a partir dessa defasagem o gráfico de autocorrelação se apresentou de forma desejável.</p>
</div>
<div id="estimativas-1" class="section level4">
<h4>Estimativas</h4>
<p>Como todas as características da cadeia gerada foram avaliadas de maneira satisfatória agora será possível conferir o ajuste dos parâmetros de maneira mais segura pois já foi constatada a convergência da cadeia</p>
</div>
<div id="comparando-com-o-modelo-linear-clássico-1" class="section level4">
<h4>Comparando com o modelo linear clássico</h4>
<p>Agora que os resultados sob o paradigma bayesiano já foram conferidos novamente será ajustado um modelo de regressão linear simples pelo método dos mínimos quadrados sob o paradigma clássico para comparar com os resultados do um modelo de regressão linear simples sob o paradigma bayesiano utilizando os resultados calculados na seção.</p>
<pre class="r"><code># Reta do modelo classico 
plot(x, y)
modelo.classico &lt;- lm(y ~ 1 + x)
a.classico      &lt;- modelo.classico$coefficients[1]
b.classico      &lt;- modelo.classico$coefficients[2]
abline(a        &lt;- a.classico, b = b.classico, col = &quot;blue&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code># Reta do modelo bayesiano
plot(x, y)
a.bayes &lt;- mean(results[, 1])
b.bayes &lt;- mean(results[, 2])
abline(a = a.bayes, b = b.bayes, col = &quot;red&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>A Tabela abaixo apresenta o resumo a posteriori dos parâmetros estimados da cadeia e note que esta tabela não conta com a coluna dos valores reais como no exemplo anterior e sim as estimativas sob o paradigma clássico.</p>
<pre class="r"><code>coef &lt;- 
  coeficientes(results,real = classico) %&gt;% as.data.frame()

tabela_coeficientes(coef)</code></pre>
<div id="htmlwidget-2" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"visdat":{"11b981cae4251":["function () ","plotlyVisDat"]},"cur_data":"11b981cae4251","attrs":{"11b981cae4251":{"columnorder":[1,2,3,4,5],"columnwidth":[80,80,80,80,80],"header":{"values":["Média","Desv. Pad.","IC inf","IC sup","Real"],"line":{"color":"#506784"},"fill":{"color":"#1F8FFFB4"},"align":["center","center","center","center","center"],"font":{"color":"white","size":15},"height":40},"cells":{"values":[[8.2374,0.1663,0.1083],[0.8481,0.017,0.0214],[6.5848,0.1326,0.0699],[9.9239,0.1997,0.1542],[8.2839,0.1656,0.1025]],"line":{"color":"#506784"},"fill":{"color":["#1F8FFF58","white","white","white","#1F8FFF58"]},"align":["center","center","center","center","center"],"font":{"color":["white","#506784","#506784","#506784","white"],"size":12},"height":30},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"table"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"hovermode":"closest","showlegend":false},"source":"A","config":{"showSendToCloud":false},"data":[{"columnorder":[1,2,3,4,5],"columnwidth":[80,80,80,80,80],"header":{"values":["Média","Desv. Pad.","IC inf","IC sup","Real"],"line":{"color":"#506784"},"fill":{"color":"#1F8FFFB4"},"align":["center","center","center","center","center"],"font":{"color":"white","size":15},"height":40},"cells":{"values":[[8.2374,0.1663,0.1083],[0.8481,0.017,0.0214],[6.5848,0.1326,0.0699],[9.9239,0.1997,0.1542],[8.2839,0.1656,0.1025]],"line":{"color":"#506784"},"fill":{"color":["#1F8FFF58","white","white","white","#1F8FFF58"]},"align":["center","center","center","center","center"],"font":{"color":["white","#506784","#506784","#506784","white"],"size":12},"height":30},"type":"table","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>O modelo estimado sob este paradigma pode ser escrito da seguinte maneira: <span class="math inline">\(\hat{y} = 8,2839 x + 0,1656\)</span>, ou seja, os valores de <span class="math inline">\(\beta_0\)</span> e de <span class="math inline">\(\beta_1\)</span> novamente foram muito próximos dos parâmetros obtidos ao estimar sob o paradigma clássico.</p>
</div>
<div id="comparando-de-forma-visual" class="section level4">
<h4>Comparando de forma visual</h4>
<p>A Figura ilustra o gráfico de dispersão dos dados citados acima, com a intenção de exibir quanto uma variável é afetada por outra, onde no eixo vertical representa a velocidade do carro e no eixo horizontal a distância tomada para parar.</p>
<p>Além do comportamento das variáveis, neste gráfico é exibido também os resultados obtidos do ajuste ao se utilizar o método de mínimos quadrados (representada pela linha em vermelho) para estimar os parâmetros e o ajuste do modelo ao se utilizar o método apresentado acima em (representada pela linha azul).</p>
<pre class="r"><code># Texto da imagem
text.classico &lt;- str_c(&quot;Modelo Classico: &quot;,&quot;y = &quot;,round(a.classico,4),&quot; x + &quot;,round(b.classico,4))
text.bayes    &lt;- str_c(&quot;Modelo Bayesiano: &quot;,&quot;y = &quot;,round(a.bayes,4),&quot; x + &quot;,round(b.bayes,4))

#Gerando o scatter.plot
cbind(y, x) %&gt;%
  as.data.frame %&gt;%
  ggplot(aes(y = y, x = x)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, se = F, col = &quot;red&quot;) +
  theme_classic() +
  geom_abline(slope = b.bayes,
              intercept = a.bayes,
              col = &quot;blue&quot;) +
  labs(title = &quot;Relação entre a Distância e a Velocidade com \nreta do modelo linear clássico vs bayesiano&quot;,
       x = &quot;Distância&quot;,
       y = &quot;Velocidade&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>É possível notar que os coeficientes calculados foram muito parecidos, mesmo apresentando pequenas diferenças decimais no valor dos coeficientes ainda é possível notar que as retas estão basicamente sobrepostas, ou seja, os valores estimados em ambas as abordagens foram praticamente os mesmos.</p>
<p>Apesar dos valores dos ajustes terem apresentado basicamente os mesmo resultados, a maneira de se conferir a qualidade do ajuste é diferente em ambas as abordagens. Enquanto sob o paradigma clássico o ajuste do modelo pode ser checado ao avaliar os pre-supostos quanto à distribuição dos resíduos, como recomenda <span class="citation">@GaussClarice</span>, ao utilizar um método de MCMC faz-se necessário conferir também outros aspectos como por exemplo se houve convergência da cadeias além do comportamento das autocorrelações, vide <span class="citation">@migon</span>.</p>
</div>
</div>
</div>
<div id="conclusão" class="section level1">
<h1>Conclusão</h1>
<p>O uso do algorítmo para simular os dados da implementação do modelo hierárquico bayesiano envolveu diversas etapas. Inicialmente foi necessária a revisão de literatura para a compreensão dos métodos que seriam utilizados na implementação do algoritmo, bem como em seu desenvolvimento. Essa pesquisa funcionou de maneira muito didática, de forma que a cada semana a abordagem pudesse envolver maior grau de complexidade.</p>
<p>Durante o estudo, diversos valores de parâmetros a priori foram selecionados para que fosse possível avaliar a sensibilidade da qualidade da escolha da distribuição a priori. Observou-se que valores elevados para variância a priori (também consideradas como “não informativas” - fazendo uma analogia à modelos clássicos) obtiveram melhores ajustes atribuindo maior importância à informação provinda da amostra.</p>
<p>O estudo com dados simulados facilitou o entendimento do algoritmo pois foi possível notar com facilidade a inadequabilidade das escolhas das prioris, que resultavam em estimativas muito distante do parâmetro populacional que gerou a amostra.</p>
</div>
<div id="referências" class="section level1">
<h1>Referências</h1>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero/">modelo bayesiano do zero</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Aprendizado Não Supervisionado</category>
      <category>Bayes</category>
      <category>Inferência Bayesiana</category>
      <category>Estatistica</category>
      <category>Modelagem Estatistica</category>
      <category>Probabilidade</category>
      <category>R</category>
      <category>Simulação</category>
      <category>Teoria</category>
      <category domain="tag">bayes</category>
      <category domain="tag">Estatistica</category>
      <category domain="tag">gomesfellipe</category>
      <category domain="tag">jags</category>
      <category domain="tag">modelagem</category>
      <category domain="tag">modelagem estatistica</category>
      <category domain="tag">modelos generalizados</category>
      <category domain="tag">modelos lineares</category>
      <category domain="tag">probabilidade</category>
      <category domain="tag">R</category>
      <category domain="tag">regression</category>
      <category domain="tag">Teoria</category>
    </item>
    <item>
      <title>Pacotes do R para avaliar o ajuste de modelos</title>
      <link>https://gomesfellipe.github.io/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos/</link>
      <pubDate>Sun, 24 Dec 2017 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos/</guid>
      <description>Alguns pacotes úteis para avaliar o ajuste do modelo de forma rápida, precisa e elegante</description>
      <content:encoded>&lt;![CDATA[
        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="funções-do-r-para-avaliar-o-ajuste-de-modelos" class="section level1">
<h1>Funções do R para avaliar o ajuste de modelos</h1>
<p>Traduzindo:</p>
<p>“<em>Essencialmente, todos os modelos estão errados, mas alguns são úteis</em>” - George E. P. Box</p>
<p>Se você estuda estatística provavelmente já deve saber quem é este simpático senhor. Box teve grande contribuição para a estatística. Foi aluno do Ronald Aylmer Fisher e ainda se casou com a filha dele!</p>
<p>Lendo um <a href="http://jaguar.fcav.unesp.br/RME/fasciculos/v27/v27_n4/A10_Millor.pdf">artigo sobre a vida de Fisher</a> um parágrafo me chamou atenção com uma fala de sua filha, que dizia o seguinte:</p>
<p>“Joan Fisher Box, filha de Fisher, em seu livro sobre a vida do pai, se referindo à péssima classificação dele em francês, escreveu: “… ele nunca teve muita paciência com irrelevâncias.” (Box, 1978)"</p>
<p>Fico imaginando o tamanho da contribuição desdes crânios para a comunidade se tivessem acesso a tantos mecanismos que temos hoje em dia e o que eles achariam relevantes..</p>
<p>Para o bom ajuste de um modelo, certamente; a inferência, as análises de desvios, os critérios de seleção de um modelo, conferir comportamento dos resíduos e avaliação das estatísticas de diagnósticos são muito relevantes.</p>
<p>No <a href="https://cran.r-project.org/">CRAN</a> já contamos com muitos pacotes disponíveis para nos auxiliar nessas avaliações, portanto vou mostrar aqui alguns pacotes com funções que já me ajudaram muito em avaliações de modelos indo além das funções nativas do R e do pacote <code>ggplot2</code> (Um excelente pacote para apresentações elegantes e práticas de resultados visuais).</p>
</div>
<div id="ggally" class="section level1">
<h1>GGally</h1>
<p>Este pacote é sensacional, existem funções muito relevantes nele para melhorar a nossa experiência com ajuste de modelos, as funções apresentadas aqui são baseadas na <a href="http://ggobi.github.io/ggally/#ggally">página de documentação GGally</a>, lá você pode conferir a documentação completa.</p>
<p>Primeiramente vamos carregar o pacote:</p>
<pre class="r"><code>library(GGally)</code></pre>
<p>Carregado o pacote, vejamos as principais funções que podem nos auxiliar.</p>
<div id="ggallyggcoef" class="section level2">
<h2><code>GGally::ggcoef</code></h2>
<p>O objetivo da função <code>GGally::ggcoef</code> é traçar rapidamente os coeficientes de um modelo.</p>
<p>Para um modelo linear:</p>
<pre class="r"><code>reg &lt;- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = iris)
ggcoef(reg)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Para um modelo logístico podemos utilizar o argumento <code>exponentiate = TRUE</code> e além disso, somos capazes de fazer diversas alterações no gráfico utilizando o <code>ggcoef()</code> veja alguns exemplo de argumentos que podem ser usados para personalizar como barras de erro e a linha vertical são plotadas:</p>
<pre class="r"><code>#Ajustando o modelo:
d &lt;- as.data.frame(Titanic)
log.reg &lt;- glm(Survived ~ Sex + Age + Class, family = binomial, data = d, weights = d$Freq)

#Elaborando o gráfico
ggcoef(
  log.reg,                      #O modelo a ser conferido
  exponentiate = TRUE,          #Para avaliar o modelo logístico
  vline_color = &quot;red&quot;,          #Reta em zero  
  #vline_linetype =  &quot;solid&quot;,   #Altera a linha de referência
  errorbar_color = &quot;blue&quot;,      #Cor da barra de erros
  errorbar_height = .25,
  shape = 18,                   #Altera o formato dos pontos centrais
  #size=3,                      #Altera o tamanho do ponto
  color=&quot;black&quot;,                #Altera a cor do ponto
  mapping = aes(x = estimate, y = term, size = p.value))+
  scale_size_continuous(trans = &quot;reverse&quot;) #Essa linha faz com que inverta o tamanho                 </code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="ggallyggduo" class="section level2">
<h2><code>GGally::ggduo</code></h2>
<p>O objetivo desta função é exibir dois dados agrupados em uma matriz de plotagem. Isso é útil para análise de correlação canônica, análise de séries temporais múltiplas e análise de regressão.</p>
<p>Os dados do exemplo apresentados aqui podem ser encontrados neste <a href="http://www.stats.idre.ucla.edu/r/dae/canonical-correlation-analysis">link</a></p>
<pre class="r"><code>data(psychademic)
head(psychademic)</code></pre>
<pre><code>##   locus_of_control self_concept motivation read write math science    sex
## 1            -0.84        -0.24          4 54.8  64.5 44.5    52.6 female
## 2            -0.38        -0.47          3 62.7  43.7 44.7    52.6 female
## 3             0.89         0.59          3 60.6  56.7 70.5    58.0   male
## 4             0.71         0.28          3 62.7  56.7 54.7    58.0   male
## 5            -0.64         0.03          4 41.6  46.3 38.4    36.3 female
## 6             1.11         0.90          2 62.7  64.5 61.4    58.0 female</code></pre>
<pre class="r"><code>psych_variables &lt;- attr(psychademic, &quot;psychology&quot;)
academic_variables &lt;- attr(psychademic, &quot;academic&quot;)</code></pre>
<pre class="r"><code>ggduo(
  psychademic, psych_variables, academic_variables,
  types = list(continuous = &quot;smooth_lm&quot;),
  title = &quot;Correlação entre as variáveis psicológicas e academicas&quot;,
  xlab = &quot;Psicológicos&quot;,
  ylab = &quot;Academicas&quot;
)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Uma vez que o <code>ggduo</code> não tem uma seção superior para exibir os valores de correlação, podemos usar uma função personalizada para adicionar a informação nas parcelas contínuas.</p>
<p>Criando uma função personalizada para informar a correlação entre as observações:</p>
<pre class="r"><code>lm_with_cor &lt;- function(data, mapping, ..., method = &quot;pearson&quot;) {
  x &lt;- eval(mapping$x, data)
  y &lt;- eval(mapping$y, data)
  cor &lt;- cor(x, y, method = method)
  ggally_smooth_lm(data, mapping, ...) +
    ggplot2::geom_label(
      data = data.frame(
        x = min(x, na.rm = TRUE),
        y = max(y, na.rm = TRUE),
        lab = round(cor, digits = 3)
      ),
      mapping = ggplot2::aes(x = x, y = y, label = lab),
      hjust = 0, vjust = 1,
      size = 5, fontface = &quot;bold&quot;,
      inherit.aes = FALSE # do not inherit anything from the ...
    )
}</code></pre>
<p>Portanto:</p>
<pre class="r"><code>ggduo(
  psychademic, psych_variables, academic_variables,
  types = list(continuous = &quot;smooth_lm&quot;),
  title = &quot;Correlação entre variáveis acadêmica e psicológica&quot;,
  xlab = &quot;Psicológica&quot;,
  ylab = &quot;Academica&quot;
)+
  theme(legend.position = &quot;bottom&quot;)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Para avaliar resíduos da uma regressão ajustada para cada uma das variáveis explanatórias vs. as variáveis explanatórias:</p>
<pre class="r"><code>dados &lt;- datasets::swiss

# Criando uma coluna &quot;fake&quot;:
dados$Residual &lt;- seq_len(nrow(dados))

# Calculando todos os resíduos que serão exibidos:
colunas=2:6  #Informe as colunas que contem as variaveis explanatorias
residuals &lt;- lapply(dados[colunas], function(x) {
  summary(lm(Fertility ~ x, data = dados))$residuals
})
# Calculando um intervalo constante para todos os resíduos
y_range &lt;- range(unlist(residuals))

# Função modificada para mostrar os resíduos:

lm_or_resid &lt;- function(data, mapping, ..., line_color = &quot;red&quot;, line_size = 1) {
  if (as.character(mapping$y) != &quot;Residual&quot;) {
    return(ggally_smooth_lm(data, mapping, ...))
  }

  # Criando os resíduos para apresentar:
  resid_data &lt;- data.frame(
    x = data[[as.character(mapping$x)]],
    y = residuals[[as.character(mapping$x)]]
  )

  ggplot(data = data, mapping = mapping) +
    geom_hline(yintercept = 0, color = line_color, size = line_size) +
    ylim(y_range) +
    geom_point(data = resid_data, mapping = aes(x = x, y = y), ...)

}

# Plote os dados:
ggduo(
  dados,
  2:6, c(1,7),
  types = list(continuous = lm_or_resid)
)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="ggallyggnostic" class="section level2">
<h2><code>GGally::ggnostic</code></h2>
<p>O <code>ggnostic</code> é um wrapper de exibição para <code>ggduo</code> que exibe diagnósticos de modelo completo para cada variável explicativa dada.</p>
<p>Por padrão, o ggduo exibe os valores residuais, o sigma do modelo de “leave-one-out”, os pontos de alavanca e a distância de Cook em relação a cada variável explicativa.</p>
<p>As linhas da matriz de plotagem podem ser expandidas para incluir valores ajustados, erro padrão dos valores ajustados, resíduos padronizados e qualquer uma das variáveis de resposta.</p>
<p>Se o modelo for um modelo linear, os asteriscos (*) são adicionados de acordo com a significância anova de cada variável explicativa.</p>
<p>A maioria das parcelas diagnósticas contêm linhas de referência para ajudar a determinar se o modelo está adequadamente instalado</p>
<p>Olhando para os conjuntos de dados do conjunto de dados <code>state.x77</code> ajustaremos um modelo de regressão múltipla para a expectativa de vida.</p>
<pre class="r"><code>#Dados que serão utilizados no exemplos:
state &lt;- as.data.frame(state.x77)
#Arrumando o nome das variaveis:
colnames(state)[c(4, 6)] &lt;- c(&quot;Life.Exp&quot;, &quot;HS.Grad&quot;)
# Ajustando o modelo completo:
model &lt;- lm(Life.Exp ~ ., data = state)
# Executando o stepwise para encontrar o melhor ajuste
model &lt;- step(model, trace = FALSE)</code></pre>
<p>Executando o diagnóstico deste modelo com a função <code>ggnostic()</code>:</p>
<pre class="r"><code># look at model diagnostics
ggnostic(model)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Para acessar as variáveis influentes do modelo podemos utilizar a função <code>influence.measures()</code>, veja:</p>
<pre class="r"><code>summary(influence.measures(model))</code></pre>
<pre><code>## Potentially influential observations of
##   lm(formula = Life.Exp ~ Population + Murder + HS.Grad + Frost,      data = state) :
## 
##            dfb.1_ dfb.Pplt dfb.Mrdr dfb.HS.G dfb.Frst dffit   cov.r   cook.d
## Alaska      0.41   0.18    -0.40    -0.35    -0.16    -0.50    1.36_*  0.05 
## California  0.04  -0.09     0.00    -0.04     0.03    -0.12    1.81_*  0.00 
## Hawaii     -0.03  -0.57    -0.28     0.66    -1.24_*   1.43_*  0.74    0.36 
## Nevada      0.40   0.14    -0.42    -0.29    -0.28    -0.52    1.46_*  0.05 
## New York    0.01  -0.06     0.00     0.00    -0.01    -0.07    1.44_*  0.00 
##            hat    
## Alaska      0.25  
## California  0.38_*
## Hawaii      0.24  
## Nevada      0.29  
## New York    0.23</code></pre>
<p>Esta função retorna as seguintes estatísticas:</p>
<table>
<colgroup>
<col width="23%" />
<col width="25%" />
<col width="17%" />
<col width="17%" />
<col width="17%" />
</colgroup>
<thead>
<tr class="header">
<th>DFBeta</th>
<th>DFFit</th>
<th>CovRatio</th>
<th>D.Cook</th>
<th>h</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Alteração no vetor estimado <span class="math inline">\(\hat \beta\)</span> ao se retirar o i-ésimo ponto da análise</td>
<td>Alteração provocada no valor ajustado pela retirada da observação <span class="math inline">\(i\)</span></td>
<td>Expressa o relação de covariancia</td>
<td>Medida de afastamento das estimativas ao retirar <span class="math inline">\(i\)</span> e também considera o resíduo estudentizado internamente</td>
<td>Elementos da diagonal da matriz H</td>
</tr>
</tbody>
</table>
<p>Vejamos então um exemplo de matriz de matriz de diagnóstico completo.</p>
<p>As seguintes linhas de código exibirão uma matriz de diagnóstico para o mesmo modelo:</p>
<pre class="r"><code>#Ajustando um modelo de exemplo:
flea_model &lt;- step(lm(head ~ ., data = flea), trace = FALSE)</code></pre>
<p>Todas as colunas possíveis e usando <code>ggally_smooth()</code> para exibir os pontos ajustados e as variáveis de resposta temos:</p>
<pre class="r"><code># default output
ggnostic(flea_model,
 #        mapping = ggplot2::aes(color = species),  #Para colorir segundo um fator
         columnsY = c(&quot;head&quot;, &quot;.fitted&quot;, &quot;.se.fit&quot;, &quot;.resid&quot;, &quot;.std.resid&quot;, &quot;.hat&quot;, &quot;.sigma&quot;, &quot;.cooksd&quot;),
        continuous = list(default = ggally_smooth, .fitted = ggally_smooth)
)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="ggallyggpairs" class="section level2">
<h2><code>GGally::ggpairs</code></h2>
<p>O <code>ggpairs</code> é uma forma especial de uma ggmatrix que produz uma comparação pairwise de dados multivariados. Por padrão, o ggpairs fornece duas comparações diferentes de cada par de colunas e exibe a densidade ou a contagem da variável respectiva ao longo da diagonal. Com diferentes configurações de parâmetros, a diagonal pode ser substituída pelos valores do eixo e rótulos variáveis.</p>
<pre class="r"><code>#Funcao de correlacoes
my_fn &lt;- function(data, mapping, method=&quot;lm&quot;, ...){
  p &lt;- ggplot(data = data, mapping = mapping) + 
    geom_point() + 
    geom_smooth(method=method, ...)
  p
}
data(tips, package = &quot;reshape&quot;)
#Correlaçoes cruzadas
ggpairs(tips, lower = list(continuous = my_fn))</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Existem muitos recursos ocultos dentro dos <code>ggpairs()</code> e muitos exemplos podem ser conferidos na internet para obter o máximo do <code>ggpairs()</code>.</p>
</div>
<div id="ggallyggscatmat" class="section level2">
<h2><code>GGally::ggscatmat</code></h2>
<p>A principal função é <code>ggscatmat</code>. É semelhante a <code>ggpairs()</code>, mas funciona apenas para dados multivariados puramente numéricos.</p>
<p>É mais rápido que ggpairs, porque é necessário fazer menos escolhas.</p>
<p>Ele cria uma matriz com diagramas de dispersão na diagonal inferior, densidades na diagonal e correlações escritas na diagonal superior.</p>
<p>A sintaxe é inserir o conjunto de dados, as colunas que deseja traçar, uma coluna de cores e um nível alfa.</p>
<pre class="r"><code>data(flea)
ggscatmat(flea, columns = 2:4, color=&quot;species&quot;, alpha=0.8)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
</div>
<div id="ggfottify" class="section level1">
<h1>ggfottify</h1>
<p>Outra opção interessante para avaliar o ajuste dos modelos é o pacote <a href="https://cran.r-project.org/web/packages/ggfortify/index.html">ggfottify</a>. Ele disponibiliza uma interface de traçado (como a função <code>plot(modelo_ajustado)</code>) de análise e gráficos em um estilo unificado, porém usando <code>ggplot2</code>.</p>
<p>Vamos então dar início carregando o pacote:</p>
<pre class="r"><code>library(ggfortify)</code></pre>
<p>Veja a seguir alguns dos gráficos disponíveis no R para a análise de resíduos:</p>
<pre class="r"><code>autoplot(flea_model, which = 1:6, ncol = 3, label.size = 3)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Especificando as opções de plot</p>
<p>Algumas propriedades desses gráficos podem ser alteradas. Por exemplo, a opção <code>colour = 'dodgerblue3'</code> é para pontos de dados, o <code>smooth.colour = 'black'</code> é para linhas de suavização e <code>ad.colour = 'blue'</code> é para opções adicionais.</p>
<p>Veja ainda que ncol e nrow controlam o layout.</p>
<pre class="r"><code>autoplot(flea_model, which = 1:6, colour = &#39;dodgerblue3&#39;,
         smooth.colour = &#39;black&#39;, smooth.linetype = &#39;dashed&#39;,
         ad.colour = &#39;blue&#39;,
         label.size = 3, label.n = 5, label.colour = &#39;blue&#39;,
         ncol = 3)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Além disso, você pode usar nomes de colunas para essas propriedades, vamos separar os grupos de machos e fêmeas por cores:</p>
<pre class="r"><code>autoplot(flea_model, which = 1:6, data = flea,
         colour = &#39;species&#39;, label.size = 3,
         ncol = 3)</code></pre>
<p><img src="/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>O que será que os crânios da estatística fariam diante de tantos recursos?</p>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos/">Pacotes do R para avaliar o ajuste de modelos</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Estatistica</category>
      <category>Modelagem Estatistica</category>
      <category>R</category>
      <category>Teoria</category>
      <category>Tidyverse</category>
      <category domain="tag">gomesfellipe</category>
      <category domain="tag">R</category>
      <category domain="tag">modelagem</category>
      <category domain="tag">modelagem estatistica</category>
      <category domain="tag">Estatistica</category>
      <category domain="tag">Correlacoes</category>
      <category domain="tag">R Markdown</category>
      <category domain="tag">regression</category>
      <category domain="tag">Teoria</category>
      <category domain="tag">modelos lineares</category>
      <category domain="tag">modelos generalizados</category>
      <category domain="tag">ggfortify</category>
      <category domain="tag">GGally</category>
    </item>
  </channel>
</rss>