&lt;?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>imbalanced on Fellipe Gomes - Data Science Blog</title>
    <link>https://gomesfellipe.github.io/tags/imbalanced/</link>
    <description>√öltimos posts sobre Data Science, Machine Learning e R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <managingEditor>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</managingEditor>
    <webMaster>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</webMaster>
    <lastBuildDate>Mon, 28 Jun 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://gomesfellipe.github.io/tags/imbalanced/" rel="self" type="application/rss+xml" />
    <item>
      <title>Otimizando pipelines que envolvem dados desbalanceados</title>
      <link>https://gomesfellipe.github.io/post/2021-06-28-imbalanced-workflowsets/</link>
      <pubDate>Mon, 28 Jun 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-06-28-imbalanced-workflowsets/</guid>
      <description>Utilizaremos o framework tidymodels para machine learning em R com o aux√≠lio do pacote workflowsets para otimizar pipelines de dados desbalanceados</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#o-problema-envolvendo-dados-desbalanceados" id="toc-o-problema-envolvendo-dados-desbalanceados">O problema envolvendo dados desbalanceados</a></li>
<li><a href="#objetivo" id="toc-objetivo">Objetivo</a></li>
<li><a href="#depend%C3%AAncias" id="toc-depend√™ncias">Depend√™ncias</a></li>
<li><a href="#preparar-dados" id="toc-preparar-dados">Preparar dados</a></li>
<li><a href="#breve-an%C3%A1lise-explorat%C3%B3ria" id="toc-breve-an√°lise-explorat√≥ria">Breve an√°lise explorat√≥ria</a></li>
<li><a href="#modelagem" id="toc-modelagem">Modelagem</a>
<ul>
<li><a href="#baselines" id="toc-baselines">Baselines</a></li>
<li><a href="#preparar-pipeline-de-dados-com-workflowsets" id="toc-preparar-pipeline-de-dados-com-workflowsets">Preparar Pipeline de dados com <code>workflowsets</code></a></li>
<li><a href="#benchmark" id="toc-benchmark">Benchmark</a></li>
</ul></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias</a></li>
</ul>
</div>

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 33%;
padding: 10px;
}

.column8 {
float: left;
width: 66%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>
<div id="o-problema-envolvendo-dados-desbalanceados" class="section level1">
<h1>O problema envolvendo dados desbalanceados</h1>
<p>A tarefa de classifica√ß√£o com dados desbalanceados √© muito comum na vida real podendo variar desde um leve vi√©s at√© um enorme desequil√≠brio na distribui√ß√£o da classe de interesse. Problemas mais comuns envolvem:</p>
<ul>
<li>Detec√ß√£o de fraude;</li>
<li>Previs√£o de inadimpl√™ncia;</li>
<li>Identificador de <em>spam</em>;</li>
<li>Busca por anomalias/outliers;</li>
<li>Detec√ß√£o de poss√≠veis roubos/furtos/vulnerabilidades;</li>
<li>Previs√£o de <em>churn</em>;</li>
<li>etc</li>
</ul>
<div class="row">
<div class="column8">
<p>Este tipo de tarefa representa um enorme desafio para modelagem preditiva pois a maioria dos algoritmos de machine learning foram projetados sob suposi√ß√£o de haver um n√∫mero igual de exemplos para cada classe de interesse.</p>
<p>E isso √© um grande problema pois normalmente estamos interessados em prever a classe minorit√°ria e para isso √© preciso tomar uma s√©rie de decis√µes, como por exemplo: m√©trica utilizada, m√©todo para valida√ß√£o cruzada, ado√ß√£o (ou n√£o) do uso de m√©todos de reamostragem, quais algoritmos utilizar, qual ser√° o threshold, etc</p>
</div>
<div class="column4">
<p></br>
<img src="https://media.giphy.com/media/JPV8lNtI59zaWyL4pf/giphy.gif" alt="Via Giphy" /></p>
</div>
</div>
<p>Lidar com dados desbalanceados √© um assunto longo portanto tentarei dar mais aten√ß√£o apenas em um <em>hack</em> para encontrar a melhor forma de se aplicar o balanceamento dos dados. N√£o pretendo me aprofundar na teoria envolvida na escolha das m√©tricas neste post, caso o leitor deseje se aprofundar sobre a teoria envolvida com classifica√ß√£o que envolve dados desbalanceados, sugiro a leitura do livro: <a href="https://machinelearningmastery.com/imbalanced-classification-with-python/">Imbalanced Classification with Python - Choose Better Metrics, Balance Skewed Classes and Apply Cost-Sensitive Learning</a> e consultar os links de refer√™ncia no final do post).</p>
</div>
<div id="objetivo" class="section level1">
<h1>Objetivo</h1>
<p>Utilizaremos neste post o pacote <code>workflowsets</code> a fim de otimizar o pipeline de reamostragem da base para lidar com o desbalanceamento dos dados.</p>
<p>Para efeitos de compara√ß√£o, utilizarei como refer√™ncia o (excelente) <a href="https://juliasilge.com/blog/sliced-aircraft/">post escrito recentemente pela Julia Silge</a> em seu blog que tamb√©m aborda o problema de dados desbalanceados utilizando um conjunto de dados de uma <a href="https://www.kaggle.com/c/sliced-s01e02-xunyc5">competi√ß√£o do Kaggle</a>. Utilizarei a mesma configura√ß√£o de pr√©-processamento adotado em seu post para que a compara√ß√£o seja justa.</p>
<p>Portanto, nosso objetivo de modelagem ser√° prever se uma colis√£o com animais selvagens resultou em danos a aeronave.</p>
<div class="w3-panel w3-pale-green w3-border">
<p>‚ö†Ô∏è Este dataset √© rico em possibilidades para diferentes tipos de pr√© processamentos e por isso convido o leitor a analis√°-lo com maior profundidade e tamb√©m a compartilhar seus resultados!</p>
</div>
</div>
<div id="depend√™ncias" class="section level1">
<h1>Depend√™ncias</h1>
<p>Primeiro vamos carregar as bibliotecas necess√°rias e algumas fun√ß√µes desenvolvidas para o post</p>
<pre class="r"><code>library(tidyverse)    # ds toolkit
library(tidymodels)   # ml toolkit
library(baguette)     # bag_tree
library(themis)       # imbalanced
library(workflowsets) # opt pipelines
library(patchwork)    # arrange plots 

doParallel::registerDoParallel()
theme_set(theme_bw())</code></pre>
<details>
<summary>
(<em>Clique aqui para ver as fun√ß√µes</em> <code>print_table</code> <em>e</em> <code>conf_mat_plot</code> <em>importadas</em>)
</summary>
<pre class="r"><code># Para o print de tabelas
print_table &lt;- function(x, round=0, cv=F, wf=F, bm=F, ...){ 
  
  if(round&gt;0) x &lt;- x %&gt;% mutate_if(is.numeric, ~round(.x, round))
  
  if(cv==T){
    columns_spec = list(
      .metric = reactable::colDef(minWidth = 75),
      .estimator = reactable::colDef(minWidth = 70),
      .config = reactable::colDef(minWidth = 120)
    )
  } else if(wf==T){
    columns_spec = list(
      wflow_id = reactable::colDef(minWidth = 100),
      .metric = reactable::colDef(minWidth = 100),
      preprocessor = reactable::colDef(minWidth = 110),
      rank = reactable::colDef(minWidth = 50),
      n = reactable::colDef(minWidth = 50)
    )
  }else if (bm==T){
    columns_spec = list(
      wflow_id = reactable::colDef(minWidth = 130),
      model = reactable::colDef(minWidth = 80)
    )
  }else{
    columns_spec = NULL
  }
  
  reactable::reactable(x, striped = T, bordered = T,
                       highlight = T, pagination = F, resizable = T, 
                       columns = columns_spec, ...)
  
}

# Para plot da matriz de confusao e distribuicoes de probabilidade
conf_mat_plot &lt;- function(x, null_model = FALSE){
  p1 &lt;- 
    x %&gt;%
    select(.pred_class, damaged) %&gt;%
    table() %&gt;% 
    conf_mat() %&gt;% 
    autoplot(type = &quot;heatmap&quot;)+
    labs(title = &quot;Matriz de confus√£o&quot;)
  
  p2 &lt;- 
    x  %&gt;%
    ggplot() +
    geom_density(aes(x = .pred_damage, fill = damaged), 
                 alpha = 0.5)+
    labs(title = &quot;Distribui√ß√µes de probabilidade previstas&quot;,
         subtitle = &quot;por classe&quot;)+ 
    scale_x_continuous(limits = 0:1)+
    scale_fill_brewer(palette=&quot;Set1&quot;)
  
  p1 | p2
} </code></pre>
</details>
<p>¬†</p>
<p>Em seguida vamos importar os dados provenientes da competi√ß√£o Inclass do Kaggle <a href="https://www.kaggle.com/c/sliced-s01e02-xunyc5">SLICED s01e02 - Predict whether an aircraft strike with wildlife causes damage</a>. Para mais informa√ß√µes consulte a <a href="https://www.kaggle.com/c/sliced-s01e02-xunyc5/data">documenta√ß√£o e dicion√°rio dos dados</a>.</p>
<pre class="r"><code>df &lt;- read_csv(&quot;train.csv&quot;)</code></pre>
<p>Note que carregamos apenas os dados de treino pois os dados de teste n√£o possuem a target.</p>
</div>
<div id="preparar-dados" class="section level1">
<h1>Preparar dados</h1>
<p>Tratar a vari√°vel target <code>damaged</code> e avaliar sua distribui√ß√£o:</p>
<pre class="r"><code>df &lt;- df %&gt;% 
  mutate(damaged = if_else(damaged==1, &quot;damage&quot;, &quot;not_damage&quot;) %&gt;% 
           factor(levels = c(&quot;damage&quot;, &quot;not_damage&quot;)))</code></pre>
<details>
<summary>
(<em>Clique aqui para ver o c√≥digo do gr√°fico abaixo</em>)
</summary>
<pre class="r"><code>p1 &lt;- df %&gt;% 
  count(damaged) %&gt;% 
  ggplot(aes(x=rev(damaged), y=n, fill=damaged))+
  geom_bar(stat = &quot;identity&quot;)+
  scale_fill_brewer(palette=&quot;Set1&quot;)+
  theme(legend.position = &quot;bottom&quot;)+
  labs(y=&quot;N√∫mero de inst√¢ncias&quot;, x = &quot;&quot;)

p2 &lt;- df %&gt;% 
  count(damaged) %&gt;% 
  arrange(desc(damaged)) %&gt;%
  mutate(prop = n / sum(n)) %&gt;%
  mutate(ypos = cumsum(prop)- 0.5*prop )%&gt;% 
  ggplot(aes(x=&quot;&quot;, y=prop, fill=damaged)) +
  geom_bar(stat=&quot;identity&quot;, width=1) +
  coord_polar(&quot;y&quot;, start=0) +
  theme_void() + 
  theme(legend.position=&quot;none&quot;) +
  geom_text(aes(y = ypos,
                label = paste(scales::comma(n, big.mark = &quot;.&quot;),
                              scales::comma(n/sum(n), big.mark = &quot;.&quot;, 
                                            suffix = &quot;%&quot; ),sep = &quot;\n&quot;)
                
  ), 
  color = &quot;white&quot;, size=6) +
  scale_fill_brewer(palette=&quot;Set1&quot;)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>p1 + p2 </code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-6-1.png" style="width:80.0%" />
</center>
<p>Veja que estamos diante de um problema que existem aproximadamente 9 casos de dano para cada 100 eventos observados.</p>
</div>
<div id="breve-an√°lise-explorat√≥ria" class="section level1">
<h1>Breve an√°lise explorat√≥ria</h1>
<p>Vamos iniciar a explorat√≥ria com uma avalia√ß√£o geral dos dados brutos</p>
<pre class="r"><code>DataExplorer::plot_intro(df, ggtheme = theme_bw(), 
                         theme_config = list(legend.position = &quot;bottom&quot;))</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-7-1.png" style="width:80.0%" />
</center>
<p>Primeira informa√ß√£o que chama aten√ß√£o √© que quase 1/4 desses dados √© faltante. Vamos olhar a estrutura dessa base de maneira mais aprofundada:</p>
<pre class="r"><code>df %&gt;% 
  sample_frac(0.01) %&gt;% 
  visdat::vis_dat()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-8-1.png" style="width:80.0%" />
</center>
<p>Parece existir algum padr√£o nos dados faltantes (que coocorrem em diveros atributos). Al√©m disso algumas colunas est√£o quase inteiramente vazias e ser√£o descartadas no processo de modelagem.</p>
<p>Uma vis√£o geral das classes das features categ√≥ricas:</p>
<pre class="r"><code>df %&gt;%
  select(-damaged, -id)%&gt;%
  mutate_all(as.factor) %&gt;%
  inspectdf::inspect_cat() %&gt;% 
  inspectdf::show_plot()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-9-1.png" style="width:80.0%" />
</center>
<p>Algumas features possuem muitas classes e caso seja feita a transforma√ß√£o <em>one-hot-encoding</em> (estrat√©gia amplamente utilizada para lidar com features categ√≥ricas) sem algum cuidado, o desempenho da maioria dos modelos de machine learning pode ser prejudicado por tornar a base anal√≠tica muito esparsa.</p>
<p>Uma vis√£o geral das classes das features num√©ricas em rela√ß√£o a target:</p>
<pre class="r"><code>num_columns &lt;- c(df %&gt;% select_if(is.numeric) %&gt;% colnames(), &#39;damaged&#39;)
df%&gt;% 
  select_at(num_columns) %&gt;% 
  select(-id) %&gt;%
  gather(key, value, -damaged) %&gt;%
  ggplot(aes(y=damaged, x=value))+
  geom_boxplot()+
  facet_wrap(~key, ncol=5, scales = &quot;free_x&quot;)+
  labs(x = &quot;&quot;, y=&quot;&quot;)</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-10-1.png" style="width:80.0%" />
</center>
<p>Parece que algumas features possuem comportamentos diferentes quando avaliados segundo a target. Al√©m disso √© poss√≠vel notar que as features <code>aircraft_mass</code>, <code>distance</code>, <code>engine4_position</code>, <code>engines</code>, <code>height</code> e <code>speed</code> apresentam outliers.</p>
</div>
<div id="modelagem" class="section level1">
<h1>Modelagem</h1>
<p>Finalmente chegamos a modelagem!</p>
<p>Primeiro vamos definir um esquema de reamostragem (com estratifica√ß√£o) que ser√° utilizado para avaliar os modelos e as m√©tricas de qualidade.</p>
<pre class="r"><code>set.seed(123)

bird_folds &lt;- vfold_cv(df, v = 5, strata = damaged)
bird_metrics &lt;- metric_set(mn_log_loss, accuracy, sensitivity, specificity)</code></pre>
<p>Nossos conjuntos de pipelines necessitar√£o de um pr√©-processador base que ser√° comum a todos como camada inicial. Para isso utilizaremos o mesmo definido no post de refer√™ncia.</p>
<pre class="r"><code>base_rec &lt;- recipe(damaged ~ ., data = df) %&gt;%
  step_select( damaged, flight_impact, precipitation,
               visibility, flight_phase, engines, incident_year,
               incident_month, species_id, engine_type,
               aircraft_model, species_quantity, height, speed) %&gt;% 
  step_novel(all_nominal_predictors()) %&gt;%
  step_other(all_nominal_predictors(), threshold = 0.01) %&gt;%
  step_unknown(all_nominal_predictors()) %&gt;%
  step_impute_median(all_numeric_predictors()) %&gt;%
  step_zv(all_predictors())</code></pre>
<div id="baselines" class="section level2">
<h2>Baselines</h2>
<p>Para efeitos de compara√ß√£o, vamos ajustar 2 modelos que ser√£o utilizados como baselines para saber se a complexidade que estamos adicionando no modelo est√° realmente trazendo algum ganho na performance do modelo. Os modelos ser√£o:</p>
<ul>
<li>Modelo nulo: um modelo que sempre prev√™ a classe majorit√°ria;</li>
<li>Modelo de base: <a href="https://bradleyboehmke.github.io/HOML/bagging.html">Bagged Decision Tree</a> sem adicionar pr√©-processamento para compensar o desequil√≠brio de classe.</li>
</ul>
<div id="modelo-nulo" class="section level3">
<h3>Modelo nulo</h3>
<p>Avaliando modelo nulo via valida√ß√£o cruzada:</p>
<pre class="r"><code>null_spec &lt;- null_model(mode = &quot;classification&quot;) %&gt;% 
  set_engine(&quot;parsnip&quot;)

null_wf &lt;-
  workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(null_spec)

null_rs &lt;-
  fit_resamples(
    object = null_wf,
    resamples = bird_folds,
    metrics = bird_metrics,
    control = control_resamples(save_pred = TRUE)
  ) 

collect_metrics(null_rs) %&gt;% print_table(round = 5, cv = T) </code></pre>
<p><img src="/post/2021-06-28-imbalanced-workflowsets/tab1.png" /></p>
<p>Qualquer modelo com desempenho pior do que este deve ser descartado. Vejamos a matriz de confus√£o:</p>
<pre class="r"><code>collect_predictions(null_rs) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-14-1.png" style="width:80.0%" />
</center>
</div>
<div id="modelo-de-base" class="section level3">
<h3>Modelo de base</h3>
<p>Agora vamos ajusta o modelo <em>Bagged Decision Tree</em> sem o pr√©-processamento para compensar o desequil√≠brio de classe:</p>
<pre class="r"><code>bag_spec &lt;-
  bag_tree(min_n = 10) %&gt;%
  set_engine(&quot;rpart&quot;, times = 25) %&gt;%
  set_mode(&quot;classification&quot;)

imb_wf &lt;-
  workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(bag_spec)

set.seed(123)
imb_rs &lt;-
  fit_resamples(
    imb_wf,
    resamples = bird_folds,
    metrics = bird_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(imb_rs) %&gt;% print_table(round = 5, cv = T)</code></pre>
<p><img src="/post/2021-06-28-imbalanced-workflowsets/tab2.png" /></p>
<p>Apesar do elevado n√∫mero de falsos negativos, este modelo j√° esta com um desempenho razo√°vel em compara√ß√£ao ao modelo nulo e o n√∫mero de verdadeiros positivos j√° √© quase o dobro do n√∫mero de falsos positivos. Veja na matriz de confus√£o abaixo:</p>
<pre class="r"><code>collect_predictions(imb_rs) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-16-1.png" style="width:80.0%" />
</center>
</div>
</div>
<div id="preparar-pipeline-de-dados-com-workflowsets" class="section level2">
<h2>Preparar Pipeline de dados com <code>workflowsets</code></h2>
<p>A escolha do m√©todo de amostragem dos dados √© t√£o importante quanto a escolha do modelo preditivo que ser√° utilizado pois o desempenho pode ser enganosamente otimista visto que o algoritmo de bagging n√£o esta usando nenhuma estrat√©gia de subamostragem aleat√≥ria da classe majorit√°ria em cada amostra de bootstrap para equilibrar as duas classes.</p>
<p>Existem muitos m√©todos para amostragem de dados e n√£o h√° um m√©todo √∫nico que seja melhor em todos os problemas de classifica√ß√£o (assim como n√£o existe o ‚Äúmelhor modelo‚Äù) portanto, utilizaremos este pacote para testar diferentes m√©todos e tamb√©m tunar seus hiperpar√¢metros.</p>
<div id="oversampling" class="section level3">
<h3>Oversampling</h3>
<p>Estes m√©todos duplicam ou sintetizam novos dados da classe minorit√°ria. Deve ser usado com cautela pois na vida real pode gerar alguns dados que n√£o condizem com a relidade ou criar tantas inst√¢ncias que acaba consumindo muito mais tempo de processamento.</p>
<div id="random-oversampling" class="section level4">
<h4>Random Oversampling</h4>
<p>Este m√©todo simplesmente duplica aleat√≥riamente exemplos da classe minorit√°ria. Vamos tunar esta propor√ß√£o buscando n√∫meros reais no intervalo [0.5,1].</p>
<pre class="r"><code>rec_up &lt;- base_rec %&gt;% 
  step_upsample(damaged, over_ratio = tune())

params_up &lt;- rec_up %&gt;% 
  parameters() %&gt;% update(over_ratio = mixture(c(0.5, 1)))</code></pre>
</div>
<div id="smote---synthetic-minority-oversampling-technique" class="section level4">
<h4>SMOTE - Synthetic Minority Oversampling Technique</h4>
<p>O SMOTE funciona gerando novos dados sint√©tios baseados em exemplos selecionando que est√£o ‚Äúpr√≥ximos‚Äù. Vamos tunar tanto a propor√ß√£o de dados que ser√£o gerados quanto a quantidade de vizinhos selecionados, buscando n√∫meros reais e inteiros no intervalo [0.5,1] e [1, 10], respectivamente.</p>
<pre class="r"><code>rec_smote &lt;- base_rec %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_smote(damaged, over_ratio = tune(), 
             neighbors = tune())

params_smote &lt;- rec_smote %&gt;% 
  parameters() %&gt;% update(over_ratio = mixture(c(0.5, 1)),
                          neighbors = neighbors())</code></pre>
</div>
<div id="adasyn---adaptive-synthetic-sampling" class="section level4">
<h4>ADASYN - Adaptive Synthetic Sampling</h4>
<p>O ADASYN √© uma extens√£o do SMOTE que busca propor melhorias. Vamos tunar os mesmos par√¢metros definidos no SMOTE.</p>
<pre class="r"><code>rec_adasyn &lt;- base_rec %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_adasyn(damaged, 
              over_ratio = tune(), 
              neighbors = tune())

params_adasyn &lt;- rec_adasyn %&gt;% 
  parameters() %&gt;% update(over_ratio = mixture(c(0.5, 1)),
                          neighbors = neighbors())</code></pre>
</div>
</div>
<div id="undersampling" class="section level3">
<h3>Undersampling</h3>
<p>S√£o t√©cnicas que excluem ou selecionam um subconjunto de exemplos da classe majorit√°ria e existem dezenas (se n√£o centenas) desses m√©todos. Neste post utilizaremos s√≥ 3 mas existem outros implementados em outras bibliotecas (em R e em Python).</p>
<div id="random-undersampling" class="section level4">
<h4>Random Undersampling</h4>
<p>Este √© o m√©todo mais simples e envolve a exclus√£o aleat√≥ria de algumas inst√¢ncias da classe majorit√°ria. Vamos tunar esta propor√ß√£o de frequ√™ncias da minorit√°ria para a majorit√°ria.</p>
<pre class="r"><code>rec_down &lt;- base_rec %&gt;% 
  step_downsample(damaged, under_ratio = tune())

params_down &lt;- rec_down %&gt;% 
  parameters() %&gt;% update(under_ratio = deg_free())</code></pre>
</div>
<div id="near-miss-undersampling" class="section level4">
<h4>Near Miss Undersampling</h4>
<p>Este algoritmo se baseia em m√©todos de KNN selecionando exemplos da classe majorit√°ria que tem menor dist√¢ncia m√©dia dos k exemplos mais pr√≥ximos. Vamos tunar tanto a propor√ß√£o quanto o n√∫mero de vizinhos utilizados.</p>
<pre class="r"><code>rec_nearmiss &lt;- base_rec %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_nearmiss(damaged, 
                under_ratio = tune(), 
                neighbors = tune())

params_nearmiss &lt;- rec_nearmiss %&gt;% 
  parameters() %&gt;% update(under_ratio = deg_free(),
                          neighbors = neighbors())</code></pre>
</div>
<div id="tomek-links-undersampling" class="section level4">
<h4>Tomek Links Undersampling</h4>
<p>Este algoritmo que tenta excluir inst√¢ncias que sejam pr√≥ximas e que possuam classes diferentes, buscando diminuir a ambiguidade dos dados. N√£o vamos tunar nenhum hiperpar√¢metro aqui.</p>
<pre class="r"><code>rec_tomek &lt;- base_rec %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_tomek(damaged)</code></pre>
</div>
</div>
<div id="preparar-pipeline-de-dados" class="section level3">
<h3>Preparar pipeline de dados</h3>
<p>Agora que todos pipelines de dados candidatos est√£o definidos, vamos combinar tudo em um √∫nico objeto com <code>workflow_set</code>:</p>
<pre class="r"><code>chi_models &lt;- 
  workflow_set(
    preproc = list(upsample = rec_up,
                   smote = rec_smote,
                   adasyn = rec_adasyn,
                   downsample = rec_down,
                   nearmiss = rec_nearmiss,
                   tomek = rec_tomek),
    models = list(bag_spec = bag_spec),
    cross = TRUE
  )</code></pre>
<p>Utilizar a fun√ß√£o <code>option_add</code> para adicionar as informa√ß√µes dos intervalos definidos para cada hiperpar√¢metro:</p>
<pre class="r"><code>chi_models &lt;- chi_models %&gt;% 
  option_add(param_info = params_up, id = &quot;upsample_bag_spec&quot;)  %&gt;% 
  option_add(param_info = params_smote, id = &quot;smote_bag_spec&quot;) %&gt;% 
  option_add(param_info = params_adasyn, id = &quot;adasyn_bag_spec&quot;) %&gt;% 
  option_add(param_info = params_down, id = &quot;downsample_bag_spec&quot;) %&gt;% 
  option_add(param_info = params_nearmiss, id = &quot;nearmiss_bag_spec&quot;)</code></pre>
<p>Finalmente, vamos ajustar todos os modelos utilizando o m√©todo simples para fazer a busca dos melhores hiperpar√¢metros em grids de 20 valores aleat√≥rios e calcular os scores via valida√ß√£o cruzada (esta parte pode demorar bastante tempo):</p>
<pre class="r"><code>set.seed(123)
chi_models &lt;- 
  chi_models %&gt;% 
  workflow_map(&quot;tune_grid&quot;,
               resamples = bird_folds, 
               grid = 20, 
               metrics = bird_metrics,
               control = control_resamples(save_pred = TRUE),
               verbose = TRUE)</code></pre>
<p>Vejamos os resultados:</p>
<pre class="r"><code>rank_results(chi_models, rank_metric = &quot;mn_log_loss&quot;, select_best = TRUE) %&gt;% 
  select(-.config) %&gt;%
  mutate(wflow_id = str_remove(wflow_id, &quot;_bag_spec&quot;)) %&gt;% 
  print_table(round = 5, wf=T, height = 300, filterable = T)</code></pre>
<p>Matriz de confus√£o do modelo com menor <em>logloss</em>:</p>
<pre class="r"><code>collect_predictions(chi_models) %&gt;% 
  filter(wflow_id == &quot;tomek_bag_spec&quot;) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-29-1.png" style="width:80.0%" />
</center>
</div>
</div>
<div id="benchmark" class="section level2">
<h2>Benchmark</h2>
<p>Comparando os resultados dos modelos ajustados:</p>
<details>
<summary>
(<em>Clique aqui para ver o c√≥digo que cria o objeto</em> <code>benchmark</code>)
</summary>
<pre class="r"><code>benchmark &lt;- bind_rows(
  mutate(collect_metrics(null_rs), wflow_id = &quot;default&quot;, model = &quot;null_model&quot;) %&gt;% 
    select(.metric, mean, wflow_id, model) %&gt;% 
    spread(.metric, mean)
  ,
  mutate(collect_metrics(imb_rs), wflow_id = &quot;default&quot;, model = &quot;bag_tree&quot;) %&gt;% 
    select(.metric, mean, wflow_id, model) %&gt;% 
    spread(.metric, mean)
  ,
  rank_results(chi_models, rank_metric = &quot;mn_log_loss&quot;, select_best = TRUE) %&gt;% 
    filter(wflow_id==&quot;smote_bag_spec&quot;) %&gt;% 
    select(.metric, mean, wflow_id, model) %&gt;% 
    spread(.metric, mean)
  ,
  rank_results(chi_models, rank_metric = &quot;mn_log_loss&quot;, select_best = TRUE) %&gt;% 
    filter(rank==1) %&gt;% 
    select(.metric, mean, wflow_id, model) %&gt;% 
    spread(.metric, mean)
) </code></pre>
</details>
<pre class="r"><code>benchmark  %&gt;%
  print_table(round = 5, bm = T)</code></pre>
<p>Como no post da Julia, a logloss e a precis√£o dos modelos que utilizaram m√©todos de balanceamento dos dados pioraram em rela√ß√£o ao modelo de <em>Bagged Decision Tree</em> sem o uso desses pipelines. Apesar da piora em rela√ß√£o ao modelo de base nota-se que outros m√©todos como <em>Tomek Links</em> e <em>Adasyn</em> se sa√≠ram ligeiramente melhores do que o <em>Smote</em> (al√©m disso vimos que o <em>Smote</em> com sua configura√ß√£o <em>default</em> n√£o necessariamente produriz√° os melhores resultados).</p>
<p>Este tipo de performance √© muito comum e at√© esperado visto que estamos avaliando o modelo atrav√©s de uma √∫nica m√©trica (com os mesmos pontos de corte e com o mesmo algoritmo). Normalmente no mundo real monitoramos diversas m√©tricas e experimentamos mais configura√ß√µes de hiperpar√¢metros de diferentes modelos com diferentes pipelines.</p>
</div>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o</h1>
<p>Assim como n√£o existe melhor modelo, n√£o existe melhor t√©cnica de balanceamento de dados. Portanto, na busca de melhores resultados n√≥s podemos tentar otimizar qual abordagem ser√° uyilizada bem como seus hiperpar√¢metros (em conjunto com os hiperpar√¢metros dos modelos em quest√£o).</p>
<p>Esta abordagem em R √© nova para mim (estou mais acostumado a utilizar em Python com o m√©todo <code>sklearn.pipeline.Pipeline</code> em conjunto com a biblioteca <a href="https://pypi.org/project/imblearn/">imblearn</a>) ent√£o qualquer cr√≠tica e sugest√£o de melhoria ser√° muito bem vinda! Basta entrar em contato ou deixar aqui nos coment√°rios!</p>
<p>Bons estudos e espero que gostem! üöÄ</p>
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias</h1>
<ul>
<li><a href="https://www.tidyverse.org/blog/2021/03/workflowsets-0-0-1/" class="uri">https://www.tidyverse.org/blog/2021/03/workflowsets-0-0-1/</a></li>
<li><a href="https://www.kaggle.com/c/sliced-s01e02-xunyc5" class="uri">https://www.kaggle.com/c/sliced-s01e02-xunyc5</a></li>
<li><a href="https://juliasilge.com/blog/sliced-aircraft/" class="uri">https://juliasilge.com/blog/sliced-aircraft/</a></li>
<li><a href="https://topepo.github.io/caret/subsampling-for-class-imbalances.html" class="uri">https://topepo.github.io/caret/subsampling-for-class-imbalances.html</a></li>
<li><a href="https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/what-is-imbalanced-classification/" class="uri">https://machinelearningmastery.com/what-is-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/" class="uri">https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/</a></li>
<li><a href="https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-06-28-imbalanced-workflowsets/">Otimizando pipelines que envolvem dados desbalanceados</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">imbalanced</category>
      <category domain="tag">imbalanced-data</category>
      <category domain="tag">kaggle</category>
      <category domain="tag">machine-learning</category>
      <category domain="tag">pratica</category>
      <category domain="tag">r</category>
      <category domain="tag">random-forest</category>
      <category domain="tag">tidymodels</category>
      <category domain="tag">tidyverse</category>
      <category domain="tag">tunning</category>
    </item>
    <item>
      <title>Prevendo a qualidade do sono utilizando Machine Learning</title>
      <link>https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/</guid>
      <description>Utilizaremos dados reais coletados pelo celular para gerar previs√µes a partir de uma pequena base de dados com target desbalanceada</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#qualidade-de-sono" id="toc-qualidade-de-sono">Qualidade de sono? ü§®</a></li>
<li><a href="#como-funciona-aplicativo-sleep-cycle" id="toc-como-funciona-aplicativo-sleep-cycle">Como funciona aplicativo Sleep Cycle? <img src="https://www.sleepcycle.com/wp-content/uploads/2020/09/sleep_cycle_app_icon-480x480.png" style="width:3.0%" /></a></li>
<li><a href="#objetivo" id="toc-objetivo">Objetivo üéØ</a></li>
<li><a href="#explorar-dados" id="toc-explorar-dados">Explorar dados üîé</a>
<ul>
<li><a href="#limpeza-e-prepara%C3%A7%C3%A3o-dos-dados" id="toc-limpeza-e-prepara√ß√£o-dos-dados">Limpeza e prepara√ß√£o dos dados</a></li>
<li><a href="#imputar-dados-de-fontes-externas" id="toc-imputar-dados-de-fontes-externas">Imputar dados de fontes externas</a></li>
<li><a href="#insights" id="toc-insights">Insights</a></li>
<li><a href="#reter-dados" id="toc-reter-dados">Reter dados</a></li>
</ul></li>
<li><a href="#modelagem" id="toc-modelagem">Modelagem üöÄ</a>
<ul>
<li><a href="#amostragem" id="toc-amostragem">Amostragem</a></li>
<li><a href="#engenharia-de-recursos" id="toc-engenharia-de-recursos">Engenharia de recursos</a></li>
<li><a href="#modelo-nulo-baseline" id="toc-modelo-nulo-baseline">Modelo Nulo (Baseline)</a></li>
<li><a href="#%C3%A1rvore-de-decis%C3%B5es" id="toc-√°rvore-de-decis√µes">√Årvore de decis√µes</a></li>
<li><a href="#random-forest" id="toc-random-forest">Random Forest</a></li>
<li><a href="#lightgbm" id="toc-lightgbm">LightGBM</a></li>
</ul></li>
<li><a href="#sele%C3%A7%C3%A3o-do-modelo" id="toc-sele√ß√£o-do-modelo">Sele√ß√£o do modelo ü§î</a></li>
<li><a href="#previs%C3%A3o-em-dados-novos" id="toc-previs√£o-em-dados-novos">Previs√£o em dados novos üí´</a></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o üçª</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias üß≥</a></li>
</ul>
</div>

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 33%;
padding: 10px;
}

.column8 {
float: left;
width: 66%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>
<div id="qualidade-de-sono" class="section level1">
<h1>Qualidade de sono? ü§®</h1>
<p>Sim, exatamente! Neste post analisaremos dados de um <em>tracking</em> que venho fazendo desde 2017 com informa√ß√µes relacionadas √† um sono de qualidade.</p>
<div class="row">
<div class="column8">
<p>Boas noites de sono nos tornam mais felizes, mais saud√°veis, mais inteligentes, mais dispostos e evita problemas de cansa√ßo, falta de concentra√ß√£o, depress√£o e ansiedade.</p>
<p>Resumindo, a nossa qualidade de vida est√° diretamente ligada √† qualidade do nosso sono, pois ao dormir nosso corpo realiza fun√ß√µes extremamente importantes como por exemplo o fortalecimento do sistema imunol√≥gico, secre√ß√£o e libera√ß√£o de horm√¥nios, consolida√ß√£o da mem√≥ria, entre outras<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
</div>
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/mguPrVJAnEHIY/giphy.gif" alt="Via Giphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/mguPrVJAnEHIY/giphy.gif">Via Giphy</a></div>
</div>
</div>
</div>
<p>Alguns fatores podem auxiliar a determinar se uma noite foi bem dormida como por exemplo: a regularidade do hor√°rio de dormir e de acordar, a frequ√™ncia card√≠aca (bpm), n√∫mero de passos dados no dia, tempo na cama, tempo antes de dormir, ronco, tipo de clima etc..</p>
<div class="row">
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/xUPJPlFxssGpmLemru/giphy.gif" style="width:80.0%" alt="Via Gyiphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/xUPJPlFxssGpmLemru/giphy.gif">Via Gyiphy</a></div>
</div>
</div>
<div class="column8">
<p>Felizmente, existe um aplicativo chamado <a href="sleepcycle.com/">Sleep Cycle</a> que √© capaz de <em>trackear</em> todas essas informa√ß√µes durante o uso do app, dentre outras funcionalidades. Desde 2017 tenho acompanhado meu sono atrav√©s dele, principalmente pela funcionalidade de <a href="https://www.sleepcycle.com/how-sleep-cycle-works/">rastreio dos padr√µes de sono para despertar durante sua fase mais leve, sem um despertador convencional</a> e tenho curtido bastante!</p>
</div>
</div>
<p>A proposta principal do aplicativo √© monitorar os sinais do corpo para nos despertar suavemente quando estivermos no est√°gio de sono mais leve poss√≠vel, pois acordar durante o sono leve √© como acordar naturalmente descansado!</p>
</div>
<div id="como-funciona-aplicativo-sleep-cycle" class="section level1">
<h1>Como funciona aplicativo Sleep Cycle? <img src="https://www.sleepcycle.com/wp-content/uploads/2020/09/sleep_cycle_app_icon-480x480.png" style="width:3.0%" /></h1>
<p><small>Tradu√ß√£o livre de <a href="https://www.sleepcycle.com/how-sleep-cycle-works/"><em>How Sleep Cycle works</em></a>:</small></p>
<p>‚ÄúO funcionamento b√°sico desse aplicativo se baseia que nos mexemos predominantemente durante o sono leve. J√° durante o sono pesado, os m√∫sculos tendem a permanecer relaxados, e em sono REM a movimenta√ß√£o muscular abaixo do pesco√ßo fica paralizada.</p>
<p>Assim sendo √© poss√≠vel selecionar um hor√°rio que gostaria de acordar, como de 6:30 at√© 7:00, e o aplicativo rastrear√° os movimentos na cama para acordar apenas quando entrar em sono leve durnte este per√≠odo.</p>
<p>Dessa forma, estar√≠amos aumentando as chances de acordar mais bem-disposto, j√° que seu sono foi interrompido em uma fase mais leve de descanso.‚Äù</p>
<p>Vejamos dois gr√°ficos que exemplificam dois dos poss√≠veis cen√°rios de uma noite de sono:</p>
<div class="row">
<div class="column">
<center>
<strong>Exemplo 1 - sono regular</strong>
<img src="https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_regular_sleep.png" style="width:80.0%" alt="via SleepCycle.com" />
</br>
<small>Os picos representam os ciclos do sono, incluindo todas as fases do sono.</small>
</center>
</div>
<div class="column">
<center>
<strong>Exemplo 2 - sono irregular</strong>
<img src="https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_irregular_sleep.png" style="width:80.0%" alt="via SleepCycle.com" />
</br>
<small>Ciclos de sono mais irregulares, onde o usu√°rio provavelmente n√£o dormiu t√£o bem como em nosso primeiro exemplo.</small>
</center>
</div>
</div>
<p>Esta √© a principal informa√ß√£o coletada no aplicativo e que permite um ‚Äúdespertar tranquilo‚Äù!</p>
<!-- Agora que j√° entendemos as benef√≠cios de uma noite bem dormida, de onde v√™m os dados, como o app funciona e quantas horas proporcionam uma boa noite de sono, vamos direto ao objetivo deste post! -->
</div>
<div id="objetivo" class="section level1">
<h1>Objetivo üéØ</h1>
<p>Apesar do aplicativo captar diversos dados sobre a noite de sono, o ‚Äúhumor ao acordar‚Äù √© uma informa√ß√£o fornecida pelo usu√°rio assim que desativa o alarme, quando a seguinte tela √© exibida:</p>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/mood.jpg" style="width:80%;">
</center>
<p>Como houveram diversos dias em que utilizei o aplicativo mas n√£o assinalei o humor (seja por ter desativado o recurso por algum tempo ou simplesmente por ter ignorado üòÖ) vamos trabalhar para responder a seguinte pergunta:</p>
<blockquote>
<p>Qual foi a probabilidade de ter acordado de <strong>mal humor</strong> durante o per√≠odo de <em>tracking</em> do app, nos dias cujo esse dado √© faltante?</p>
</blockquote>
<p>Onde <strong>mal humor</strong> ser√° a classe positiva da <strong>target</strong>, traduzido nos dados da seguinte forma:</p>
<p><span class="math display">\[
mood=
\begin{cases}
Bom, &amp; \text{se}\  mood = Bom \\
Ruim, &amp; \text{c.c}\
\end{cases}
\]</span></p>
<p>Logo, <code>mood</code> ser√° bin√°ria, avaliando se o humor foi <code>Bom</code> ou <code>Ruim</code> ao acordar, onde <code>Ruim</code> a combina√ß√£o do status üòë (Ok) e üò° (Mau) e ser√° a classe mais importante para controlar os erros de previs√£o.</p>
<p>Tomei a liberdade de fazer essa transforma√ß√£o pois desde o in√≠cio do uso do app, marco como <code>Ruim</code> apenas quando realmente n√£o descansei de forma satisfat√≥ria. Isso pode ter ocorrido por diversos fatores, como por exemplo: acordar ap√≥s um pesadelo; acordar com barulho da rua ou de casa; acordar meio doente ou passando mal e por ai vai..</p>
<p>Por enquanto, estas informa√ß√µes ser√£o suficientes. Vejamos na an√°lise explorat√≥ria como se apresenta a vari√°vel target e quais dados dispon√≠veis para atingir tal objetivo.</p>
</div>
<div id="explorar-dados" class="section level1">
<h1>Explorar dados üîé</h1>
<p>Carregar as depend√™ncias:</p>
<pre class="r"><code>library(tidyverse)  # datascience toolkit 
library(lubridate)  # manipule date
library(patchwork)  # grid ggplot
library(tidymodels) # machine learning toolkit
library(reactable)  # print tables 
library(treesnip)   # lightgbm

# Definir tema para ggplot
theme_set(theme_bw()) </code></pre>
<p>Vamos carregar fun√ß√µes que foram desenvolvidas ao longo das an√°lises para facilitar tanto na apresenta√ß√£o dos resultados quanto na portabilidade dos c√≥digos (bastando pequenos ajustes para ‚Äúrecicl√°-los‚Äù ‚ôªÔ∏è):</p>
<details>
<summary>
(<em>Clique aqui para exibir as fun√ß√µes customizadas</em>)
</summary>
<pre class="r"><code># Para o print de tabelas
print_table &lt;- function(x, round=0, evalue_model = F, ...){ 
  
  if(round&gt;0) x &lt;- x %&gt;% mutate_if(is.numeric, ~round(.x, round))
  
  if(evalue_model == T){
    
    reactable::reactable(x, striped = T, bordered = T, 
                         highlight = T, pagination = F,
                         width = 800,
                         defaultColDef = colDef(minWidth = 85),
                         defaultSorted = list(auc_pr = &quot;desc&quot;),
                         columns = list(
                           model = colDef(minWidth = 110),
                           tp = colDef(minWidth = 40),
                           fp = colDef(minWidth = 40),
                           fn = colDef(minWidth = 40),
                           tn = colDef(minWidth = 40)),
                         ...)  
    
  }else{
    reactable::reactable(x, striped = T, bordered = T, width = 800,
                         highlight = T, pagination = F, ...)  
  }
  
  
}

# Graficos de features numericas
plot_num &lt;- function(data, num_feature, 
                     title = NULL, bins = 30, legend = NULL){
  
  if(is.null(title)) title = num_feature
  
  data = data %&gt;% filter(!is.na(mood))
  
  p_shapiro = round(shapiro.test(data$air_pressure_pa)$p.value, 5)
  
  p1 &lt;- 
    data %&gt;% 
    ggplot(aes_string(x = num_feature, fill = &quot;mood&quot;))+
    geom_histogram(aes(y=..density..), bins = bins, alpha = 0.5,
                   show.legend = ifelse(!is.null(legend), T, F))+
    geom_density(alpha = 0.5,
                 show.legend = ifelse(!is.null(legend), T, F))+
    labs(y = &quot;&quot;, x= &quot;&quot;, title = title)+
    scale_fill_viridis_d(end = 0.8, direction = 1)
  
  if(!is.null(legend)){
    p1 = p1 + theme(legend.position = legend)
  }
  
  p2 &lt;- 
    data %&gt;% 
    ggplot(aes_string(x = num_feature))+
    geom_boxplot(aes(y = &quot;&quot;, color = mood), 
                 show.legend = F)+
    labs(y = &quot;&quot;, x= &quot;&quot;, 
         caption = paste0(&quot;Shapiro-Wilk normality test: &quot;,
                          ifelse(p_shapiro == 0, &quot;P&lt;0.05&quot;, p_shapiro) ))+
    scale_color_viridis_d(end = 0.8, direction = 1)
  
  p1 / p2  + plot_layout(heights = c(4/5, 1/5))
}  

# Graficos de features categoricas
plot_cat &lt;- function(data, cat_feature, title = NULL, label = TRUE, legend = NULL){
  
  data = data %&gt;% filter(!is.na(mood))
  
  valor_p = round(chisq.test(data %&gt;% pull(cat_feature), 
                             data$mood, 
                             simulate.p.value = T)$p.value, 5)
  
  to_plot = data %&gt;%
    count(!!as.name(cat_feature), mood) %&gt;% 
    group_by(!!as.name(cat_feature)) 
  
  final_plot = to_plot %&gt;% 
    mutate(prop = n/sum(n),
           lab = paste0(round(prop*100, 2), &quot;%&quot;)) %&gt;% 
    ggplot()+
    geom_bar(aes_string(x = cat_feature, y = &quot;n&quot;, fill = &quot;mood&quot;),
             stat = &quot;identity&quot;, alpha = 0.7, 
             position = position_dodge2(0.9),
             show.legend = ifelse(!is.null(legend), T, F))+
    scale_fill_viridis_d(end = 0.8, direction = 1)+
    labs(title = title, y = &quot;&quot;,
         caption = paste0(&quot;Pearson&#39;s Chi-squared test: &quot;, valor_p))
  
  if(label == TRUE){
    final_plot = final_plot+
      geom_label(aes_string(x = cat_feature, y = &quot;n&quot;, label = &quot;lab&quot;),
                 position = position_dodge2(0.9), show.legend = F)  
  }
  
  if(!is.null(legend)){
    final_plot = final_plot + theme(legend.position = legend)
  }
  
  return(final_plot)
  
}

# Grafico interativo de features temporais
plot_dygraph &lt;- function(x, order.by, feature, title = NULL){
  x %&gt;%  
    xts::xts(order.by = order.by) %&gt;% 
    .[,feature] %&gt;%
    dygraphs::dygraph(main = title) %&gt;% 
    dygraphs::dyRangeSelector()
}

# Calcula o ponto de corte que maximiza a funcao f beta
threshold_max &lt;- function(x){
  
  fbeta &lt;- function(precision, recall){ 
    (beta+1)*(precision*recall)/(beta*(precision+recall))
  }
  
  # https://machinelearningmastery.com/fbeta-measure-for-machine-learning/
  # F05: + precision - recall
  # F1 : + precision + recall
  # F2 : - precision + recall 
  beta = 0.5
  
  x  %&gt;%
    pr_curve(mood, .pred_Ruim) %&gt;% 
    mutate(fbeta = fbeta(precision, recall) ) %&gt;% 
    filter(fbeta == max(fbeta, na.rm = T))
}

# Plot da matriz de confusao e da funcao das funcoes de densidade estimadas
conf_mat_plot &lt;- function(x, null_model = FALSE){
  trs &lt;- threshold_max(x)$.threshold
  
  if(null_model==FALSE){
    x &lt;- x %&gt;% 
      mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs, &quot;Ruim&quot;, &quot;Bom&quot;) %&gt;%
               factor(levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE))  
  }
  
  p1 &lt;- 
    x %&gt;%
    select(.pred_class, mood) %&gt;%
    table() %&gt;% 
    conf_mat() %&gt;% 
    autoplot(type = &quot;heatmap&quot;)+
    labs(title = &quot;Matriz de Confusao&quot;,
         subtitle = paste0(&quot;Threshold max F0.5: &quot;, round(trs, 4)))
  
  p2 &lt;- 
    x  %&gt;%
    ggplot() +
    geom_density(aes(x = .pred_Ruim, fill = mood), 
                 alpha = 0.5)+
    labs(title = &quot;Distribui√ß√µes de probabilidade previstas&quot;,
         subtitle = &quot;por classe&quot;)+ 
    scale_x_continuous(limits = 0:1)+
    geom_vline(aes(xintercept = trs, color = &quot;threshold max F0.5&quot;), linetype = 2) +
    scale_color_manual(name = &quot;&quot;, values = c(`threshold max F0.5` =  &quot;red&quot;))+
    scale_fill_viridis_d(end = 0.7, direction = 1)
  
  p1 | p2
} 

# Conjunto de metricas utilizadas para avaliar os modelos
evalue_model &lt;- function(x, model = &quot;&quot;, null_model=FALSE){
  
  trs &lt;- threshold_max(x)$.threshold
  
  if(null_model==FALSE){
    x &lt;- x %&gt;%
      mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs, &quot;Ruim&quot;, &quot;Bom&quot;) %&gt;% 
               factor(levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE))
  }
  
  cm &lt;- x %&gt;% 
    select(.pred_class, mood) %&gt;% 
    table() 
  
  tibble(
    model = model,
    tp = cm[1,1],
    fp = cm[1,2],
    fn = cm[2,1],
    tn = cm[2,2],
    auc_roc   = yardstick::roc_auc(x, mood, `.pred_Ruim`)$.estimate,
    auc_pr    = yardstick::pr_auc(x, mood, `.pred_Ruim`)$.estimate,
    logloss   = yardstick::mn_log_loss_vec(x$mood, x$.pred_Ruim),
    f1        = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 1),
    f05       = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 0.5),
    f2        = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 2),
    precision = yardstick::precision_vec(x$mood, x$.pred_class),
    recall    = yardstick::recall_vec(x$mood, x$.pred_class),
    trs_fbeta = trs
  ) 
}  

plot_auc &lt;- function(x){
  
  p1 &lt;-  
    x %&gt;% 
    group_by(model) %&gt;%
    roc_curve(mood, .pred_Ruim) %&gt;%
    ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
    geom_line(size = 1, alpha = 0.5, show.legend = F) +
    geom_abline(lty = 2, alpha = 0.5, color = &quot;gray50&quot;, size = 1.3)+
    labs(title = &quot;AUC&quot;)+
    scale_color_viridis_d(direction = 1)
  
  p2 &lt;- 
    x %&gt;%
    group_by(model) %&gt;%
    pr_curve(mood, .pred_Ruim) %&gt;%
    ggplot(aes(x = recall, y = precision, color = model)) +
    geom_line(size = 1.15, alpha = 0.5) +
    # geom_abline(slope = -1, intercept = 1, lty = 2, alpha = 0.5, color = &quot;gray50&quot;, size = 1.2)+
    labs(title = &quot;PR AUC&quot;)+
    theme(legend.position = &quot;right&quot;)+
    scale_color_viridis_d(direction = 1)
  
  (p1 | p2)
}</code></pre>
</details>
<p>¬†</p>
<p>Importar os dados obtidos no app <a href="https://www.sleepcycle.com/">SleepCycle</a> e padronizar nomes das colunas:</p>
<pre class="r"><code>sleep &lt;- read_csv2(&quot;sleepdata.csv&quot;) %&gt;% janitor::clean_names(case = &quot;snake&quot;)</code></pre>
<p>A seguir, uma tabela com uma descri√ß√£o do conte√∫do de cada coluna:</p>
<table>
<colgroup>
<col width="9%" />
<col width="11%" />
<col width="79%" />
</colgroup>
<thead>
<tr class="header">
<th>Coluna</th>
<th>Descri√ß√£o curta</th>
<th>Descri√ß√£o detalhada</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>start</strong></td>
<td>In√≠cio</td>
<td>In√≠cio do monitoramento</td>
</tr>
<tr class="even">
<td><strong>end</strong></td>
<td>Fim</td>
<td>Fim do monitoramento</td>
</tr>
<tr class="odd">
<td><strong>sleep_quality</strong></td>
<td>Qualidade do Sono</td>
<td>Qualidade do sono √© baseada em: tempo que passa a dormir, movimentos durante a noite e momentos em que est√° totalmente desperto</td>
</tr>
<tr class="even">
<td><strong>regularity</strong></td>
<td>Regularidade</td>
<td>Informa sobre a regularidade do hor√°rio de dormir e de acordar durante um per√≠odo de tempo. Quanto maior, mais regular tem sido o hor√°rio de acordar e dormir e isso pode resultar em um sono melhor</td>
</tr>
<tr class="odd">
<td><strong>mood</strong> üéØ</td>
<td>Humor</td>
<td>Humor informado no app ao acordar: üòÉ (Bom), üòë (Ok), üò° (Mau), ‚õî (N√£o informado)</td>
</tr>
<tr class="even">
<td><strong>heart_rate_bpm</strong></td>
<td>Frequ√™ncia card√≠aca (bpm)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>steps</strong></td>
<td>Passos</td>
<td>Quantos passos d√° por dia (bom a partir de 10.000 passos por dia)</td>
</tr>
<tr class="even">
<td><strong>alarm_mode</strong></td>
<td>Modo de alarme</td>
<td>Alarme ligado ou apenas monitoramento</td>
</tr>
<tr class="odd">
<td><strong>air_pressure_pa</strong></td>
<td>Press√£o do Ar (Pa)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>city</strong></td>
<td>Cidade</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>movements_per_hour</strong></td>
<td>Movimentos por hora</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>time_in_bed_seconds</strong></td>
<td>Tempo na cama (segundos)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>time_asleep_seconds</strong></td>
<td>Tempo adormecido (segundos)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>time_before_sleep_seconds</strong></td>
<td>Tempo antes de dormir (segundos)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>window_start</strong></td>
<td>In√≠cio da janela</td>
<td>In√≠cio do modo soneca</td>
</tr>
<tr class="even">
<td><strong>window_stop</strong></td>
<td>Fim da janela</td>
<td>Fim do modo soneca</td>
</tr>
<tr class="odd">
<td><strong>did_snore</strong></td>
<td>Ronco</td>
<td>Detector de ru√≠dos (pode captar outros barulhos que n√£o seja ronco)</td>
</tr>
<tr class="even">
<td><strong>snore_time</strong></td>
<td>Hora do ronco</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>weather_temperature_c</strong></td>
<td>Temperatura (¬∞C)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>weather_type</strong></td>
<td>Tipo de clima</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>notes</strong></td>
<td>Notas</td>
<td>Alguma nota ao acordar</td>
</tr>
</tbody>
</table>
<p>¬†</p>
<div id="limpeza-e-prepara√ß√£o-dos-dados" class="section level2">
<h2>Limpeza e prepara√ß√£o dos dados</h2>
<p>Vamos realizar uma limpeza inicial, preparando os dados para possibilitar as an√°lise em um objeto <code>tibble</code> minimamente arrumado:</p>
<pre class="r"><code>sleep &lt;- sleep %&gt;% 
  # fix target
  mutate(mood = case_when(mood == &quot;Bom&quot; ~ &quot;Bom&quot;,
                          mood == &quot;Mau&quot; ~ &quot;Ruim&quot;,
                          mood == &quot;Ok&quot; ~ &quot;Ruim&quot;,
                          is.na(mood) ~ NA_character_),
         mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;% 
  # fix window
  mutate_at(c(&quot;window_start&quot;, &quot;window_stop&quot;), 
            ~ifelse(is.na(.x), end, .x)) %&gt;% 
  # fix string %
  mutate_at(c(&quot;sleep_quality&quot;, &quot;regularity&quot;),
            ~ .x %&gt;% str_remove(&quot;%&quot;) %&gt;% as.numeric() ) %&gt;% 
  # fix heart_rate_bpm e criar bug indicator 
  mutate(heart_rate_bug = ifelse(heart_rate_bpm == 0, &quot;sim&quot;, &quot;nao&quot;)) %&gt;% 
  mutate(heart_rate_bpm = ifelse(heart_rate_bpm == 0, 
                                 NA_integer_, heart_rate_bpm)) %&gt;% 
  # fix dados de soneca
  mutate(snore_time = as.numeric(snore_time),
         did_snore = ifelse(did_snore == TRUE, &quot;sim&quot;, &quot;nao&quot;)) %&gt;% 
  # fix para numerico
  mutate_at(c(&quot;time_before_sleep_seconds&quot;, 
              &quot;time_asleep_seconds&quot;, 
              &quot;time_in_bed_seconds&quot;),
            ~as.numeric(.x) ) %&gt;% 
  # fix movements_per_hour para double
  mutate(movements_per_hour = as.double(movements_per_hour)) %&gt;% 
  # fix weather_type
  mutate(weather_type = 
           factor(weather_type, 
                  levels = c(&quot;No weather&quot;, &quot;Rain&quot;, &quot;Rainy showers&quot;, &quot;Cloudy&quot;,
                             &quot;Partly cloudy&quot;, &quot;Fair&quot;, &quot;Sunny&quot;),
                  ordered = TRUE))  %&gt;% 
  mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
            ~ as.numeric(.x) %&gt;% if_else(. == 0, NA_real_, .)) %&gt;% 
  # remover unused columns
  select(-one_of(c(&quot;city&quot;, &quot;notes&quot;))) %&gt;% 
  select(mood, everything()) %&gt;% 
  arrange(end)</code></pre>
<p>Qual a estrutura geral dos dados? Ser√° que existe algum padr√£o nos dados ausentes?</p>
<pre class="r"><code>sleep %&gt;% 
  arrange(end) %&gt;% 
  mutate(Date = as.Date(end))%&gt;%
  # complete(Date = seq.Date(min(Date), max(Date), by=&quot;day&quot;))  %&gt;%  
  visdat::vis_dat() </code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-7-1.png" style="width:80.0%" />
</center>
<p>Os dados ausentes ocorrem tanto espalhados (<code>heart_rate_bpm</code>) quanto em sequ√™ncia (<code>air_pressure_pa</code>, <code>weather_temperature_c</code>, <code>mood</code>) portando, adotaremos as seguintes estrat√©gias para inputar dados ausentes:</p>
<ol style="list-style-type: decimal">
<li><code>air_pressure_pa</code>: Ser√° obtidos no site <a href="https://www.data.rio/datasets/dados-hor%C3%A1rios-do-monitoramento-da-qualidade-do-ar-monitorar?selectedAttribute=Pres">data.rio/datasets</a> e caso ainda exista dados ausentes, ser√° preenchido com as m√©dias m√≥veis dos √∫ltimos 7 dias;</li>
<li><code>weather_temperature_c</code>: Mesma estrat√©gia do item (1);</li>
<li><code>heart_rate_bpm</code>: C√°lculo das m√©dias m√≥veis dos √∫ltimos 7 dias;</li>
<li><code>mood</code>: Como √© a <em>target</em>, as inst√¢ncias aonde <code>is.na(mood)</code> ser√£o retidas para estima√ß√£o ap√≥s o ajuste do modelo.</li>
</ol>
</div>
<div id="imputar-dados-de-fontes-externas" class="section level2">
<h2>Imputar dados de fontes externas</h2>
<p>O preenchimento das features <code>air_pressure_pa</code>, <code>weather_temperature_c</code> ser√£o realizados a partir do download de dados p√∫blicos do Rio de Janeiro no link: <a href="https://www.data.rio/datasets/dados-hor%C3%A1rios-do-monitoramento-da-qualidade-do-ar-monitorar?selectedAttribute=Pres">data.rio/datasets</a>. Para obter este dado utilizaremos a fun√ß√£o <code>get_rj_data()</code> desenvolvida para este post, que est√° omitida mas para quem tiver interesse basta conferir clicando no item abaixo:</p>
<details>
<summary>
(<em>C√≥digo da fun√ß√£o <code>get_rj_data()</code></em>)
</summary>
<pre class="r"><code>get_rj_data &lt;- function(){ 
  
  if(!file.exists(&quot;rj_data.rds&quot;)){ 
    
    url &lt;- &quot;https://opendata.arcgis.com/datasets/5b1bf5c3e5114564bbf9b7a372b85e17_2.csv?outSR=%7B%22latestWkid%22%3A4326%2C%22wkid%22%3A4326%7D&quot;
    
    download.file(url, &quot;rj_data.csv&quot;)
    
    rj_data &lt;- readr::read_csv(&quot;rj_data.csv&quot;)
    
    saveRDS(rj_data, &quot;rj_data.rds&quot;)
    
  }else{
    rj_data &lt;- readRDS(&quot;rj_data.rds&quot;)
  }
  
  # preparar dados de pressao atmosferica e temperatura no periodo desejado
  rj_data &lt;- rj_data %&gt;% 
    mutate(Data = ymd_hms(Data)) %&gt;% 
    filter(Data &gt;= min(sleep$start) &amp;  Data &lt;= max(sleep$start)) %&gt;% 
    group_by(Data = as.Date(Data)) %&gt;% 
    summarise(air_pressure_pa = mean(Pres/10, rm.na=T),
              weather_temperature_c = mean(Temp, rm.na=T))
  
  return(rj_data)
  
}</code></pre>
</details>
<!-- &nbsp; -->
<p>Com acesso aos dados, hora de combinar as bases e preencher os dados faltantes:</p>
<pre class="r"><code>sleep &lt;- sleep %&gt;% 
  mutate(Data = as.Date(start)) %&gt;%
  # to numeric
  mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
            ~ as.numeric(.x) %&gt;% if_else(. == 0, NA_real_, .)) %&gt;% 
  # join Rio data
  left_join(get_rj_data() , by = c(&quot;Data&quot;)) %&gt;% 
  # fill with new data
  mutate(air_pressure_pa = ifelse(is.na(air_pressure_pa.x),
                                  air_pressure_pa.y,
                                  air_pressure_pa.x)) %&gt;%
  mutate(weather_temperature_c = ifelse(is.na(weather_temperature_c.x),
                                        weather_temperature_c.y, 
                                        weather_temperature_c.x)) %&gt;%
  # remove aux columns
  select(-air_pressure_pa.x, -air_pressure_pa.y,
         -weather_temperature_c.x, -weather_temperature_c.y,
         -Data)</code></pre>
</div>
<div id="insights" class="section level2">
<h2>Insights</h2>
<p>Nesta se√ß√£o vamos responder algumas perguntas com dados!</p>
<div id="start-e-end" class="section level3">
<h3><code>start</code> e <code>end</code></h3>
<p>Qual a m√©dia mensal de horas dormidas e que horas costumo acordar, em m√©dia, mensalmente ao longo desses anos?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>dy1 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(dif_sleep_hours = as.numeric(end - start)/60) %&gt;% 
  mutate(dif_sleep_hours = zoo::rollmean(dif_sleep_hours, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;dif_sleep_hours&#39;)

dy2 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(end_hour = hour(end)) %&gt;% 
  mutate(end_hour = zoo::rollmean(end_hour, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;end_hour&#39;)</code></pre>
</details>
<p>¬†¬†</p>
<!-- <div class="row"> -->
<!-- <div class="column"> -->
<!-- <center> -->
<!-- **Tempo dormindo (em horas)** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3,echo = F} -->
<!-- dy1 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O tempo que passa dormindo parece variar (em m√©dia) em torno de 6 √† 7 horas</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- <div class="column"> -->
<!-- <center>   -->
<!-- **Hora que acorda** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3,echo = F} -->
<!-- dy2 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O pico no in√≠cio no gr√°fico corresponde ao pen√∫ltimo semestre da facultado. No final de 2017 comecei a trabalhare passei a acordar mais cedo  </small> -->
<!-- </center> -->
<!-- </div> -->
<!-- </div> -->
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img1.png" style="width:80.0%" /></p>
<div class="w3-panel w3-sand w3-border">
<p>‚ö†Ô∏è Note que existem alguns espa√ßos vazios, que correspondem aos dias que o app n√£o foi utilizado.</p>
</div>
</div>
<div id="window_start-e-window_stop" class="section level3">
<h3><code>window_start</code> e <code>window_stop</code></h3>
<p>Quanto tempo costumo usar o modo ‚Äúsoneca‚Äù ao longo da semana? E aos finais de semana?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>p &lt;- sleep %&gt;% 
  mutate(mood = ifelse(is.na(mood), &quot;NA&quot;, as.character(mood)) %&gt;% 
           factor(levels = c(&quot;Ruim&quot;, &quot;NA&quot;, &quot;Bom&quot;))) %&gt;% 
  mutate(nap_minutes = (window_stop - window_start) / 30,
         final_de_semana = lubridate::wday(start) %in% c(1, 7)) %&gt;% 
  count(mood, final_de_semana, nap_minutes) %&gt;% 
  group_by(mood, final_de_semana) %&gt;% 
  mutate(
    fnap_minutes = case_when(
      nap_minutes == 0 ~ &quot;Sem modo soneca&quot;,
      nap_minutes == 20 ~ &quot;20 minutos&quot;,
      nap_minutes == 30 ~ &quot;30 minutos&quot;,
      nap_minutes == 60 ~ &quot;1 hora&quot;),
    fnap_minutes = reorder(fnap_minutes, nap_minutes),
    final_de_semana = ifelse(final_de_semana == T, &quot;Final de semena&quot;, &quot;Dia de semana&quot;),
    label = paste0( n, &quot; (&quot;, round(n/sum(n)*100, 2), &quot;%)&quot;)
  ) %&gt;% 
  ggplot(aes(x = fnap_minutes, y = n, label = label, fill = mood))+
  geom_bar(stat = &quot;identity&quot;, alpha = 0.8)+
  scale_fill_viridis_d(end = 0.7, direction = 1)+
  # ggrepel::geom_label_repel(aes(label = label))+
  labs(x = &quot;&quot;, y = &quot;&quot;)+
  facet_wrap(~final_de_semana)+
  theme(axis.text.x = element_text(angle = 30, hjust=1))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>p %&gt;% plotly::ggplotly() %&gt;% plotly::config(displayModeBar = F)</code></pre>
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img2.png" style="width:80.0%" /></p>
<p>Como era de se esperar, os dias em que <code>mood=="Ruim"</code> ocorrem mais quando o modo soneca n√£o √© ativado pois acaba mesmo sendo menos prop√≠cio a voltar a dormir. Outro detalhe √© que muitas vezes usei o soneca por um tempo muito prolongado! (üò± pelo menos <code>mood=="Bom"</code> na maioria desses casos!)</p>
<p>J√° nos finais de semana, ocorre pouqu√≠ssimo <code>mood== "Ruim"</code> e praticamente n√£o h√° uso do alarme e quando h√°, n√£o utiliza soneca.</p>
</div>
<div id="weather_type-e-alarm_mode" class="section level3">
<h3><code>weather_type</code> e <code>alarm_mode</code></h3>
<p>Ser√° que o humor ao acordar esta relacionado com o tipo de clima ou com o modo utilizado no alarme?</p>
<pre class="r"><code>p1 &lt;- plot_cat(sleep, cat_feature=&quot;weather_type&quot;, 
               title = &quot;Tipo de clima&quot;, label = F)+ 
  theme(axis.text.x = element_text(angle = 30, hjust=1))

p2 &lt;- plot_cat(sleep, cat_feature=&quot;alarm_mode&quot;, 
               title = &quot;Modo de alarme&quot;, label = F, legend = &quot;right&quot;)

p1 | p2</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-15-1.png" style="width:80.0%" />
</center>
<p>Nota-se que n√£o existem evid√™ncias estatisticas para afimar que essas features (sozinhas) est√£o associadas √† target, por√©m como ser√£o utilizados modelos baseados em √°rvores que experimentam diversas combina√ß√µes de features, vamos manter na base e deixar o modelo decidir como usar.</p>
</div>
<div id="sleep_quality-e-time_in_bed_seconds" class="section level3">
<h3><code>sleep_quality</code> e <code>time_in_bed_seconds</code></h3>
<p>A qualidade de sono e o tempo da cama est√£o normalmente distribu√≠dos em torno de uma m√©dia?</p>
<pre class="r"><code>p1 &lt;- sleep %&gt;% plot_num(&quot;sleep_quality&quot;)
p2 &lt;- sleep %&gt;% plot_num(&quot;time_in_bed_seconds&quot;, legend = &quot;right&quot;)

p1 | p2</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-16-1.png" style="width:80.0%" />
</center>
<p>Existem alguns registros em que o tempo na cama √© menor que 10.000 segundos (~3horas) o que corresponde aos pequenos cochilos que registrei no app. N√£o foram muitos registros mas talvez seja √∫til na modelagem pois existem ocorr√™ncias de humor (<code>mood</code>) <code>Bom</code> e <code>Ruim</code> ali.</p>
<p>Como a correla√ß√£o de spearman entre estas duas feautures √© muito alta (0.8705) √© poss√≠vel notar que baixa qualidade do sono esta altamente correlacionada com o tempo na cama.</p>
<p>Mais uma pergunta sobre estas features: Como a m√©dia mensal da qualidade do sono e do tempo na cama em horas est√£o distribu√≠dos ao longo do tempo?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>dy1 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)),
                            max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(sleep_quality = zoo::rollmean(sleep_quality, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;sleep_quality&#39;)

dy2 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), 
                            max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(time_in_bed_seconds = 
           zoo::rollmean(time_in_bed_seconds, k =  30, fill = NA)) %&gt;%
  mutate(time_in_bed_seconds = time_in_bed_seconds / 60 / 60) %&gt;% 
  plot_dygraph(order.by = .$start, feature =  &#39;time_in_bed_seconds&#39;)</code></pre>
</details>
<p>¬†¬†</p>
<!-- <div class="row"> -->
<!-- <div class="column"> -->
<!-- <center> -->
<!-- **Qualidade do sono** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3, echo = F} -->
<!-- dy1 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>Parece que a qualidade do sono vem aumentando desde final de 2019, mantendo um patamar semlhante ao final e 2018.</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- <div class="column"> -->
<!-- <center>   -->
<!-- **Tempo na cama em horas** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3, echo = F} -->
<!-- dy2 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O tempo na cama varia entre 6 √† 7 horas (Apesar de alguns picos em 2020, provavelmente por conta da pandemia do corona virus quando estabeleceu-se o home office)</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- </div> -->
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img3.png" style="width:80.0%" /></p>
</div>
</div>
<div id="reter-dados" class="section level2">
<h2>Reter dados</h2>
<p>Antes de iniciar o processo de modelagem, ser√° necess√°rio reter dados aonde <code>mood</code> √© <code>NA</code>, pois faremos as previs√µes nestes dados apenas ap√≥s o ajuste e sele√ß√£o do modelo final.</p>
<pre class="r"><code>new_sleep &lt;- sleep %&gt;% filter(is.na(mood))
sleep &lt;- sleep %&gt;% filter(!is.na(mood))</code></pre>
</div>
</div>
<div id="modelagem" class="section level1">
<h1>Modelagem üöÄ</h1>
<p>Hora de criar alguns modelos para estimar a probabilidade das classes da target: <code>mood</code>.</p>
Como estamos diante de um cen√°rio onde os dados est√£o desbalanceados, ser√° necess√°rio tomar algumas decis√µes muito importantes (sim, cientistas de dados precisam tomar decis√µes o tempo inteiro).
<div class="row">
<div class="column8">
<div class="center">
<span>
<div>
<p>Neste caso, as quest√µes s√£o as seguintes:</p>
<ol style="list-style-type: decimal">
<li>Qual a classe mais importante?</li>
<li>Qual a m√©trica ser√° utilizada para selecionar os modelos?</li>
<li>Qual ser√° o <em>threshold</em>?</li>
<li>Qual ser√° estrat√©gia para lidar com o desbalanceamento?</li>
<li>Quais m√©tricas ser√£o monitoradas?</li>
</ol>
</div>
<p></span></p>
</div>
</div>
<div class="column4">
<p></br>
<img src="https://media.giphy.com/media/XeH1MFu4x3etVsllUN/giphy.gif" alt="Via Giphy" /></p>
</div>
</div>
<p>A classe mais importante para nossa previs√£o √© a positiva, ou seja, <code>mood=="Ruim"</code>. Sendo assim desejamos <strong>evitar falsos positivos</strong>.</p>
<p>A m√©trica utilizada para selecionar os modelos ser√° a <a href="https://www.kaggle.com/dansbecker/what-is-log-loss"><strong>logloss</strong></a>. Esta √© uma m√©trica probabilistica que foca na incerteza que o modelo tem nas previs√µes e penaliza as previs√µes que est√£o erradas<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>Ap√≥s calibrar a probabilidade, estabeleceremos um ponto de corte que <strong>maximizar a medida F-Beta</strong>, (que √© uma abstra√ß√£o da medida <em>F1</em>, m√©dia harm√¥nica entre <em>Precision</em> e <em>Recall</em>) onde <em>Beta = 0.5</em>. Essa medida tem o efeito de aumentar a import√¢ncia da <em>Precision</em> e diminui a import√¢ncia do <em>Recall</em>. <a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Parra lidar com o desbalanceamento da <em>target</em>, utilizaremos o m√©todo de <em>undersampling</em> chamado ** <em>Tomek Links</em> **<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. Este m√©todo faz uma amostragem da classe majorit√°ria de forma ‚Äúmais esperta‚Äù que uma simples amostragem aleat√≥ria.</p>
<p>Por fim, a principal m√©trica que ser√° monitorada ser√° a <strong><em>AUC-PR</em></strong><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> (<em>Area Under Precision Recall Curve</em>). Ela √© uma esp√©cie de <em>AUC</em> que c√°lculada a √°rea sobre a <em>Precision</em> x <em>Recall</em>. Essa m√©trica √© prefer√≠vel neste caso pois foca maisn na classe positiva e a <em>ROC AUC</em> tente a superestimar os valores nesse caso.</p>
<div id="amostragem" class="section level2">
<h2>Amostragem</h2>
<p>Para preparar os dados para modelagem vamos dividir os dados em treino (70%) e teste (30%).</p>
<pre class="r"><code>set.seed(123456789)

# treino e teste
sleep_split &lt;- initial_split(data = sleep, strata = mood, prop = 0.7)
sleep_train &lt;- training(sleep_split)
sleep_test  &lt;- testing(sleep_split)</code></pre>
<p>Al√©m disso, vamos dividir o conjunto de treino em 4 folds para obter resultados de valida√ß√£o cruzada. Este valor corresponde metade da quantidade em que <code>mood=="Ruim"</code> nos dados teste.</p>
<pre class="r"><code>set.seed(123456789)
k_fold &lt;- sleep_test %&gt;% count(mood) %&gt;% filter(mood==&quot;Ruim&quot;) %&gt;% pull(n)

sleep_folds &lt;- sleep_train %&gt;% 
  rsample::vfold_cv(v = round(k_fold/2), repeats = 10, strata = mood)</code></pre>
<p>A decis√£o de utilizar o valor de <code>k</code> como metade do tamanho da classe minorit√°ria foi uma decis√£o pessoal, n√£o sei se √© √≥tima mas foi conveniente neste caso.</p>
<p>Como ficou dividido:</p>
<details>
<summary>
(<em>C√≥digo para tabela abaixo</em>)
</summary>
<pre class="r"><code>tab &lt;- 
  full_join(sleep_train %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            sleep_test %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            by = &quot;mood&quot;) %&gt;% 
  print_table(round = 2,
              columns = list(
                n.x = colDef(name = &quot;N&quot;),
                prop.x = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n.y = colDef(name = &quot;N&quot;),
                prop.y = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;)
              ), 
              columnGroups = list(
                colGroup(name = &quot;Train&quot;, columns = c(&quot;n.x&quot;, &quot;prop.x&quot;)),
                colGroup(name = &quot;Test&quot;, columns = c(&quot;n.y&quot;, &quot;prop.y&quot;))
              ))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>tab</code></pre>
<div class="w3-panel w3-pale-red w3-border">
<p>‚ò†Ô∏è A quantidade reduzida de dados para teste reflete a baixa quantidade de dados no geral!</p>
</div>
</div>
<div id="engenharia-de-recursos" class="section level2">
<h2>Engenharia de recursos</h2>
<p>Hora de criar o objeto que vai conter todos os passos do pr√©-processamento necess√°rio! Esse passo √© muito importante pois algumas estat√≠sticas precisam ser calculadas nos dados de treino isoladamente para n√£o ‚Äúdar pistas‚Äù para modelo sobre as informa√ß√µes contidas nos dados de teste, comprometendo o desempenho do modelo em novos dados.</p>
<p>De forma semelhante (mas n√£o igual) ao <code>sklearn.pipeline.Pipeline</code>, dispon√≠vel para Python, na linguagem R existe o pacote <code>recipes</code> que permite a cria√ß√£o de ‚Äúreceitas‚Äù com a fun√ß√£o <code>recipe()</code> e que pode ser utilizada em um <code>workflow()</code> para treinar o modelo na sequ√™ncia.</p>
<p>Sendo assim, algumas das opera√ß√µes realizadas no pr√©processamento do modelo:</p>
<ul>
<li>Criar feature: <code>ano</code>;</li>
<li>Criar feature: <code>mes</code>;</li>
<li>Criar feature: <code>dia da semana</code>;</li>
<li>Criar feature: <code>dia do mes</code>;</li>
<li>Criar feature: <code>hora que acordou</code>;</li>
<li>Criar feature: <code>final de semana</code>;</li>
<li>Criar feature: <code>tempo dormindo</code>;;</li>
<li>Criar feature: <code>tempo de soneca</code></li>
<li>Criar feature: <code>quarentena</code>;</li>
<li>Inputar m√©dia movel semanal para preencher as features de <code>weather_temperature_c</code> e <code>air_pressure_pa</code> no RJ;</li>
<li>Transformar categ√≥ricas em dummy;</li>
<li>Remover colunas com dados inv√°lidos para modelo (timestamp);</li>
<li>Preencher os dados faltantes de <code>heart_rate_bpm</code> utilizando o algor√≠tmo <code>knn</code> com 2 vizinhos mais pr√≥ximos;</li>
<li>Aplicar o algoritmo <em>Tomek Links</em>, que √© um m√©todo de <em>undersampling</em>.</li>
</ul>
<p>Caso queira saber mais sobre m√©todos de <em>undersampling</em> para tratar dados desbalanceados sugiro a leitura <a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/">deste excelente post</a>! (Os c√≥digos est√£o em Python por√©m a explica√ß√£o da teoria √© o que importa neste caso)</p>
<p>Preparar objeto <code>recipe</code> que cont√©m um conjunto de etapas para pr√©-processamento de dados:</p>
<pre class="r"><code>sleep_recipe &lt;- 
  recipe(mood~., data = sleep_train) %&gt;%
  step_ordinalscore(weather_type) %&gt;% 
  step_mutate(
    ano = factor(year(end)),
    mes = month(end),
    dia_semana = wday(end) %&gt;% ifelse(. == 7, 0, .),
    dia_mes = mday(end),
    end_hour = hour(end),
    final_de_semana = 
      ifelse(lubridate::wday(start) %in% c(1, 7),  &quot;sim&quot;, &quot;nao&quot;) %&gt;% as.factor(),
    dif_sleep_hours = as.numeric(end - start)/60,
    dif_nap = as.numeric(window_stop - window_start) / 60,
    quarentena = ifelse(start &gt; dmy(&quot;20/03/2020&quot;), &quot;sim&quot;, &quot;nao&quot;) %&gt;% as.factor(),
    nap_minutes = (window_stop - window_start) / 30
  ) %&gt;% 
  step_mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
                 fn = ~ imputeTS::na_ma(.x, k = 7, weighting = &quot;simple&quot;)) %&gt;% 
  step_dummy(all_nominal(), -all_outcomes())  %&gt;% 
  step_mutate_at(starts_with(&quot;ano&quot;), # Fix 2018 nos novos dados
                 fn = ~ ifelse(is.na(.x), 0, .x)) %&gt;% 
  step_rm(start, end, window_start, window_stop)%&gt;%
  step_knnimpute(heart_rate_bpm, neighbors = 2) %&gt;% 
  themis::step_tomek(mood) %&gt;%
  prep()

# bake(sleep_recipe, new_data = NULL)</code></pre>
<p>Finalmente! ü•µ</p>
<p>Com os dados devidamente preparados, vamos ligar as turbinas e partir para modelagem!</p>
<pre class="r"><code>doParallel::registerDoParallel(4)</code></pre>
</div>
<div id="modelo-nulo-baseline" class="section level2">
<h2>Modelo Nulo (Baseline)</h2>
<p>Este n√£o √© o tipo de modelo que serve para resolver problemas reais mas pode servir como um bom baseline (‚Äúpior que isso n√£o fica‚Äù) pois ele vai prever apenas a classe majorit√°ria, e com base nisso, poderemos comparar as m√©tricas de performance do ajuste para saber se nossos modelos est√£o (no m√≠nimo) performando melhor que um modelo que classifica unicamente 1 classe,</p>
<pre class="r"><code>null_model &lt;- null_model(mode = &quot;classification&quot;) %&gt;% 
  set_engine(&quot;parsnip&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>null_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(null_model) </code></pre>
<p>Realizar ajuste final nos dados de treino:</p>
<pre class="r"><code>null_final_fit_bas &lt;- null_wflow_bas %&gt;% last_fit(sleep_split) </code></pre>
<p>Coletar previs√µes nos dados de teste:</p>
<pre class="r"><code>null_test_preds_bas &lt;- collect_predictions(null_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>null_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot(null_model = T)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-31-1.png" style="width:80.0%" />
</center>
<p>Modelo nulo pronto! Vamos para a modelagem propriamente dita!</p>
</div>
<div id="√°rvore-de-decis√µes" class="section level2">
<h2>√Årvore de decis√µes</h2>
<p>Este algor√≠timo √© um √≥timo ponto de partida pois possui alta explicabilidade, gerando um plot intuitivo e muito f√°cil de interpretar. As <em>features</em> que aparecem no topo s√£o as mais importantes e cada n√≥ seguinte √© gerado a partir de regras que otimizam a divis√£o dos dados daquele ramo.</p>
<p>Existem recursos interessantes ao trabalhar com √°rvores, como determinar uma regra de parada ou ainda deixar a √°rvore crescer e depois realizar a poda. Primeiramente vamos ajusta uma √°rvore de decis√µes <em>default</em> e em seguida realizar algum tipo de tunning para tentar obter resultados melhores.</p>
<!-- `gini`: -->
<!-- Se selecionarmos dois itens de uma populacao aleatoriamente, entao eles devem ser da mesma classe e a probabilidade para isto √© 1 se a popula√ß√£o √© pura. -->
<div id="default" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>rpart</code> em <a href="https://cran.r-project.org/web/packages/rpart/rpart.pdf" class="uri">https://cran.r-project.org/web/packages/rpart/rpart.pdf</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do pacote <code>parsnip</code> em <a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="uri">https://parsnip.tidymodels.org/reference/decision_tree.html</a></p>
<pre class="r"><code>tree_model_bas &lt;- decision_tree(
  cost_complexity = 0.01, # cp
  tree_depth = 30,        # maxdepth
  min_n = 20              # minsplit
) %&gt;% 
  set_engine(&quot;rpart&quot;) %&gt;%
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>tree_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(tree_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>tree_res_bas &lt;- fit_resamples(
  tree_wflow_bas,
  sleep_folds,
  metrics = metric_set(pr_auc, roc_auc, mn_log_loss),
  control = control_resamples(save_pred = TRUE)
)
# Salvar &quot;cache&quot; da otimizacao 
saveRDS(tree_res_bas, &quot;tree_res_bas.rds&quot;)</code></pre>
<p>Finalizar o modelo:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
tree_final_wflow_bas &lt;- 
  finalize_workflow(
    tree_wflow_bas,
    select_best(tree_res_bas, metric = &#39;mn_log_loss&#39;) 
  )

# Realizar ajuste final nos dados de treino
tree_final_fit_bas &lt;- tree_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
tree_test_preds_bas &lt;- collect_predictions(tree_final_fit_bas)</code></pre>
<p>Vejamos como ficou o modelo baseline:</p>
<details>
<summary>
(<em>C√≥digo do objeto <code>tre_model_bas</code></em>)
</summary>
<pre class="r"><code>tre_model_bas &lt;- 
  tree_final_fit_bas$.workflow[[1]] %&gt;% 
  pull_workflow_fit()</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>rattle::fancyRpartPlot(tre_model_bas$fit, sub = NULL, cex = 0.6)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-38-1.png" style="width:80.0%" />
</center>
<p>Note que o modelo <em>default</em> se baseia nas features <code>time_before_sleep_seconds</code> e <code>steps</code>. Talvez, com outra combina√ß√£o de par√¢metros seja poss√≠vel conseguir um modelo uma √°rvore um pouco maior com resultado igual/melhor.</p>
<p>Como s√£o apenas duas features, √© poss√≠vel visualizar os regras de classifica√ß√£o a partir de um gr√°fio de dispers√£o</p>
<pre class="r"><code>sleep_train %&gt;%
  ggplot(aes(time_before_sleep_seconds, steps)) +
  parttree::geom_parttree(data = tre_model_bas$fit, alpha = 0.3) +
  geom_jitter(aes(color = mood), alpha = 0.7) +
  scale_color_viridis_d(end = 0.8, direction = 1)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-39-1.png" style="width:80.0%" />
</center>
<p>Vamos avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>tree_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-40-1.png" style="width:80.0%" />
</center>
<p>O modelo n√£o esta muito bom‚Ä¶ mas tamb√©m n√£o esta muito ruim para come√ßar! üòÖ</p>
<p>Coram 5/8 acertos para classe de interesse, vamos tentar fazer o tunning deste modelo!</p>
</div>
<div id="tunning" class="section level3">
<h3>Tunning</h3>
<p>Definir o modelo que ser√° utilizado:</p>
<pre class="r"><code>tree_model_tun &lt;- decision_tree(
  min_n = tune(),
  cost_complexity = tune(), 
  tree_depth = tune()
) %&gt;%
  set_engine(&quot;rpart&quot;) %&gt;%
  set_mode(&quot;classification&quot;)
# tree_model_tun %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>tree_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(tree_model_tun) </code></pre>
<p>O grid utilizado foi alterado para tentar previnir que a √°rvore tenha apenas o n√≥ raiz pois o grid default, combinado com o <em>threshold</em>, estava gerando um ‚Äúcotoco‚Äù.</p>
<ul>
<li><code>min_n</code>: [1, 5]</li>
<li><code>cost_complexity</code>: (transformed scale): [-10, -1]</li>
<li><code>tree_depth</code>: [10, 20]</li>
</ul>
<p>Definir um grid aleat√≥rio para otimiza√ß√£o dos hiperpar√¢metros:</p>
<pre class="r"><code>tree_params &lt;- 
  tree_model_tun %&gt;% 
  parameters() %&gt;%
  update(
    min_n = min_n(c(1, 5)), 
    cost_complexity = cost_complexity(),
    tree_depth = tree_depth(c(10, 20)) 
  )

tree_grid &lt;-grid_regular(tree_params, levels = 3)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>tree_res_tun &lt;- 
  tree_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = tree_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
# saveRDS(tree_res_tun, &quot;tree_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;%
  slice(1) %&gt;% 
  pull(.config)

plot_tree_tun &lt;- 
  tree_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)
         # cost_complexity = log(cost_complexity)-10
  ) %&gt;% 
  select(.metric, mean, best_model,
         cost_complexity:min_n) %&gt;%
  pivot_longer(cost_complexity:min_n,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% 
  mutate(parameter = case_when(
    parameter == &quot;cost_complexity&quot; ~ &quot;Cost-Complexity Parameter&quot;,
    parameter == &quot;tree_depth&quot; ~ &quot;Tree Depth&quot;,
    parameter == &quot;min_n&quot; ~ &quot;Minimal Node Size&quot;,
    
  ))%&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }
# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(tree_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_tree_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img4.png" style="width:80.0%" />
</center>
<p>5 Melhores resultados:</p>
<pre class="r"><code>show_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<pre><code>## # A tibble: 5 x 6
##   cost_complexity tree_depth min_n .metric      mean std_err
##             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1             0.1         10     1 mn_log_loss  1.64   0.212
## 2             0.1         15     1 mn_log_loss  1.64   0.212
## 3             0.1         20     1 mn_log_loss  1.64   0.212
## 4             0.1         10     3 mn_log_loss  1.64   0.212
## 5             0.1         15     3 mn_log_loss  1.64   0.212</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
tree_final_wflow_tun &lt;- 
  finalize_workflow(
    tree_wflow_tun,
    select_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
tree_final_fit_tun &lt;- tree_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
tree_test_preds_tun &lt;- collect_predictions(tree_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>tre_model_tun &lt;- pull_workflow_fit(tree_final_fit_tun$.workflow[[1]])</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>rattle::fancyRpartPlot(tre_model_tun$fit, sub = NULL, cex = 0.6)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-51-1.png" style="width:80.0%" />
</center>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>tree_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-52-1.png" style="width:80.0%" />
</center>
<p>Ao comparar o modelo default com o modelo ap√≥s o <em>tunning</em> √© poss√≠vel notar que o n√∫mero de verdadeiros positivos foi menor por√©m o n√∫mero de fasos positivos tbm foi menor devido ao elevado <code>trs_fbeta</code> encontrado (maximizando F0.5).</p>
<p>No geral, o modelo tunado ficou pior que o modelo default mas como o modelo de √°rvore de deci√µes costuma ser bem inst√°vel, ainda mais em um cen√°rio de dados desbalanceados vamos apenas guardar estes resultados e dar mais um passo, combinando diversas √°rvore de decis√µes!</p>
</div>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<p>O <em>Random Forest</em> √© um algoritmo que (de forma simplificada) realiza bootstrap em cima de √°rvores de decis√µes (modelos que utilizamos anteriormente) construindo modelos de √°rvores de decis√µes em diferentes amostras com diferentes combina√ß√µes de <em>features</em> e assim uma previs√£o final √© feita ap√≥s uma ‚Äúvota√ß√£o entre os modelos‚Äù.</p>
<div id="default-1" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>ranger</code> em <a href="https://cran.r-project.org/web/packages/ranger/ranger.pdf" class="uri">https://cran.r-project.org/web/packages/ranger/ranger.pdf</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do pacote <code>parsnip</code> em <a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="uri">https://parsnip.tidymodels.org/reference/rand_forest.html</a></p>
<pre class="r"><code># raiz quadrada do numero de features 
n_col = ncol(juice(sleep_recipe))

rf_model_bas &lt;- rand_forest(
  mtry = sqrt(n_col) %&gt;% floor(), # mtry
  trees = 500,                    # num.trees
  min_n = 1                       # min.node.size 
) %&gt;% 
  set_engine(&quot;ranger&quot;, num.threads = 4, importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>rf_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(rf_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>rf_res_bas &lt;- fit_resamples(
  rf_wflow_bas,
  sleep_folds,
  metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
  control = control_resamples(save_pred = TRUE)
)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
rf_final_wflow_bas &lt;- 
  finalize_workflow(
    rf_wflow_bas,
    select_best(rf_res_bas, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
rf_final_fit_bas &lt;- rf_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
rf_test_preds_bas &lt;- collect_predictions(rf_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>rf_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-58-1png" style="width:80.0%" />
</center>
<p>Este modelo n√£o fez nenhuma previs√£o de falso positivo! Por√©m note que o <code>trs_fbeta</code> ficou bastante alto, o que deve ter ocorrido como reflexo do elevado <code>logloss</code> que indicaria que a incerteza que o modelo tem nas previs√µes esta alta.</p>
</div>
<div id="tunning-1" class="section level3">
<h3>Tunning</h3>
<p>Definir o modelo que ser√° utilizado:</p>
<pre class="r"><code>rf_model_tun &lt;- rand_forest(
  mtry = tune(),
  trees = tune(), 
  min_n = tune()
) %&gt;% 
  set_engine(&quot;ranger&quot;, num.threads = 4, importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)
# tree_model %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>rf_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(rf_model_tun) </code></pre>
<p>O grid utilizado tentar√° valores superiores e inferiores ao n√∫mero de √°rvores <em>default</em> do algoritmo e vamos incluir o valor 1 ao <code>min_n</code> pois √°rvores mais longas neste m√©todo podem ser √∫teis. O <code>mtry</code> ser√° calculado baseado nas informa√ß√µes do dataset de treino.</p>
<ul>
<li><code>trees</code>: [100, 900]</li>
<li><code>min_n</code>: [1, 40]</li>
<li><code>mtry</code>: [1, 20]</li>
</ul>
<p>Definir t√©cnica de otimiza√ß√£o de hiperpar√¢metros</p>
<pre class="r"><code>rf_grid &lt;-grid_max_entropy(
  trees() %&gt;% range_set(c(100, 900)), # Default Range: [1, 2000]
  min_n() %&gt;% range_set(c(1, 40)),    # Default Range: [2, 40]
  finalize(mtry(), sleep_train),
  size = 30)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>rf_res_tun &lt;- 
  rf_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = rf_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
saveRDS(rf_res_tun, &quot;rf_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;%
  slice(1) %&gt;% 
  pull(.config)

plot_rf_tun &lt;- 
  rf_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)) %&gt;% 
  select(.metric, mean, best_model,
         mtry:min_n) %&gt;%
  pivot_longer(mtry:min_n,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% 
  mutate(parameter = case_when(
    parameter == &quot;mtry&quot; ~ &quot;Randomly Selected Predictors&quot;,
    parameter == &quot;min_n&quot; ~ &quot;Minimal Node Size&quot;,
    parameter == &quot;trees&quot; ~ &quot;# Trees&quot;
  )) %&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }
# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(rf_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_rf_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img5.png" style="width:80.0%" />
</center>
<p>Melhores resultados:</p>
<pre class="r"><code>show_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
rf_final_wflow_tun &lt;- 
  finalize_workflow(
    rf_wflow_tun,
    select_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
rf_final_fit_tun &lt;- rf_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
rf_test_preds_tun &lt;- collect_predictions(rf_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>rf_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-68-1.png" style="width:80.0%" />
</center>
<p>Note que apesar do maior n√∫mero de Verdadeiros Positivos, este modelo apresentou um Falso Positivo. Parece estranho pois √© exatamente o que queriamos evitar por√©m √© poss√≠vel notar que o <code>logloss</code> foi bem inferior e o <code>trs_fbeta</code> est√° bem mais razoavel agora.</p>
<p>Importancia de cada <em>feature</em> conforme o modelo:</p>
<pre class="r"><code>vip::vip(pull_workflow_fit(rf_final_fit_tun$.workflow[[1]]))</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-70-1.png" style="width:80.0%" />
</center>
<p>Diferente do modelo baseado em 1 unica √°rvore de decis√µes, a <em>feature</em> <code>steps</code> n√£o foi t√£o importante assim. A <code>time_asleep_seconds</code> foi a mais importante mas com a ordem de grandeza muito pr√≥xima de <code>time_before_sleep_seconds</code>.</p>
<p><em>Random Forest</em> √© um excelente modelo e poder√≠amos investir mais tempo tentando otimizando sua performance mas para este post acho que j√° esta suficiente. Vamos para o pr√≥ximo modelo! üòç</p>
</div>
</div>
<div id="lightgbm" class="section level2">
<h2>LightGBM</h2>
<p>Este modelo consiste em um m√©todo de <em>boosting</em>. Tamb√©m √© baseado nos modelos de √°rvore de decis√µes, mas, diferentemente do <em>Random Forest</em>, suas √°rvores s√£o calculadas em sequ√™ncia, ‚Äúaprendendo‚Äù com o erro das √°rvores anteriores.</p>
<p>A mec√¢nica do <em>LightGBM</em> √© um pouco diferente do <em>XGBoost.</em> N√£o entrarei em detalhes sobre a teoria neste post at√© porque a documenta√ß√£o oficial no github em <a href="https://github.com/microsoft/LightGBM" class="uri">https://github.com/microsoft/LightGBM</a> √© bastante rica, e seus recursos s√£o muito bem apresentados neste link: <a href="https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst" class="uri">https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst</a></p>
<p>Links √∫teis para consulta ao trabalhar com este algoritmo:</p>
<ul>
<li>Documenta√ß√£o oficial: <a href="https://lightgbm.readthedocs.io/en/latest/" class="uri">https://lightgbm.readthedocs.io/en/latest/</a></li>
<li>Excelente post: <a href="https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/" class="uri">https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/</a></li>
<li>Documenta√ß√£o oficial do pacote <code>treesnip</code>: <a href="https://curso-r.github.io/treesnip/articles/working-with-lightgbm-catboost.html" class="uri">https://curso-r.github.io/treesnip/articles/working-with-lightgbm-catboost.html</a></li>
<li>Reposit√≥rio no github do pacote <code>treesnip</code>: <a href="https://github.com/curso-r/treesnip" class="uri">https://github.com/curso-r/treesnip</a></li>
<li>√ìtimo link para consulta dos par√¢metros: <a href="https://sites.google.com/view/lauraepp/parameters" class="uri">https://sites.google.com/view/lauraepp/parameters</a></li>
</ul>
<div id="default-2" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>lightgbm</code> em <a href="https://lightgbm.readthedocs.io/en/latest/" class="uri">https://lightgbm.readthedocs.io/en/latest/</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do (incr√≠vel ü§©) pacote <code>treesnip</code> em <a href="https://github.com/curso-r/treesnip/blob/master/R/lightgbm.R" class="uri">https://github.com/curso-r/treesnip/blob/master/R/lightgbm.R</a></p>
<pre class="r"><code>lgbm_model_bas &lt;- parsnip::boost_tree(
  mode = &quot;classification&quot;,
  trees = 100,       # num_iterations
  learn_rate = 0.1,  # fixo
  min_n = 20,        # min_data_in_leaf
  tree_depth = 6,    # max_depth
  sample_size = 1,   # bagging_fraction
  mtry = 1,          # feature_fraction
  loss_reduction = 0 # min_gain_to_split
) %&gt;%  
  set_engine(&quot;lightgbm&quot;,
             nthread = 4,
             importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>lgbm_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(lgbm_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>lgbm_res_bas &lt;- fit_resamples(
  lgbm_wflow_bas,
  sleep_folds,
  metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
  control = control_resamples(save_pred = TRUE)
)
saveRDS(lgbm_res_bas, &quot;lgbm_res_bas.rds&quot;)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
lgbm_final_wflow_bas &lt;- 
  finalize_workflow(
    lgbm_wflow_bas,
    select_best(lgbm_res_bas, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
lgbm_final_fit_bas &lt;- lgbm_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
lgbm_test_preds_bas &lt;- collect_predictions(lgbm_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>lgbm_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-76-1.png" style="width:80.0%" />
</center>
</div>
<div id="tunning-2" class="section level3">
<h3>Tunning</h3>
<p>Para o tunning vamos utilizar uma estrat√©gia um pouco diferente. Vamos fixar o n√∫mero de √°rvores <code>trees</code> e a taxa de aprendizado <code>learning_rate</code> pois vamos separar mais uma pequena parte dos dados para usar o recurso <code>early_stopping</code>. Esta op√ß√£o basicamente ‚Äútrava‚Äù o crescimento da √°rvore caso o modelo n√£o melhore a performance a partir da n-√©sima itera√ß√£o.</p>
<pre class="r"><code>lgbm_model_tun &lt;- parsnip::boost_tree(
  mode = &quot;classification&quot;,
  trees = 700,             # autotune com early stopping
  learn_rate = 0.01,       # early stopping
  min_n = tune(),          # min_data_in_leaf
  tree_depth = tune(),     # max_depth
  sample_size = 1,         # bagging_fraction, n funciona com goss
  mtry = tune(),           # feature_fraction
  loss_reduction = tune()  # min_gain_to_split
) %&gt;%  
  set_engine(&quot;lightgbm&quot;, nthread = 4, 
             # parametros para early stopping
             early_stop = 30,
             validation = .20,
             eval_metric = &quot;mn_log_loss&quot;,
             importance = &quot;permutation&quot;
             # feature_fraction = tune(&quot;feature_fraction&quot;)
  ) %&gt;% 
  set_mode(&quot;classification&quot;)
# tree_model %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>lgbm_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(lgbm_model_tun) </code></pre>
<p>Definir grid para otimiza√ß√£o de hiperpar√¢metros baseados nas sugest√µes de <a href="https://github.com/Laurae2">github/Laurae2</a> em uma <a href="https://github.com/microsoft/LightGBM/issues/695">issue</a> no reposit√≥rio <a href="https://github.com/microsoft/LightGBM/issues/695">oficial</a> do modelo</p>
<pre class="r"><code>lightgbm_params &lt;- 
  dials::parameters(
    # learn_rate(),           # learning_rate
    # trees()                 # num_iterations
    min_n(),                  # min_data_in_leaf
    tree_depth(c(2, 63)),     # max_depth
    # sample_prop(c(0.4, 1)), # bagging_fraction (vai para sample_size)
    mtry(),                   # feature_fraction
    loss_reduction()          # min_gain_to_split
  ) 

lgbm_grid &lt;- lightgbm_params %&gt;% 
  finalize(sleep_train) %&gt;% 
  grid_max_entropy(size = 30)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>lgbm_res_tun &lt;- 
  lgbm_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = lgbm_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
saveRDS(lgbm_res_tun, &quot;lgbm_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;)[1, ] %&gt;% 
  pull(.config)

plot_lgbm_tun &lt;- 
  lgbm_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)) %&gt;% 
  select(.metric, mean, best_model,
         mtry:loss_reduction) %&gt;%
  pivot_longer(mtry:loss_reduction,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }

# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(lgbm_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_lgbm_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img6.png" style="width:80.0%" />
</center>
<p>Melhores resultados:</p>
<pre class="r"><code>show_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<pre><code>## # A tibble: 5 x 7
##    mtry min_n tree_depth loss_reduction .metric      mean std_err
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;          &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1     2    35         28 0.000000000108 mn_log_loss 0.259 0.00888
## 2     1    16          5 0.00000160     mn_log_loss 0.267 0.0100 
## 3     4    28         31 0.000507       mn_log_loss 0.272 0.0111 
## 4     5    39         62 0.000164       mn_log_loss 0.273 0.00955
## 5     2    14         19 0.0642         mn_log_loss 0.274 0.0138</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
lgbm_final_wflow_tun &lt;- 
  finalize_workflow(
    lgbm_wflow_tun,
    select_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
lgbm_final_fit_tun &lt;- lgbm_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
lgbm_test_preds_tun &lt;- collect_predictions(lgbm_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>lgbm_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-87-1.png" style="width:80.0%" />
</center>
<p>Que maravilha! Modelos acertaram mais a classe de interesse do que os anteriores (apesar do <em>default</em> ainda apresentar alta propor√ß√£o de falsos positivos). Note ainda que o LightGBM ap√≥s o <em>tunning</em> apresentou as melhores m√©tricas no geral (melhor AUC-PR, menor <em>logloss</em> e um bom equil√≠brio no <em>trade-off</em> de <em>Precision</em> x <em>Recall</em>).</p>
<p>Vejamos quais as <em>features</em> mais importantes no ajuste do modelo:</p>
<pre class="r"><code>lgbm_imp_tun &lt;- lightgbm::lgb.importance(lgbm_final_fit_tun$.workflow[[1]]$fit$fit$fit, percentage = T)

lgbm_imp_tun%&gt;% 
  mutate(Feature = reorder(Feature, Gain)) %&gt;% 
  ggplot(aes(x = Feature, y = Gain))+
  geom_bar(stat = &quot;identity&quot;)+
  labs(y = &quot;Importance&quot;, x= &quot;&quot;)+
  coord_flip()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-89-1.png" style="width:80.0%" />
</center>
</div>
</div>
</div>
<div id="sele√ß√£o-do-modelo" class="section level1">
<h1>Sele√ß√£o do modelo ü§î</h1>
<!-- Curva Roc e Precision-Recall Curve: -->
<!-- ```{r} -->
<!-- bind_rows( -->
<!--   # null_res_bas %>% unnest(.predictions) %>% mutate(model = "null baseline"),   -->
<!--   tree_res_bas %>% unnest(.predictions) %>% mutate(model = "rpart baseline"),   -->
<!--   tree_res_tun %>% unnest(.predictions) %>% mutate(model = "rpart tunning"), -->
<!--   rf_res_bas %>% unnest(.predictions) %>% mutate(model = "rf baseline"), -->
<!--   rf_res_tun %>% unnest(.predictions) %>% mutate(model = "rf tunning"), -->
<!--   lgbm_res_bas %>% unnest(.predictions) %>% mutate(model = "lgbm baseline"), -->
<!--   lgbm_res_tun %>% unnest(.predictions) %>% mutate(model = "lgbm tunning") -->
<!-- ) %>%   -->
<!--   plot_auc() +  -->
<!--   plot_annotation(title = 'Resultados nos dados de treino', -->
<!--                   theme = theme(plot.title = element_text(hjust = 0.4))) -->
<!-- ``` -->
<p>Comparar os modelos de forma visual com os gr√°ficos da ROC AUC e da PR AUC:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>auc_plots &lt;- 
  bind_rows(
    null_test_preds_bas %&gt;% mutate(model = &quot;null baseline&quot;),
    tree_test_preds_bas %&gt;% mutate(model = &quot;rpart default&quot;),
    tree_test_preds_tun %&gt;% mutate(model = &quot;rpart tunning&quot;),
    rf_test_preds_bas %&gt;% mutate(model = &quot;rf default&quot;),
    rf_test_preds_tun %&gt;% mutate(model = &quot;rf tunning&quot;),
    lgbm_test_preds_bas %&gt;% mutate(model = &quot;lgbm default&quot;),
    lgbm_test_preds_tun %&gt;% mutate(model = &quot;lgbm tunning&quot;)
  ) %&gt;% 
  plot_auc() + 
  plot_annotation(title = &#39;Resultados nos dados de teste&#39;,
                  theme = theme(plot.title = element_text(hjust = 0.4)))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>auc_plots</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-91-1.png" style="width:80.0%" />
</center>
<p>Apenas olhando o gr√°fico n√£o da para fazer uma an√°lise conclusiva, vejamos as medidas de qualidade (ordenado por <code>auc_pr</code>):</p>
<details>
<summary>
(<em>C√≥digo da tabela</em>)
</summary>
<pre class="r"><code>test_results &lt;- 
  bind_rows(
    evalue_model(null_test_preds_bas, model = &quot;null baseline&quot;, null_model = TRUE),
    evalue_model(tree_test_preds_bas, model = &quot;rpart default&quot;),
    evalue_model(tree_test_preds_tun, model = &quot;rpart tunning&quot;),
    evalue_model(rf_test_preds_bas, model = &quot;rf default&quot;),
    evalue_model(rf_test_preds_tun, model = &quot;rf tunning&quot;),
    evalue_model(lgbm_test_preds_bas, model = &quot;lgbm default&quot;),
    evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)
  ) %&gt;% print_table(round = 4, evalue_model = T)   </code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>test_results</code></pre>
<table>
<colgroup>
<col width="13%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="10%" />
<col width="7%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th>model</th>
<th>tp</th>
<th>fp</th>
<th>fn</th>
<th>tn</th>
<th>auc_roc</th>
<th>auc_pr</th>
<th>logloss</th>
<th>f1</th>
<th>f05</th>
<th>f2</th>
<th>precision</th>
<th>recall</th>
<th>trs_fbeta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>lgbm tunning</td>
<td>6</td>
<td>1</td>
<td>2</td>
<td>72</td>
<td>0.8699</td>
<td>0.7804</td>
<td>0.2190</td>
<td>0.8000</td>
<td>0.8333</td>
<td>0.7692</td>
<td>0.8571</td>
<td>0.7500</td>
<td>0.5937</td>
</tr>
<tr class="even">
<td>rf default</td>
<td>4</td>
<td>0</td>
<td>4</td>
<td>73</td>
<td>0.8399</td>
<td>0.6916</td>
<td>0.6613</td>
<td>0.6667</td>
<td>0.8333</td>
<td>0.5556</td>
<td>1.0000</td>
<td>0.5000</td>
<td>0.7140</td>
</tr>
<tr class="odd">
<td>rf tunning</td>
<td>5</td>
<td>1</td>
<td>3</td>
<td>72</td>
<td>0.8493</td>
<td>0.6658</td>
<td>0.2722</td>
<td>0.7143</td>
<td>0.7812</td>
<td>0.6579</td>
<td>0.8333</td>
<td>0.6250</td>
<td>0.3888</td>
</tr>
<tr class="even">
<td>null baseline</td>
<td>0</td>
<td>0</td>
<td>8</td>
<td>73</td>
<td>0.5000</td>
<td>0.5494</td>
<td>0.3236</td>
<td></td>
<td></td>
<td></td>
<td>0.0000</td>
<td>0.1141</td>
<td></td>
</tr>
<tr class="odd">
<td>lgbm default</td>
<td>6</td>
<td>3</td>
<td>2</td>
<td>70</td>
<td>0.8527</td>
<td>0.5038</td>
<td>0.2313</td>
<td>0.7059</td>
<td>0.6818</td>
<td>0.7317</td>
<td>0.6667</td>
<td>0.7500</td>
<td>0.4286</td>
</tr>
<tr class="even">
<td>rpart default</td>
<td>5</td>
<td>9</td>
<td>3</td>
<td>64</td>
<td>0.7312</td>
<td>0.4471</td>
<td>0.3267</td>
<td>0.4545</td>
<td>0.3906</td>
<td>0.5435</td>
<td>0.3571</td>
<td>0.6250</td>
<td>0.5714</td>
</tr>
<tr class="odd">
<td>rpart tunning</td>
<td>4</td>
<td>7</td>
<td>4</td>
<td>66</td>
<td>0.7243</td>
<td>0.4390</td>
<td>0.3399</td>
<td>0.4211</td>
<td>0.3846</td>
<td>0.4651</td>
<td>0.3636</td>
<td>0.5000</td>
<td>0.7857</td>
</tr>
</tbody>
</table>
<p>O modelo LightGBM ap√≥s o processo de tunning foi o que apresentou as melhores medidas no geral. Note que o LightGBM com os par√¢metro default ficou pior do que o modelo nulo üò±! Isso mostra como o processo de tunning pode ser importante. Al√©m disso note que o modelo <code>rf baseline</code> apresentou o segundo maior AUC-PR mas o pior logloss (note que o <code>threshold</code> est√° muito alto e as demais m√©tricas n√£o ficaram muito boas).</p>
<p>Portanto, apenas os modelos <em>LightGBM</em> e <em>Random Forest</em> apresentaram resultados melhores que um modelo nulo (sempre estima a classe majorit√°ria) e como o LightGBM foi o mais satisfat√≥rio, este ser√° o modelo selecionado. üòé</p>
</div>
<div id="previs√£o-em-dados-novos" class="section level1">
<h1>Previs√£o em dados novos üí´</h1>
<p>Obter as previs√µes nos novos dados:</p>
<pre class="r"><code>trs_final &lt;- evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$trs_fbeta

final &lt;- 
  predict(lgbm_final_fit_tun$.workflow[[1]], new_sleep, type = &quot;prob&quot;) %&gt;% 
  mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs_final, &quot;Ruim&quot;, &quot;Bom&quot;)) 

# new_sleep %&gt;% filter(final$.pred_class == &quot;Ruim&quot;)</code></pre>
<p>Comparar a quantidade de previs√µes de cada classe com o conjunto de treino/teste:</p>
<details>
<summary>
(<em>C√≥digo para tabela abaixo</em>)
</summary>
<pre class="r"><code>tab &lt;- 
  full_join(sleep_train %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            sleep_test %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            by = &quot;mood&quot;) %&gt;% 
  full_join(final %&gt;% 
              count(mood = .pred_class) %&gt;% mutate(prop = n/sum(n)*100)) %&gt;% 
  print_table(round = 2,
              columns = list(
                n.x = colDef(name = &quot;N&quot;),
                prop.x = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n.y = colDef(name = &quot;N&quot;),
                prop.y = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n = colDef(name = &quot;N&quot;),
                prop = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;)
              ), 
              columnGroups = list(
                colGroup(name = &quot;Train&quot;, columns = c(&quot;n.x&quot;, &quot;prop.x&quot;)),
                colGroup(name = &quot;Test&quot;, columns = c(&quot;n.y&quot;, &quot;prop.y&quot;)),
                colGroup(name = &quot;New Data&quot;, columns = c(&quot;n&quot;, &quot;prop&quot;))
              ))</code></pre>
</details>
<p>¬†¬†</p>
<pre class="r"><code>tab</code></pre>
<details>
<summary>
(<em>C√≥digo do c√°lculo das medidas abaixo</em>)
</summary>
<pre class="r"><code># ref: https://en.wikipedia.org/wiki/Sensitivity_and_specificity

# Obter medidas da matriz de confusao
tp = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$tp
tn = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$tn
fn = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$fn
fp = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$fn

# true positive rate
tpr = tp / (tp + fn)
# false negative rate
fnr = 1 - tpr
#false positive rate
fpr = fp / (fp + tn)</code></pre>
</details>
<p>¬†¬†</p>
<p>Como nosso modelo foi otimizado para ser menos ‚Äúalarmista‚Äù (com uma Taxa de Falso Positivo: 2.7%) √© poss√≠vel que o modelo tenha deixado passar alguns dias em que <code>mood=="Ruim"</code> (Taxa de Falso Negativo: 25%). N√£o vejo isto como um grande problema pois dado a pequena quantidade de dados dispon√≠veis at√© que o resultado para a classe de interesse estava bem razo√°vel (Taxa de Verdadeiro Positivo: 75%).</p>
<p>Para n√£o alongar aida mais o post com an√°lise explorat√≥ria das previs√µes, vamos comparar como foram as previs√µes nestes novos dados em rela√ß√£o aos dados utilizados para treinar o modelo e ver se, pelo menos visualmente, o modelo esteja conseguindo prever de semelhante ao padr√£o de dados conhecidos.</p>
<p>A t√©cnica <a href="https://cran.r-project.org/web/packages/umap/vignettes/umap.html">UMAP</a> ser√° utilizada com a finalidade de reduzir a dimensionalidade para visualiza√ß√£o:</p>
<details>
<summary>
(<em>C√≥digo para gr√°fico abaixo</em>)
</summary>
<pre class="r"><code># Treinar UMAP: 
sleep_umap &lt;-  juice(sleep_recipe) %&gt;% select(-mood) %&gt;% umap::umap()

# Aplicar em novos dados:
new_data &lt;- bake(sleep_recipe, new_sleep) %&gt;% select(-mood)
new_data_umap &lt;- predict(sleep_umap, new_data)

# Preparar plot comparando treino com novos dados:
umap_plot &lt;-
  bind_rows(
    sleep_umap$layout %&gt;% 
      as_tibble() %&gt;% 
      bind_cols(juice(sleep_recipe) %&gt;% select(mood))  %&gt;% 
      bind_cols(dataset =  &quot;Train&quot;)
    ,
    new_data_umap %&gt;% 
      as_tibble() %&gt;% 
      mutate(mood = factor(final$.pred_class,
                           levels = c(&quot;Ruim&quot;, &quot;Bom&quot;)))  %&gt;% 
      bind_cols(dataset =  &quot;New Data&quot;)
  ) %&gt;%
  mutate(dataset = factor(dataset, levels = c(&quot;New Data&quot;, &quot;Train&quot;))) %&gt;% {
    ggplot(., aes(x = V1, y = V2, color = mood, shape = mood))+
      geom_point(show.legend = F)+
      geom_point(aes(x = V1, y = V2, color = mood), 
                 data = subset(., mood == &#39;Ruim&#39;), 
                 size = 2, shape = 3)+
      labs(x = &quot;&quot;, y = &quot;&quot;, 
           title = &quot;UMAP (Uniform Manifold Approximation and Projection)&quot;)+
      scale_color_viridis_d(end = 0.8, direction = 1)+
      # scale_size_manual(values=c(2,5))+
      theme(legend.position = &quot;bottom&quot;)+
      facet_wrap(~dataset)
  }</code></pre>
</details>
<p>¬†¬†</p>
<pre class="r"><code>umap_plot %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<p>Parece que o modelo fez previs√µes nos novos dados em um padr√£o espec√≠fico dos dados (√† direita) enquanto que nos dados de treino podemos observar alguma informa√ß√£o da classe <code>Ruim</code> na massa de dados √† esquerda. Isso pode estar acontecendo devido ao foco que demos para minimizar falsos positivos. √â uma boa indica√ß√£o para analisar melhor o padr√£o que o modelo esta aprendendo em rela√ß√£o aos falsos negativos.</p>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img7.png" style="width:80.0%" />
</center>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o üçª</h1>
<p>Apesar da pequena quantidade dados dados dispon√≠veis, conseguimos ajustar um modelo razo√°vel para prever a qualidade de sono em dias que n√£o foram registrados!</p>
<div class="row">
<div class="column8">
<p>Utilizamos diversas t√©cnicas de <em>Machine Leaning</em> combinadas em dados reais (que n√£o s√£o nada comportados) e, obviamente, para colocar um modelo em produ√ß√£o na vida real seria necess√°rio aplicar mais uma s√©rie de an√°lises, al√©m de entender como o modelo est√° funcionando, aplicando t√©cnicas de <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">XAI</a> (Explainable AI) mas isso pode ser assunto para um futuro <em>post</em>, hora de dormir! üò¥</p>
<p>Espero que este pequeno ‚Äú<em>case</em>‚Äù seja √∫til para voc√™! Para mim foi √≥timo combinar a pr√°tica do uso do pacote <code>tidymodels</code> para resolver um problema com dados reais com um estudo que me trouxe mais auto-conhecmento e um monte de <em>insights</em> pessoais.</p>
</div>
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/U7Lvtcuqh4WZy/giphy.gif" alt="Via Giphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/U7Lvtcuqh4WZy/giphy.gif">Via Giphy</a></div>
</div>
</div>
</div>
<hr />
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias üß≥</h1>
<ul>
<li><a href="https://juliasilge.com/blog/wind-turbine/" class="uri">https://juliasilge.com/blog/wind-turbine/</a></li>
<li><a href="https://juliasilge.com/blog/hotels-recipes/" class="uri">https://juliasilge.com/blog/hotels-recipes/</a></li>
<li><a href="https://juliasilge.com/blog/xgboost-tune-volleyball/" class="uri">https://juliasilge.com/blog/xgboost-tune-volleyball/</a></li>
<li><a href="http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/" class="uri">http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/</a></li>
<li><a href="https://machinelearningmastery.com/imbalanced-classification-with-python/" class="uri">https://machinelearningmastery.com/imbalanced-classification-with-python/</a></li>
<li><a href="https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/fbeta-measure-for-machine-learning/" class="uri">https://machinelearningmastery.com/fbeta-measure-for-machine-learning/</a></li>
<li><a href="https://sites.google.com/view/lauraepp/parameters" class="uri">https://sites.google.com/view/lauraepp/parameters</a></li>
<li><a href="https://github.com/microsoft/LightGBM/issues/695" class="uri">https://github.com/microsoft/LightGBM/issues/695</a></li>
</ul>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p><a href="https://www.usp.br/espacoaberto/?materia=a-importancia-de-dormir-bem" class="uri">https://www.usp.br/espacoaberto/?materia=a-importancia-de-dormir-bem</a><a href="#fnref1" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p><a href="https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/</a><a href="#fnref2" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn3"><p><a href="https://machinelearningmastery.com/fbeta-measure-for-machine-learning/" class="uri">https://machinelearningmastery.com/fbeta-measure-for-machine-learning/</a><a href="#fnref3" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn4"><p><a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/</a><a href="#fnref4" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn5"><p><a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/</a><a href="#fnref5" class="footnote-back">‚Ü©Ô∏é</a></p></li>
</ol>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/">Prevendo a qualidade do sono utilizando Machine Learning</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">imbalanced</category>
      <category domain="tag">imbalanced-data</category>
      <category domain="tag">lightgbm</category>
      <category domain="tag">r</category>
      <category domain="tag">random-forest</category>
      <category domain="tag">threshold-movel</category>
      <category domain="tag">tidymodels</category>
      <category domain="tag">tidyverse</category>
      <category domain="tag">tunning</category>
    </item>
  </channel>
</rss>