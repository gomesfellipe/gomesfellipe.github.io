&lt;?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>random forest on Fellipe Gomes - Data Science Blog</title>
    <link>https://gomesfellipe.github.io/tags/random-forest/</link>
    <description>√öltimos posts sobre Data Science, Machine Learning e R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <managingEditor>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</managingEditor>
    <webMaster>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</webMaster>
    <lastBuildDate>Mon, 28 Jun 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://gomesfellipe.github.io/tags/random-forest/" rel="self" type="application/rss+xml" />
    <item>
      <title>Otimizando pipelines que envolvem dados desbalanceados</title>
      <link>https://gomesfellipe.github.io/post/2021-06-28-imbalanced-workflowsets/</link>
      <pubDate>Mon, 28 Jun 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-06-28-imbalanced-workflowsets/</guid>
      <description>Utilizaremos o framework tidymodels para machine learning em R com o aux√≠lio do pacote workflowsets para otimizar pipelines de dados desbalanceados</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#o-problema-envolvendo-dados-desbalanceados" id="toc-o-problema-envolvendo-dados-desbalanceados">O problema envolvendo dados desbalanceados</a></li>
<li><a href="#objetivo" id="toc-objetivo">Objetivo</a></li>
<li><a href="#depend%C3%AAncias" id="toc-depend√™ncias">Depend√™ncias</a></li>
<li><a href="#preparar-dados" id="toc-preparar-dados">Preparar dados</a></li>
<li><a href="#breve-an%C3%A1lise-explorat%C3%B3ria" id="toc-breve-an√°lise-explorat√≥ria">Breve an√°lise explorat√≥ria</a></li>
<li><a href="#modelagem" id="toc-modelagem">Modelagem</a>
<ul>
<li><a href="#baselines" id="toc-baselines">Baselines</a></li>
<li><a href="#preparar-pipeline-de-dados-com-workflowsets" id="toc-preparar-pipeline-de-dados-com-workflowsets">Preparar Pipeline de dados com <code>workflowsets</code></a></li>
<li><a href="#benchmark" id="toc-benchmark">Benchmark</a></li>
</ul></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias</a></li>
</ul>
</div>

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 33%;
padding: 10px;
}

.column8 {
float: left;
width: 66%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>
<div id="o-problema-envolvendo-dados-desbalanceados" class="section level1">
<h1>O problema envolvendo dados desbalanceados</h1>
<p>A tarefa de classifica√ß√£o com dados desbalanceados √© muito comum na vida real podendo variar desde um leve vi√©s at√© um enorme desequil√≠brio na distribui√ß√£o da classe de interesse. Problemas mais comuns envolvem:</p>
<ul>
<li>Detec√ß√£o de fraude;</li>
<li>Previs√£o de inadimpl√™ncia;</li>
<li>Identificador de <em>spam</em>;</li>
<li>Busca por anomalias/outliers;</li>
<li>Detec√ß√£o de poss√≠veis roubos/furtos/vulnerabilidades;</li>
<li>Previs√£o de <em>churn</em>;</li>
<li>etc</li>
</ul>
<div class="row">
<div class="column8">
<p>Este tipo de tarefa representa um enorme desafio para modelagem preditiva pois a maioria dos algoritmos de machine learning foram projetados sob suposi√ß√£o de haver um n√∫mero igual de exemplos para cada classe de interesse.</p>
<p>E isso √© um grande problema pois normalmente estamos interessados em prever a classe minorit√°ria e para isso √© preciso tomar uma s√©rie de decis√µes, como por exemplo: m√©trica utilizada, m√©todo para valida√ß√£o cruzada, ado√ß√£o (ou n√£o) do uso de m√©todos de reamostragem, quais algoritmos utilizar, qual ser√° o threshold, etc</p>
</div>
<div class="column4">
<p></br>
<img src="https://media.giphy.com/media/JPV8lNtI59zaWyL4pf/giphy.gif" alt="Via Giphy" /></p>
</div>
</div>
<p>Lidar com dados desbalanceados √© um assunto longo portanto tentarei dar mais aten√ß√£o apenas em um <em>hack</em> para encontrar a melhor forma de se aplicar o balanceamento dos dados. N√£o pretendo me aprofundar na teoria envolvida na escolha das m√©tricas neste post, caso o leitor deseje se aprofundar sobre a teoria envolvida com classifica√ß√£o que envolve dados desbalanceados, sugiro a leitura do livro: <a href="https://machinelearningmastery.com/imbalanced-classification-with-python/">Imbalanced Classification with Python - Choose Better Metrics, Balance Skewed Classes and Apply Cost-Sensitive Learning</a> e consultar os links de refer√™ncia no final do post).</p>
</div>
<div id="objetivo" class="section level1">
<h1>Objetivo</h1>
<p>Utilizaremos neste post o pacote <code>workflowsets</code> a fim de otimizar o pipeline de reamostragem da base para lidar com o desbalanceamento dos dados.</p>
<p>Para efeitos de compara√ß√£o, utilizarei como refer√™ncia o (excelente) <a href="https://juliasilge.com/blog/sliced-aircraft/">post escrito recentemente pela Julia Silge</a> em seu blog que tamb√©m aborda o problema de dados desbalanceados utilizando um conjunto de dados de uma <a href="https://www.kaggle.com/c/sliced-s01e02-xunyc5">competi√ß√£o do Kaggle</a>. Utilizarei a mesma configura√ß√£o de pr√©-processamento adotado em seu post para que a compara√ß√£o seja justa.</p>
<p>Portanto, nosso objetivo de modelagem ser√° prever se uma colis√£o com animais selvagens resultou em danos a aeronave.</p>
<div class="w3-panel w3-pale-green w3-border">
<p>‚ö†Ô∏è Este dataset √© rico em possibilidades para diferentes tipos de pr√© processamentos e por isso convido o leitor a analis√°-lo com maior profundidade e tamb√©m a compartilhar seus resultados!</p>
</div>
</div>
<div id="depend√™ncias" class="section level1">
<h1>Depend√™ncias</h1>
<p>Primeiro vamos carregar as bibliotecas necess√°rias e algumas fun√ß√µes desenvolvidas para o post</p>
<pre class="r"><code>library(tidyverse)    # ds toolkit
library(tidymodels)   # ml toolkit
library(baguette)     # bag_tree
library(themis)       # imbalanced
library(workflowsets) # opt pipelines
library(patchwork)    # arrange plots 

doParallel::registerDoParallel()
theme_set(theme_bw())</code></pre>
<details>
<summary>
(<em>Clique aqui para ver as fun√ß√µes</em> <code>print_table</code> <em>e</em> <code>conf_mat_plot</code> <em>importadas</em>)
</summary>
<pre class="r"><code># Para o print de tabelas
print_table &lt;- function(x, round=0, cv=F, wf=F, bm=F, ...){ 
  
  if(round&gt;0) x &lt;- x %&gt;% mutate_if(is.numeric, ~round(.x, round))
  
  if(cv==T){
    columns_spec = list(
      .metric = reactable::colDef(minWidth = 75),
      .estimator = reactable::colDef(minWidth = 70),
      .config = reactable::colDef(minWidth = 120)
    )
  } else if(wf==T){
    columns_spec = list(
      wflow_id = reactable::colDef(minWidth = 100),
      .metric = reactable::colDef(minWidth = 100),
      preprocessor = reactable::colDef(minWidth = 110),
      rank = reactable::colDef(minWidth = 50),
      n = reactable::colDef(minWidth = 50)
    )
  }else if (bm==T){
    columns_spec = list(
      wflow_id = reactable::colDef(minWidth = 130),
      model = reactable::colDef(minWidth = 80)
    )
  }else{
    columns_spec = NULL
  }
  
  reactable::reactable(x, striped = T, bordered = T,
                       highlight = T, pagination = F, resizable = T, 
                       columns = columns_spec, ...)
  
}

# Para plot da matriz de confusao e distribuicoes de probabilidade
conf_mat_plot &lt;- function(x, null_model = FALSE){
  p1 &lt;- 
    x %&gt;%
    select(.pred_class, damaged) %&gt;%
    table() %&gt;% 
    conf_mat() %&gt;% 
    autoplot(type = &quot;heatmap&quot;)+
    labs(title = &quot;Matriz de confus√£o&quot;)
  
  p2 &lt;- 
    x  %&gt;%
    ggplot() +
    geom_density(aes(x = .pred_damage, fill = damaged), 
                 alpha = 0.5)+
    labs(title = &quot;Distribui√ß√µes de probabilidade previstas&quot;,
         subtitle = &quot;por classe&quot;)+ 
    scale_x_continuous(limits = 0:1)+
    scale_fill_brewer(palette=&quot;Set1&quot;)
  
  p1 | p2
} </code></pre>
</details>
<p>¬†</p>
<p>Em seguida vamos importar os dados provenientes da competi√ß√£o Inclass do Kaggle <a href="https://www.kaggle.com/c/sliced-s01e02-xunyc5">SLICED s01e02 - Predict whether an aircraft strike with wildlife causes damage</a>. Para mais informa√ß√µes consulte a <a href="https://www.kaggle.com/c/sliced-s01e02-xunyc5/data">documenta√ß√£o e dicion√°rio dos dados</a>.</p>
<pre class="r"><code>df &lt;- read_csv(&quot;train.csv&quot;)</code></pre>
<p>Note que carregamos apenas os dados de treino pois os dados de teste n√£o possuem a target.</p>
</div>
<div id="preparar-dados" class="section level1">
<h1>Preparar dados</h1>
<p>Tratar a vari√°vel target <code>damaged</code> e avaliar sua distribui√ß√£o:</p>
<pre class="r"><code>df &lt;- df %&gt;% 
  mutate(damaged = if_else(damaged==1, &quot;damage&quot;, &quot;not_damage&quot;) %&gt;% 
           factor(levels = c(&quot;damage&quot;, &quot;not_damage&quot;)))</code></pre>
<details>
<summary>
(<em>Clique aqui para ver o c√≥digo do gr√°fico abaixo</em>)
</summary>
<pre class="r"><code>p1 &lt;- df %&gt;% 
  count(damaged) %&gt;% 
  ggplot(aes(x=rev(damaged), y=n, fill=damaged))+
  geom_bar(stat = &quot;identity&quot;)+
  scale_fill_brewer(palette=&quot;Set1&quot;)+
  theme(legend.position = &quot;bottom&quot;)+
  labs(y=&quot;N√∫mero de inst√¢ncias&quot;, x = &quot;&quot;)

p2 &lt;- df %&gt;% 
  count(damaged) %&gt;% 
  arrange(desc(damaged)) %&gt;%
  mutate(prop = n / sum(n)) %&gt;%
  mutate(ypos = cumsum(prop)- 0.5*prop )%&gt;% 
  ggplot(aes(x=&quot;&quot;, y=prop, fill=damaged)) +
  geom_bar(stat=&quot;identity&quot;, width=1) +
  coord_polar(&quot;y&quot;, start=0) +
  theme_void() + 
  theme(legend.position=&quot;none&quot;) +
  geom_text(aes(y = ypos,
                label = paste(scales::comma(n, big.mark = &quot;.&quot;),
                              scales::comma(n/sum(n), big.mark = &quot;.&quot;, 
                                            suffix = &quot;%&quot; ),sep = &quot;\n&quot;)
                
  ), 
  color = &quot;white&quot;, size=6) +
  scale_fill_brewer(palette=&quot;Set1&quot;)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>p1 + p2 </code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-6-1.png" style="width:80.0%" />
</center>
<p>Veja que estamos diante de um problema que existem aproximadamente 9 casos de dano para cada 100 eventos observados.</p>
</div>
<div id="breve-an√°lise-explorat√≥ria" class="section level1">
<h1>Breve an√°lise explorat√≥ria</h1>
<p>Vamos iniciar a explorat√≥ria com uma avalia√ß√£o geral dos dados brutos</p>
<pre class="r"><code>DataExplorer::plot_intro(df, ggtheme = theme_bw(), 
                         theme_config = list(legend.position = &quot;bottom&quot;))</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-7-1.png" style="width:80.0%" />
</center>
<p>Primeira informa√ß√£o que chama aten√ß√£o √© que quase 1/4 desses dados √© faltante. Vamos olhar a estrutura dessa base de maneira mais aprofundada:</p>
<pre class="r"><code>df %&gt;% 
  sample_frac(0.01) %&gt;% 
  visdat::vis_dat()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-8-1.png" style="width:80.0%" />
</center>
<p>Parece existir algum padr√£o nos dados faltantes (que coocorrem em diveros atributos). Al√©m disso algumas colunas est√£o quase inteiramente vazias e ser√£o descartadas no processo de modelagem.</p>
<p>Uma vis√£o geral das classes das features categ√≥ricas:</p>
<pre class="r"><code>df %&gt;%
  select(-damaged, -id)%&gt;%
  mutate_all(as.factor) %&gt;%
  inspectdf::inspect_cat() %&gt;% 
  inspectdf::show_plot()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-9-1.png" style="width:80.0%" />
</center>
<p>Algumas features possuem muitas classes e caso seja feita a transforma√ß√£o <em>one-hot-encoding</em> (estrat√©gia amplamente utilizada para lidar com features categ√≥ricas) sem algum cuidado, o desempenho da maioria dos modelos de machine learning pode ser prejudicado por tornar a base anal√≠tica muito esparsa.</p>
<p>Uma vis√£o geral das classes das features num√©ricas em rela√ß√£o a target:</p>
<pre class="r"><code>num_columns &lt;- c(df %&gt;% select_if(is.numeric) %&gt;% colnames(), &#39;damaged&#39;)
df%&gt;% 
  select_at(num_columns) %&gt;% 
  select(-id) %&gt;%
  gather(key, value, -damaged) %&gt;%
  ggplot(aes(y=damaged, x=value))+
  geom_boxplot()+
  facet_wrap(~key, ncol=5, scales = &quot;free_x&quot;)+
  labs(x = &quot;&quot;, y=&quot;&quot;)</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-10-1.png" style="width:80.0%" />
</center>
<p>Parece que algumas features possuem comportamentos diferentes quando avaliados segundo a target. Al√©m disso √© poss√≠vel notar que as features <code>aircraft_mass</code>, <code>distance</code>, <code>engine4_position</code>, <code>engines</code>, <code>height</code> e <code>speed</code> apresentam outliers.</p>
</div>
<div id="modelagem" class="section level1">
<h1>Modelagem</h1>
<p>Finalmente chegamos a modelagem!</p>
<p>Primeiro vamos definir um esquema de reamostragem (com estratifica√ß√£o) que ser√° utilizado para avaliar os modelos e as m√©tricas de qualidade.</p>
<pre class="r"><code>set.seed(123)

bird_folds &lt;- vfold_cv(df, v = 5, strata = damaged)
bird_metrics &lt;- metric_set(mn_log_loss, accuracy, sensitivity, specificity)</code></pre>
<p>Nossos conjuntos de pipelines necessitar√£o de um pr√©-processador base que ser√° comum a todos como camada inicial. Para isso utilizaremos o mesmo definido no post de refer√™ncia.</p>
<pre class="r"><code>base_rec &lt;- recipe(damaged ~ ., data = df) %&gt;%
  step_select( damaged, flight_impact, precipitation,
               visibility, flight_phase, engines, incident_year,
               incident_month, species_id, engine_type,
               aircraft_model, species_quantity, height, speed) %&gt;% 
  step_novel(all_nominal_predictors()) %&gt;%
  step_other(all_nominal_predictors(), threshold = 0.01) %&gt;%
  step_unknown(all_nominal_predictors()) %&gt;%
  step_impute_median(all_numeric_predictors()) %&gt;%
  step_zv(all_predictors())</code></pre>
<div id="baselines" class="section level2">
<h2>Baselines</h2>
<p>Para efeitos de compara√ß√£o, vamos ajustar 2 modelos que ser√£o utilizados como baselines para saber se a complexidade que estamos adicionando no modelo est√° realmente trazendo algum ganho na performance do modelo. Os modelos ser√£o:</p>
<ul>
<li>Modelo nulo: um modelo que sempre prev√™ a classe majorit√°ria;</li>
<li>Modelo de base: <a href="https://bradleyboehmke.github.io/HOML/bagging.html">Bagged Decision Tree</a> sem adicionar pr√©-processamento para compensar o desequil√≠brio de classe.</li>
</ul>
<div id="modelo-nulo" class="section level3">
<h3>Modelo nulo</h3>
<p>Avaliando modelo nulo via valida√ß√£o cruzada:</p>
<pre class="r"><code>null_spec &lt;- null_model(mode = &quot;classification&quot;) %&gt;% 
  set_engine(&quot;parsnip&quot;)

null_wf &lt;-
  workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(null_spec)

null_rs &lt;-
  fit_resamples(
    object = null_wf,
    resamples = bird_folds,
    metrics = bird_metrics,
    control = control_resamples(save_pred = TRUE)
  ) 

collect_metrics(null_rs) %&gt;% print_table(round = 5, cv = T) </code></pre>
<p><img src="/post/2021-06-28-imbalanced-workflowsets/tab1.png" /></p>
<p>Qualquer modelo com desempenho pior do que este deve ser descartado. Vejamos a matriz de confus√£o:</p>
<pre class="r"><code>collect_predictions(null_rs) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-14-1.png" style="width:80.0%" />
</center>
</div>
<div id="modelo-de-base" class="section level3">
<h3>Modelo de base</h3>
<p>Agora vamos ajusta o modelo <em>Bagged Decision Tree</em> sem o pr√©-processamento para compensar o desequil√≠brio de classe:</p>
<pre class="r"><code>bag_spec &lt;-
  bag_tree(min_n = 10) %&gt;%
  set_engine(&quot;rpart&quot;, times = 25) %&gt;%
  set_mode(&quot;classification&quot;)

imb_wf &lt;-
  workflow() %&gt;%
  add_recipe(base_rec) %&gt;%
  add_model(bag_spec)

set.seed(123)
imb_rs &lt;-
  fit_resamples(
    imb_wf,
    resamples = bird_folds,
    metrics = bird_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(imb_rs) %&gt;% print_table(round = 5, cv = T)</code></pre>
<p><img src="/post/2021-06-28-imbalanced-workflowsets/tab2.png" /></p>
<p>Apesar do elevado n√∫mero de falsos negativos, este modelo j√° esta com um desempenho razo√°vel em compara√ß√£ao ao modelo nulo e o n√∫mero de verdadeiros positivos j√° √© quase o dobro do n√∫mero de falsos positivos. Veja na matriz de confus√£o abaixo:</p>
<pre class="r"><code>collect_predictions(imb_rs) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-16-1.png" style="width:80.0%" />
</center>
</div>
</div>
<div id="preparar-pipeline-de-dados-com-workflowsets" class="section level2">
<h2>Preparar Pipeline de dados com <code>workflowsets</code></h2>
<p>A escolha do m√©todo de amostragem dos dados √© t√£o importante quanto a escolha do modelo preditivo que ser√° utilizado pois o desempenho pode ser enganosamente otimista visto que o algoritmo de bagging n√£o esta usando nenhuma estrat√©gia de subamostragem aleat√≥ria da classe majorit√°ria em cada amostra de bootstrap para equilibrar as duas classes.</p>
<p>Existem muitos m√©todos para amostragem de dados e n√£o h√° um m√©todo √∫nico que seja melhor em todos os problemas de classifica√ß√£o (assim como n√£o existe o ‚Äúmelhor modelo‚Äù) portanto, utilizaremos este pacote para testar diferentes m√©todos e tamb√©m tunar seus hiperpar√¢metros.</p>
<div id="oversampling" class="section level3">
<h3>Oversampling</h3>
<p>Estes m√©todos duplicam ou sintetizam novos dados da classe minorit√°ria. Deve ser usado com cautela pois na vida real pode gerar alguns dados que n√£o condizem com a relidade ou criar tantas inst√¢ncias que acaba consumindo muito mais tempo de processamento.</p>
<div id="random-oversampling" class="section level4">
<h4>Random Oversampling</h4>
<p>Este m√©todo simplesmente duplica aleat√≥riamente exemplos da classe minorit√°ria. Vamos tunar esta propor√ß√£o buscando n√∫meros reais no intervalo [0.5,1].</p>
<pre class="r"><code>rec_up &lt;- base_rec %&gt;% 
  step_upsample(damaged, over_ratio = tune())

params_up &lt;- rec_up %&gt;% 
  parameters() %&gt;% update(over_ratio = mixture(c(0.5, 1)))</code></pre>
</div>
<div id="smote---synthetic-minority-oversampling-technique" class="section level4">
<h4>SMOTE - Synthetic Minority Oversampling Technique</h4>
<p>O SMOTE funciona gerando novos dados sint√©tios baseados em exemplos selecionando que est√£o ‚Äúpr√≥ximos‚Äù. Vamos tunar tanto a propor√ß√£o de dados que ser√£o gerados quanto a quantidade de vizinhos selecionados, buscando n√∫meros reais e inteiros no intervalo [0.5,1] e [1, 10], respectivamente.</p>
<pre class="r"><code>rec_smote &lt;- base_rec %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_smote(damaged, over_ratio = tune(), 
             neighbors = tune())

params_smote &lt;- rec_smote %&gt;% 
  parameters() %&gt;% update(over_ratio = mixture(c(0.5, 1)),
                          neighbors = neighbors())</code></pre>
</div>
<div id="adasyn---adaptive-synthetic-sampling" class="section level4">
<h4>ADASYN - Adaptive Synthetic Sampling</h4>
<p>O ADASYN √© uma extens√£o do SMOTE que busca propor melhorias. Vamos tunar os mesmos par√¢metros definidos no SMOTE.</p>
<pre class="r"><code>rec_adasyn &lt;- base_rec %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_adasyn(damaged, 
              over_ratio = tune(), 
              neighbors = tune())

params_adasyn &lt;- rec_adasyn %&gt;% 
  parameters() %&gt;% update(over_ratio = mixture(c(0.5, 1)),
                          neighbors = neighbors())</code></pre>
</div>
</div>
<div id="undersampling" class="section level3">
<h3>Undersampling</h3>
<p>S√£o t√©cnicas que excluem ou selecionam um subconjunto de exemplos da classe majorit√°ria e existem dezenas (se n√£o centenas) desses m√©todos. Neste post utilizaremos s√≥ 3 mas existem outros implementados em outras bibliotecas (em R e em Python).</p>
<div id="random-undersampling" class="section level4">
<h4>Random Undersampling</h4>
<p>Este √© o m√©todo mais simples e envolve a exclus√£o aleat√≥ria de algumas inst√¢ncias da classe majorit√°ria. Vamos tunar esta propor√ß√£o de frequ√™ncias da minorit√°ria para a majorit√°ria.</p>
<pre class="r"><code>rec_down &lt;- base_rec %&gt;% 
  step_downsample(damaged, under_ratio = tune())

params_down &lt;- rec_down %&gt;% 
  parameters() %&gt;% update(under_ratio = deg_free())</code></pre>
</div>
<div id="near-miss-undersampling" class="section level4">
<h4>Near Miss Undersampling</h4>
<p>Este algoritmo se baseia em m√©todos de KNN selecionando exemplos da classe majorit√°ria que tem menor dist√¢ncia m√©dia dos k exemplos mais pr√≥ximos. Vamos tunar tanto a propor√ß√£o quanto o n√∫mero de vizinhos utilizados.</p>
<pre class="r"><code>rec_nearmiss &lt;- base_rec %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_nearmiss(damaged, 
                under_ratio = tune(), 
                neighbors = tune())

params_nearmiss &lt;- rec_nearmiss %&gt;% 
  parameters() %&gt;% update(under_ratio = deg_free(),
                          neighbors = neighbors())</code></pre>
</div>
<div id="tomek-links-undersampling" class="section level4">
<h4>Tomek Links Undersampling</h4>
<p>Este algoritmo que tenta excluir inst√¢ncias que sejam pr√≥ximas e que possuam classes diferentes, buscando diminuir a ambiguidade dos dados. N√£o vamos tunar nenhum hiperpar√¢metro aqui.</p>
<pre class="r"><code>rec_tomek &lt;- base_rec %&gt;%
  step_dummy(all_nominal_predictors()) %&gt;%
  step_tomek(damaged)</code></pre>
</div>
</div>
<div id="preparar-pipeline-de-dados" class="section level3">
<h3>Preparar pipeline de dados</h3>
<p>Agora que todos pipelines de dados candidatos est√£o definidos, vamos combinar tudo em um √∫nico objeto com <code>workflow_set</code>:</p>
<pre class="r"><code>chi_models &lt;- 
  workflow_set(
    preproc = list(upsample = rec_up,
                   smote = rec_smote,
                   adasyn = rec_adasyn,
                   downsample = rec_down,
                   nearmiss = rec_nearmiss,
                   tomek = rec_tomek),
    models = list(bag_spec = bag_spec),
    cross = TRUE
  )</code></pre>
<p>Utilizar a fun√ß√£o <code>option_add</code> para adicionar as informa√ß√µes dos intervalos definidos para cada hiperpar√¢metro:</p>
<pre class="r"><code>chi_models &lt;- chi_models %&gt;% 
  option_add(param_info = params_up, id = &quot;upsample_bag_spec&quot;)  %&gt;% 
  option_add(param_info = params_smote, id = &quot;smote_bag_spec&quot;) %&gt;% 
  option_add(param_info = params_adasyn, id = &quot;adasyn_bag_spec&quot;) %&gt;% 
  option_add(param_info = params_down, id = &quot;downsample_bag_spec&quot;) %&gt;% 
  option_add(param_info = params_nearmiss, id = &quot;nearmiss_bag_spec&quot;)</code></pre>
<p>Finalmente, vamos ajustar todos os modelos utilizando o m√©todo simples para fazer a busca dos melhores hiperpar√¢metros em grids de 20 valores aleat√≥rios e calcular os scores via valida√ß√£o cruzada (esta parte pode demorar bastante tempo):</p>
<pre class="r"><code>set.seed(123)
chi_models &lt;- 
  chi_models %&gt;% 
  workflow_map(&quot;tune_grid&quot;,
               resamples = bird_folds, 
               grid = 20, 
               metrics = bird_metrics,
               control = control_resamples(save_pred = TRUE),
               verbose = TRUE)</code></pre>
<p>Vejamos os resultados:</p>
<pre class="r"><code>rank_results(chi_models, rank_metric = &quot;mn_log_loss&quot;, select_best = TRUE) %&gt;% 
  select(-.config) %&gt;%
  mutate(wflow_id = str_remove(wflow_id, &quot;_bag_spec&quot;)) %&gt;% 
  print_table(round = 5, wf=T, height = 300, filterable = T)</code></pre>
<p>Matriz de confus√£o do modelo com menor <em>logloss</em>:</p>
<pre class="r"><code>collect_predictions(chi_models) %&gt;% 
  filter(wflow_id == &quot;tomek_bag_spec&quot;) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-06-28-imbalanced-workflowsets/unnamed-chunk-29-1.png" style="width:80.0%" />
</center>
</div>
</div>
<div id="benchmark" class="section level2">
<h2>Benchmark</h2>
<p>Comparando os resultados dos modelos ajustados:</p>
<details>
<summary>
(<em>Clique aqui para ver o c√≥digo que cria o objeto</em> <code>benchmark</code>)
</summary>
<pre class="r"><code>benchmark &lt;- bind_rows(
  mutate(collect_metrics(null_rs), wflow_id = &quot;default&quot;, model = &quot;null_model&quot;) %&gt;% 
    select(.metric, mean, wflow_id, model) %&gt;% 
    spread(.metric, mean)
  ,
  mutate(collect_metrics(imb_rs), wflow_id = &quot;default&quot;, model = &quot;bag_tree&quot;) %&gt;% 
    select(.metric, mean, wflow_id, model) %&gt;% 
    spread(.metric, mean)
  ,
  rank_results(chi_models, rank_metric = &quot;mn_log_loss&quot;, select_best = TRUE) %&gt;% 
    filter(wflow_id==&quot;smote_bag_spec&quot;) %&gt;% 
    select(.metric, mean, wflow_id, model) %&gt;% 
    spread(.metric, mean)
  ,
  rank_results(chi_models, rank_metric = &quot;mn_log_loss&quot;, select_best = TRUE) %&gt;% 
    filter(rank==1) %&gt;% 
    select(.metric, mean, wflow_id, model) %&gt;% 
    spread(.metric, mean)
) </code></pre>
</details>
<pre class="r"><code>benchmark  %&gt;%
  print_table(round = 5, bm = T)</code></pre>
<p>Como no post da Julia, a logloss e a precis√£o dos modelos que utilizaram m√©todos de balanceamento dos dados pioraram em rela√ß√£o ao modelo de <em>Bagged Decision Tree</em> sem o uso desses pipelines. Apesar da piora em rela√ß√£o ao modelo de base nota-se que outros m√©todos como <em>Tomek Links</em> e <em>Adasyn</em> se sa√≠ram ligeiramente melhores do que o <em>Smote</em> (al√©m disso vimos que o <em>Smote</em> com sua configura√ß√£o <em>default</em> n√£o necessariamente produriz√° os melhores resultados).</p>
<p>Este tipo de performance √© muito comum e at√© esperado visto que estamos avaliando o modelo atrav√©s de uma √∫nica m√©trica (com os mesmos pontos de corte e com o mesmo algoritmo). Normalmente no mundo real monitoramos diversas m√©tricas e experimentamos mais configura√ß√µes de hiperpar√¢metros de diferentes modelos com diferentes pipelines.</p>
</div>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o</h1>
<p>Assim como n√£o existe melhor modelo, n√£o existe melhor t√©cnica de balanceamento de dados. Portanto, na busca de melhores resultados n√≥s podemos tentar otimizar qual abordagem ser√° uyilizada bem como seus hiperpar√¢metros (em conjunto com os hiperpar√¢metros dos modelos em quest√£o).</p>
<p>Esta abordagem em R √© nova para mim (estou mais acostumado a utilizar em Python com o m√©todo <code>sklearn.pipeline.Pipeline</code> em conjunto com a biblioteca <a href="https://pypi.org/project/imblearn/">imblearn</a>) ent√£o qualquer cr√≠tica e sugest√£o de melhoria ser√° muito bem vinda! Basta entrar em contato ou deixar aqui nos coment√°rios!</p>
<p>Bons estudos e espero que gostem! üöÄ</p>
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias</h1>
<ul>
<li><a href="https://www.tidyverse.org/blog/2021/03/workflowsets-0-0-1/" class="uri">https://www.tidyverse.org/blog/2021/03/workflowsets-0-0-1/</a></li>
<li><a href="https://www.kaggle.com/c/sliced-s01e02-xunyc5" class="uri">https://www.kaggle.com/c/sliced-s01e02-xunyc5</a></li>
<li><a href="https://juliasilge.com/blog/sliced-aircraft/" class="uri">https://juliasilge.com/blog/sliced-aircraft/</a></li>
<li><a href="https://topepo.github.io/caret/subsampling-for-class-imbalances.html" class="uri">https://topepo.github.io/caret/subsampling-for-class-imbalances.html</a></li>
<li><a href="https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/what-is-imbalanced-classification/" class="uri">https://machinelearningmastery.com/what-is-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/" class="uri">https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/</a></li>
<li><a href="https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-06-28-imbalanced-workflowsets/">Otimizando pipelines que envolvem dados desbalanceados</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">imbalanced</category>
      <category domain="tag">imbalanced-data</category>
      <category domain="tag">kaggle</category>
      <category domain="tag">machine-learning</category>
      <category domain="tag">pratica</category>
      <category domain="tag">r</category>
      <category domain="tag">random-forest</category>
      <category domain="tag">tidymodels</category>
      <category domain="tag">tidyverse</category>
      <category domain="tag">tunning</category>
    </item>
    <item>
      <title>Prevendo a qualidade do sono utilizando Machine Learning</title>
      <link>https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/</guid>
      <description>Utilizaremos dados reais coletados pelo celular para gerar previs√µes a partir de uma pequena base de dados com target desbalanceada</description>
      <content:encoded>&lt;![CDATA[
        

<div id="TOC">
<ul>
<li><a href="#qualidade-de-sono" id="toc-qualidade-de-sono">Qualidade de sono? ü§®</a></li>
<li><a href="#como-funciona-aplicativo-sleep-cycle" id="toc-como-funciona-aplicativo-sleep-cycle">Como funciona aplicativo Sleep Cycle? <img src="https://www.sleepcycle.com/wp-content/uploads/2020/09/sleep_cycle_app_icon-480x480.png" style="width:3.0%" /></a></li>
<li><a href="#objetivo" id="toc-objetivo">Objetivo üéØ</a></li>
<li><a href="#explorar-dados" id="toc-explorar-dados">Explorar dados üîé</a>
<ul>
<li><a href="#limpeza-e-prepara%C3%A7%C3%A3o-dos-dados" id="toc-limpeza-e-prepara√ß√£o-dos-dados">Limpeza e prepara√ß√£o dos dados</a></li>
<li><a href="#imputar-dados-de-fontes-externas" id="toc-imputar-dados-de-fontes-externas">Imputar dados de fontes externas</a></li>
<li><a href="#insights" id="toc-insights">Insights</a></li>
<li><a href="#reter-dados" id="toc-reter-dados">Reter dados</a></li>
</ul></li>
<li><a href="#modelagem" id="toc-modelagem">Modelagem üöÄ</a>
<ul>
<li><a href="#amostragem" id="toc-amostragem">Amostragem</a></li>
<li><a href="#engenharia-de-recursos" id="toc-engenharia-de-recursos">Engenharia de recursos</a></li>
<li><a href="#modelo-nulo-baseline" id="toc-modelo-nulo-baseline">Modelo Nulo (Baseline)</a></li>
<li><a href="#%C3%A1rvore-de-decis%C3%B5es" id="toc-√°rvore-de-decis√µes">√Årvore de decis√µes</a></li>
<li><a href="#random-forest" id="toc-random-forest">Random Forest</a></li>
<li><a href="#lightgbm" id="toc-lightgbm">LightGBM</a></li>
</ul></li>
<li><a href="#sele%C3%A7%C3%A3o-do-modelo" id="toc-sele√ß√£o-do-modelo">Sele√ß√£o do modelo ü§î</a></li>
<li><a href="#previs%C3%A3o-em-dados-novos" id="toc-previs√£o-em-dados-novos">Previs√£o em dados novos üí´</a></li>
<li><a href="#conclus%C3%A3o" id="toc-conclus√£o">Conclus√£o üçª</a></li>
<li><a href="#refer%C3%AAncias" id="toc-refer√™ncias">Refer√™ncias üß≥</a></li>
</ul>
</div>

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 33%;
padding: 10px;
}

.column8 {
float: left;
width: 66%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>
<div id="qualidade-de-sono" class="section level1">
<h1>Qualidade de sono? ü§®</h1>
<p>Sim, exatamente! Neste post analisaremos dados de um <em>tracking</em> que venho fazendo desde 2017 com informa√ß√µes relacionadas √† um sono de qualidade.</p>
<div class="row">
<div class="column8">
<p>Boas noites de sono nos tornam mais felizes, mais saud√°veis, mais inteligentes, mais dispostos e evita problemas de cansa√ßo, falta de concentra√ß√£o, depress√£o e ansiedade.</p>
<p>Resumindo, a nossa qualidade de vida est√° diretamente ligada √† qualidade do nosso sono, pois ao dormir nosso corpo realiza fun√ß√µes extremamente importantes como por exemplo o fortalecimento do sistema imunol√≥gico, secre√ß√£o e libera√ß√£o de horm√¥nios, consolida√ß√£o da mem√≥ria, entre outras<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
</div>
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/mguPrVJAnEHIY/giphy.gif" alt="Via Giphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/mguPrVJAnEHIY/giphy.gif">Via Giphy</a></div>
</div>
</div>
</div>
<p>Alguns fatores podem auxiliar a determinar se uma noite foi bem dormida como por exemplo: a regularidade do hor√°rio de dormir e de acordar, a frequ√™ncia card√≠aca (bpm), n√∫mero de passos dados no dia, tempo na cama, tempo antes de dormir, ronco, tipo de clima etc..</p>
<div class="row">
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/xUPJPlFxssGpmLemru/giphy.gif" style="width:80.0%" alt="Via Gyiphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/xUPJPlFxssGpmLemru/giphy.gif">Via Gyiphy</a></div>
</div>
</div>
<div class="column8">
<p>Felizmente, existe um aplicativo chamado <a href="sleepcycle.com/">Sleep Cycle</a> que √© capaz de <em>trackear</em> todas essas informa√ß√µes durante o uso do app, dentre outras funcionalidades. Desde 2017 tenho acompanhado meu sono atrav√©s dele, principalmente pela funcionalidade de <a href="https://www.sleepcycle.com/how-sleep-cycle-works/">rastreio dos padr√µes de sono para despertar durante sua fase mais leve, sem um despertador convencional</a> e tenho curtido bastante!</p>
</div>
</div>
<p>A proposta principal do aplicativo √© monitorar os sinais do corpo para nos despertar suavemente quando estivermos no est√°gio de sono mais leve poss√≠vel, pois acordar durante o sono leve √© como acordar naturalmente descansado!</p>
</div>
<div id="como-funciona-aplicativo-sleep-cycle" class="section level1">
<h1>Como funciona aplicativo Sleep Cycle? <img src="https://www.sleepcycle.com/wp-content/uploads/2020/09/sleep_cycle_app_icon-480x480.png" style="width:3.0%" /></h1>
<p><small>Tradu√ß√£o livre de <a href="https://www.sleepcycle.com/how-sleep-cycle-works/"><em>How Sleep Cycle works</em></a>:</small></p>
<p>‚ÄúO funcionamento b√°sico desse aplicativo se baseia que nos mexemos predominantemente durante o sono leve. J√° durante o sono pesado, os m√∫sculos tendem a permanecer relaxados, e em sono REM a movimenta√ß√£o muscular abaixo do pesco√ßo fica paralizada.</p>
<p>Assim sendo √© poss√≠vel selecionar um hor√°rio que gostaria de acordar, como de 6:30 at√© 7:00, e o aplicativo rastrear√° os movimentos na cama para acordar apenas quando entrar em sono leve durnte este per√≠odo.</p>
<p>Dessa forma, estar√≠amos aumentando as chances de acordar mais bem-disposto, j√° que seu sono foi interrompido em uma fase mais leve de descanso.‚Äù</p>
<p>Vejamos dois gr√°ficos que exemplificam dois dos poss√≠veis cen√°rios de uma noite de sono:</p>
<div class="row">
<div class="column">
<center>
<strong>Exemplo 1 - sono regular</strong>
<img src="https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_regular_sleep.png" style="width:80.0%" alt="via SleepCycle.com" />
</br>
<small>Os picos representam os ciclos do sono, incluindo todas as fases do sono.</small>
</center>
</div>
<div class="column">
<center>
<strong>Exemplo 2 - sono irregular</strong>
<img src="https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_irregular_sleep.png" style="width:80.0%" alt="via SleepCycle.com" />
</br>
<small>Ciclos de sono mais irregulares, onde o usu√°rio provavelmente n√£o dormiu t√£o bem como em nosso primeiro exemplo.</small>
</center>
</div>
</div>
<p>Esta √© a principal informa√ß√£o coletada no aplicativo e que permite um ‚Äúdespertar tranquilo‚Äù!</p>
<!-- Agora que j√° entendemos as benef√≠cios de uma noite bem dormida, de onde v√™m os dados, como o app funciona e quantas horas proporcionam uma boa noite de sono, vamos direto ao objetivo deste post! -->
</div>
<div id="objetivo" class="section level1">
<h1>Objetivo üéØ</h1>
<p>Apesar do aplicativo captar diversos dados sobre a noite de sono, o ‚Äúhumor ao acordar‚Äù √© uma informa√ß√£o fornecida pelo usu√°rio assim que desativa o alarme, quando a seguinte tela √© exibida:</p>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/mood.jpg" style="width:80%;">
</center>
<p>Como houveram diversos dias em que utilizei o aplicativo mas n√£o assinalei o humor (seja por ter desativado o recurso por algum tempo ou simplesmente por ter ignorado üòÖ) vamos trabalhar para responder a seguinte pergunta:</p>
<blockquote>
<p>Qual foi a probabilidade de ter acordado de <strong>mal humor</strong> durante o per√≠odo de <em>tracking</em> do app, nos dias cujo esse dado √© faltante?</p>
</blockquote>
<p>Onde <strong>mal humor</strong> ser√° a classe positiva da <strong>target</strong>, traduzido nos dados da seguinte forma:</p>
<p><span class="math display">\[
mood=
\begin{cases}
Bom, &amp; \text{se}\  mood = Bom \\
Ruim, &amp; \text{c.c}\
\end{cases}
\]</span></p>
<p>Logo, <code>mood</code> ser√° bin√°ria, avaliando se o humor foi <code>Bom</code> ou <code>Ruim</code> ao acordar, onde <code>Ruim</code> a combina√ß√£o do status üòë (Ok) e üò° (Mau) e ser√° a classe mais importante para controlar os erros de previs√£o.</p>
<p>Tomei a liberdade de fazer essa transforma√ß√£o pois desde o in√≠cio do uso do app, marco como <code>Ruim</code> apenas quando realmente n√£o descansei de forma satisfat√≥ria. Isso pode ter ocorrido por diversos fatores, como por exemplo: acordar ap√≥s um pesadelo; acordar com barulho da rua ou de casa; acordar meio doente ou passando mal e por ai vai..</p>
<p>Por enquanto, estas informa√ß√µes ser√£o suficientes. Vejamos na an√°lise explorat√≥ria como se apresenta a vari√°vel target e quais dados dispon√≠veis para atingir tal objetivo.</p>
</div>
<div id="explorar-dados" class="section level1">
<h1>Explorar dados üîé</h1>
<p>Carregar as depend√™ncias:</p>
<pre class="r"><code>library(tidyverse)  # datascience toolkit 
library(lubridate)  # manipule date
library(patchwork)  # grid ggplot
library(tidymodels) # machine learning toolkit
library(reactable)  # print tables 
library(treesnip)   # lightgbm

# Definir tema para ggplot
theme_set(theme_bw()) </code></pre>
<p>Vamos carregar fun√ß√µes que foram desenvolvidas ao longo das an√°lises para facilitar tanto na apresenta√ß√£o dos resultados quanto na portabilidade dos c√≥digos (bastando pequenos ajustes para ‚Äúrecicl√°-los‚Äù ‚ôªÔ∏è):</p>
<details>
<summary>
(<em>Clique aqui para exibir as fun√ß√µes customizadas</em>)
</summary>
<pre class="r"><code># Para o print de tabelas
print_table &lt;- function(x, round=0, evalue_model = F, ...){ 
  
  if(round&gt;0) x &lt;- x %&gt;% mutate_if(is.numeric, ~round(.x, round))
  
  if(evalue_model == T){
    
    reactable::reactable(x, striped = T, bordered = T, 
                         highlight = T, pagination = F,
                         width = 800,
                         defaultColDef = colDef(minWidth = 85),
                         defaultSorted = list(auc_pr = &quot;desc&quot;),
                         columns = list(
                           model = colDef(minWidth = 110),
                           tp = colDef(minWidth = 40),
                           fp = colDef(minWidth = 40),
                           fn = colDef(minWidth = 40),
                           tn = colDef(minWidth = 40)),
                         ...)  
    
  }else{
    reactable::reactable(x, striped = T, bordered = T, width = 800,
                         highlight = T, pagination = F, ...)  
  }
  
  
}

# Graficos de features numericas
plot_num &lt;- function(data, num_feature, 
                     title = NULL, bins = 30, legend = NULL){
  
  if(is.null(title)) title = num_feature
  
  data = data %&gt;% filter(!is.na(mood))
  
  p_shapiro = round(shapiro.test(data$air_pressure_pa)$p.value, 5)
  
  p1 &lt;- 
    data %&gt;% 
    ggplot(aes_string(x = num_feature, fill = &quot;mood&quot;))+
    geom_histogram(aes(y=..density..), bins = bins, alpha = 0.5,
                   show.legend = ifelse(!is.null(legend), T, F))+
    geom_density(alpha = 0.5,
                 show.legend = ifelse(!is.null(legend), T, F))+
    labs(y = &quot;&quot;, x= &quot;&quot;, title = title)+
    scale_fill_viridis_d(end = 0.8, direction = 1)
  
  if(!is.null(legend)){
    p1 = p1 + theme(legend.position = legend)
  }
  
  p2 &lt;- 
    data %&gt;% 
    ggplot(aes_string(x = num_feature))+
    geom_boxplot(aes(y = &quot;&quot;, color = mood), 
                 show.legend = F)+
    labs(y = &quot;&quot;, x= &quot;&quot;, 
         caption = paste0(&quot;Shapiro-Wilk normality test: &quot;,
                          ifelse(p_shapiro == 0, &quot;P&lt;0.05&quot;, p_shapiro) ))+
    scale_color_viridis_d(end = 0.8, direction = 1)
  
  p1 / p2  + plot_layout(heights = c(4/5, 1/5))
}  

# Graficos de features categoricas
plot_cat &lt;- function(data, cat_feature, title = NULL, label = TRUE, legend = NULL){
  
  data = data %&gt;% filter(!is.na(mood))
  
  valor_p = round(chisq.test(data %&gt;% pull(cat_feature), 
                             data$mood, 
                             simulate.p.value = T)$p.value, 5)
  
  to_plot = data %&gt;%
    count(!!as.name(cat_feature), mood) %&gt;% 
    group_by(!!as.name(cat_feature)) 
  
  final_plot = to_plot %&gt;% 
    mutate(prop = n/sum(n),
           lab = paste0(round(prop*100, 2), &quot;%&quot;)) %&gt;% 
    ggplot()+
    geom_bar(aes_string(x = cat_feature, y = &quot;n&quot;, fill = &quot;mood&quot;),
             stat = &quot;identity&quot;, alpha = 0.7, 
             position = position_dodge2(0.9),
             show.legend = ifelse(!is.null(legend), T, F))+
    scale_fill_viridis_d(end = 0.8, direction = 1)+
    labs(title = title, y = &quot;&quot;,
         caption = paste0(&quot;Pearson&#39;s Chi-squared test: &quot;, valor_p))
  
  if(label == TRUE){
    final_plot = final_plot+
      geom_label(aes_string(x = cat_feature, y = &quot;n&quot;, label = &quot;lab&quot;),
                 position = position_dodge2(0.9), show.legend = F)  
  }
  
  if(!is.null(legend)){
    final_plot = final_plot + theme(legend.position = legend)
  }
  
  return(final_plot)
  
}

# Grafico interativo de features temporais
plot_dygraph &lt;- function(x, order.by, feature, title = NULL){
  x %&gt;%  
    xts::xts(order.by = order.by) %&gt;% 
    .[,feature] %&gt;%
    dygraphs::dygraph(main = title) %&gt;% 
    dygraphs::dyRangeSelector()
}

# Calcula o ponto de corte que maximiza a funcao f beta
threshold_max &lt;- function(x){
  
  fbeta &lt;- function(precision, recall){ 
    (beta+1)*(precision*recall)/(beta*(precision+recall))
  }
  
  # https://machinelearningmastery.com/fbeta-measure-for-machine-learning/
  # F05: + precision - recall
  # F1 : + precision + recall
  # F2 : - precision + recall 
  beta = 0.5
  
  x  %&gt;%
    pr_curve(mood, .pred_Ruim) %&gt;% 
    mutate(fbeta = fbeta(precision, recall) ) %&gt;% 
    filter(fbeta == max(fbeta, na.rm = T))
}

# Plot da matriz de confusao e da funcao das funcoes de densidade estimadas
conf_mat_plot &lt;- function(x, null_model = FALSE){
  trs &lt;- threshold_max(x)$.threshold
  
  if(null_model==FALSE){
    x &lt;- x %&gt;% 
      mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs, &quot;Ruim&quot;, &quot;Bom&quot;) %&gt;%
               factor(levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE))  
  }
  
  p1 &lt;- 
    x %&gt;%
    select(.pred_class, mood) %&gt;%
    table() %&gt;% 
    conf_mat() %&gt;% 
    autoplot(type = &quot;heatmap&quot;)+
    labs(title = &quot;Matriz de Confusao&quot;,
         subtitle = paste0(&quot;Threshold max F0.5: &quot;, round(trs, 4)))
  
  p2 &lt;- 
    x  %&gt;%
    ggplot() +
    geom_density(aes(x = .pred_Ruim, fill = mood), 
                 alpha = 0.5)+
    labs(title = &quot;Distribui√ß√µes de probabilidade previstas&quot;,
         subtitle = &quot;por classe&quot;)+ 
    scale_x_continuous(limits = 0:1)+
    geom_vline(aes(xintercept = trs, color = &quot;threshold max F0.5&quot;), linetype = 2) +
    scale_color_manual(name = &quot;&quot;, values = c(`threshold max F0.5` =  &quot;red&quot;))+
    scale_fill_viridis_d(end = 0.7, direction = 1)
  
  p1 | p2
} 

# Conjunto de metricas utilizadas para avaliar os modelos
evalue_model &lt;- function(x, model = &quot;&quot;, null_model=FALSE){
  
  trs &lt;- threshold_max(x)$.threshold
  
  if(null_model==FALSE){
    x &lt;- x %&gt;%
      mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs, &quot;Ruim&quot;, &quot;Bom&quot;) %&gt;% 
               factor(levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE))
  }
  
  cm &lt;- x %&gt;% 
    select(.pred_class, mood) %&gt;% 
    table() 
  
  tibble(
    model = model,
    tp = cm[1,1],
    fp = cm[1,2],
    fn = cm[2,1],
    tn = cm[2,2],
    auc_roc   = yardstick::roc_auc(x, mood, `.pred_Ruim`)$.estimate,
    auc_pr    = yardstick::pr_auc(x, mood, `.pred_Ruim`)$.estimate,
    logloss   = yardstick::mn_log_loss_vec(x$mood, x$.pred_Ruim),
    f1        = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 1),
    f05       = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 0.5),
    f2        = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 2),
    precision = yardstick::precision_vec(x$mood, x$.pred_class),
    recall    = yardstick::recall_vec(x$mood, x$.pred_class),
    trs_fbeta = trs
  ) 
}  

plot_auc &lt;- function(x){
  
  p1 &lt;-  
    x %&gt;% 
    group_by(model) %&gt;%
    roc_curve(mood, .pred_Ruim) %&gt;%
    ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
    geom_line(size = 1, alpha = 0.5, show.legend = F) +
    geom_abline(lty = 2, alpha = 0.5, color = &quot;gray50&quot;, size = 1.3)+
    labs(title = &quot;AUC&quot;)+
    scale_color_viridis_d(direction = 1)
  
  p2 &lt;- 
    x %&gt;%
    group_by(model) %&gt;%
    pr_curve(mood, .pred_Ruim) %&gt;%
    ggplot(aes(x = recall, y = precision, color = model)) +
    geom_line(size = 1.15, alpha = 0.5) +
    # geom_abline(slope = -1, intercept = 1, lty = 2, alpha = 0.5, color = &quot;gray50&quot;, size = 1.2)+
    labs(title = &quot;PR AUC&quot;)+
    theme(legend.position = &quot;right&quot;)+
    scale_color_viridis_d(direction = 1)
  
  (p1 | p2)
}</code></pre>
</details>
<p>¬†</p>
<p>Importar os dados obtidos no app <a href="https://www.sleepcycle.com/">SleepCycle</a> e padronizar nomes das colunas:</p>
<pre class="r"><code>sleep &lt;- read_csv2(&quot;sleepdata.csv&quot;) %&gt;% janitor::clean_names(case = &quot;snake&quot;)</code></pre>
<p>A seguir, uma tabela com uma descri√ß√£o do conte√∫do de cada coluna:</p>
<table>
<colgroup>
<col width="9%" />
<col width="11%" />
<col width="79%" />
</colgroup>
<thead>
<tr class="header">
<th>Coluna</th>
<th>Descri√ß√£o curta</th>
<th>Descri√ß√£o detalhada</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>start</strong></td>
<td>In√≠cio</td>
<td>In√≠cio do monitoramento</td>
</tr>
<tr class="even">
<td><strong>end</strong></td>
<td>Fim</td>
<td>Fim do monitoramento</td>
</tr>
<tr class="odd">
<td><strong>sleep_quality</strong></td>
<td>Qualidade do Sono</td>
<td>Qualidade do sono √© baseada em: tempo que passa a dormir, movimentos durante a noite e momentos em que est√° totalmente desperto</td>
</tr>
<tr class="even">
<td><strong>regularity</strong></td>
<td>Regularidade</td>
<td>Informa sobre a regularidade do hor√°rio de dormir e de acordar durante um per√≠odo de tempo. Quanto maior, mais regular tem sido o hor√°rio de acordar e dormir e isso pode resultar em um sono melhor</td>
</tr>
<tr class="odd">
<td><strong>mood</strong> üéØ</td>
<td>Humor</td>
<td>Humor informado no app ao acordar: üòÉ (Bom), üòë (Ok), üò° (Mau), ‚õî (N√£o informado)</td>
</tr>
<tr class="even">
<td><strong>heart_rate_bpm</strong></td>
<td>Frequ√™ncia card√≠aca (bpm)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>steps</strong></td>
<td>Passos</td>
<td>Quantos passos d√° por dia (bom a partir de 10.000 passos por dia)</td>
</tr>
<tr class="even">
<td><strong>alarm_mode</strong></td>
<td>Modo de alarme</td>
<td>Alarme ligado ou apenas monitoramento</td>
</tr>
<tr class="odd">
<td><strong>air_pressure_pa</strong></td>
<td>Press√£o do Ar (Pa)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>city</strong></td>
<td>Cidade</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>movements_per_hour</strong></td>
<td>Movimentos por hora</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>time_in_bed_seconds</strong></td>
<td>Tempo na cama (segundos)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>time_asleep_seconds</strong></td>
<td>Tempo adormecido (segundos)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>time_before_sleep_seconds</strong></td>
<td>Tempo antes de dormir (segundos)</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>window_start</strong></td>
<td>In√≠cio da janela</td>
<td>In√≠cio do modo soneca</td>
</tr>
<tr class="even">
<td><strong>window_stop</strong></td>
<td>Fim da janela</td>
<td>Fim do modo soneca</td>
</tr>
<tr class="odd">
<td><strong>did_snore</strong></td>
<td>Ronco</td>
<td>Detector de ru√≠dos (pode captar outros barulhos que n√£o seja ronco)</td>
</tr>
<tr class="even">
<td><strong>snore_time</strong></td>
<td>Hora do ronco</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>weather_temperature_c</strong></td>
<td>Temperatura (¬∞C)</td>
<td>-</td>
</tr>
<tr class="even">
<td><strong>weather_type</strong></td>
<td>Tipo de clima</td>
<td>-</td>
</tr>
<tr class="odd">
<td><strong>notes</strong></td>
<td>Notas</td>
<td>Alguma nota ao acordar</td>
</tr>
</tbody>
</table>
<p>¬†</p>
<div id="limpeza-e-prepara√ß√£o-dos-dados" class="section level2">
<h2>Limpeza e prepara√ß√£o dos dados</h2>
<p>Vamos realizar uma limpeza inicial, preparando os dados para possibilitar as an√°lise em um objeto <code>tibble</code> minimamente arrumado:</p>
<pre class="r"><code>sleep &lt;- sleep %&gt;% 
  # fix target
  mutate(mood = case_when(mood == &quot;Bom&quot; ~ &quot;Bom&quot;,
                          mood == &quot;Mau&quot; ~ &quot;Ruim&quot;,
                          mood == &quot;Ok&quot; ~ &quot;Ruim&quot;,
                          is.na(mood) ~ NA_character_),
         mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;% 
  # fix window
  mutate_at(c(&quot;window_start&quot;, &quot;window_stop&quot;), 
            ~ifelse(is.na(.x), end, .x)) %&gt;% 
  # fix string %
  mutate_at(c(&quot;sleep_quality&quot;, &quot;regularity&quot;),
            ~ .x %&gt;% str_remove(&quot;%&quot;) %&gt;% as.numeric() ) %&gt;% 
  # fix heart_rate_bpm e criar bug indicator 
  mutate(heart_rate_bug = ifelse(heart_rate_bpm == 0, &quot;sim&quot;, &quot;nao&quot;)) %&gt;% 
  mutate(heart_rate_bpm = ifelse(heart_rate_bpm == 0, 
                                 NA_integer_, heart_rate_bpm)) %&gt;% 
  # fix dados de soneca
  mutate(snore_time = as.numeric(snore_time),
         did_snore = ifelse(did_snore == TRUE, &quot;sim&quot;, &quot;nao&quot;)) %&gt;% 
  # fix para numerico
  mutate_at(c(&quot;time_before_sleep_seconds&quot;, 
              &quot;time_asleep_seconds&quot;, 
              &quot;time_in_bed_seconds&quot;),
            ~as.numeric(.x) ) %&gt;% 
  # fix movements_per_hour para double
  mutate(movements_per_hour = as.double(movements_per_hour)) %&gt;% 
  # fix weather_type
  mutate(weather_type = 
           factor(weather_type, 
                  levels = c(&quot;No weather&quot;, &quot;Rain&quot;, &quot;Rainy showers&quot;, &quot;Cloudy&quot;,
                             &quot;Partly cloudy&quot;, &quot;Fair&quot;, &quot;Sunny&quot;),
                  ordered = TRUE))  %&gt;% 
  mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
            ~ as.numeric(.x) %&gt;% if_else(. == 0, NA_real_, .)) %&gt;% 
  # remover unused columns
  select(-one_of(c(&quot;city&quot;, &quot;notes&quot;))) %&gt;% 
  select(mood, everything()) %&gt;% 
  arrange(end)</code></pre>
<p>Qual a estrutura geral dos dados? Ser√° que existe algum padr√£o nos dados ausentes?</p>
<pre class="r"><code>sleep %&gt;% 
  arrange(end) %&gt;% 
  mutate(Date = as.Date(end))%&gt;%
  # complete(Date = seq.Date(min(Date), max(Date), by=&quot;day&quot;))  %&gt;%  
  visdat::vis_dat() </code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-7-1.png" style="width:80.0%" />
</center>
<p>Os dados ausentes ocorrem tanto espalhados (<code>heart_rate_bpm</code>) quanto em sequ√™ncia (<code>air_pressure_pa</code>, <code>weather_temperature_c</code>, <code>mood</code>) portando, adotaremos as seguintes estrat√©gias para inputar dados ausentes:</p>
<ol style="list-style-type: decimal">
<li><code>air_pressure_pa</code>: Ser√° obtidos no site <a href="https://www.data.rio/datasets/dados-hor%C3%A1rios-do-monitoramento-da-qualidade-do-ar-monitorar?selectedAttribute=Pres">data.rio/datasets</a> e caso ainda exista dados ausentes, ser√° preenchido com as m√©dias m√≥veis dos √∫ltimos 7 dias;</li>
<li><code>weather_temperature_c</code>: Mesma estrat√©gia do item (1);</li>
<li><code>heart_rate_bpm</code>: C√°lculo das m√©dias m√≥veis dos √∫ltimos 7 dias;</li>
<li><code>mood</code>: Como √© a <em>target</em>, as inst√¢ncias aonde <code>is.na(mood)</code> ser√£o retidas para estima√ß√£o ap√≥s o ajuste do modelo.</li>
</ol>
</div>
<div id="imputar-dados-de-fontes-externas" class="section level2">
<h2>Imputar dados de fontes externas</h2>
<p>O preenchimento das features <code>air_pressure_pa</code>, <code>weather_temperature_c</code> ser√£o realizados a partir do download de dados p√∫blicos do Rio de Janeiro no link: <a href="https://www.data.rio/datasets/dados-hor%C3%A1rios-do-monitoramento-da-qualidade-do-ar-monitorar?selectedAttribute=Pres">data.rio/datasets</a>. Para obter este dado utilizaremos a fun√ß√£o <code>get_rj_data()</code> desenvolvida para este post, que est√° omitida mas para quem tiver interesse basta conferir clicando no item abaixo:</p>
<details>
<summary>
(<em>C√≥digo da fun√ß√£o <code>get_rj_data()</code></em>)
</summary>
<pre class="r"><code>get_rj_data &lt;- function(){ 
  
  if(!file.exists(&quot;rj_data.rds&quot;)){ 
    
    url &lt;- &quot;https://opendata.arcgis.com/datasets/5b1bf5c3e5114564bbf9b7a372b85e17_2.csv?outSR=%7B%22latestWkid%22%3A4326%2C%22wkid%22%3A4326%7D&quot;
    
    download.file(url, &quot;rj_data.csv&quot;)
    
    rj_data &lt;- readr::read_csv(&quot;rj_data.csv&quot;)
    
    saveRDS(rj_data, &quot;rj_data.rds&quot;)
    
  }else{
    rj_data &lt;- readRDS(&quot;rj_data.rds&quot;)
  }
  
  # preparar dados de pressao atmosferica e temperatura no periodo desejado
  rj_data &lt;- rj_data %&gt;% 
    mutate(Data = ymd_hms(Data)) %&gt;% 
    filter(Data &gt;= min(sleep$start) &amp;  Data &lt;= max(sleep$start)) %&gt;% 
    group_by(Data = as.Date(Data)) %&gt;% 
    summarise(air_pressure_pa = mean(Pres/10, rm.na=T),
              weather_temperature_c = mean(Temp, rm.na=T))
  
  return(rj_data)
  
}</code></pre>
</details>
<!-- &nbsp; -->
<p>Com acesso aos dados, hora de combinar as bases e preencher os dados faltantes:</p>
<pre class="r"><code>sleep &lt;- sleep %&gt;% 
  mutate(Data = as.Date(start)) %&gt;%
  # to numeric
  mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
            ~ as.numeric(.x) %&gt;% if_else(. == 0, NA_real_, .)) %&gt;% 
  # join Rio data
  left_join(get_rj_data() , by = c(&quot;Data&quot;)) %&gt;% 
  # fill with new data
  mutate(air_pressure_pa = ifelse(is.na(air_pressure_pa.x),
                                  air_pressure_pa.y,
                                  air_pressure_pa.x)) %&gt;%
  mutate(weather_temperature_c = ifelse(is.na(weather_temperature_c.x),
                                        weather_temperature_c.y, 
                                        weather_temperature_c.x)) %&gt;%
  # remove aux columns
  select(-air_pressure_pa.x, -air_pressure_pa.y,
         -weather_temperature_c.x, -weather_temperature_c.y,
         -Data)</code></pre>
</div>
<div id="insights" class="section level2">
<h2>Insights</h2>
<p>Nesta se√ß√£o vamos responder algumas perguntas com dados!</p>
<div id="start-e-end" class="section level3">
<h3><code>start</code> e <code>end</code></h3>
<p>Qual a m√©dia mensal de horas dormidas e que horas costumo acordar, em m√©dia, mensalmente ao longo desses anos?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>dy1 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(dif_sleep_hours = as.numeric(end - start)/60) %&gt;% 
  mutate(dif_sleep_hours = zoo::rollmean(dif_sleep_hours, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;dif_sleep_hours&#39;)

dy2 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(end_hour = hour(end)) %&gt;% 
  mutate(end_hour = zoo::rollmean(end_hour, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;end_hour&#39;)</code></pre>
</details>
<p>¬†¬†</p>
<!-- <div class="row"> -->
<!-- <div class="column"> -->
<!-- <center> -->
<!-- **Tempo dormindo (em horas)** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3,echo = F} -->
<!-- dy1 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O tempo que passa dormindo parece variar (em m√©dia) em torno de 6 √† 7 horas</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- <div class="column"> -->
<!-- <center>   -->
<!-- **Hora que acorda** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3,echo = F} -->
<!-- dy2 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O pico no in√≠cio no gr√°fico corresponde ao pen√∫ltimo semestre da facultado. No final de 2017 comecei a trabalhare passei a acordar mais cedo  </small> -->
<!-- </center> -->
<!-- </div> -->
<!-- </div> -->
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img1.png" style="width:80.0%" /></p>
<div class="w3-panel w3-sand w3-border">
<p>‚ö†Ô∏è Note que existem alguns espa√ßos vazios, que correspondem aos dias que o app n√£o foi utilizado.</p>
</div>
</div>
<div id="window_start-e-window_stop" class="section level3">
<h3><code>window_start</code> e <code>window_stop</code></h3>
<p>Quanto tempo costumo usar o modo ‚Äúsoneca‚Äù ao longo da semana? E aos finais de semana?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>p &lt;- sleep %&gt;% 
  mutate(mood = ifelse(is.na(mood), &quot;NA&quot;, as.character(mood)) %&gt;% 
           factor(levels = c(&quot;Ruim&quot;, &quot;NA&quot;, &quot;Bom&quot;))) %&gt;% 
  mutate(nap_minutes = (window_stop - window_start) / 30,
         final_de_semana = lubridate::wday(start) %in% c(1, 7)) %&gt;% 
  count(mood, final_de_semana, nap_minutes) %&gt;% 
  group_by(mood, final_de_semana) %&gt;% 
  mutate(
    fnap_minutes = case_when(
      nap_minutes == 0 ~ &quot;Sem modo soneca&quot;,
      nap_minutes == 20 ~ &quot;20 minutos&quot;,
      nap_minutes == 30 ~ &quot;30 minutos&quot;,
      nap_minutes == 60 ~ &quot;1 hora&quot;),
    fnap_minutes = reorder(fnap_minutes, nap_minutes),
    final_de_semana = ifelse(final_de_semana == T, &quot;Final de semena&quot;, &quot;Dia de semana&quot;),
    label = paste0( n, &quot; (&quot;, round(n/sum(n)*100, 2), &quot;%)&quot;)
  ) %&gt;% 
  ggplot(aes(x = fnap_minutes, y = n, label = label, fill = mood))+
  geom_bar(stat = &quot;identity&quot;, alpha = 0.8)+
  scale_fill_viridis_d(end = 0.7, direction = 1)+
  # ggrepel::geom_label_repel(aes(label = label))+
  labs(x = &quot;&quot;, y = &quot;&quot;)+
  facet_wrap(~final_de_semana)+
  theme(axis.text.x = element_text(angle = 30, hjust=1))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>p %&gt;% plotly::ggplotly() %&gt;% plotly::config(displayModeBar = F)</code></pre>
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img2.png" style="width:80.0%" /></p>
<p>Como era de se esperar, os dias em que <code>mood=="Ruim"</code> ocorrem mais quando o modo soneca n√£o √© ativado pois acaba mesmo sendo menos prop√≠cio a voltar a dormir. Outro detalhe √© que muitas vezes usei o soneca por um tempo muito prolongado! (üò± pelo menos <code>mood=="Bom"</code> na maioria desses casos!)</p>
<p>J√° nos finais de semana, ocorre pouqu√≠ssimo <code>mood== "Ruim"</code> e praticamente n√£o h√° uso do alarme e quando h√°, n√£o utiliza soneca.</p>
</div>
<div id="weather_type-e-alarm_mode" class="section level3">
<h3><code>weather_type</code> e <code>alarm_mode</code></h3>
<p>Ser√° que o humor ao acordar esta relacionado com o tipo de clima ou com o modo utilizado no alarme?</p>
<pre class="r"><code>p1 &lt;- plot_cat(sleep, cat_feature=&quot;weather_type&quot;, 
               title = &quot;Tipo de clima&quot;, label = F)+ 
  theme(axis.text.x = element_text(angle = 30, hjust=1))

p2 &lt;- plot_cat(sleep, cat_feature=&quot;alarm_mode&quot;, 
               title = &quot;Modo de alarme&quot;, label = F, legend = &quot;right&quot;)

p1 | p2</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-15-1.png" style="width:80.0%" />
</center>
<p>Nota-se que n√£o existem evid√™ncias estatisticas para afimar que essas features (sozinhas) est√£o associadas √† target, por√©m como ser√£o utilizados modelos baseados em √°rvores que experimentam diversas combina√ß√µes de features, vamos manter na base e deixar o modelo decidir como usar.</p>
</div>
<div id="sleep_quality-e-time_in_bed_seconds" class="section level3">
<h3><code>sleep_quality</code> e <code>time_in_bed_seconds</code></h3>
<p>A qualidade de sono e o tempo da cama est√£o normalmente distribu√≠dos em torno de uma m√©dia?</p>
<pre class="r"><code>p1 &lt;- sleep %&gt;% plot_num(&quot;sleep_quality&quot;)
p2 &lt;- sleep %&gt;% plot_num(&quot;time_in_bed_seconds&quot;, legend = &quot;right&quot;)

p1 | p2</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-16-1.png" style="width:80.0%" />
</center>
<p>Existem alguns registros em que o tempo na cama √© menor que 10.000 segundos (~3horas) o que corresponde aos pequenos cochilos que registrei no app. N√£o foram muitos registros mas talvez seja √∫til na modelagem pois existem ocorr√™ncias de humor (<code>mood</code>) <code>Bom</code> e <code>Ruim</code> ali.</p>
<p>Como a correla√ß√£o de spearman entre estas duas feautures √© muito alta (0.8705) √© poss√≠vel notar que baixa qualidade do sono esta altamente correlacionada com o tempo na cama.</p>
<p>Mais uma pergunta sobre estas features: Como a m√©dia mensal da qualidade do sono e do tempo na cama em horas est√£o distribu√≠dos ao longo do tempo?</p>
<details>
<summary>
(<em>C√≥digo para gr√°fco abaixo</em>)
</summary>
<pre class="r"><code>dy1 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)),
                            max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(sleep_quality = zoo::rollmean(sleep_quality, k =  30, fill = NA)) %&gt;%
  plot_dygraph(order.by = .$start, feature =  &#39;sleep_quality&#39;)

dy2 &lt;- sleep %&gt;% 
  complete(start = seq.Date(min(as.Date(start)), 
                            max(as.Date(start)), by=&quot;day&quot;)) %&gt;%
  mutate(time_in_bed_seconds = 
           zoo::rollmean(time_in_bed_seconds, k =  30, fill = NA)) %&gt;%
  mutate(time_in_bed_seconds = time_in_bed_seconds / 60 / 60) %&gt;% 
  plot_dygraph(order.by = .$start, feature =  &#39;time_in_bed_seconds&#39;)</code></pre>
</details>
<p>¬†¬†</p>
<!-- <div class="row"> -->
<!-- <div class="column"> -->
<!-- <center> -->
<!-- **Qualidade do sono** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3, echo = F} -->
<!-- dy1 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>Parece que a qualidade do sono vem aumentando desde final de 2019, mantendo um patamar semlhante ao final e 2018.</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- <div class="column"> -->
<!-- <center>   -->
<!-- **Tempo na cama em horas** -->
<!-- </br> -->
<!-- <small>M√©dia m√≥vel 30 dias</small> -->
<!-- ```{r, fig.height=2, fig.width=3, echo = F} -->
<!-- dy2 -->
<!-- ``` -->
<!-- </br> -->
<!-- <small>O tempo na cama varia entre 6 √† 7 horas (Apesar de alguns picos em 2020, provavelmente por conta da pandemia do corona virus quando estabeleceu-se o home office)</small> -->
<!-- </center> -->
<!-- </div> -->
<!-- </div> -->
<p><img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img3.png" style="width:80.0%" /></p>
</div>
</div>
<div id="reter-dados" class="section level2">
<h2>Reter dados</h2>
<p>Antes de iniciar o processo de modelagem, ser√° necess√°rio reter dados aonde <code>mood</code> √© <code>NA</code>, pois faremos as previs√µes nestes dados apenas ap√≥s o ajuste e sele√ß√£o do modelo final.</p>
<pre class="r"><code>new_sleep &lt;- sleep %&gt;% filter(is.na(mood))
sleep &lt;- sleep %&gt;% filter(!is.na(mood))</code></pre>
</div>
</div>
<div id="modelagem" class="section level1">
<h1>Modelagem üöÄ</h1>
<p>Hora de criar alguns modelos para estimar a probabilidade das classes da target: <code>mood</code>.</p>
Como estamos diante de um cen√°rio onde os dados est√£o desbalanceados, ser√° necess√°rio tomar algumas decis√µes muito importantes (sim, cientistas de dados precisam tomar decis√µes o tempo inteiro).
<div class="row">
<div class="column8">
<div class="center">
<span>
<div>
<p>Neste caso, as quest√µes s√£o as seguintes:</p>
<ol style="list-style-type: decimal">
<li>Qual a classe mais importante?</li>
<li>Qual a m√©trica ser√° utilizada para selecionar os modelos?</li>
<li>Qual ser√° o <em>threshold</em>?</li>
<li>Qual ser√° estrat√©gia para lidar com o desbalanceamento?</li>
<li>Quais m√©tricas ser√£o monitoradas?</li>
</ol>
</div>
<p></span></p>
</div>
</div>
<div class="column4">
<p></br>
<img src="https://media.giphy.com/media/XeH1MFu4x3etVsllUN/giphy.gif" alt="Via Giphy" /></p>
</div>
</div>
<p>A classe mais importante para nossa previs√£o √© a positiva, ou seja, <code>mood=="Ruim"</code>. Sendo assim desejamos <strong>evitar falsos positivos</strong>.</p>
<p>A m√©trica utilizada para selecionar os modelos ser√° a <a href="https://www.kaggle.com/dansbecker/what-is-log-loss"><strong>logloss</strong></a>. Esta √© uma m√©trica probabilistica que foca na incerteza que o modelo tem nas previs√µes e penaliza as previs√µes que est√£o erradas<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>Ap√≥s calibrar a probabilidade, estabeleceremos um ponto de corte que <strong>maximizar a medida F-Beta</strong>, (que √© uma abstra√ß√£o da medida <em>F1</em>, m√©dia harm√¥nica entre <em>Precision</em> e <em>Recall</em>) onde <em>Beta = 0.5</em>. Essa medida tem o efeito de aumentar a import√¢ncia da <em>Precision</em> e diminui a import√¢ncia do <em>Recall</em>. <a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>Parra lidar com o desbalanceamento da <em>target</em>, utilizaremos o m√©todo de <em>undersampling</em> chamado ** <em>Tomek Links</em> **<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. Este m√©todo faz uma amostragem da classe majorit√°ria de forma ‚Äúmais esperta‚Äù que uma simples amostragem aleat√≥ria.</p>
<p>Por fim, a principal m√©trica que ser√° monitorada ser√° a <strong><em>AUC-PR</em></strong><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> (<em>Area Under Precision Recall Curve</em>). Ela √© uma esp√©cie de <em>AUC</em> que c√°lculada a √°rea sobre a <em>Precision</em> x <em>Recall</em>. Essa m√©trica √© prefer√≠vel neste caso pois foca maisn na classe positiva e a <em>ROC AUC</em> tente a superestimar os valores nesse caso.</p>
<div id="amostragem" class="section level2">
<h2>Amostragem</h2>
<p>Para preparar os dados para modelagem vamos dividir os dados em treino (70%) e teste (30%).</p>
<pre class="r"><code>set.seed(123456789)

# treino e teste
sleep_split &lt;- initial_split(data = sleep, strata = mood, prop = 0.7)
sleep_train &lt;- training(sleep_split)
sleep_test  &lt;- testing(sleep_split)</code></pre>
<p>Al√©m disso, vamos dividir o conjunto de treino em 4 folds para obter resultados de valida√ß√£o cruzada. Este valor corresponde metade da quantidade em que <code>mood=="Ruim"</code> nos dados teste.</p>
<pre class="r"><code>set.seed(123456789)
k_fold &lt;- sleep_test %&gt;% count(mood) %&gt;% filter(mood==&quot;Ruim&quot;) %&gt;% pull(n)

sleep_folds &lt;- sleep_train %&gt;% 
  rsample::vfold_cv(v = round(k_fold/2), repeats = 10, strata = mood)</code></pre>
<p>A decis√£o de utilizar o valor de <code>k</code> como metade do tamanho da classe minorit√°ria foi uma decis√£o pessoal, n√£o sei se √© √≥tima mas foi conveniente neste caso.</p>
<p>Como ficou dividido:</p>
<details>
<summary>
(<em>C√≥digo para tabela abaixo</em>)
</summary>
<pre class="r"><code>tab &lt;- 
  full_join(sleep_train %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            sleep_test %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            by = &quot;mood&quot;) %&gt;% 
  print_table(round = 2,
              columns = list(
                n.x = colDef(name = &quot;N&quot;),
                prop.x = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n.y = colDef(name = &quot;N&quot;),
                prop.y = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;)
              ), 
              columnGroups = list(
                colGroup(name = &quot;Train&quot;, columns = c(&quot;n.x&quot;, &quot;prop.x&quot;)),
                colGroup(name = &quot;Test&quot;, columns = c(&quot;n.y&quot;, &quot;prop.y&quot;))
              ))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>tab</code></pre>
<div class="w3-panel w3-pale-red w3-border">
<p>‚ò†Ô∏è A quantidade reduzida de dados para teste reflete a baixa quantidade de dados no geral!</p>
</div>
</div>
<div id="engenharia-de-recursos" class="section level2">
<h2>Engenharia de recursos</h2>
<p>Hora de criar o objeto que vai conter todos os passos do pr√©-processamento necess√°rio! Esse passo √© muito importante pois algumas estat√≠sticas precisam ser calculadas nos dados de treino isoladamente para n√£o ‚Äúdar pistas‚Äù para modelo sobre as informa√ß√µes contidas nos dados de teste, comprometendo o desempenho do modelo em novos dados.</p>
<p>De forma semelhante (mas n√£o igual) ao <code>sklearn.pipeline.Pipeline</code>, dispon√≠vel para Python, na linguagem R existe o pacote <code>recipes</code> que permite a cria√ß√£o de ‚Äúreceitas‚Äù com a fun√ß√£o <code>recipe()</code> e que pode ser utilizada em um <code>workflow()</code> para treinar o modelo na sequ√™ncia.</p>
<p>Sendo assim, algumas das opera√ß√µes realizadas no pr√©processamento do modelo:</p>
<ul>
<li>Criar feature: <code>ano</code>;</li>
<li>Criar feature: <code>mes</code>;</li>
<li>Criar feature: <code>dia da semana</code>;</li>
<li>Criar feature: <code>dia do mes</code>;</li>
<li>Criar feature: <code>hora que acordou</code>;</li>
<li>Criar feature: <code>final de semana</code>;</li>
<li>Criar feature: <code>tempo dormindo</code>;;</li>
<li>Criar feature: <code>tempo de soneca</code></li>
<li>Criar feature: <code>quarentena</code>;</li>
<li>Inputar m√©dia movel semanal para preencher as features de <code>weather_temperature_c</code> e <code>air_pressure_pa</code> no RJ;</li>
<li>Transformar categ√≥ricas em dummy;</li>
<li>Remover colunas com dados inv√°lidos para modelo (timestamp);</li>
<li>Preencher os dados faltantes de <code>heart_rate_bpm</code> utilizando o algor√≠tmo <code>knn</code> com 2 vizinhos mais pr√≥ximos;</li>
<li>Aplicar o algoritmo <em>Tomek Links</em>, que √© um m√©todo de <em>undersampling</em>.</li>
</ul>
<p>Caso queira saber mais sobre m√©todos de <em>undersampling</em> para tratar dados desbalanceados sugiro a leitura <a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/">deste excelente post</a>! (Os c√≥digos est√£o em Python por√©m a explica√ß√£o da teoria √© o que importa neste caso)</p>
<p>Preparar objeto <code>recipe</code> que cont√©m um conjunto de etapas para pr√©-processamento de dados:</p>
<pre class="r"><code>sleep_recipe &lt;- 
  recipe(mood~., data = sleep_train) %&gt;%
  step_ordinalscore(weather_type) %&gt;% 
  step_mutate(
    ano = factor(year(end)),
    mes = month(end),
    dia_semana = wday(end) %&gt;% ifelse(. == 7, 0, .),
    dia_mes = mday(end),
    end_hour = hour(end),
    final_de_semana = 
      ifelse(lubridate::wday(start) %in% c(1, 7),  &quot;sim&quot;, &quot;nao&quot;) %&gt;% as.factor(),
    dif_sleep_hours = as.numeric(end - start)/60,
    dif_nap = as.numeric(window_stop - window_start) / 60,
    quarentena = ifelse(start &gt; dmy(&quot;20/03/2020&quot;), &quot;sim&quot;, &quot;nao&quot;) %&gt;% as.factor(),
    nap_minutes = (window_stop - window_start) / 30
  ) %&gt;% 
  step_mutate_at(c(&quot;weather_temperature_c&quot;, &quot;air_pressure_pa&quot;),
                 fn = ~ imputeTS::na_ma(.x, k = 7, weighting = &quot;simple&quot;)) %&gt;% 
  step_dummy(all_nominal(), -all_outcomes())  %&gt;% 
  step_mutate_at(starts_with(&quot;ano&quot;), # Fix 2018 nos novos dados
                 fn = ~ ifelse(is.na(.x), 0, .x)) %&gt;% 
  step_rm(start, end, window_start, window_stop)%&gt;%
  step_knnimpute(heart_rate_bpm, neighbors = 2) %&gt;% 
  themis::step_tomek(mood) %&gt;%
  prep()

# bake(sleep_recipe, new_data = NULL)</code></pre>
<p>Finalmente! ü•µ</p>
<p>Com os dados devidamente preparados, vamos ligar as turbinas e partir para modelagem!</p>
<pre class="r"><code>doParallel::registerDoParallel(4)</code></pre>
</div>
<div id="modelo-nulo-baseline" class="section level2">
<h2>Modelo Nulo (Baseline)</h2>
<p>Este n√£o √© o tipo de modelo que serve para resolver problemas reais mas pode servir como um bom baseline (‚Äúpior que isso n√£o fica‚Äù) pois ele vai prever apenas a classe majorit√°ria, e com base nisso, poderemos comparar as m√©tricas de performance do ajuste para saber se nossos modelos est√£o (no m√≠nimo) performando melhor que um modelo que classifica unicamente 1 classe,</p>
<pre class="r"><code>null_model &lt;- null_model(mode = &quot;classification&quot;) %&gt;% 
  set_engine(&quot;parsnip&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>null_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(null_model) </code></pre>
<p>Realizar ajuste final nos dados de treino:</p>
<pre class="r"><code>null_final_fit_bas &lt;- null_wflow_bas %&gt;% last_fit(sleep_split) </code></pre>
<p>Coletar previs√µes nos dados de teste:</p>
<pre class="r"><code>null_test_preds_bas &lt;- collect_predictions(null_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>null_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot(null_model = T)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-31-1.png" style="width:80.0%" />
</center>
<p>Modelo nulo pronto! Vamos para a modelagem propriamente dita!</p>
</div>
<div id="√°rvore-de-decis√µes" class="section level2">
<h2>√Årvore de decis√µes</h2>
<p>Este algor√≠timo √© um √≥timo ponto de partida pois possui alta explicabilidade, gerando um plot intuitivo e muito f√°cil de interpretar. As <em>features</em> que aparecem no topo s√£o as mais importantes e cada n√≥ seguinte √© gerado a partir de regras que otimizam a divis√£o dos dados daquele ramo.</p>
<p>Existem recursos interessantes ao trabalhar com √°rvores, como determinar uma regra de parada ou ainda deixar a √°rvore crescer e depois realizar a poda. Primeiramente vamos ajusta uma √°rvore de decis√µes <em>default</em> e em seguida realizar algum tipo de tunning para tentar obter resultados melhores.</p>
<!-- `gini`: -->
<!-- Se selecionarmos dois itens de uma populacao aleatoriamente, entao eles devem ser da mesma classe e a probabilidade para isto √© 1 se a popula√ß√£o √© pura. -->
<div id="default" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>rpart</code> em <a href="https://cran.r-project.org/web/packages/rpart/rpart.pdf" class="uri">https://cran.r-project.org/web/packages/rpart/rpart.pdf</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do pacote <code>parsnip</code> em <a href="https://parsnip.tidymodels.org/reference/decision_tree.html" class="uri">https://parsnip.tidymodels.org/reference/decision_tree.html</a></p>
<pre class="r"><code>tree_model_bas &lt;- decision_tree(
  cost_complexity = 0.01, # cp
  tree_depth = 30,        # maxdepth
  min_n = 20              # minsplit
) %&gt;% 
  set_engine(&quot;rpart&quot;) %&gt;%
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>tree_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(tree_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>tree_res_bas &lt;- fit_resamples(
  tree_wflow_bas,
  sleep_folds,
  metrics = metric_set(pr_auc, roc_auc, mn_log_loss),
  control = control_resamples(save_pred = TRUE)
)
# Salvar &quot;cache&quot; da otimizacao 
saveRDS(tree_res_bas, &quot;tree_res_bas.rds&quot;)</code></pre>
<p>Finalizar o modelo:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
tree_final_wflow_bas &lt;- 
  finalize_workflow(
    tree_wflow_bas,
    select_best(tree_res_bas, metric = &#39;mn_log_loss&#39;) 
  )

# Realizar ajuste final nos dados de treino
tree_final_fit_bas &lt;- tree_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
tree_test_preds_bas &lt;- collect_predictions(tree_final_fit_bas)</code></pre>
<p>Vejamos como ficou o modelo baseline:</p>
<details>
<summary>
(<em>C√≥digo do objeto <code>tre_model_bas</code></em>)
</summary>
<pre class="r"><code>tre_model_bas &lt;- 
  tree_final_fit_bas$.workflow[[1]] %&gt;% 
  pull_workflow_fit()</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>rattle::fancyRpartPlot(tre_model_bas$fit, sub = NULL, cex = 0.6)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-38-1.png" style="width:80.0%" />
</center>
<p>Note que o modelo <em>default</em> se baseia nas features <code>time_before_sleep_seconds</code> e <code>steps</code>. Talvez, com outra combina√ß√£o de par√¢metros seja poss√≠vel conseguir um modelo uma √°rvore um pouco maior com resultado igual/melhor.</p>
<p>Como s√£o apenas duas features, √© poss√≠vel visualizar os regras de classifica√ß√£o a partir de um gr√°fio de dispers√£o</p>
<pre class="r"><code>sleep_train %&gt;%
  ggplot(aes(time_before_sleep_seconds, steps)) +
  parttree::geom_parttree(data = tre_model_bas$fit, alpha = 0.3) +
  geom_jitter(aes(color = mood), alpha = 0.7) +
  scale_color_viridis_d(end = 0.8, direction = 1)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-39-1.png" style="width:80.0%" />
</center>
<p>Vamos avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>tree_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;% 
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-40-1.png" style="width:80.0%" />
</center>
<p>O modelo n√£o esta muito bom‚Ä¶ mas tamb√©m n√£o esta muito ruim para come√ßar! üòÖ</p>
<p>Coram 5/8 acertos para classe de interesse, vamos tentar fazer o tunning deste modelo!</p>
</div>
<div id="tunning" class="section level3">
<h3>Tunning</h3>
<p>Definir o modelo que ser√° utilizado:</p>
<pre class="r"><code>tree_model_tun &lt;- decision_tree(
  min_n = tune(),
  cost_complexity = tune(), 
  tree_depth = tune()
) %&gt;%
  set_engine(&quot;rpart&quot;) %&gt;%
  set_mode(&quot;classification&quot;)
# tree_model_tun %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>tree_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(tree_model_tun) </code></pre>
<p>O grid utilizado foi alterado para tentar previnir que a √°rvore tenha apenas o n√≥ raiz pois o grid default, combinado com o <em>threshold</em>, estava gerando um ‚Äúcotoco‚Äù.</p>
<ul>
<li><code>min_n</code>: [1, 5]</li>
<li><code>cost_complexity</code>: (transformed scale): [-10, -1]</li>
<li><code>tree_depth</code>: [10, 20]</li>
</ul>
<p>Definir um grid aleat√≥rio para otimiza√ß√£o dos hiperpar√¢metros:</p>
<pre class="r"><code>tree_params &lt;- 
  tree_model_tun %&gt;% 
  parameters() %&gt;%
  update(
    min_n = min_n(c(1, 5)), 
    cost_complexity = cost_complexity(),
    tree_depth = tree_depth(c(10, 20)) 
  )

tree_grid &lt;-grid_regular(tree_params, levels = 3)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>tree_res_tun &lt;- 
  tree_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = tree_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
# saveRDS(tree_res_tun, &quot;tree_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;%
  slice(1) %&gt;% 
  pull(.config)

plot_tree_tun &lt;- 
  tree_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)
         # cost_complexity = log(cost_complexity)-10
  ) %&gt;% 
  select(.metric, mean, best_model,
         cost_complexity:min_n) %&gt;%
  pivot_longer(cost_complexity:min_n,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% 
  mutate(parameter = case_when(
    parameter == &quot;cost_complexity&quot; ~ &quot;Cost-Complexity Parameter&quot;,
    parameter == &quot;tree_depth&quot; ~ &quot;Tree Depth&quot;,
    parameter == &quot;min_n&quot; ~ &quot;Minimal Node Size&quot;,
    
  ))%&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }
# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(tree_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_tree_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img4.png" style="width:80.0%" />
</center>
<p>5 Melhores resultados:</p>
<pre class="r"><code>show_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<pre><code>## # A tibble: 5 x 6
##   cost_complexity tree_depth min_n .metric      mean std_err
##             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1             0.1         10     1 mn_log_loss  1.64   0.212
## 2             0.1         15     1 mn_log_loss  1.64   0.212
## 3             0.1         20     1 mn_log_loss  1.64   0.212
## 4             0.1         10     3 mn_log_loss  1.64   0.212
## 5             0.1         15     3 mn_log_loss  1.64   0.212</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
tree_final_wflow_tun &lt;- 
  finalize_workflow(
    tree_wflow_tun,
    select_best(tree_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
tree_final_fit_tun &lt;- tree_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
tree_test_preds_tun &lt;- collect_predictions(tree_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>tre_model_tun &lt;- pull_workflow_fit(tree_final_fit_tun$.workflow[[1]])</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>rattle::fancyRpartPlot(tre_model_tun$fit, sub = NULL, cex = 0.6)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-51-1.png" style="width:80.0%" />
</center>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>tree_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-52-1.png" style="width:80.0%" />
</center>
<p>Ao comparar o modelo default com o modelo ap√≥s o <em>tunning</em> √© poss√≠vel notar que o n√∫mero de verdadeiros positivos foi menor por√©m o n√∫mero de fasos positivos tbm foi menor devido ao elevado <code>trs_fbeta</code> encontrado (maximizando F0.5).</p>
<p>No geral, o modelo tunado ficou pior que o modelo default mas como o modelo de √°rvore de deci√µes costuma ser bem inst√°vel, ainda mais em um cen√°rio de dados desbalanceados vamos apenas guardar estes resultados e dar mais um passo, combinando diversas √°rvore de decis√µes!</p>
</div>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<p>O <em>Random Forest</em> √© um algoritmo que (de forma simplificada) realiza bootstrap em cima de √°rvores de decis√µes (modelos que utilizamos anteriormente) construindo modelos de √°rvores de decis√µes em diferentes amostras com diferentes combina√ß√µes de <em>features</em> e assim uma previs√£o final √© feita ap√≥s uma ‚Äúvota√ß√£o entre os modelos‚Äù.</p>
<div id="default-1" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>ranger</code> em <a href="https://cran.r-project.org/web/packages/ranger/ranger.pdf" class="uri">https://cran.r-project.org/web/packages/ranger/ranger.pdf</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do pacote <code>parsnip</code> em <a href="https://parsnip.tidymodels.org/reference/rand_forest.html" class="uri">https://parsnip.tidymodels.org/reference/rand_forest.html</a></p>
<pre class="r"><code># raiz quadrada do numero de features 
n_col = ncol(juice(sleep_recipe))

rf_model_bas &lt;- rand_forest(
  mtry = sqrt(n_col) %&gt;% floor(), # mtry
  trees = 500,                    # num.trees
  min_n = 1                       # min.node.size 
) %&gt;% 
  set_engine(&quot;ranger&quot;, num.threads = 4, importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>rf_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(rf_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>rf_res_bas &lt;- fit_resamples(
  rf_wflow_bas,
  sleep_folds,
  metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
  control = control_resamples(save_pred = TRUE)
)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
rf_final_wflow_bas &lt;- 
  finalize_workflow(
    rf_wflow_bas,
    select_best(rf_res_bas, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
rf_final_fit_bas &lt;- rf_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
rf_test_preds_bas &lt;- collect_predictions(rf_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>rf_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-58-1png" style="width:80.0%" />
</center>
<p>Este modelo n√£o fez nenhuma previs√£o de falso positivo! Por√©m note que o <code>trs_fbeta</code> ficou bastante alto, o que deve ter ocorrido como reflexo do elevado <code>logloss</code> que indicaria que a incerteza que o modelo tem nas previs√µes esta alta.</p>
</div>
<div id="tunning-1" class="section level3">
<h3>Tunning</h3>
<p>Definir o modelo que ser√° utilizado:</p>
<pre class="r"><code>rf_model_tun &lt;- rand_forest(
  mtry = tune(),
  trees = tune(), 
  min_n = tune()
) %&gt;% 
  set_engine(&quot;ranger&quot;, num.threads = 4, importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)
# tree_model %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>rf_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(rf_model_tun) </code></pre>
<p>O grid utilizado tentar√° valores superiores e inferiores ao n√∫mero de √°rvores <em>default</em> do algoritmo e vamos incluir o valor 1 ao <code>min_n</code> pois √°rvores mais longas neste m√©todo podem ser √∫teis. O <code>mtry</code> ser√° calculado baseado nas informa√ß√µes do dataset de treino.</p>
<ul>
<li><code>trees</code>: [100, 900]</li>
<li><code>min_n</code>: [1, 40]</li>
<li><code>mtry</code>: [1, 20]</li>
</ul>
<p>Definir t√©cnica de otimiza√ß√£o de hiperpar√¢metros</p>
<pre class="r"><code>rf_grid &lt;-grid_max_entropy(
  trees() %&gt;% range_set(c(100, 900)), # Default Range: [1, 2000]
  min_n() %&gt;% range_set(c(1, 40)),    # Default Range: [2, 40]
  finalize(mtry(), sleep_train),
  size = 30)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>rf_res_tun &lt;- 
  rf_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = rf_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
saveRDS(rf_res_tun, &quot;rf_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;%
  slice(1) %&gt;% 
  pull(.config)

plot_rf_tun &lt;- 
  rf_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)) %&gt;% 
  select(.metric, mean, best_model,
         mtry:min_n) %&gt;%
  pivot_longer(mtry:min_n,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% 
  mutate(parameter = case_when(
    parameter == &quot;mtry&quot; ~ &quot;Randomly Selected Predictors&quot;,
    parameter == &quot;min_n&quot; ~ &quot;Minimal Node Size&quot;,
    parameter == &quot;trees&quot; ~ &quot;# Trees&quot;
  )) %&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }
# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(rf_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_rf_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img5.png" style="width:80.0%" />
</center>
<p>Melhores resultados:</p>
<pre class="r"><code>show_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
rf_final_wflow_tun &lt;- 
  finalize_workflow(
    rf_wflow_tun,
    select_best(rf_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
rf_final_fit_tun &lt;- rf_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
rf_test_preds_tun &lt;- collect_predictions(rf_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>rf_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-68-1.png" style="width:80.0%" />
</center>
<p>Note que apesar do maior n√∫mero de Verdadeiros Positivos, este modelo apresentou um Falso Positivo. Parece estranho pois √© exatamente o que queriamos evitar por√©m √© poss√≠vel notar que o <code>logloss</code> foi bem inferior e o <code>trs_fbeta</code> est√° bem mais razoavel agora.</p>
<p>Importancia de cada <em>feature</em> conforme o modelo:</p>
<pre class="r"><code>vip::vip(pull_workflow_fit(rf_final_fit_tun$.workflow[[1]]))</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-70-1.png" style="width:80.0%" />
</center>
<p>Diferente do modelo baseado em 1 unica √°rvore de decis√µes, a <em>feature</em> <code>steps</code> n√£o foi t√£o importante assim. A <code>time_asleep_seconds</code> foi a mais importante mas com a ordem de grandeza muito pr√≥xima de <code>time_before_sleep_seconds</code>.</p>
<p><em>Random Forest</em> √© um excelente modelo e poder√≠amos investir mais tempo tentando otimizando sua performance mas para este post acho que j√° esta suficiente. Vamos para o pr√≥ximo modelo! üòç</p>
</div>
</div>
<div id="lightgbm" class="section level2">
<h2>LightGBM</h2>
<p>Este modelo consiste em um m√©todo de <em>boosting</em>. Tamb√©m √© baseado nos modelos de √°rvore de decis√µes, mas, diferentemente do <em>Random Forest</em>, suas √°rvores s√£o calculadas em sequ√™ncia, ‚Äúaprendendo‚Äù com o erro das √°rvores anteriores.</p>
<p>A mec√¢nica do <em>LightGBM</em> √© um pouco diferente do <em>XGBoost.</em> N√£o entrarei em detalhes sobre a teoria neste post at√© porque a documenta√ß√£o oficial no github em <a href="https://github.com/microsoft/LightGBM" class="uri">https://github.com/microsoft/LightGBM</a> √© bastante rica, e seus recursos s√£o muito bem apresentados neste link: <a href="https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst" class="uri">https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst</a></p>
<p>Links √∫teis para consulta ao trabalhar com este algoritmo:</p>
<ul>
<li>Documenta√ß√£o oficial: <a href="https://lightgbm.readthedocs.io/en/latest/" class="uri">https://lightgbm.readthedocs.io/en/latest/</a></li>
<li>Excelente post: <a href="https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/" class="uri">https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/</a></li>
<li>Documenta√ß√£o oficial do pacote <code>treesnip</code>: <a href="https://curso-r.github.io/treesnip/articles/working-with-lightgbm-catboost.html" class="uri">https://curso-r.github.io/treesnip/articles/working-with-lightgbm-catboost.html</a></li>
<li>Reposit√≥rio no github do pacote <code>treesnip</code>: <a href="https://github.com/curso-r/treesnip" class="uri">https://github.com/curso-r/treesnip</a></li>
<li>√ìtimo link para consulta dos par√¢metros: <a href="https://sites.google.com/view/lauraepp/parameters" class="uri">https://sites.google.com/view/lauraepp/parameters</a></li>
</ul>
<div id="default-2" class="section level3">
<h3>Default</h3>
<p>Os par√¢metros <em>default</em> foram definidos baseados na documenta√ß√£o oficial do pacote <code>lightgbm</code> em <a href="https://lightgbm.readthedocs.io/en/latest/" class="uri">https://lightgbm.readthedocs.io/en/latest/</a> e o <em>de/para</em> para defini√ß√£o dos par√¢metros na p√°gina do (incr√≠vel ü§©) pacote <code>treesnip</code> em <a href="https://github.com/curso-r/treesnip/blob/master/R/lightgbm.R" class="uri">https://github.com/curso-r/treesnip/blob/master/R/lightgbm.R</a></p>
<pre class="r"><code>lgbm_model_bas &lt;- parsnip::boost_tree(
  mode = &quot;classification&quot;,
  trees = 100,       # num_iterations
  learn_rate = 0.1,  # fixo
  min_n = 20,        # min_data_in_leaf
  tree_depth = 6,    # max_depth
  sample_size = 1,   # bagging_fraction
  mtry = 1,          # feature_fraction
  loss_reduction = 0 # min_gain_to_split
) %&gt;%  
  set_engine(&quot;lightgbm&quot;,
             nthread = 4,
             importance = &quot;permutation&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>lgbm_wflow_bas &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(lgbm_model_bas) </code></pre>
<p>Ajustar modelo via valida√ß√£o cruzada:</p>
<pre class="r"><code>lgbm_res_bas &lt;- fit_resamples(
  lgbm_wflow_bas,
  sleep_folds,
  metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
  control = control_resamples(save_pred = TRUE)
)
saveRDS(lgbm_res_bas, &quot;lgbm_res_bas.rds&quot;)</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># Finalizar workflow com parametros selecionados (default nesse caso)
lgbm_final_wflow_bas &lt;- 
  finalize_workflow(
    lgbm_wflow_bas,
    select_best(lgbm_res_bas, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
lgbm_final_fit_bas &lt;- lgbm_final_wflow_bas %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
lgbm_test_preds_bas &lt;- collect_predictions(lgbm_final_fit_bas)</code></pre>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>lgbm_test_preds_bas %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-76-1.png" style="width:80.0%" />
</center>
</div>
<div id="tunning-2" class="section level3">
<h3>Tunning</h3>
<p>Para o tunning vamos utilizar uma estrat√©gia um pouco diferente. Vamos fixar o n√∫mero de √°rvores <code>trees</code> e a taxa de aprendizado <code>learning_rate</code> pois vamos separar mais uma pequena parte dos dados para usar o recurso <code>early_stopping</code>. Esta op√ß√£o basicamente ‚Äútrava‚Äù o crescimento da √°rvore caso o modelo n√£o melhore a performance a partir da n-√©sima itera√ß√£o.</p>
<pre class="r"><code>lgbm_model_tun &lt;- parsnip::boost_tree(
  mode = &quot;classification&quot;,
  trees = 700,             # autotune com early stopping
  learn_rate = 0.01,       # early stopping
  min_n = tune(),          # min_data_in_leaf
  tree_depth = tune(),     # max_depth
  sample_size = 1,         # bagging_fraction, n funciona com goss
  mtry = tune(),           # feature_fraction
  loss_reduction = tune()  # min_gain_to_split
) %&gt;%  
  set_engine(&quot;lightgbm&quot;, nthread = 4, 
             # parametros para early stopping
             early_stop = 30,
             validation = .20,
             eval_metric = &quot;mn_log_loss&quot;,
             importance = &quot;permutation&quot;
             # feature_fraction = tune(&quot;feature_fraction&quot;)
  ) %&gt;% 
  set_mode(&quot;classification&quot;)
# tree_model %&gt;% translate()</code></pre>
<p>Definir o objeto <code>workflow</code>:</p>
<pre class="r"><code>lgbm_wflow_tun &lt;- workflow() %&gt;% 
  add_recipe(sleep_recipe) %&gt;% 
  add_model(lgbm_model_tun) </code></pre>
<p>Definir grid para otimiza√ß√£o de hiperpar√¢metros baseados nas sugest√µes de <a href="https://github.com/Laurae2">github/Laurae2</a> em uma <a href="https://github.com/microsoft/LightGBM/issues/695">issue</a> no reposit√≥rio <a href="https://github.com/microsoft/LightGBM/issues/695">oficial</a> do modelo</p>
<pre class="r"><code>lightgbm_params &lt;- 
  dials::parameters(
    # learn_rate(),           # learning_rate
    # trees()                 # num_iterations
    min_n(),                  # min_data_in_leaf
    tree_depth(c(2, 63)),     # max_depth
    # sample_prop(c(0.4, 1)), # bagging_fraction (vai para sample_size)
    mtry(),                   # feature_fraction
    loss_reduction()          # min_gain_to_split
  ) 

lgbm_grid &lt;- lightgbm_params %&gt;% 
  finalize(sleep_train) %&gt;% 
  grid_max_entropy(size = 30)</code></pre>
<p>Ajustar modelo:</p>
<pre class="r"><code>lgbm_res_tun &lt;- 
  lgbm_wflow_tun %&gt;% 
  tune_grid(
    resamples = sleep_folds,
    grid = lgbm_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
saveRDS(lgbm_res_tun, &quot;lgbm_res_tun.rds&quot;)</code></pre>
<p>Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>id_best_model &lt;- 
  show_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;)[1, ] %&gt;% 
  pull(.config)

plot_lgbm_tun &lt;- 
  lgbm_res_tun %&gt;% 
  collect_metrics() %&gt;% 
  mutate(best_model = if_else(.config == id_best_model, 
                              &quot;BestModel&quot;, &quot;Try&quot;)) %&gt;% 
  select(.metric, mean, best_model,
         mtry:loss_reduction) %&gt;%
  pivot_longer(mtry:loss_reduction,
               values_to = &quot;value&quot;,
               names_to = &quot;parameter&quot;
  ) %&gt;% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == &#39;BestModel&#39;), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c(&quot;red&quot;, &quot;black&quot;))+
      facet_grid(.metric~parameter, scales = &quot;free&quot;) +
      labs(x = NULL, y = NULL)
  }

# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(lgbm_res_tun)</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>plot_lgbm_tun %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img6.png" style="width:80.0%" />
</center>
<p>Melhores resultados:</p>
<pre class="r"><code>show_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;) %&gt;% 
  select(-.estimator, -n, -.config)</code></pre>
<pre><code>## # A tibble: 5 x 7
##    mtry min_n tree_depth loss_reduction .metric      mean std_err
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;          &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;
## 1     2    35         28 0.000000000108 mn_log_loss 0.259 0.00888
## 2     1    16          5 0.00000160     mn_log_loss 0.267 0.0100 
## 3     4    28         31 0.000507       mn_log_loss 0.272 0.0111 
## 4     5    39         62 0.000164       mn_log_loss 0.273 0.00955
## 5     2    14         19 0.0642         mn_log_loss 0.274 0.0138</code></pre>
<p>Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:</p>
<pre class="r"><code># finalizar workflow definindo modelo final
lgbm_final_wflow_tun &lt;- 
  finalize_workflow(
    lgbm_wflow_tun,
    select_best(lgbm_res_tun, metric = &#39;mn_log_loss&#39;) )

# Realizar ajuste final nos dados de treino
lgbm_final_fit_tun &lt;- lgbm_final_wflow_tun %&gt;% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
lgbm_test_preds_tun &lt;- collect_predictions(lgbm_final_fit_tun)</code></pre>
<p>Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o <em>tunning</em> final:</p>
<p>Avaliar desempenho do modelo nos dados de teste:</p>
<pre class="r"><code>lgbm_test_preds_tun %&gt;% 
  mutate(mood = factor(mood, levels = c(&quot;Ruim&quot;, &quot;Bom&quot;), ordered = TRUE)) %&gt;%
  conf_mat_plot()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-87-1.png" style="width:80.0%" />
</center>
<p>Que maravilha! Modelos acertaram mais a classe de interesse do que os anteriores (apesar do <em>default</em> ainda apresentar alta propor√ß√£o de falsos positivos). Note ainda que o LightGBM ap√≥s o <em>tunning</em> apresentou as melhores m√©tricas no geral (melhor AUC-PR, menor <em>logloss</em> e um bom equil√≠brio no <em>trade-off</em> de <em>Precision</em> x <em>Recall</em>).</p>
<p>Vejamos quais as <em>features</em> mais importantes no ajuste do modelo:</p>
<pre class="r"><code>lgbm_imp_tun &lt;- lightgbm::lgb.importance(lgbm_final_fit_tun$.workflow[[1]]$fit$fit$fit, percentage = T)

lgbm_imp_tun%&gt;% 
  mutate(Feature = reorder(Feature, Gain)) %&gt;% 
  ggplot(aes(x = Feature, y = Gain))+
  geom_bar(stat = &quot;identity&quot;)+
  labs(y = &quot;Importance&quot;, x= &quot;&quot;)+
  coord_flip()</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-89-1.png" style="width:80.0%" />
</center>
</div>
</div>
</div>
<div id="sele√ß√£o-do-modelo" class="section level1">
<h1>Sele√ß√£o do modelo ü§î</h1>
<!-- Curva Roc e Precision-Recall Curve: -->
<!-- ```{r} -->
<!-- bind_rows( -->
<!--   # null_res_bas %>% unnest(.predictions) %>% mutate(model = "null baseline"),   -->
<!--   tree_res_bas %>% unnest(.predictions) %>% mutate(model = "rpart baseline"),   -->
<!--   tree_res_tun %>% unnest(.predictions) %>% mutate(model = "rpart tunning"), -->
<!--   rf_res_bas %>% unnest(.predictions) %>% mutate(model = "rf baseline"), -->
<!--   rf_res_tun %>% unnest(.predictions) %>% mutate(model = "rf tunning"), -->
<!--   lgbm_res_bas %>% unnest(.predictions) %>% mutate(model = "lgbm baseline"), -->
<!--   lgbm_res_tun %>% unnest(.predictions) %>% mutate(model = "lgbm tunning") -->
<!-- ) %>%   -->
<!--   plot_auc() +  -->
<!--   plot_annotation(title = 'Resultados nos dados de treino', -->
<!--                   theme = theme(plot.title = element_text(hjust = 0.4))) -->
<!-- ``` -->
<p>Comparar os modelos de forma visual com os gr√°ficos da ROC AUC e da PR AUC:</p>
<details>
<summary>
(<em>C√≥digo do gr√°fico</em>)
</summary>
<pre class="r"><code>auc_plots &lt;- 
  bind_rows(
    null_test_preds_bas %&gt;% mutate(model = &quot;null baseline&quot;),
    tree_test_preds_bas %&gt;% mutate(model = &quot;rpart default&quot;),
    tree_test_preds_tun %&gt;% mutate(model = &quot;rpart tunning&quot;),
    rf_test_preds_bas %&gt;% mutate(model = &quot;rf default&quot;),
    rf_test_preds_tun %&gt;% mutate(model = &quot;rf tunning&quot;),
    lgbm_test_preds_bas %&gt;% mutate(model = &quot;lgbm default&quot;),
    lgbm_test_preds_tun %&gt;% mutate(model = &quot;lgbm tunning&quot;)
  ) %&gt;% 
  plot_auc() + 
  plot_annotation(title = &#39;Resultados nos dados de teste&#39;,
                  theme = theme(plot.title = element_text(hjust = 0.4)))</code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>auc_plots</code></pre>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/unnamed-chunk-91-1.png" style="width:80.0%" />
</center>
<p>Apenas olhando o gr√°fico n√£o da para fazer uma an√°lise conclusiva, vejamos as medidas de qualidade (ordenado por <code>auc_pr</code>):</p>
<details>
<summary>
(<em>C√≥digo da tabela</em>)
</summary>
<pre class="r"><code>test_results &lt;- 
  bind_rows(
    evalue_model(null_test_preds_bas, model = &quot;null baseline&quot;, null_model = TRUE),
    evalue_model(tree_test_preds_bas, model = &quot;rpart default&quot;),
    evalue_model(tree_test_preds_tun, model = &quot;rpart tunning&quot;),
    evalue_model(rf_test_preds_bas, model = &quot;rf default&quot;),
    evalue_model(rf_test_preds_tun, model = &quot;rf tunning&quot;),
    evalue_model(lgbm_test_preds_bas, model = &quot;lgbm default&quot;),
    evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)
  ) %&gt;% print_table(round = 4, evalue_model = T)   </code></pre>
</details>
<p>¬†</p>
<pre class="r"><code>test_results</code></pre>
<table>
<colgroup>
<col width="13%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="3%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="10%" />
<col width="7%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th>model</th>
<th>tp</th>
<th>fp</th>
<th>fn</th>
<th>tn</th>
<th>auc_roc</th>
<th>auc_pr</th>
<th>logloss</th>
<th>f1</th>
<th>f05</th>
<th>f2</th>
<th>precision</th>
<th>recall</th>
<th>trs_fbeta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>lgbm tunning</td>
<td>6</td>
<td>1</td>
<td>2</td>
<td>72</td>
<td>0.8699</td>
<td>0.7804</td>
<td>0.2190</td>
<td>0.8000</td>
<td>0.8333</td>
<td>0.7692</td>
<td>0.8571</td>
<td>0.7500</td>
<td>0.5937</td>
</tr>
<tr class="even">
<td>rf default</td>
<td>4</td>
<td>0</td>
<td>4</td>
<td>73</td>
<td>0.8399</td>
<td>0.6916</td>
<td>0.6613</td>
<td>0.6667</td>
<td>0.8333</td>
<td>0.5556</td>
<td>1.0000</td>
<td>0.5000</td>
<td>0.7140</td>
</tr>
<tr class="odd">
<td>rf tunning</td>
<td>5</td>
<td>1</td>
<td>3</td>
<td>72</td>
<td>0.8493</td>
<td>0.6658</td>
<td>0.2722</td>
<td>0.7143</td>
<td>0.7812</td>
<td>0.6579</td>
<td>0.8333</td>
<td>0.6250</td>
<td>0.3888</td>
</tr>
<tr class="even">
<td>null baseline</td>
<td>0</td>
<td>0</td>
<td>8</td>
<td>73</td>
<td>0.5000</td>
<td>0.5494</td>
<td>0.3236</td>
<td></td>
<td></td>
<td></td>
<td>0.0000</td>
<td>0.1141</td>
<td></td>
</tr>
<tr class="odd">
<td>lgbm default</td>
<td>6</td>
<td>3</td>
<td>2</td>
<td>70</td>
<td>0.8527</td>
<td>0.5038</td>
<td>0.2313</td>
<td>0.7059</td>
<td>0.6818</td>
<td>0.7317</td>
<td>0.6667</td>
<td>0.7500</td>
<td>0.4286</td>
</tr>
<tr class="even">
<td>rpart default</td>
<td>5</td>
<td>9</td>
<td>3</td>
<td>64</td>
<td>0.7312</td>
<td>0.4471</td>
<td>0.3267</td>
<td>0.4545</td>
<td>0.3906</td>
<td>0.5435</td>
<td>0.3571</td>
<td>0.6250</td>
<td>0.5714</td>
</tr>
<tr class="odd">
<td>rpart tunning</td>
<td>4</td>
<td>7</td>
<td>4</td>
<td>66</td>
<td>0.7243</td>
<td>0.4390</td>
<td>0.3399</td>
<td>0.4211</td>
<td>0.3846</td>
<td>0.4651</td>
<td>0.3636</td>
<td>0.5000</td>
<td>0.7857</td>
</tr>
</tbody>
</table>
<p>O modelo LightGBM ap√≥s o processo de tunning foi o que apresentou as melhores medidas no geral. Note que o LightGBM com os par√¢metro default ficou pior do que o modelo nulo üò±! Isso mostra como o processo de tunning pode ser importante. Al√©m disso note que o modelo <code>rf baseline</code> apresentou o segundo maior AUC-PR mas o pior logloss (note que o <code>threshold</code> est√° muito alto e as demais m√©tricas n√£o ficaram muito boas).</p>
<p>Portanto, apenas os modelos <em>LightGBM</em> e <em>Random Forest</em> apresentaram resultados melhores que um modelo nulo (sempre estima a classe majorit√°ria) e como o LightGBM foi o mais satisfat√≥rio, este ser√° o modelo selecionado. üòé</p>
</div>
<div id="previs√£o-em-dados-novos" class="section level1">
<h1>Previs√£o em dados novos üí´</h1>
<p>Obter as previs√µes nos novos dados:</p>
<pre class="r"><code>trs_final &lt;- evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$trs_fbeta

final &lt;- 
  predict(lgbm_final_fit_tun$.workflow[[1]], new_sleep, type = &quot;prob&quot;) %&gt;% 
  mutate(.pred_class = ifelse(.pred_Ruim &gt;= trs_final, &quot;Ruim&quot;, &quot;Bom&quot;)) 

# new_sleep %&gt;% filter(final$.pred_class == &quot;Ruim&quot;)</code></pre>
<p>Comparar a quantidade de previs√µes de cada classe com o conjunto de treino/teste:</p>
<details>
<summary>
(<em>C√≥digo para tabela abaixo</em>)
</summary>
<pre class="r"><code>tab &lt;- 
  full_join(sleep_train %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            sleep_test %&gt;% count(mood) %&gt;% mutate(prop = n/sum(n)*100),
            by = &quot;mood&quot;) %&gt;% 
  full_join(final %&gt;% 
              count(mood = .pred_class) %&gt;% mutate(prop = n/sum(n)*100)) %&gt;% 
  print_table(round = 2,
              columns = list(
                n.x = colDef(name = &quot;N&quot;),
                prop.x = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n.y = colDef(name = &quot;N&quot;),
                prop.y = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;),
                n = colDef(name = &quot;N&quot;),
                prop = colDef(name = &quot;(%)&quot;, align = &quot;left&quot;)
              ), 
              columnGroups = list(
                colGroup(name = &quot;Train&quot;, columns = c(&quot;n.x&quot;, &quot;prop.x&quot;)),
                colGroup(name = &quot;Test&quot;, columns = c(&quot;n.y&quot;, &quot;prop.y&quot;)),
                colGroup(name = &quot;New Data&quot;, columns = c(&quot;n&quot;, &quot;prop&quot;))
              ))</code></pre>
</details>
<p>¬†¬†</p>
<pre class="r"><code>tab</code></pre>
<details>
<summary>
(<em>C√≥digo do c√°lculo das medidas abaixo</em>)
</summary>
<pre class="r"><code># ref: https://en.wikipedia.org/wiki/Sensitivity_and_specificity

# Obter medidas da matriz de confusao
tp = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$tp
tn = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$tn
fn = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$fn
fp = evalue_model(lgbm_test_preds_tun, model = &quot;lgbm tunning&quot;)$fn

# true positive rate
tpr = tp / (tp + fn)
# false negative rate
fnr = 1 - tpr
#false positive rate
fpr = fp / (fp + tn)</code></pre>
</details>
<p>¬†¬†</p>
<p>Como nosso modelo foi otimizado para ser menos ‚Äúalarmista‚Äù (com uma Taxa de Falso Positivo: 2.7%) √© poss√≠vel que o modelo tenha deixado passar alguns dias em que <code>mood=="Ruim"</code> (Taxa de Falso Negativo: 25%). N√£o vejo isto como um grande problema pois dado a pequena quantidade de dados dispon√≠veis at√© que o resultado para a classe de interesse estava bem razo√°vel (Taxa de Verdadeiro Positivo: 75%).</p>
<p>Para n√£o alongar aida mais o post com an√°lise explorat√≥ria das previs√µes, vamos comparar como foram as previs√µes nestes novos dados em rela√ß√£o aos dados utilizados para treinar o modelo e ver se, pelo menos visualmente, o modelo esteja conseguindo prever de semelhante ao padr√£o de dados conhecidos.</p>
<p>A t√©cnica <a href="https://cran.r-project.org/web/packages/umap/vignettes/umap.html">UMAP</a> ser√° utilizada com a finalidade de reduzir a dimensionalidade para visualiza√ß√£o:</p>
<details>
<summary>
(<em>C√≥digo para gr√°fico abaixo</em>)
</summary>
<pre class="r"><code># Treinar UMAP: 
sleep_umap &lt;-  juice(sleep_recipe) %&gt;% select(-mood) %&gt;% umap::umap()

# Aplicar em novos dados:
new_data &lt;- bake(sleep_recipe, new_sleep) %&gt;% select(-mood)
new_data_umap &lt;- predict(sleep_umap, new_data)

# Preparar plot comparando treino com novos dados:
umap_plot &lt;-
  bind_rows(
    sleep_umap$layout %&gt;% 
      as_tibble() %&gt;% 
      bind_cols(juice(sleep_recipe) %&gt;% select(mood))  %&gt;% 
      bind_cols(dataset =  &quot;Train&quot;)
    ,
    new_data_umap %&gt;% 
      as_tibble() %&gt;% 
      mutate(mood = factor(final$.pred_class,
                           levels = c(&quot;Ruim&quot;, &quot;Bom&quot;)))  %&gt;% 
      bind_cols(dataset =  &quot;New Data&quot;)
  ) %&gt;%
  mutate(dataset = factor(dataset, levels = c(&quot;New Data&quot;, &quot;Train&quot;))) %&gt;% {
    ggplot(., aes(x = V1, y = V2, color = mood, shape = mood))+
      geom_point(show.legend = F)+
      geom_point(aes(x = V1, y = V2, color = mood), 
                 data = subset(., mood == &#39;Ruim&#39;), 
                 size = 2, shape = 3)+
      labs(x = &quot;&quot;, y = &quot;&quot;, 
           title = &quot;UMAP (Uniform Manifold Approximation and Projection)&quot;)+
      scale_color_viridis_d(end = 0.8, direction = 1)+
      # scale_size_manual(values=c(2,5))+
      theme(legend.position = &quot;bottom&quot;)+
      facet_wrap(~dataset)
  }</code></pre>
</details>
<p>¬†¬†</p>
<pre class="r"><code>umap_plot %&gt;% 
  plotly::ggplotly()%&gt;% 
  plotly::layout(showlegend = FALSE) %&gt;% 
  plotly::config(displayModeBar = F)</code></pre>
<p>Parece que o modelo fez previs√µes nos novos dados em um padr√£o espec√≠fico dos dados (√† direita) enquanto que nos dados de treino podemos observar alguma informa√ß√£o da classe <code>Ruim</code> na massa de dados √† esquerda. Isso pode estar acontecendo devido ao foco que demos para minimizar falsos positivos. √â uma boa indica√ß√£o para analisar melhor o padr√£o que o modelo esta aprendendo em rela√ß√£o aos falsos negativos.</p>
<center>
<img src="/post/2021-02-28-qualidade-do-sono-machine-learning/img7.png" style="width:80.0%" />
</center>
</div>
<div id="conclus√£o" class="section level1">
<h1>Conclus√£o üçª</h1>
<p>Apesar da pequena quantidade dados dados dispon√≠veis, conseguimos ajustar um modelo razo√°vel para prever a qualidade de sono em dias que n√£o foram registrados!</p>
<div class="row">
<div class="column8">
<p>Utilizamos diversas t√©cnicas de <em>Machine Leaning</em> combinadas em dados reais (que n√£o s√£o nada comportados) e, obviamente, para colocar um modelo em produ√ß√£o na vida real seria necess√°rio aplicar mais uma s√©rie de an√°lises, al√©m de entender como o modelo est√° funcionando, aplicando t√©cnicas de <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">XAI</a> (Explainable AI) mas isso pode ser assunto para um futuro <em>post</em>, hora de dormir! üò¥</p>
<p>Espero que este pequeno ‚Äú<em>case</em>‚Äù seja √∫til para voc√™! Para mim foi √≥timo combinar a pr√°tica do uso do pacote <code>tidymodels</code> para resolver um problema com dados reais com um estudo que me trouxe mais auto-conhecmento e um monte de <em>insights</em> pessoais.</p>
</div>
<div class="column4">
<div class="float">
<img src="https://media.giphy.com/media/U7Lvtcuqh4WZy/giphy.gif" alt="Via Giphy" />
<div class="figcaption"><a href="https://media.giphy.com/media/U7Lvtcuqh4WZy/giphy.gif">Via Giphy</a></div>
</div>
</div>
</div>
<hr />
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias üß≥</h1>
<ul>
<li><a href="https://juliasilge.com/blog/wind-turbine/" class="uri">https://juliasilge.com/blog/wind-turbine/</a></li>
<li><a href="https://juliasilge.com/blog/hotels-recipes/" class="uri">https://juliasilge.com/blog/hotels-recipes/</a></li>
<li><a href="https://juliasilge.com/blog/xgboost-tune-volleyball/" class="uri">https://juliasilge.com/blog/xgboost-tune-volleyball/</a></li>
<li><a href="http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/" class="uri">http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/</a></li>
<li><a href="https://machinelearningmastery.com/imbalanced-classification-with-python/" class="uri">https://machinelearningmastery.com/imbalanced-classification-with-python/</a></li>
<li><a href="https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/</a></li>
<li><a href="https://machinelearningmastery.com/fbeta-measure-for-machine-learning/" class="uri">https://machinelearningmastery.com/fbeta-measure-for-machine-learning/</a></li>
<li><a href="https://sites.google.com/view/lauraepp/parameters" class="uri">https://sites.google.com/view/lauraepp/parameters</a></li>
<li><a href="https://github.com/microsoft/LightGBM/issues/695" class="uri">https://github.com/microsoft/LightGBM/issues/695</a></li>
</ul>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p><a href="https://www.usp.br/espacoaberto/?materia=a-importancia-de-dormir-bem" class="uri">https://www.usp.br/espacoaberto/?materia=a-importancia-de-dormir-bem</a><a href="#fnref1" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p><a href="https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/</a><a href="#fnref2" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn3"><p><a href="https://machinelearningmastery.com/fbeta-measure-for-machine-learning/" class="uri">https://machinelearningmastery.com/fbeta-measure-for-machine-learning/</a><a href="#fnref3" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn4"><p><a href="https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/</a><a href="#fnref4" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn5"><p><a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/" class="uri">https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/</a><a href="#fnref5" class="footnote-back">‚Ü©Ô∏é</a></p></li>
</ol>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2021-02-28-qualidade-do-sono-machine-learning/">Prevendo a qualidade do sono utilizando Machine Learning</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Fundamentos de Data Science</category>
      <category>Intelig√™ncia Artificial</category>
      <category>Machine Learning</category>
      <category>Programa√ß√£o e Ferramentas</category>
      <category domain="tag">imbalanced</category>
      <category domain="tag">imbalanced-data</category>
      <category domain="tag">lightgbm</category>
      <category domain="tag">r</category>
      <category domain="tag">random-forest</category>
      <category domain="tag">threshold-movel</category>
      <category domain="tag">tidymodels</category>
      <category domain="tag">tidyverse</category>
      <category domain="tag">tunning</category>
    </item>
    <item>
      <title>Um estudo sobre modelos de aprendizagem baseados em √°rvores com desafio do Kaggle</title>
      <link>https://gomesfellipe.github.io/post/2018-08-31-modelos-em-arvore/modelos-em-arvore/</link>
      <pubDate>Fri, 31 Aug 2018 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2018-08-31-modelos-em-arvore/modelos-em-arvore/</guid>
      <description>Um estudo aplicado de modelos de aprendizagem baseados em √°rvores utilizando a base de dados do Kaggle para prever o pre√ßo final de casas residenciais em Ames, Iowa, utilizando uma variedade de aspectos</description>
      <content:encoded>&lt;![CDATA[
        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="kaggle" class="section level1">
<h1>Kaggle</h1>
<p>Segundo o <a href="https://en.wikipedia.org/wiki/Kaggle">Wikip√©dia</a>: ‚ÄúKaggle √© a maior comunidade mundial de cientistas de dados e machine learning.‚Äù Aprendo muito estudando as resolu√ß√µes de alguns competidores pois l√° √© poss√≠vel conferir tanto as metodologias utilizadas pelos competidores quando os c√≥digos e √© not√°vel o cuidado dos participantes para que seja poss√≠vel a reprodutibilidade dos resultados, o que pode impulsionar o aprendizado.</p>
<p>O Kaggle trabalha com a ideia de <a href="https://en.wikipedia.org/wiki/Gamification">gamifica√ß√£o</a>, que √© um assunto do qual j√° escrevi em um post sobre <a href="https://gomesfellipe.github.io/post/2018-02-17-cheatsheet-gamificacao-r/cheatsheet-gamificacao-r/">gamifica√ß√£o e porque aprender R √© t√£o divertido</a> e gosto deste conceito de se criar jogos para motivar e engajar as pessoas em atividades profissionais e a ideia de se estar em um jogo possibilita doses de motiva√ß√£o especialmente a quem gosta de competir.</p>
<p>A plataforma √© focada em competi√ß√µes que envolvem modelagem preditiva, que julgam apenas o seu desempenho preditivo, embora a inteligibilidade n√£o deixe de ser importante. Neste post farei tamb√©m a modelagem descritiva com modelos de aprendizagem baseados em √°rvores, na qual o principal objetivo ser√° obter informa√ß√µes sobre os dados para o ajuste dos modelos preditivos que iremos submeter √† competi√ß√£o do Kaggle <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/">House Prices: Advanced Regression Techniques</a>.</p>
<p>A diferen√ßa entre modelos preditivos e descritivos n√£o √© t√£o rigorosa assim pois algumas das t√©cnicas podem ser utilizadas para ambos e geralmente um modelo pode servir para ambos os prop√≥sitos (mesmo que de de forma insuficiente).</p>
<p>Al√©m dos modelos de machine learning baseados em √°rvores, tamb√©m ser√° ajustado um modelo de regress√£o linear multivariado para compararmos os resultados dos ajustes e submeter nossas previs√µes no site do <a href="https://kaggle.com">kaggle</a>.</p>
<p>Os pacotes que ser√£o utilizados ser√£o os seguintes:</p>
<pre class="r"><code>library(purrr)       # Programacao funciona
library(broom)       # Arrumar outputs
library(dplyr)       # Manipulacao de dados
library(magrittr)    # pipes
library(funModeling) # df_status()
library(plyr)        # revalue()
library(gridExtra)   # Juntar ggplots
library(reshape)     # funcao melt()
library(rpart)       # Arvore de Decisoes
library(rpart.plot)  # Plot da Arvore de Decisoes
library(data.table)  # aux na manipulacao do heatmap
library(readr)       # Leitura da base de dados
library(stringr)     # Manipulacao de strings
library(ggplot2)     # Graficos elegantes
library(caret)       # Machine Learning 
library(GGally)      # up ggplot
library(ggfortify)   # autoplot()</code></pre>
<div id="base-de-dados" class="section level2">
<h2>Base de dados</h2>
<p>A base de dados deste post vem de uma competi√ß√£o √≥tima para estudantes de ci√™ncia de dados de dados com alguma experi√™ncia com R ou Python e no√ß√µes b√°sicas de machine learning e estat√≠stica.</p>
<p>Pode ser √∫til para aqueles que desejam expandir seu conjunto de habilidades em uma tarefa de regress√£o, quando a vari√°vel <span class="math inline">\(y\)</span> que desejamos estimar √© do tipo num√©rico (cont√≠nuo ou discreto).</p>
<p>Trata-se do <a href="https://ww2.amstat.org/publications/jse/v19n3/decock.pdf">conjunto de dados Ames Housing</a> que foi compilado por Dean De Cock para uso em educa√ß√£o de ci√™ncia de dados.</p>
<pre class="r"><code>train &lt;- read_csv(&quot;train.csv&quot;)
test  &lt;- read_csv(&quot;test.csv&quot;)
full  &lt;- bind_rows(train, test)

id    &lt;- test$Id
full %&lt;&gt;% select(-Id)</code></pre>
<div id="descri√ß√£o-da-competi√ß√£o" class="section level3">
<h3>Descri√ß√£o da Competi√ß√£o</h3>
<p>Traduzido do site oficial do kaggle:</p>
<p>"Pe√ßa a um comprador que descreva a casa dos seus sonhos, e eles provavelmente n√£o come√ßar√£o com a altura do teto do por√£o ou a proximidade de uma ferrovia leste-oeste. Mas o conjunto de dados desta competi√ß√£o de playground prova que muito mais influencia as negocia√ß√µes de pre√ßo do que o n√∫mero de quartos ou uma cerca branca.</p>
<p>Com 79 vari√°veis explicativas descrevendo (quase) todos os aspectos de casas residenciais em Ames, Iowa, esta competi√ß√£o desafia voc√™ a prever o pre√ßo final de cada casa."</p>
<p>Portanto, primeiramente vamos entender o comportamento da vari√°vel resposta, depois buscar quais dessas 79 vari√°veis explicativas s√£o mais importantes para representar a varia√ß√£o do pre√ßo de venda das casas atrav√©s dos m√©todos baseados em √°rvores e por fim ajustar os modelos propostos e submeter nossas estimativas no site!</p>
</div>
</div>
</div>
<div id="an√°lise-explorat√≥ria-dos-dados" class="section level1">
<h1>An√°lise explorat√≥ria dos dados</h1>
<p>Antes de pensar em ajustar algum modelo √© extremamente necess√°rio entender como se comportam os dados, portanto, tanto a vari√°vel resposta quanto as vari√°veis explicativas ser√£o avaliadas.</p>
<div id="vari√°vel-resposta" class="section level2">
<h2>Vari√°vel resposta:</h2>
<p><code>SalePrice</code> - o pre√ßo de venda da propriedade em d√≥lares. Essa √© a vari√°vel de destino que estamos tentando prever.</p>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Note que a distribui√ß√£o dos dados referentes ao pre√ßo de venda se distribui de maneira assim√©trica e n√£o possuem evid√™ncias de normalidade dos dados. Apesar dos m√©todos baseados em √°rvore se tratarem de t√©cnicas n√£o param√©tricas essa transforma√ß√£o ser√° feita pois ao final deste post desejo comparar os resultados com um modelo de regress√£o linear m√∫ltipla.</p>
</div>
</div>
<div id="√°rvore-de-decis√£o" class="section level1">
<h1>√Årvore de decis√£o</h1>
<p>Uma t√©cnica muito popular que √© mais comumente usada para resolver tarefas de classifica√ß√£o de dados por√©m a √°rvore conhecida como <a href="https://tinyurl.com/ybhlsgom">CART (Classification and Regression Trees)(Breiman, 1986)</a> lida com todos os tipos de atributos (incluindo atributos num√©ricos que s√£o tratados a partir da cria√ß√£o de intervalos). Para seu ajuste √© poss√≠vel realizar podas e produzir √°rvores bin√°rias.</p>
<p>A constru√ß√£o da √°rvore √© realizada por meio do algoritmo que iterativamente analisa os atributos descritivos de um conjunto de dados previamente rotulado. Sua popularidade como apoio para a tomada de decis√£o se deve principalmente ao fato da f√°cil visualiza√ß√£o do conhecimento gerado e o f√°cil entendimento.</p>
<p>Outra caracter√≠stica legal da √°rvore de decis√µes √© que ela permite ajustar um modelo sem um pr√©-processamento detalhado, pois √© f√°cil de ajustar, aceita valores faltantes e √© de f√°cil interpreta√ß√£o, veja:</p>
<pre class="r"><code>library(rpart)

control &lt;- rpart.control(minsplit =10, # o n√∫mero m√≠nimo de observa√ß√µes em um n√≥
                         cp = 0.006    # parametro de complexidade q controla o tamanho da arvore
)
rpartFit &lt;- rpart(exp(SalePrice) ~ . , train, method = &quot;anova&quot;, control = control) 

rpart.plot::rpart.plot(rpartFit,cex = 0.6)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-5-1.png" width="1200" /></p>
<p>No topo, vemos o primeiro n√≥ com 100% das observa√ß√µes, que representa o total da base (100%). Em seguida, vemos que a primeira vari√°vel que determina o pre√ßo de venda das casas <code>SalePrice</code> √© a vari√°vel <code>OverallQual</code>. As casas que apresentaram <code>OverallQual</code> &lt; 7.5 ocorrem em maior propor√ß√£o do que as que tiveram <code>OverallQual</code>&gt;7.5. A interpreta√ß√£o pode continuar dessa forma recursivamente.</p>
<p>√â poss√≠vel notar que as vari√°veis <code>OverallQual</code>,<code>Neighborhood</code>,<code>1stFlrSF</code>,<code>2ndFlrSF</code>,<code>GrLivArea</code>, <code>BsmtFinSF1</code> foram as que melhor representaram os dados de acordo com os par√¢metros que determinamos para ajustar esta √°rvore, vejamos com mais detalhes se existe rela√ß√£o linear e intensidade e dire√ß√£o dessa rela√ß√£o com o <a href="https://pt.wikipedia.org/wiki/Coeficiente_de_correla%C3%A7%C3%A3o_de_Pearson">coeficiente de correla√ß√£o de Pearson</a> entre estas vari√°veis dois a dois e em rela√ß√£o √† vari√°vel resposta:</p>
<pre class="r"><code>devtools::source_url(&quot;https://raw.githubusercontent.com/gomesfellipe/functions/master/correlations_for_ggpairs.R&quot;)

train %&gt;% 
  select(SalePrice,OverallQual,`1stFlrSF`,`2ndFlrSF`,GrLivArea,BsmtFinSF1) %&gt;% 
  ggpairs(lower = list(continuous = my_fn))+
  theme_bw()</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Com esta figura temos muitas informa√ß√µes, destaca-se que todas essas vari√°veis possuem algum tipo de rela√ß√£o linear com a vari√°vel resposta, a menor correla√ß√£o observada foi com o <code>BsmtFinSF1</code> e a vari√°vel que apresentou a maior correla√ß√£o foi a <code>OverallQual</code>. Aten√ß√£o para a correla√ß√£o entre <code>SalePrice</code> e <code>OverallQual</code>, pois <code>Overallqual</code> parece ser uma vari√°vel ordinal e uma outra medida de correla√ß√£o que melhor representaria esta rela√ß√£o √© o <a href="https://pt.wikipedia.org/wiki/Coeficiente_de_correla%C3%A7%C3%A3o_de_postos_de_Spearman">coeficiente de correla√ß√£o de Spearman</a>, veja:</p>
<pre class="r"><code>cor(full$SalePrice, full$OverallQual, method = &quot;spearman&quot;, use = &quot;complete.obs&quot;)</code></pre>
<pre><code>## [1] 0.8098286</code></pre>
<p>Um pouco diferente do resultado da correla√ß√£o de Pearson pois avalia rela√ß√µes lineares, j√° a correla√ß√£o de Spearman avalia rela√ß√µes mon√≥tonas, sejam elas lineares ou n√£o.</p>
<div id="an√°lise-explorat√≥ria-e-input-de-nas" class="section level2 tabset">
<h2>An√°lise explorat√≥ria e input de <code>NA</code>s</h2>
<p>Arrumar a base de dados √© uma tarefa longa e que geralmente consome grande parte no tempo em um projeto de ci√™ncia de dados. N√£o adianta usar o algor√≠timo mais poderoso de machine learning se a base de dados n√£o estiver arrumada de maneira que possibilite a an√°lise dos dados.</p>
<p>Para obter informa√ß√µes da amostra, confira no <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data">link do dataset da competi√ß√£o no Kaggle</a>. Na p√°gina √© poss√≠vel conferir <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/data_description.txt">a descri√ß√£o da amostra</a> e nela nota-se que alguns dos valores faltantes possuem significado, ent√£o √© necess√°rio rotul√°-los para que o R possa interpretar estes valores da maneira correta.</p>
<div id="status-da-amostra" class="section level3">
<h3>Status da amostra</h3>
<p>Conferindo o status da amostra com a fun√ß√£o <code>df_status()</code> do pacote <a href="https://cran.r-project.org/web/packages/funModeling/index.html"><code>funModeling</code></a>:</p>
<pre class="r"><code>full %&gt;% 
  df_status(print_results = F) %&gt;% 
  as_tibble() %&gt;%
  arrange(-p_na, -p_zeros)</code></pre>
<pre><code>## # A tibble: 80 x 9
##    variable     q_zeros p_zeros  q_na  p_na q_inf p_inf type      unique
##    &lt;chr&gt;          &lt;int&gt;   &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;
##  1 PoolQC             0       0  2909 99.7      0     0 character      3
##  2 MiscFeature        0       0  2814 96.4      0     0 character      4
##  3 Alley              0       0  2721 93.2      0     0 character      2
##  4 Fence              0       0  2348 80.4      0     0 character      4
##  5 SalePrice          0       0  1459 50.0      0     0 numeric      663
##  6 FireplaceQu        0       0  1420 48.6      0     0 character      5
##  7 LotFrontage        0       0   486 16.6      0     0 numeric      128
##  8 GarageYrBlt        0       0   159  5.45     0     0 numeric      103
##  9 GarageFinish       0       0   159  5.45     0     0 character      3
## 10 GarageQual         0       0   159  5.45     0     0 character      5
## # ‚Ä¶ with 70 more rows</code></pre>
<p>Note que as vari√°veis problem√°ticas foram ordenadas de forma decrescente (maior n√∫mero de dados faltantes e zeros) vamos tratar uma de cada vez partindo da vari√°vel mais cr√≠tica</p>
</div>
<div id="pool" class="section level3">
<h3>Pool</h3>
<ul>
<li><code>PoolQC</code> √© a vari√°vel que possui mais <code>NA</code> e a descri√ß√£o da base informa que:</li>
</ul>
<p><code>PoolQC</code>: qualidade da piscina</p>
<ul>
<li>Ex Excelente</li>
<li>Gd Good</li>
<li>TA M√©dia / T√≠pica</li>
<li>Fa Pequena</li>
<li>NA sem piscina</li>
</ul>
<p>√â poss√≠vel observar que se trata de uma vari√°vel ordinal, portanto vamos criar uma vari√°vel auxiliar (pois esta descri√ß√£o se repete em outras vari√°veis):</p>
<pre class="r"><code># Criando vari√°vel auxilar ordinal
Qualidade &lt;- c(&#39;None&#39; = 0, &#39;Po&#39; = 1, &#39;Fa&#39; = 2, &#39;TA&#39; = 3, &#39;Gd&#39; = 4, &#39;Ex&#39; = 5)

full %&lt;&gt;%
  mutate(PoolQC =  ifelse(PoolQC %&gt;% is.na, &quot;None&quot;, PoolQC) %&gt;% as.factor() ) %&gt;% 
  mutate(PoolQC = as.integer(revalue(PoolQC, Qualidade)))</code></pre>
<p>Al√©m disso, existe outra vari√°vel relacionada √† piscina, veja:</p>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Pool&quot;)]) %&gt;% 
  table </code></pre>
<pre><code>##         PoolQC
## PoolArea    1    2    3    4
##      0      0    0    0 2906
##      144    1    0    0    0
##      228    1    0    0    0
##      368    0    0    0    1
##      444    0    0    0    1
##      480    0    0    1    0
##      512    1    0    0    0
##      519    0    1    0    0
##      555    1    0    0    0
##      561    0    0    0    1
##      576    0    0    1    0
##      648    0    1    0    0
##      738    0    0    1    0
##      800    0    0    1    0</code></pre>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Pool&quot;)]) %&gt;%
  map(~sum(is.na(.x)))</code></pre>
<pre><code>## $PoolArea
## [1] 0
## 
## $PoolQC
## [1] 0</code></pre>
<pre class="r"><code># Arrumando inconsist√´ncias:
full %&lt;&gt;% 
  mutate(PoolQC = ifelse(PoolQC == 0 &amp; PoolArea !=0, 2, PoolQC))

# Arrumando inconsist√´ncias:
full %&lt;&gt;% 
  mutate(Pool = ifelse(PoolQC == 0 &amp; PoolArea ==0, &quot;no&quot;, &quot;yes&quot;))</code></pre>
</div>
<div id="misc" class="section level3">
<h3>Misc</h3>
<p>Se referem aos recursos diversos</p>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Misc&quot;)],
         SalePrice
  ) %&gt;%
  map(~sum(is.na(.x)))</code></pre>
<pre><code>## $MiscFeature
## [1] 2814
## 
## $MiscVal
## [1] 0
## 
## $SalePrice
## [1] 1459</code></pre>
<p><code>MiscFeature</code>: recurso diverso n√£o coberto em outras categorias</p>
<ul>
<li>Elevador elev</li>
<li>Gar2 2nd Garage (se n√£o for descrito na se√ß√£o de garagem)</li>
<li>Othr Outro</li>
<li>Galp√£o derramado (mais de 100 SF)</li>
<li>TenC Campo de t√©nis</li>
<li>NA Nenhum</li>
</ul>
<p>Desta vez n√£o se trata de uma vari√°vel ordinal, vejamos:</p>
<pre class="r"><code>full %&lt;&gt;%
  mutate(MiscFeature =  if_else(MiscFeature %&gt;% is.na, &quot;None&quot;, MiscFeature) %&gt;% as.factor) 

# Breve resumo:
g1 &lt;- 
  full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Misc&quot;)], SalePrice) %&gt;% 
  ggplot(aes(y=MiscVal,x= reorder(MiscFeature, -MiscVal,FUN = median) ,fill=MiscFeature))+
  geom_boxplot()+
  theme_bw() +
  scale_fill_viridis_d() +
  labs(x = &quot;Recurso Diverso&quot;)

g2 &lt;- 
  full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Misc&quot;)], SalePrice) %&gt;% 
  ggplot(aes(y=SalePrice,x= reorder(MiscFeature, -MiscVal,FUN = median) ,fill=MiscFeature))+
  geom_boxplot()+
  theme_bw() +
  scale_fill_viridis_d() +
  labs(x = &quot;Pre√ßo de Venda&quot;)

grid.arrange(g1, g2)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code>rm(g1,g2)</code></pre>
<p>Al√©m disso, <code>MiscVal</code>: Valor do recurso variado</p>
</div>
<div id="alley" class="section level3">
<h3>Alley</h3>
<p><code>Alley</code>: Tipo de acesso ao beco para a propriedade</p>
<ul>
<li>Grvl Cascalho</li>
<li>Pave pavimentado</li>
<li>NA Nenhum acesso de beco</li>
</ul>
<p>Basta realizar o input:</p>
<pre class="r"><code>full %&lt;&gt;% 
  mutate(Alley = Alley %&gt;% str_replace_na(&quot;None&quot;)) %&gt;% 
  mutate(Alley = as.factor(Alley))</code></pre>
<pre class="r"><code>full[!is.na(full$SalePrice),] %&gt;% 
  select(Alley, SalePrice) %&gt;% 
  ggplot(aes(y=SalePrice,x= reorder(Alley, -SalePrice,FUN = median) ,fill=Alley))+
  geom_boxplot()+
  theme_bw() +
  scale_fill_viridis_d() +
  labs(x = &quot;tipo de Acesso&quot;)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
<div id="fence" class="section level3">
<h3>Fence</h3>
<p><code>Fence</code>: qualidade da cerca</p>
<ul>
<li>GdPrv Boa privacidade</li>
<li>MnPrv minima privacidade</li>
<li>GdWo boa madeira</li>
<li>MnWw M√≠nima Madeira / Fio</li>
<li>NA Sem cerca</li>
</ul>
<p>Input ser√° da seguinte forma:</p>
<pre class="r"><code>full %&lt;&gt;% 
  mutate(Fence = Fence %&gt;% str_replace_na(&quot;None&quot;))</code></pre>
<pre class="r"><code>full[1:nrow(train),] %&gt;% 
  select(Fence, SalePrice) %&gt;% 
  ggplot(aes(y=SalePrice,x= reorder(Fence, -SalePrice, median) ,fill=Fence))+
  geom_boxplot()+
  theme_bw() +
  scale_fill_viridis_d() +
  labs(x = &quot;tipo de Acesso&quot;)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<pre class="r"><code>full %&lt;&gt;% mutate(Fence = as.factor(Fence))</code></pre>
<p>Aparentemente n√£o parece existir uma rela√ß√£o ordinal sobre o tipo de cerca quanto ao pre;o de venda da casa, portanto foi convertida para fator</p>
</div>
<div id="fireplace" class="section level3">
<h3>FirePlace</h3>
<p>Vari√°veis relacionadas com lareira. Segundo a descri√ß√£o, temos:</p>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Fireplace&quot;)], SalePrice)</code></pre>
<pre><code>## # A tibble: 2,919 x 3
##    Fireplaces FireplaceQu SalePrice
##         &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;
##  1          0 &lt;NA&gt;             12.2
##  2          1 TA               12.1
##  3          1 TA               12.3
##  4          1 Gd               11.8
##  5          1 TA               12.4
##  6          0 &lt;NA&gt;             11.9
##  7          1 Gd               12.6
##  8          2 TA               12.2
##  9          2 TA               11.8
## 10          2 TA               11.7
## # ‚Ä¶ with 2,909 more rows</code></pre>
<p><code>Fireplaces</code>: Numero de lareiras</p>
<p><code>FireplaceQu</code>: Qualidade da lareira</p>
<ul>
<li>Ex Excellente - Excepcional Lareira de Alvenaria</li>
<li>Gd Boa - Lareira de alvenaria no n√≠vel principal</li>
<li>TA M√©dia - lareira pr√©-fabricada na sala principal ou Lareira de alvenaria no por√£o</li>
<li>Fa Pequena - Lareira pr√©-fabricada no por√£o</li>
<li>Po Pobre - Fog√£o Ben Franklin</li>
<li>NA sem lareira</li>
</ul>
<p>Nota-se que se trata de uma vari√°vel ordinal de acordo com a qualidade, portanto:</p>
<pre class="r"><code>full %&lt;&gt;% 
  mutate(FireplaceQu =  if_else(FireplaceQu %&gt;% is.na, &quot;None&quot;, FireplaceQu) ) %&gt;% 
  mutate(FireplaceQu = as.integer(revalue(FireplaceQu, Qualidade)))</code></pre>
<p>Conferindo se existem inconsist√™ncias:</p>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Fireplace&quot;)]) %&gt;% 
  table </code></pre>
<pre><code>##           FireplaceQu
## Fireplaces    0    1    2    3    4    5
##          0 1420    0    0    0    0    0
##          1    0   46   63  495  627   37
##          2    0    0   10   92  112    5
##          3    0    0    1    4    5    1
##          4    0    0    0    1    0    0</code></pre>
</div>
<div id="lot" class="section level3">
<h3>Lot</h3>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Lot&quot;)], SalePrice) %&gt;% 
  map_dbl(~sum(is.na(.x)))</code></pre>
<pre><code>## LotFrontage     LotArea    LotShape   LotConfig   SalePrice 
##         486           0           0           0        1459</code></pre>
<p>Segundo a descri√ß√£o:</p>
<p><code>LotFrontage</code>: Ruas linearmente conectadas √† propriedade</p>
<p><code>LotArea</code> : Tamanho do lote em p√©s quadrados</p>
<p><code>LotShape</code>: forma geral da propriedade</p>
<ul>
<li>Regue Regular<br />
</li>
<li>IR1 ligeiramente irregular</li>
<li>IR2 moderadamente irregular</li>
<li>IR3 Irregular</li>
</ul>
<p><code>LotConfig</code>: configura√ß√£o de lote</p>
<ul>
<li>Inside Lote muito para dentro</li>
<li>Corner Canto de esquina</li>
<li>CulDSac Cul-de-sac</li>
<li>FR2 Frente em 2 lados da propriedade</li>
<li>FR3 Frente em 3 lados da propriedade</li>
</ul>
<p>Input para o <code>LotFrontage</code> ser√° feito considerando a configura√ß√£o do lote, veja:</p>
<pre class="r"><code>inputsLot &lt;- full %&gt;% 
  select(LotFrontage, LotConfig) %&gt;% 
  group_by(LotConfig) %&gt;%
  dplyr::summarise(Media = mean(LotFrontage, na.rm = T),
            Mediana = median(LotFrontage, na.rm = T))

full$LotFrontage[is.na(full$LotFrontage) &amp; full$LotConfig == inputsLot$LotConfig[1]] &lt;- inputsLot$Mediana[1] 
full$LotFrontage[is.na(full$LotFrontage) &amp; full$LotConfig == inputsLot$LotConfig[2]] &lt;- inputsLot$Mediana[2] 
full$LotFrontage[is.na(full$LotFrontage) &amp; full$LotConfig == inputsLot$LotConfig[3]] &lt;- inputsLot$Mediana[3] 
full$LotFrontage[is.na(full$LotFrontage) &amp; full$LotConfig == inputsLot$LotConfig[4]] &lt;- inputsLot$Mediana[4] 
full$LotFrontage[is.na(full$LotFrontage) &amp; full$LotConfig == inputsLot$LotConfig[5]] &lt;- inputsLot$Mediana[5] </code></pre>
<p>Arrumando vari√°veis nominais e ordinais:</p>
<pre class="r"><code>full %&lt;&gt;% 
  mutate(LotShape = as.integer(revalue(full$LotShape, c(&#39;IR3&#39;=0, &#39;IR2&#39;=1, &#39;IR1&#39;=2, &#39;Reg&#39;=3))))</code></pre>
</div>
<div id="garages" class="section level3">
<h3>Garages</h3>
<p>Vari√°veis relacionadas, segundo a descri√ß√£o, temos:</p>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Garage&quot;)], SalePrice) %&gt;% 
  map_dbl(~sum(is.na(.x)))</code></pre>
<pre><code>##   GarageType  GarageYrBlt GarageFinish   GarageCars   GarageArea   GarageQual 
##          157          159          159            1            1          159 
##   GarageCond    SalePrice 
##          159         1459</code></pre>
<p><code>GarageType</code>: localiza√ß√£o da garagem</p>
<ul>
<li>2Types Mais de um tipo de garagem</li>
<li>Attchd anexa a casa</li>
<li>Basement tipo porao</li>
<li>BuiltIn (garagem parte da casa - normalmente tem sala acima da garagem)</li>
<li>CarPort Porta do carro</li>
<li>Detchd nao anexa a casa</li>
<li>NA Sem Garagem</li>
</ul>
<p><code>GarageYrBlt</code>: garagem do ano foi constru√≠da</p>
<p><code>GarageFinish</code>: acabamento interior da garagem</p>
<ul>
<li>Fin Finished</li>
<li>RFn √Åspero Finalizado<br />
</li>
<li>Unf inacabado</li>
<li>NA Sem Garagem</li>
</ul>
<p><code>GarageCars</code>: Tamanho da garagem na capacidade do carro</p>
<p><code>GarageArea</code>: Tamanho da garagem em p√©s quadrados</p>
<p><code>GarageQual</code>: GarageQuality</p>
<ul>
<li>Ex Excelente</li>
<li>Gd Good</li>
<li>TA T√≠pico / M√©dio</li>
<li>FA Justo</li>
<li>Po Poor</li>
<li>NA Sem Garagem</li>
</ul>
<p><code>GarageCond</code>: condi√ß√£o de garagem</p>
<ul>
<li>Ex Excelente</li>
<li>Gd Good</li>
<li>TA T√≠pico / M√©dio</li>
<li>Fa Justo</li>
<li>Po Poor</li>
<li>NA Sem Garagem</li>
</ul>
<pre class="r"><code>full %&lt;&gt;% 
  mutate(GarageType   =  if_else(GarageType %&gt;% is.na, &quot;None&quot;, GarageType) ) %&gt;% 
  mutate(GarageYrBlt  = if_else(GarageYrBlt %&gt;% is.na,YearBuilt, GarageYrBlt) ) %&gt;% 
  mutate(GarageFinish =  if_else(GarageFinish %&gt;% is.na, &quot;None&quot;, GarageFinish) ) %&gt;% 
  mutate(GarageFinish = as.integer(revalue(GarageFinish, c(&#39;None&#39;=0, &#39;Unf&#39;=1, &#39;RFn&#39;=2, &#39;Fin&#39;=3)))) %&gt;% 
  mutate(GarageCars   = ifelse(GarageCars %&gt;% is.na, 0, GarageCars) ) %&gt;% 
  mutate(GarageArea   = ifelse(GarageArea %&gt;% is.na, 0, GarageArea)) %&gt;% 
  mutate(GarageQual   = if_else(GarageQual %&gt;% is.na, &quot;None&quot;, GarageQual)) %&gt;% 
  mutate(GarageQual   = as.integer(revalue(GarageQual, Qualidade))) %&gt;% 
  mutate(GarageCond   = if_else(GarageCond %&gt;% is.na, &quot;None&quot;, GarageCond)) %&gt;% 
  mutate(GarageCond   = as.integer(revalue(GarageCond, Qualidade))) 
  
table(full$GarageCond)</code></pre>
<pre><code>## 
##    0    1    2    3    4    5 
##  159   14   74 2654   15    3</code></pre>
</div>
<div id="bsmt" class="section level3">
<h3>Bsmt</h3>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;Bsmt&quot;)], SalePrice) %&gt;% 
  map_dbl(~sum(is.na(.x)))</code></pre>
<pre><code>##     BsmtQual     BsmtCond BsmtExposure BsmtFinType1   BsmtFinSF1 BsmtFinType2 
##           81           82           82           79            1           80 
##   BsmtFinSF2    BsmtUnfSF  TotalBsmtSF BsmtFullBath BsmtHalfBath    SalePrice 
##            1            1            1            2            2         1459</code></pre>
<p><code>BsmtQual</code>: Avalia a altura do por√£o</p>
<ul>
<li>Ex Excelente (100+ polegadas)<br />
</li>
<li>Gd Bom (90-99 polegadas)</li>
<li>TA T√≠pica (80-89 polegadas)</li>
<li>Fa Justo (70-79 polegadas)</li>
<li>Po Pobre (&lt;70 polegadas</li>
<li>NA Sem Por√£o</li>
</ul>
<p><code>BsmtCond</code>: Avalia o estado geral do por√£o</p>
<ul>
<li>Ex Excelente</li>
<li>Gd Bom</li>
<li>TA T√≠pica - umidade ligeira permitida</li>
<li>Fa Razo√°vel - umidade ou alguma rachadura ou sedimenta√ß√£o</li>
<li>Po Insuficiente - Craqueamento severo, sedimenta√ß√£o ou umidade</li>
<li>NA Sem Por√£o</li>
</ul>
<p><code>BsmtExposure</code>: Refere-se a paralisa√ß√µes ou paredes no n√≠vel do jardim</p>
<ul>
<li>Gd Good Exposi√ß√£o</li>
<li>Av M√©dia Exposi√ß√£o (n√≠veis divididos ou foyers normalmente pontua√ß√£o m√©dia ou acima)<br />
</li>
<li>Mn Exposi√ß√£o M√≠nima</li>
<li>No N√£o Exposi√ß√£o</li>
<li>NA Sem por√£o</li>
</ul>
<p><code>BsmtFinType1</code>: Avalia√ß√£o da √°rea acabada do por√£o</p>
<ul>
<li>GLQ Bons Viver</li>
<li>ALQ M√©dia Living Quarters</li>
<li>BLQ Abaixo da m√©dia Living Quarters<br />
</li>
<li>Rec M√©dia Rec Room</li>
<li>LwQ Baixa Qualidade</li>
<li>Unf unfinshed</li>
<li>NA nenhum por√£o</li>
</ul>
<p><code>BsmtFinSF1</code>: pes quadrados do tipo 1 terminado</p>
<p><code>BsmtFinType2</code>: Avalia√ß√£o do por√£o √°rea terminado (se v√°rios tipos)</p>
<ul>
<li>GLQ Bons aposentos</li>
<li>ALQ Medianos</li>
<li>BLQ abaixo da media</li>
<li>Rec Aposentos m√©dia qualidade</li>
<li>LwQ Baixa Qualidade</li>
<li>Unf</li>
<li>N√£o Sem Por√£o</li>
</ul>
<p><code>BsmtFinSF2</code>: P√©s quadrados acabados do Tipo 2</p>
<p><code>BsmtUnfSF</code>: P√©s quadrados inacabados da √°rea do por√£o</p>
<p><code>TotalBsmtSF</code>: Total p√©s quadrados da √°rea do por√£o</p>
<p>Input das vari√°veis n√£o num√©ricas com <code>None</code> e convertendo para ordinal as vari√°veis com rela√ß√£o de ordem. Para os faltantes das vari√°veis num√©ricas foram imputados o valor 0 (zeros).</p>
<pre class="r"><code># Categ√≥ricos:
full[,names(full)[names(full) %&gt;% str_detect(&quot;Bsmt&quot;)]] &lt;- 
  full[,names(full)[names(full) %&gt;% str_detect(&quot;Bsmt&quot;)]] %&gt;%
  select(names(full)[names(full) %&gt;% str_detect(&quot;Bsmt&quot;)]) %&gt;%
  mutate_if( ~ !is.numeric(.x) , ~ ifelse(is.na(.x), &quot;None&quot;, .x)) %&gt;% 
  mutate(BsmtQual = as.integer(revalue(BsmtQual, Qualidade))) %&gt;% 
  mutate(BsmtCond = as.integer(revalue(BsmtCond, Qualidade))) %&gt;% 
  mutate(BsmtExposure = as.integer(revalue(BsmtExposure, c(&#39;None&#39;=0, &#39;No&#39;=1, &#39;Mn&#39;=2, &#39;Av&#39;=3, &#39;Gd&#39;=4)))) %&gt;% 
  mutate(BsmtFinType1 = as.integer(revalue(BsmtFinType1,c(&#39;None&#39;=0, &#39;Unf&#39;=1, &#39;LwQ&#39;=2, &#39;Rec&#39;=3, &#39;BLQ&#39;=4, &#39;ALQ&#39;=5, &#39;GLQ&#39;=6)))) 

# Num√©ricos:
full[,names(full)[names(full) %&gt;% str_detect(&quot;Bsmt&quot;)]] &lt;- 
  full[,names(full)[names(full) %&gt;% str_detect(&quot;Bsmt&quot;)]] %&gt;%
  select(names(full)[names(full) %&gt;% str_detect(&quot;Bsmt&quot;)]) %&gt;%
  mutate_if( ~ is.numeric(.x) , ~ ifelse(is.na(.x), 0, .x))</code></pre>
</div>
<div id="masvnr" class="section level3">
<h3>MasVnr</h3>
<pre class="r"><code>full %&gt;% 
  select(names(full)[names(full) %&gt;% str_detect(&quot;MasVnr&quot;)], SalePrice) %&gt;% 
  map_dbl(~sum(is.na(.x)))</code></pre>
<pre><code>## MasVnrType MasVnrArea  SalePrice 
##         24         23       1459</code></pre>
<p><code>MasVnrType</code>: Alvenaria tipo de verniz</p>
<ul>
<li>BrkCmn Brick Common</li>
<li>BrkFace Face de tijolos</li>
<li>CBlock Bloco cinza</li>
<li>None Nenhum</li>
<li>Stone Pedra</li>
</ul>
<p><code>MasVnrArea</code>: √Årea de folheado de alvenaria em p√©s quadrados</p>
<pre class="r"><code>full %&lt;&gt;% 
  mutate(MasVnrType = if_else(is.na(MasVnrType), &quot;None&quot;, MasVnrType)) %&gt;% 
  mutate(MasVnrType = as.integer(revalue(MasVnrType, c(&#39;None&#39;=0, &#39;BrkCmn&#39;=0, &#39;BrkFace&#39;=1, &#39;Stone&#39;=2)))) %&gt;% 
  mutate(MasVnrArea = if_else(is.na(MasVnrArea), 0, 1))</code></pre>
</div>
<div id="vari√°veis-restantes-com-poucos-na" class="section level3">
<h3>Vari√°veis restantes com poucos <code>NA</code></h3>
<p>A estrat√©gia adotada para imputar estes dados ser√° tomada de maneira arbitr√°ria. Os valores faltantes ser√£o preenchidos com o valor comum mais frequente daquela vari√°vel. As vari√°veis que restam s√£o:</p>
<pre class="r"><code>full %&gt;% 
  df_status(print_results = F) %&gt;% 
  as_tibble() %&gt;%
  arrange(-p_na, -p_zeros)</code></pre>
<pre><code>## # A tibble: 81 x 9
##    variable    q_zeros p_zeros  q_na  p_na q_inf p_inf type      unique
##    &lt;chr&gt;         &lt;int&gt;   &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;
##  1 SalePrice         0     0    1459 50.0      0     0 numeric      663
##  2 MSZoning          0     0       4  0.14     0     0 character      5
##  3 Utilities         0     0       2  0.07     0     0 character      2
##  4 Functional        0     0       2  0.07     0     0 character      7
##  5 Exterior1st       0     0       1  0.03     0     0 character     15
##  6 Exterior2nd       0     0       1  0.03     0     0 character     16
##  7 Electrical        0     0       1  0.03     0     0 character      5
##  8 KitchenQual       0     0       1  0.03     0     0 character      4
##  9 SaleType          0     0       1  0.03     0     0 character      9
## 10 PoolArea       2906    99.6     0  0        0     0 numeric       14
## # ‚Ä¶ with 71 more rows</code></pre>
<p>Vejamos:</p>
<p><code>MSZoning</code>: Identifica a classifica√ß√£o geral de zoneamento da venda.</p>
<ul>
<li>Ser√° convertida para fator, vari√°vel nominal</li>
</ul>
<p><code>KitchenQual</code>: Qualidade da cozinha</p>
<ul>
<li>Ser√° convertida para ordinal</li>
</ul>
<p><code>Utilities</code>: Tipo de utilidade dispon√≠vel</p>
<ul>
<li>Ser√° removida</li>
</ul>
<p><code>Functional</code>: Funcionalidade dom√©stica</p>
<ul>
<li>Ser√° considerada como ordinal</li>
</ul>
<p><code>Exterior1st</code>: revestimento Exterior em casa</p>
<ul>
<li>Convertida para fator, vari√°vel nominal</li>
</ul>
<p><code>Electrical</code>: Sistema el√©trico</p>
<ul>
<li>Convertida para fator, vari√°vel nominal</li>
</ul>
<p><code>SaleType</code>: Tipo de venda</p>
<ul>
<li>Convertida para fator, vari√°vel nominal</li>
</ul>
<pre class="r"><code>full &lt;- full %&gt;% 
  mutate(MSZoning    = ifelse(is.na(MSZoning),
                            full$MSZoning %&gt;% table %&gt;% sort %&gt;% names %&gt;% last, MSZoning)) %&gt;% 
  mutate(MSZoning    = as.factor(MSZoning)) %&gt;% 
  mutate(KitchenQual = ifelse(is.na(KitchenQual),
                            full$KitchenQual %&gt;% 
                              table %&gt;% sort %&gt;% names %&gt;% last, KitchenQual)) %&gt;% 
  mutate(KitchenQual = as.integer(revalue(as.character(full$KitchenQual), Qualidade))) %&gt;% 
  select(-Utilities) %&gt;% 
  mutate(Exterior1st = ifelse(is.na(Exterior1st),
                            full$Exterior1st %&gt;% table %&gt;% sort %&gt;% names %&gt;% last, Exterior1st)) %&gt;% 
  mutate(Exterior1st = as.factor(Exterior1st)) %&gt;% 
  mutate(Exterior2nd = ifelse(is.na(Exterior2nd),
                            full$Exterior2nd %&gt;% table %&gt;% sort %&gt;% names %&gt;% last, Exterior2nd)) %&gt;% 
  mutate(Exterior2nd = as.factor(Exterior2nd)) %&gt;% 
  mutate(Electrical  = ifelse(is.na(Electrical),
                            full$Electrical %&gt;% table %&gt;% sort %&gt;% names %&gt;% last, Electrical)) %&gt;% 
  mutate(Electrical  = as.factor(Electrical)) %&gt;% 
  mutate(SaleType    = ifelse(is.na(SaleType ),
                            full$SaleType  %&gt;% table %&gt;% sort %&gt;% names %&gt;% last, SaleType )) %&gt;% 
  mutate(SaleType    = as.factor(SaleType )) 


full[is.na(full$Functional),&quot;Functional&quot;] &lt;- full$Functional %&gt;% table %&gt;% sort %&gt;% names %&gt;% last
full$Functional = as.integer(revalue(full$Functional, c(&#39;Sal&#39;=0, &#39;Sev&#39;=1, &#39;Maj2&#39;=2, &#39;Maj1&#39;=3, &#39;Mod&#39;=4, &#39;Min2&#39;=5, &#39;Min1&#39;=6, &#39;Typ&#39;=7)))
full[is.na(full$KitchenQual),&quot;KitchenQual&quot;] &lt;- full$KitchenQual %&gt;% table %&gt;% sort %&gt;% names %&gt;% last %&gt;% as.numeric()
full$KitchenQual = as.integer(revalue(as.character(full$KitchenQual), Qualidade))
# full[is.na(full$Electrical),&quot;Electrical&quot;] &lt;- 3

to_remove &lt;- full %&gt;% map(~table(.x) %&gt;% length()) %&gt;% .[.== 1] %&gt;% names()
full &lt;- full %&gt;% select(-one_of(to_remove))</code></pre>
<p>Status da base no momento:</p>
<pre class="r"><code>full %&gt;% 
  df_status(print_results = F) %&gt;% 
  as_tibble() %&gt;%
  arrange(-p_na,-p_zeros, type)</code></pre>
<pre><code>## # A tibble: 79 x 9
##    variable      q_zeros p_zeros  q_na  p_na q_inf p_inf type    unique
##    &lt;chr&gt;           &lt;int&gt;   &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;
##  1 SalePrice           0     0    1459  50.0     0     0 numeric    663
##  2 PoolArea         2906    99.6     0   0       0     0 numeric     14
##  3 3SsnPorch        2882    98.7     0   0       0     0 numeric     31
##  4 LowQualFinSF     2879    98.6     0   0       0     0 numeric     36
##  5 MiscVal          2816    96.5     0   0       0     0 numeric     38
##  6 BsmtHalfBath     2744    94       0   0       0     0 numeric      3
##  7 ScreenPorch      2663    91.2     0   0       0     0 numeric    121
##  8 BsmtFinSF2       2572    88.1     0   0       0     0 numeric    272
##  9 EnclosedPorch    2460    84.3     0   0       0     0 numeric    183
## 10 HalfBath         1834    62.8     0   0       0     0 numeric      3
## # ‚Ä¶ with 69 more rows</code></pre>
<p>Transformando o <code>character</code> para <code>factor</code>:</p>
<pre class="r"><code>full %&lt;&gt;% mutate_if(is.character, as.factor)</code></pre>
<p>Transformando novamente nossa base de treino e de teste:</p>
<pre class="r"><code>train &lt;- full[1:nrow(train),] %&gt;% as.data.frame() 
test  &lt;- full[(nrow(train)+1):nrow(full),] %&gt;% select(-SalePrice) %&gt;% as.data.frame()

# # Input Missing
# train_miss_model = preProcess(train, &quot;knnImpute&quot;)
# train = predict(train_miss_model, train)
# test = predict(train_miss_model, test)
# 
# train$SalePrice &lt;- y</code></pre>
</div>
</div>
</div>
<div id="machine-learning-com-algor√≠tmos-de-aprendizagem-baseados-em-√°rvores" class="section level1">
<h1>Machine Learning com algor√≠tmos de aprendizagem baseados em √°rvores</h1>
<p>Os m√©todos baseados em √°rvores fornecem modelos preditivos de alta precis√£o, estabilidade e facilidade de interpreta√ß√£o. Ao contr√°rio dos modelos lineares, eles s√£o capazes de lidar bem com rela√ß√µes n√£o-lineares al√©m de poderem ser adaptados para resolver tanto problemas de classifica√ß√£o quanto problemas de regress√£o.</p>
<p>Algoritmos como √°rvores de decis√£o, random forest e ‚Äúgradient boosting‚Äù est√£o sendo muito usados em todos os tipos de problemas de data science e √© not√°vel o uso desses algor√≠timos para resolver os desafios do <a href="https://www.kaggle.com/">Kaggle</a>. Para resolver este problema utilizaremos estes tr√™s algoritmos e ao final, pegando carona na sele√ß√£o de vari√°veis para os algoritmos de √°rvore, ser√° ajustado um modelo de regress√£o linear para compararmos e conferirmos a signific√¢ncia estat√≠stica de cada uma das vari√°veis.</p>
<div id="varimp-com-random-forest" class="section level2">
<h2>VarImp com Random Forest</h2>
<p>Um dos benef√≠cios da floresta aleat√≥ria √© o poder de lidar com grande conjunto de dados com maior dimensionalidade e identificar as vari√°veis a import√¢ncia das vari√°veis, que pode ser uma caracter√≠stica muito √∫til por√©m deve ser feita com cautela.</p>
<p>Veja uma reflex√£o (traduzida) da <a href="https://www.stat.berkeley.edu/~breiman/RandomForests/reg_philosophy.htm">nota de Leo Breiman (Universidade da Calif√≥rnia em Berkeley)</a></p>
<blockquote>
<p>‚ÄúUma nota filos√≥fica: RF √© um exemplo de uma ferramenta que √© √∫til para fazer an√°lises de dados cient√≠ficos; Mas os algoritmos mais inteligentes n√£o substituem a intelig√™ncia humana e o conhecimento dos dados do problema; Pegue a sa√≠da de florestas aleat√≥rias n√£o como verdade absoluta, mas como suposi√ß√µes geradas por um computador inteligente que podem ser √∫teis para levar a uma compreens√£o mais profunda do problema.‚Äù</p>
</blockquote>
<p>O ajuste da √°rvore ser√° feito com o pacote <code>caret</code> e o estudo de estimativas de erro foi definido como o <a href="https://en.wikipedia.org/wiki/Out-of-bag_error">Out of bag</a> que remove a necessidade de um conjunto de teste pois √© o erro m√©dio de previs√£o em cada amostra de treinamento <span class="math inline">\(x_i\)</span> , usando apenas as √°rvores que n√£o tinham <span class="math inline">\(x_i\)</span> em sua amostra de <a href="https://www.ime.usp.br/~chang/home/mae5704/aula-bootstrap.pdf">bootstrap</a>.</p>
<pre class="r"><code>set.seed(1)
control &lt;- trainControl(method = &quot;oob&quot;,verboseIter = F)

rfFit1 &lt;- train(SalePrice ~. ,
      data=train,
      method=&quot;rf&quot;,
      metric = &quot;Rsquared&quot;,
      trControl = control,
      preProcess = c(&quot;knnImpute&quot;)
      )

randomForest::varImpPlot(rfFit1$finalModel)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<pre class="r"><code>rfFit1$finalModel$importance %&gt;% 
  as.data.frame %&gt;%
  mutate(row = rownames(.)) %&gt;% 
  arrange(desc(IncNodePurity)) %&gt;% 
  as_tibble()</code></pre>
<pre><code>## # A tibble: 217 x 2
##    IncNodePurity row        
##            &lt;dbl&gt; &lt;chr&gt;      
##  1         77.9  OverallQual
##  2         35.0  GrLivArea  
##  3         14.8  YearBuilt  
##  4         11.5  KitchenQual
##  5          9.75 TotalBsmtSF
##  6          9.29 GarageCars 
##  7          6.74 `1stFlrSF` 
##  8          6.33 GarageArea 
##  9          5.02 ExterQualTA
## 10          4.04 BsmtFinSF1 
## # ‚Ä¶ with 207 more rows</code></pre>
<p>Ap√≥s inspecionar a import√¢ncia das vari√°veis vamos selecionar as seguintes vari√°veis:</p>
<pre class="r"><code>full %&lt;&gt;% 
  select(
    SalePrice  , Neighborhood, OverallQual , GrLivArea   , YearBuilt   ,  KitchenQual, 
    GarageCars ,  GarageArea , `1stFlrSF`  , ExterQual   , BsmtFinSF1  , FireplaceQu, 
    BsmtQual   , `2ndFlrSF`  , CentralAir  , GarageFinish, YearRemodAdd, FullBath, 
    GarageYrBlt, Fireplaces  , LotFrontage , BsmtUnfSF   , TotalBsmtSF , BsmtFinType1,
    OpenPorchSF, GarageType  , BsmtExposure, OverallCond , TotalBsmtSF , LotArea
  )</code></pre>
<p>Portanto, vamos definir novamente o conjunto de dados de treino e de teste:</p>
<pre class="r"><code>train &lt;- full[1:nrow(train),] %&gt;% as.data.frame()
test  &lt;- full[(nrow(train)+1):nrow(full),-1] %&gt;% as.data.frame()</code></pre>
</div>
<div id="vari√°veis-num√©ricas" class="section level2">
<h2>Vari√°veis num√©ricas</h2>
<p>Ap√≥s a sele√ß√£o dessas vari√°veis, vamos entender como elas est√£o correlacionadas dois a dois com o <a href="https://pt.wikipedia.org/wiki/Coeficiente_de_correla%C3%A7%C3%A3o_de_Pearson">coeficiente de correla√ß√£o de pearson</a>, exibindo a matrix em um <a href="https://en.wikipedia.org/wiki/Heat_map">Heatmap</a> (ou mapa de calor ), que √© uma representa√ß√£o gr√°fica de dados em que os valores individuais contidos em uma matriz representados como cores.</p>
<pre class="r"><code>cormat &lt;- 
  full %&gt;% 
  select(SalePrice, everything()) %&gt;% 
  select_if(is.numeric) %&gt;% 
  as.data.frame() %&gt;% 
  cor(use = &quot;na.or.complete&quot;) %&gt;% 
  melt

cormat %&gt;%   
  ggplot( aes(reorder(Var1,value), reorder(Var2,value), fill=value))+
  geom_tile(color=&quot;white&quot;)+
  scale_fill_gradient2(low=&quot;blue&quot;, high=&quot;red&quot;, mid=&quot;white&quot;, midpoint=0, limit=c(-1,1), space=&quot;Lab&quot;, name=&quot;Pearson\nCorrelation&quot;)+
  theme_bw()+
  theme(axis.text.x=element_text(angle=45, vjust=1, size=10, hjust=1))+
  coord_fixed()+
  labs(x=&quot;&quot;,y=&quot;&quot;)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-37-1.png" width="1152" /></p>
<p>√â poss√≠vel notar que existem vari√°veis explicativas correlacionadas o que indica que a presen√ßa de algumas vari√°veis pode possivelmente interferir no ajuste final do modelo linear multivariado.</p>
</div>
<div id="vari√°veis-categ√≥ricas" class="section level2">
<h2>Vari√°veis categ√≥ricas</h2>
<p>J√° a rela√ß√£o das var√°veis categ√≥ricas n√£o podem ser calculada com o coeficiente de correla√ß√£o calculado anteriormente, para avaliar como elas est√£o associadas ser√° calculado a medida de associa√ß√£o <a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V">V de Cram√©r</a>. Novamente a matrix dos resultados ser√£o novamente apresentados em um <a href="https://en.wikipedia.org/wiki/Heat_map">Heatmap</a> (ou mapa de calor ) que foi inspirado <a href="http://analysingstuffs.xyz/2017/12/01/visualizing-the-correlations-between-categorical-variables-with-r-a-cramers-v-heatmap/">neste post</a> (neste post tamb√©m √© apresentada uma fun√ß√£o para o c√°lculo da matrix, adaptei de forma que se tornasse mais geral e disponibilizei no meu github <a href="https://github.com/gomesfellipe/functions/blob/master/interaction_all.R">neste link</a>).</p>
<pre class="r"><code># Carrega funcao que calcula o V de Cramer:
devtools::source_url(&quot;https://raw.githubusercontent.com/gomesfellipe/functions/master/cv_test.R&quot;)
# Carrega a funcao que realiza as intera√ß√µes dos calculos dois a dois:
devtools::source_url(&quot;https://raw.githubusercontent.com/gomesfellipe/functions/master/interaction_all.R&quot;)</code></pre>
<p>Veja:</p>
<pre class="r"><code>cvmat &lt;- 
train %&gt;%
  select_if(~!is.numeric(.x)) %&gt;% 
  as.data.table() %&gt;%
  interaction_all(cv_test) %&gt;% 
  as_tibble() 

cvmat %&gt;% 
  ggplot( aes(variable_x, variable_y, fill=v_cramer))+
  geom_tile(color=&quot;white&quot;)+
  scale_fill_gradient2(low=&quot;blue&quot;, high=&quot;red&quot;, mid=&quot;white&quot;, midpoint=0, limit=c(-1,1), space=&quot;Lab&quot;, name=&quot;Cramer&#39;s V&quot;)+
  theme_bw()+
  theme(axis.text.x=element_text(angle=45, vjust=1, size=10, hjust=1))+
  coord_fixed()+
  labs(x=&quot;&quot;,y=&quot;&quot;)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
</div>
</div>
<div id="ajustando-modelos" class="section level1">
<h1>Ajustando modelos</h1>
<div id="arvore-de-decisao" class="section level2">
<h2>Arvore de decisao</h2>
<p>O modelo de √°rvore de decis√£o j√° foi comentado e deixei algumas refer√™ncias ao final do post portanto vejamos a seguir o ajusto no R. Segundo a <a href="https://cran.r-project.org/web/packages/rpart/rpart.pdf">documenta√ß√£o</a>:</p>
<p><code>cp</code>: par√¢metro de complexidade. No nosso caso isso significa que o <a href="https://pt.wikipedia.org/wiki/R%C2%B2"><span class="math inline">\(R^2\)</span></a> total deve aumentar em cp em cada etapa. O principal papel desse par√¢metro √© economizar tempo de computa√ß√£o removendo as divis√µes que obviamente n√£o valem a pena. Essencialmente, informamos ao programa que qualquer divis√£o que n√£o melhore o ajuste por <code>cp</code> provavelmente ser√° eliminada por <a href="https://pt.wikipedia.org/wiki/Valida%C3%A7%C3%A3o_cruzada">valida√ß√£o cruzada</a>, e que, portanto, o programa n√£o precisa busc√°-la.</p>
<p>Para pesquisa de grade existem duas maneiras de ajustar um algoritmo no pacote <code>caret</code>: permitir que o sistema fa√ßa isso automaticamente ou especificar o <code>tuneGride</code> manualmente onde cada par√¢metro do algoritmo pode ser especificado como um vetor de valores poss√≠veis. Confira o ajuste manual em R:</p>
<pre class="r"><code>set.seed(1)

control &lt;- trainControl(method = &quot;cv&quot;, number = 5,verboseIter = F)

tunegrid &lt;- expand.grid(cp=seq(0.001, 0.01, 0.001))

rpartFit2 &lt;- 
  train(y=train$SalePrice, x=train[,-1],
        method=&quot;rpart&quot;,
        trControl=control,
        tuneGrid=tunegrid,
        metric = &quot;Rsquared&quot;
  )
rpartFit2</code></pre>
<pre><code>## CART 
## 
## 1460 samples
##   28 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 1169, 1169, 1168, 1168, 1166 
## Resampling results across tuning parameters:
## 
##   cp     RMSE       Rsquared   MAE      
##   0.001  0.1918932  0.7757730  0.1386651
##   0.002  0.1943654  0.7690391  0.1410967
##   0.003  0.2016485  0.7513005  0.1457213
##   0.004  0.2029596  0.7462748  0.1457752
##   0.005  0.2098812  0.7279462  0.1534384
##   0.006  0.2090073  0.7291130  0.1539830
##   0.007  0.2110066  0.7227211  0.1544402
##   0.008  0.2120734  0.7198280  0.1555415
##   0.009  0.2142488  0.7143975  0.1570535
##   0.010  0.2148236  0.7126454  0.1575360
## 
## Rsquared was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.001.</code></pre>
<p>Podemos conferir os resultados novamente de maneira visual:</p>
<pre class="r"><code>rpart.plot(rpartFit2$finalModel, cex = 0.5)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-41-1.png" width="1200" /></p>
<p>Gerando arquivo para submiss√£o no kaggle:</p>
<pre class="r"><code>id %&gt;% cbind(predict(rpartFit2, test) %&gt;% exp) %&gt;% 
  `colnames&lt;-`(c(&quot;Id&quot;, &quot;SalePrice&quot;)) %&gt;%
  write.csv(&quot;rpartFit2.csv&quot;,row.names = F)</code></pre>
</div>
<div id="bagging" class="section level2">
<h2>Bagging</h2>
<p><a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating">‚ÄúBagging‚Äù</a> √© usado quando desejamos reduzir a varia√ß√£o de uma √°rvore de decis√£o. Ela combina o resultado de v√°rios modelos onde todas as vari√°veis s√£o considerados para divis√£o um n√≥. Em R:</p>
<pre class="r"><code>set.seed(1)

control &lt;- trainControl(method = &quot;cv&quot;, number = 5,verboseIter = F)

treebagFit &lt;- train(y=train$SalePrice, 
                    x=train[,-1], 
                    method = &quot;treebag&quot;,
                    metric = &quot;Rsquared&quot;,
                    trControl=control
)
treebagFit</code></pre>
<pre><code>## Bagged CART 
## 
## 1460 samples
##   28 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 1169, 1169, 1168, 1168, 1166 
## Resampling results:
## 
##   RMSE       Rsquared   MAE      
##   0.1831872  0.7946059  0.1288626</code></pre>
<p>Note que o <span class="math inline">\(R^2\)</span> aumentou e o <a href="https://en.wikipedia.org/wiki/Root-mean-square_deviation"><span class="math inline">\(RMSE\)</span></a> diminuiu ap√≥s o uso desta t√©cnica.</p>
<p>Resultados para enviar para o Kaggle:</p>
<pre class="r"><code>id %&gt;% cbind(predict(treebagFit, test)%&gt;% exp) %&gt;% 
  `colnames&lt;-`(c(&quot;Id&quot;, &quot;SalePrice&quot;)) %&gt;%
  write.csv(&quot;treebagFit.csv&quot;,row.names = F)</code></pre>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<p>A principal diferen√ßa entre ‚Äúbagging‚Äù e o algoritmo Random Forest √© que em <code>randomForest</code>, apenas um subconjunto de caracter√≠sticas √© selecionado aleatoriamente em cada divis√£o em uma √°rvore de decis√£o enquanto que no bagging todos os recursos s√£o usados.</p>
<p>Para pesquisa de grade especificaremos um vetor com os poss√≠veis valores, <a href="https://cran.r-project.org/web/packages/randomForest/randomForest.pdf">pois o default adotado para o par√¢metro</a> <code>mtry</code> √© <code>mtry</code> = p/3 (N√∫mero de vari√°veis amostradas aleatoriamente como candidatos em cada divis√£o), onde p √© o n√∫mero de vari√°veis e pode ser que o modelo se ajuste melhor aos dados ao utilizar outro valor.</p>
<p>Veja:</p>
<pre class="r"><code>set.seed(1)

tunegrid &lt;- expand.grid(mtry = seq(4, ncol(train) * 0.8, 2))

control &lt;- trainControl(method = &quot;cv&quot;, number = 5,verboseIter = F)

rfFit &lt;- train(SalePrice ~. ,
               data=train,
               method=&quot;rf&quot;,
               metric = &quot;Rsquared&quot;,
               tuneGrid=tunegrid,
               trControl=control
)
rfFit</code></pre>
<pre><code>## Random Forest 
## 
## 1460 samples
##   28 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 1169, 1169, 1168, 1168, 1166 
## Resampling results across tuning parameters:
## 
##   mtry  RMSE       Rsquared   MAE       
##    4    0.1455656  0.8781772  0.09755474
##    6    0.1417368  0.8817193  0.09435674
##    8    0.1405084  0.8826370  0.09350712
##   10    0.1395367  0.8834153  0.09290816
##   12    0.1385338  0.8845102  0.09181049
##   14    0.1386865  0.8840165  0.09223527
##   16    0.1381776  0.8846283  0.09155563
##   18    0.1384532  0.8837305  0.09222536
##   20    0.1380863  0.8840803  0.09173754
##   22    0.1383788  0.8835938  0.09189772
## 
## Rsquared was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 16.</code></pre>
<p>Note que o <span class="math inline">\(R^2\)</span> aumentou e o <span class="math inline">\(RMSE\)</span> apresentou resultados ainda mais satisfat√≥rios.</p>
<p>Veja visualmente a import√¢ncia de ada vari√°vel:</p>
<pre class="r"><code>randomForest::varImpPlot(rfFit$finalModel)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>Resultados para enviar para o Kaggle:</p>
<pre class="r"><code>id %&gt;% cbind(predict(rfFit, test) %&gt;% exp) %&gt;% 
  `colnames&lt;-`(c(&quot;Id&quot;, &quot;SalePrice&quot;)) %&gt;%
  write.csv(&quot;rfFit.csv&quot;,row.names = F) </code></pre>
</div>
<div id="gbm" class="section level2">
<h2>GBM</h2>
<p>Diferentemente do ‚Äúbagging‚Äù, o ‚Äúboosting‚Äù √© uma t√©cnica de ensemble (conjunto) na qual os preditores n√£o s√£o feitos independentemente, mas sequencialmente. Na imagem a seguir √© poss√≠vel ver uma representa√ß√£o visual dessa diferen√ßa:</p>
<p><img src="https://cdn-images-1.medium.com/max/1600/1*PaXJ8HCYE9r2MgiZ32TQ2A.png" /></p>
<p>A imagem foi obtida <a href="https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d">neste artigo: Gradient Boosting from scratch</a>, recomendo a leitura pois da uma boa intui√ß√£o de como o algoritmo funciona.</p>
<p>Para a pesquisa de grade vamos permitir que o sistema fa√ßa isso automaticamente configurando apenas o <code>tuneLength</code> para indicar o n√∫mero de valores diferentes para cada par√¢metro do algoritmo.</p>
<pre class="r"><code>set.seed(1)

control &lt;- trainControl(method = &quot;cv&quot;, number = 5,verboseIter = F)

gbmFit &lt;- train(SalePrice~.,data=train,
                method = &quot;gbm&quot;,
                trControl=control,
                tuneLength=5,
                metric = &quot;Rsquared&quot;,
                verbose = FALSE
)
gbmFit</code></pre>
<pre><code>## Stochastic Gradient Boosting 
## 
## 1460 samples
##   28 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 1169, 1169, 1168, 1168, 1166 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  RMSE       Rsquared   MAE       
##   1                   50      0.1736970  0.8346902  0.12145158
##   1                  100      0.1474386  0.8663694  0.10371271
##   1                  150      0.1400060  0.8775141  0.09804851
##   1                  200      0.1381902  0.8803999  0.09607709
##   1                  250      0.1375854  0.8817130  0.09502881
##   2                   50      0.1511051  0.8640075  0.10557294
##   2                  100      0.1379357  0.8815852  0.09546142
##   2                  150      0.1360260  0.8846503  0.09326628
##   2                  200      0.1355702  0.8852090  0.09248558
##   2                  250      0.1362827  0.8841734  0.09254710
##   3                   50      0.1434808  0.8743589  0.09910961
##   3                  100      0.1363881  0.8838715  0.09355652
##   3                  150      0.1346606  0.8868808  0.09163759
##   3                  200      0.1339427  0.8880370  0.09062153
##   3                  250      0.1336666  0.8886732  0.08979366
##   4                   50      0.1376575  0.8824442  0.09516571
##   4                  100      0.1334392  0.8884173  0.09192150
##   4                  150      0.1330866  0.8890336  0.09156893
##   4                  200      0.1334706  0.8886198  0.09096598
##   4                  250      0.1335809  0.8884950  0.09101981
##   5                   50      0.1384852  0.8813449  0.09535954
##   5                  100      0.1350803  0.8863344  0.09231165
##   5                  150      0.1340246  0.8878172  0.09112111
##   5                  200      0.1342892  0.8874590  0.09088714
##   5                  250      0.1349331  0.8867525  0.09104875
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## 
## Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
## Rsquared was used to select the optimal model using the largest value.
## The final values used for the model were n.trees = 150, interaction.depth =
##  4, shrinkage = 0.1 and n.minobsinnode = 10.</code></pre>
<p>Note que este foi o modelo que apresentou os melhores resultados quanto s√≥ <span class="math inline">\(R^2\)</span> e ao <span class="math inline">\(RMSE\)</span> em compara√ß√£o com os outros modelos.</p>
<p>Submiss√£o para Kaggle:</p>
<pre class="r"><code>id %&gt;% cbind(predict(gbmFit, test) %&gt;% exp) %&gt;%
  `colnames&lt;-`(c(&quot;Id&quot;, &quot;SalePrice&quot;)) %&gt;%
  write.csv(&quot;gbmFit.csv&quot;, row.names = F)</code></pre>
</div>
<div id="regress√£o-linear" class="section level2">
<h2>Regress√£o Linear</h2>
<p>Por fim faremos o ajuste de um modelo de regress√£o linear multivariado utilizando o pacote caret.</p>
<p>Utilizaremos valida√ß√£o cruzada separando nossa amostra em 5 e utilizaremos o m√©todo <code>lmStepAIC</code> que realiza a sele√ß√£o do modelo escalonado pelo crit√©rio de informa√ß√£o de Akaike - <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">AIC</a>.</p>
<pre class="r"><code>set.seed(1)

control &lt;- trainControl(method = &quot;cv&quot;, number = 5,verboseIter = F)

lmFit &lt;- train(SalePrice~.,data=train,
               method = &quot;lmStepAIC&quot;,
               trControl=control,
               metric = &quot;Rsquared&quot;,trace=F
)
lmFit</code></pre>
<pre><code>## Linear Regression with Stepwise Selection 
## 
## 1460 samples
##   28 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 1169, 1169, 1168, 1168, 1166 
## Resampling results:
## 
##   RMSE      Rsquared   MAE       
##   0.147716  0.8632513  0.09574552</code></pre>
<p>Note que o ajuste do modelo se apresenta de maneira satisfat√≥ria com <span class="math inline">\(R^2\)</span> e <span class="math inline">\(RMSE\)</span> semelhantes aos modelos de <code>bagging</code> e <code>boosting</code> e al√©m disso, diferente dos modelos baseados em √°rvore, com este ajuste √© poss√≠vel notar a signific√¢ncia estat√≠stica de cada par√¢metro ajustado, o que possibilita tanto o uso tanto como modelo preditivo quanto como modelo descritivo. Veja:</p>
<pre class="r"><code>ggcoef(
  lmFit$finalModel,                      #O modelo a ser conferido
  vline_color = &quot;red&quot;,          #Reta em zero  
  errorbar_color = &quot;blue&quot;,      #Cor da barra de erros
  errorbar_height = .25,
  shape = 18,                   #Altera o formato dos pontos centrais
  size=2,                      #Altera o tamanho do ponto
  color=&quot;black&quot;,
  exclude_intercept = TRUE,                #Altera a cor do ponto
  mapping = aes(x = estimate, y = term, size = p.value))+
  scale_size_continuous(trans = &quot;reverse&quot;)+ #Essa linha faz com que inverta o tamanho
  theme_bw()</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>Note que o intercepto <span class="math inline">\(\beta_0\)</span> foi retirado da imagem pois √© muito superior aos demais coeficientes. Note tamb√©m que <span class="math inline">\(\beta_i\)</span> informa qu√£o sens√≠vel √© <span class="math inline">\(y\)</span>, no caso <code>log(SalePrice)</code> √†s varia√ß√µes de cara umas das <span class="math inline">\(x_{i,j}\)</span> vari√°veis explicativas. Mais concretamente, se <span class="math inline">\(x_{i,j}\)</span> aumenta em uma unidade, o valor de <span class="math inline">\(y\)</span> varia em <span class="math inline">\(\beta_1\)</span> unidades.</p>
<p>Uma r√°pida <a href="http://www.portalaction.com.br/analise-de-regressao/analise-dos-residuos">An√°lise dos Res√≠duos</a>:</p>
<pre class="r"><code>lmFit$finalModel %&gt;% 
  autoplot(which = 1:2) + 
  theme_bw()</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-52-1.png" width="1500" /></p>
<p>√â poss√≠vel notar que parece haver alguns outliers em ambas as figuras. Na primeira √© poss√≠vel notar uma nuvem de pontos aleat√≥rios em torno de zero por√©m na segunda figura nota-se que alguns valores n√£o est√£o de acordo com os quantils te√≥ricos de uma distribui√ß√£o normal, o que pode prejudicar nossa interpreta√ß√£o dos coeficientes do modelo. Vamos encerrar o modelo por aqui mesmo e ver como ele se sai na competi√ß√£o do Kaggle, preparando a submiss√£o:</p>
<pre class="r"><code>id %&gt;% cbind(predict(lmFit, test) %&gt;% exp ) %&gt;% 
  `colnames&lt;-`(c(&quot;Id&quot;, &quot;SalePrice&quot;)) %&gt;%
  write.csv(&quot;lmFit.csv&quot;,row.names = F)</code></pre>
<p>O score obtido com esta submiss√£o no Kaggle foi muito pr√≥ximo dos modelos baseados e √°rvore e o tempo computacional para este ajuste foi bem menor.</p>
</div>
<div id="comparando-ajustes" class="section level2">
<h2>Comparando ajustes</h2>
<p>Vejamos a seguir uma compara√ß√£o entre estes modelos com as fun√ß√µes fornecidas pelo pacote `caret:.</p>
<pre class="r"><code>resamps &lt;- resamples(list(rpart = rpartFit2,
                          treebag = treebagFit,
                          rf = rfFit,
                          gbm = gbmFit,
                          lm = lmFit 
                          )) 
bwplot(resamps)</code></pre>
<p><img src="/post/2018-08-31-modelos-em-arvore/modelos-em-arvore_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<p>Com este gr√°fico √© poss√≠vel notar que o modelo de regress√£o linear m√∫ltipla apresentou resultados semelhantes aos de bagging e boosting.</p>
<p>√â importante frisar que a maneira como as vari√°veis foram selecionadas para o modelo de regress√£o linear m√∫ltipla atrav√©s da import√¢ncia das vari√°veis obtida com o modelo randomForest n√£o √© um padr√£o e existem diversos outros modos estat√≠sticos de se de determinar a signific√¢ncia e a rela√ß√£o das vari√°veis para o modelo.</p>
<p>Um poss√≠vel problema neste m√©todo √© que n√£o detecta a multicolinearidade, que ocorre quando as vari√°veis explicativas est√£o fortemente correlacionadas entre si e a an√°lise de regress√£o linear pode ficar confusa e desprovida de significado, pois h√° dificuldade em distinguir o efeito de uma ou outra vari√°vel explicativa sobre a vari√°vel resposta <span class="math inline">\(Y\)</span> devido √† vari√¢ncias muito elevadas ou sinais inconsistentes.</p>
<p>Essa proposta de aprender se divertindo e de maneira produtiva me deixa muito empolgado, espero que tenham se divertido como eu me diverti fazendo este post!</p>
</div>
</div>
<div id="refer√™ncias" class="section level1">
<h1>Refer√™ncias:</h1>
<ul>
<li><a href="https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-r">DataCamp Course:Machine Learning with Tree-Based Models in R</a></li>
<li><a href="https://tinyurl.com/y796aa4t">Data Science <em>for</em> Business</a></li>
<li><a href="https://lethalbrains.com/learn-ml-algorithms-by-coding-decision-trees-439ac503c9a4">Learn ML Algorithms by coding: Decision Trees</a></li>
<li><a href="https://www.datacamp.com/community/tutorials/decision-trees-R">DataCamp Tutorials: Decision Trees in R</a></li>
<li><a href="https://topepo.github.io/caret/">The caret Package - Max Kuhn</a></li>
<li><a href="https://www.vooo.pro/insights/um-tutorial-completo-sobre-a-modelagem-baseada-em-tree-arvore-do-zero-em-r-python/">Um tutorial completo sobre modelagem baseada em √°rvores de decis√£o (c√≥digos R e Python)</a></li>
<li><a href="https://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/">Tuning Machine Learning Models Using the Caret R Package</a></li>
<li><a href="https://medium.com/mlreview/gradient-boosting-from-scratch-1e317ae4587d">Gradient Boosting from scratch</a></li>
<li><a href="https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/">Tune Machine Learning Algorithms in R (random forest case study)</a></li>
<li><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/cc_manual.htm">Random Forests - Leo Breiman and Adele Cutler</a></li>
<li><a href="https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf">An Introduction to Recursive Partitioning Using the RPART Routines - CRAN</a></li>
</ul>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2018-08-31-modelos-em-arvore/modelos-em-arvore/">Um estudo sobre modelos de aprendizagem baseados em √°rvores com desafio do Kaggle</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Analise Explorat√≥ria</category>
      <category>Aprendizado Supervisionado</category>
      <category>Data mining</category>
      <category>Estatistica</category>
      <category>Machine Learning</category>
      <category>Pr√°tica</category>
      <category>Probabilidade</category>
      <category>R</category>
      <category>modelo baseado em arvores</category>
      <category>kaggle</category>
      <category>Regress√£o</category>
      <category domain="tag">Data Mining</category>
      <category domain="tag">Estatistica</category>
      <category domain="tag">gomesfellipe</category>
      <category domain="tag">kaggle</category>
      <category domain="tag">Correlacoes</category>
      <category domain="tag">modelagem</category>
      <category domain="tag">modelagem estatistica</category>
      <category domain="tag">Pr√°tica</category>
      <category domain="tag">R</category>
      <category domain="tag">regression</category>
      <category domain="tag">caret</category>
      <category domain="tag">xgboost</category>
      <category domain="tag">random forest</category>
      <category domain="tag">decisiontree</category>
    </item>
  </channel>
</rss>