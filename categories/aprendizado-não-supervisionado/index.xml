&lt;?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Aprendizado Não Supervisionado on Fellipe Gomes - Data Science Blog</title>
    <link>https://gomesfellipe.github.io/categories/aprendizado-n%C3%A3o-supervisionado/</link>
    <description>Últimos posts sobre Data Science, Machine Learning e R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <managingEditor>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</managingEditor>
    <webMaster>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</webMaster>
    <lastBuildDate>Sat, 28 Jul 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://gomesfellipe.github.io/categories/aprendizado-n%C3%A3o-supervisionado/" rel="self" type="application/rss+xml" />
    <item>
      <title>modelo bayesiano do zero</title>
      <link>https://gomesfellipe.github.io/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero/</link>
      <pubDate>Sat, 28 Jul 2018 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero/</guid>
      <description>Um pouco sobre as duas grandes escolas de inferência, contas e implementação de um modelo linear bayesiano na mão para dados simulados e para dados reais</description>
      <content:encoded>&lt;![CDATA[
        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/plotly-binding/plotly.js"></script>
<script src="/rmarkdown-libs/typedarray/typedarray.min.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>
<link href="/rmarkdown-libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="/rmarkdown-libs/plotly-main/plotly-latest.min.js"></script>


<div id="modelagem-estatística-e-as-duas-grandes-escolas-de-inferência" class="section level1">
<h1>Modelagem estatística e as duas grandes escolas de inferência</h1>
<p>Através da modelagem estatística é possível tomar decisões sobre diversos assuntos de interesse como por exemplo na análise de risco de crédito, previsões de quantidade de chuva em um dado local, estimativas de erros ou falhas de um novo produto ou serviço além de diversas áreas como na Educação, Economia, nas Ciências Sociais, Saúde etc.</p>
<p>Muitas vezes os parâmetros das distribuições em estudo podem ser desconhecidos e existe o desejo de se inferir sobre eles. Existem duas grandes escolas de inferência: a clássica e a bayesiana. A clássica trata esses parâmetros como quantidades fixas e não atribui distribuição a eles, a estimação desses parâmetros é dada através da função de verossimilhança, enquanto que na escola bayesiana atribui-se uma distribuição, chamada de distribuição a priori, ao conjunto de parâmetros desconhecidos quantificando a sua crença sobre esse conjunto e a estimação dos parâmetros é dada através da distribuição à posteriori, que é proporcional ao produto da função de verossimilhança com a distribuição a priori.</p>
<p>O interesse pela modelagem estatística através da abordagem bayesiana surgiu a partir de um projeto de iniciação científica quando cursava o 6º período do curso de Graduação em Estatística que tinha como objetivo o cálculo e apresentação de estatísticas descritivas para ajudar uma pesquisadora. Após obter os resultados da análise exploratória e descritiva, notei, junto com meu orientador, que havia possibilidade de dar continuidade ao estudo a partir de uma abordagem estatística mais elaborada. Sendo assim, outro projeto de iniciação científica foi iniciado em seguida com a finalidade de me preparar para utilizar um modelo linear hierárquico bayesiano sob os dados disponibilizados pela pesquisadora em minha monografia.</p>
<p>Caso tenha interesse em conferir o projeto com o estudo sobre modelos hierárquicos bayesianos, disponibilizei os resultados e os códigos em meu github <a href="https://github.com/gomesfellipe/projeto_modelos_hierarquicos_bayesianos">neste repositório</a>. Neste post farei uma breve introdução sobre o ajuste de um modelo linear bayesiano simples e os resultados obtidos (utilizando uma distribuição a priori não informativa). Os resultados obtidos serão comparados com os resultados obtidos com o ajuste de um modelo de regressão linear através da abordagem clássica.</p>
<div id="distribuição-a-priori" class="section level2">
<h2>Distribuição a priori</h2>
<p>Para o estudo, optou-se pela utilização de valores elevados para variância a priori (também consideradas como “não informativas”, fazendo uma analogia à modelos clássicos) obtendo ajustes que atribuem maior importância à informação provinda da amostra.</p>
<p>Portanto com valores elevados para variância da distribuição a priori (consideradas como “não informativas”) foram obtida a distribuição a posteriori de um parâmetro <span class="math inline">\(\theta\)</span> que contém toda a informação probabilística a respeito deste parâmetro e quando a forma analítica dessa distribuição é conhecida o gráfico da <a href="https://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_densidade">fdp</a> pode ilustrar o comportamento probabilístico do parâmetro de interesse e auxiliar em alguma tomada de decisão, porém, quando a forma analítica não é conhecida ou é muito custosa de ser obtida, pode-se recorrer a métodos de simulação tais como os métodos MCMC.</p>
</div>
<div id="amostrador-de-gibbs---método-mcmc" class="section level2">
<h2>Amostrador de Gibbs - método MCMC</h2>
<p>Com os avanços dos métodos de MCMC, surgiu o amostrador de Gibbs, proposto por <span class="citation">@GemanGeman</span> e tornou-se popular por <span class="citation">@GelfandSmith</span>, falo um pouco mais sobre o algoritmo no <a href="https://github.com/gomesfellipe/projeto_modelos_hierarquicos_bayesianos/blob/master/texto.pdf">texto do projeto</a>.</p>
<p>Como a convergência ocorre após o aquecimento (ou burn-in), é comum usar os valores de <span class="math inline">\(\theta^{(a)}\)</span>, <span class="math inline">\(\theta^{(a+t)}\)</span>, <span class="math inline">\(\theta^{(a+2t)}\)</span>,… para compor a amostra de <span class="math inline">\(\theta\)</span>, sendo <span class="math inline">\(a-1\)</span> o número de iterações iniciais do aquecimento e <span class="math inline">\(t\)</span> o espaçamento utilizado para diminuir a autocorrelação dos parâmetros. Maiores detalhes podem ser vistos em <span class="citation">@Gamerman06</span>.</p>
</div>
</div>
<div id="ao-que-interessa" class="section level1">
<h1>Ao que interessa</h1>
<p>O objetivo deste post é apresentar e comparar os resultados do ajuste de um modelo linear bayesiano simples utilizando uma distribuição a priori não informativa com o modelo de regressão linear simples para dados simulados e para dados reais.</p>
<p>Diversas funções foram criadas ao longo o estudo para conferir o comportamento das cadeias geradas e os resultados do ajuste do modelo, aproveitarei essas funções para este post importando do <a href="https://github.com/gomesfellipe/projeto_modelos_hierarquicos_bayesianos/blob/master/dependencies.R">repositório no github</a> da seguinte maneira:</p>
<pre class="r"><code>path_to_dep &lt;- &quot;https://raw.githubusercontent.com/gomesfellipe/projeto_modelos_hierarquicos_bayesianos/master/dependencies.R&quot;
devtools::source_url(path_to_dep, encoding=&quot;UTF-8&quot;)</code></pre>
</div>
<div id="ajuste-do-modelo-para-dados-simulados" class="section level1">
<h1>Ajuste do modelo para dados simulados</h1>
<p>Suponha então um exemplo em que a população de interesse tenha distribuição normal com média <span class="math inline">\(\beta_0 + \beta_1 X\)</span>, sendo <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> desconhecidos e variância <span class="math inline">\(\sigma^2\)</span> desconhecida. Seja <span class="math inline">\(\tau=\frac{1}{\sigma^2}\)</span> o parâmetro chamado de precisão.</p>
<p>O parâmetro <span class="math inline">\(\beta_0\)</span> é conhecido como intercepto ou coeficiente linear e o <span class="math inline">\(\beta_1\)</span> como coeficiente angular. Além disso, suponha que as unidades dessa população sejam iid. Dessa forma, tem-se que as unidades dessa população tem a seguinte distribuição:</p>
<p><span class="math display">\[
Y_i \stackrel{iid}{\sim} N(\beta_0 + \beta_1 X_i,\frac{1}{\tau}), 
\]</span></p>
<p>onde <span class="math inline">\(i=1,...,N\)</span>.</p>
<p>Para o estudo do modelo primeiramente foi utilizado um conjunto de dados simulados utilizando uma amostra de tamanho <span class="math inline">\(N=1000\)</span> e com os seguintes parâmetros “desconhecidos” dos quais desejamos estimar: <span class="math inline">\(\beta_0 = 1\)</span>, <span class="math inline">\(\beta_1 = 0,5\)</span>, <span class="math inline">\(\tau = 2\)</span>. A amostra será simulada segundo a variável aleatória: <span class="math inline">\(X_i ~ N(0,1)\)</span> e em seguida os parâmetros deste modelo, denotados por <span class="math inline">\(\theta = (\beta_0, \beta_1, \tau)\)</span> foram estimados usando o paradigma Bayesiano.</p>
<div id="gerando-a-amostra" class="section level2">
<h2>Gerando a amostra</h2>
<p>A amostra que foi simulada foi obtida da seguinte maneira:</p>
<pre class="r"><code># Amostra que sera utilizada:

set.seed(12)
n   &lt;- 1000                 # N=1000
b0  &lt;- 1                    # \beta_0 = 1
b1  &lt;- 0.5                  # \beta_1 = 0,5
tau &lt;- 2                    # \tau = 2 e 
x   &lt;- rnorm(n)             # X_i ~ N(0,1), logo:
y   &lt;- b0 + b1 * x + rnorm(n,0,sqrt(1/tau))</code></pre>
<p>Obtendo-se uma amostra de tamanho <span class="math inline">\(n\)</span>, pode-se inferir sob os parâmetros desconhecidos <span class="math inline">\(\theta = (\beta_0, \beta_1, \tau)\)</span> através da distribuição a posteriori e para obter essa distribuição faz-se necessário calcular a função de verossimilhança, que pode ser obtida da seguinte forma:</p>
<p><span class="math display">\[
p(y| \beta_0, \beta_1 , \tau) =\prod^n_{i=1} p(y_i | \beta_0, \beta_1, \tau )  
\]</span></p>
<p>portanto</p>
<p><span class="math display">\[
p(y| \beta_0, \beta_1 , \tau) = \prod_{i=1}^n \frac{ \sqrt{\tau} }{ \sqrt{2\pi} } exp { - \frac{\tau}{2} ( y_i - \beta_0 - \beta_1 x_i )^2 }
\]</span></p>
<p>onde <span class="math inline">\(y = (y_1, ..., y_n)\)</span> é a amostra coletada. O valor p para o teste de Shapiro para conferir a suposição de normalidade da variável resposta foi de 0.6181791 enquanto que o valor p para conferir a normalidade da variável explicativa foi de 0.7413229.</p>
</div>
<div id="distribuição-a-priori-1" class="section level2">
<h2>Distribuição a priori</h2>
<p>Durante o estudo diversos valores os parâmetros a priori foram selecionados para que fosse possível avaliar a sensibilidade da qualidade da escolha da distribuição priori, aqui será apresentado os resultados obtidos com valores elevados para variância a priori (também consideradas como “não informativas”, fazendo uma analogia à modelos clássicos) que ajusta o modelo atribuindo maior importância à informação provinda da amostra.</p>
<p>Considere a priori que os parâmetros sejam independentes e que</p>
<p><span class="math display">\[
\beta_0 \sim N(m_0,\sigma_0^2),  \\
\beta_1 \sim N(m_1,\sigma_1^2) \mbox{ e }  \\
\tau    \sim G(a,b).
\]</span></p>
<p>Portanto, para a estimação foram utilizados os seguintes hiperparâmetros : <span class="math inline">\(m_0 = m_1 = 0\)</span>, <span class="math inline">\(\sigma_0^2 = \sigma_1^2 = 100\)</span>, <span class="math inline">\(a=0,1\)</span> e <span class="math inline">\(b=0,1\)</span></p>
<p>No R:</p>
<pre class="r"><code>#Parametros para b0 ~ N(mu0, sig0)
mu0 &lt;-  0
sig0 &lt;-  1000

#Parametros para b1 ~ N(mu1, sig1)
mu1 &lt;-  0
sig1 &lt;-  1000

#Parametros para tau ~ G(a,b)
a &lt;-  0.1
b &lt;-  0.1</code></pre>
<p>Dessa forma, tem-se que a distribuição conjunta a priori possui a seguinte forma:</p>
<p><span class="math display">\[
 p(\beta_0, \beta_1 , \tau) \propto exp\Big\{-\frac{1}{2\sigma_0^2}( \beta_0 - m_0)^2\Big\} exp\Big\{-\frac{1}{2\sigma_1^2}( \beta_1 - m_1)^2\Big\} \tau^{a-1}exp \{-b \tau\}.
\]</span></p>
</div>
<div id="distribuição-a-posteriori" class="section level2">
<h2>Distribuição a posteriori</h2>
<p>Combinando a função de verossimilhança com a distribuição a priori, obtêm-se a distribuição a posteriori que é proporcional a:</p>
<p><span class="math display">\[
p(\beta_0, \beta_1 , \tau|y) \propto \tau^{\frac{n}{2}+a-1} exp \left\{ -\frac{\tau}{2} \sum^n_{i=1} (y_i - \beta_0 - \beta_1 x_i)^2 - b\tau  - \frac{1}{2\sigma_0^2}(\beta_0-m_0)^2  \right\} \times   exp\left\{- \frac{1}{2\sigma_1^2}(\beta_1-m_1)^2  \right\} . 
\]</span></p>
<p>Note que essa distribuição é multivariada e não possui forma analítica conhecida. Sendo assim, recorre-se aos métodos de MCMC para se obter amostras dessa distribuição. E então faz-se necessário obter as DCCP de <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> e <span class="math inline">\(\tau\)</span>.</p>
</div>
<div id="implementando-o-amostrador-de-gibbs" class="section level2">
<h2>Implementando o amostrador de Gibbs</h2>
<p>O tamanho da cadeia foi de 30000 simulações e o <em>burn-in</em> (ou amostra de aquecimento) utilizado considerada após o ajuste foi de 15000. no R:</p>
<pre class="r"><code>nsim           &lt;-  3*10000
burnin         &lt;-  nsim / 2 
cadeia.b0      &lt;-  rep(0,nsim)
cadeia.b1      &lt;-  rep(0,nsim)
cadeia.tau     &lt;-  rep(0,nsim)

# Chutes iniciais: 
cadeia.b0[1]    &lt;-  0
cadeia.b1[1]    &lt;-  0
cadeia.tau[1]   &lt;-  1</code></pre>
<div id="calculos-para-implementar-o-algoritimo-na-mão" class="section level3">
<h3>Calculos para implementar o algoritimo na mão</h3>
<p>Para a implementação do algoritmo, fez-se necessário o cálculo das distribuições condicionais completas a posteriori (DCCP), primeiramente veja os resultados obtidos para <span class="math inline">\(\tau\)</span>:</p>
<ul>
<li>DCCP de <span class="math inline">\(\tau\)</span>:</li>
</ul>
<p><span class="math display">\[
\tau|y_1, ...,y_n,\beta_0, \beta_1 \sim Gama ( \frac{n}{2}+a,b+\frac{1}{2} \sum^n_{i=1}(y_i-\beta_0-\beta_1 x_i)^2 ) 
\]</span></p>
<p>Em seguida, veja o resultado obtido para <span class="math inline">\(\beta_0\)</span>, o coeficiente linear da reta, isto é, a altura em que a reta de regressão intercepta o eixo dos <span class="math inline">\(Y\)</span>’s:</p>
<ul>
<li>DCCP de <span class="math inline">\(\beta_0\)</span>:</li>
</ul>
<p><span class="math display">\[
\beta_0 | y_1,...,y_n , \tau,\beta_1 \sim N(\dfrac{(\tau\sum^n_{i=1}y_i - \tau\beta_1\sum^n_{i=1}x_i  +\frac{m_0}{\sigma_0^2})}{ \tau n + \frac{1}{\sigma_0^2}},  (n\tau +   \frac{1}{\sigma_0^2} )^{-1})
\]</span></p>
<p>Por fim, veja o resultado obtido para <span class="math inline">\(\beta_1\)</span>, é o coeficiente angular da reta, ou seja, é o a variação esperada na variável <span class="math inline">\(Y\)</span> quando a variável explicativa é acrescida de 1 unidade:</p>
<ul>
<li>DCCP de <span class="math inline">\(\beta_1\)</span>:</li>
</ul>
<p><span class="math display">\[
\beta_1 | y_1,...,y_n , \tau,\beta_0 \sim N(\frac{\tau\sum^n_{i=1}x_i y_i  - \tau\beta_0\sum^n_{i=1}x_i + \frac{m_1}{\sigma_1^2}}{\tau \sum^n_{i=1}x_i^2 + \frac{1}{\sigma_1^2}}, ( \tau \sum^n_{i=1}x_i^2 + \frac{1}{\sigma_1^2} )^{-1})
\]</span></p>
<p>Agora que todas as distribuições condicionais completas estão calculadas o algorítimo já pode ser implementado, no R foi feito da seguinte maneira: (note que as linhas que foram comentadas executariam uma barra de carregamento, com ilustrado em seguida)</p>
<pre class="r"><code># pb &lt;- txtProgressBar(min = 0, max = nsim, style = 3) # iniciando barra de processo
for (k in 2:nsim){
  
  #Cadeia tau
  cadeia.tau[k]   &lt;-  rgamma(1, (n/2) + a, b + (sum((y - cadeia.b0[k-1] - (cadeia.b1[k-1]*x))^2)/2))
  
  # Cadeia B0
  c0              &lt;-  (n*cadeia.tau[k]) + (1/sig0)
  m0              &lt;-  (cadeia.tau[k]*sum(y) - (cadeia.tau[k]*cadeia.b1[k-1]*sum(x)) + (mu0/sig0))/c0
  cadeia.b0[k]    &lt;-  rnorm(1, m0, 1/sqrt(c0))
  
  # Cadeia B1
  c1              &lt;-   (sum(x^2)*cadeia.tau[k]) + (1/sig1)
  m1              &lt;-   ((cadeia.tau[k]*sum(x*y)) - (cadeia.tau[k]*cadeia.b0[k]*sum(x)) + (mu1/sig1))/c1
  cadeia.b1[k]    &lt;-   rnorm(1, m1, 1/sqrt(c1))
  
  # setTxtProgressBar(pb, k)
  
}# ;close(pb) #Encerrando barra de processo</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/loading.png" /></p>
</div>
<div id="resultados-da-cadeia" class="section level3">
<h3>Resultados da cadeia</h3>
<p>A seguir definiremos a variável <code>inds</code> que indica os valores após a amostra de aquecimento (ou <em>burn-in</em>), a variável <code>real</code> que contém os valores reais utilizados para gerar a amostra para conferir se o modelo foi capaz de recuperá-los, os nomes dos parâmetros e os resultados das cadeias foram agregados em uma matriz:</p>
<pre class="r"><code># Juntando resultados:
inds    &lt;- seq(burnin, nsim) # Definindo os indices
real    &lt;- c(b0, b1, tau)
name    &lt;- c(expression(beta[0]), expression(beta[1]), expression(tau))
results &lt;- cbind(cadeia.b0, cadeia.b1, cadeia.tau) %&gt;% as.data.frame() %&gt;% .[inds, ] %T&gt;% head</code></pre>
<div id="histograma-e-densidade" class="section level4">
<h4>Histograma e densidade</h4>
<p>A figura abaixo apresenta os histogramas junto com as densidades de três cadeias obtidas ao se inicializar o amostrador em pontos diferentes de todos os parâmetros contidos em <span class="math inline">\(\theta\)</span> e uma linha vermelha indicará o valor do real parâmetro utilizado para estimar a cadeia.</p>
<pre class="r"><code>g1 &lt;- hist_den(results[,1],name = name[1], p = real[1])
g2 &lt;- hist_den(results[,2],name = name[2], p = real[2])
g3 &lt;- hist_den(results[,3],name = name[3], p = real[3])
grid.arrange(g1,g2,g3,ncol=1)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="cadeia" class="section level4">
<h4>Cadeia</h4>
<p>A figura abaixo apresenta os traços das cadeias dos parâmetros amostrados exibindo o intervalo de credibilidade com a linha pontilhada em azul e o valor verdadeiro do parâmetro em vermelho. Note que há indícios de convergência.</p>
<pre class="r"><code># Cadeia
cadeia(results, name, real)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>é possível notar que todos os intervalos de credibilidade contêm o parâmetro populacional real utilizado para gerar a amostra.</p>
</div>
<div id="autocorrelação" class="section level4">
<h4>Autocorrelação</h4>
<p>A figura abaixo apresenta os gráficos de autocorrelação, que indicam se houve a influência dos “valores vizinhos” dos parâmetros amostrados. Note que parece haver independência entre as interações.</p>
<pre class="r"><code># ACF
FAC(results)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>é possível notar que nenhuma das cadeias apresentaram estimativas autocorrelacionada</p>
</div>
<div id="estimativas" class="section level4">
<h4>Estimativas</h4>
<p>Agora que já foi verificado que a cadeia se comportou de maneira satisfatória, veja os resultados obtidos sobre as estimativas dos parâmetros através do algoritmo. apresenta os resumos a posteriori dos parâmetros amostrados.</p>
<pre class="r"><code>coef &lt;- coeficientes(results, real = real) %&gt;% as.data.frame()

tabela_coeficientes(coef)</code></pre>
<div id="htmlwidget-1" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"visdat":{"11b9832b6bfa0":["function () ","plotlyVisDat"]},"cur_data":"11b9832b6bfa0","attrs":{"11b9832b6bfa0":{"columnorder":[1,2,3,4,5],"columnwidth":[80,80,80,80,80],"header":{"values":["Média","Desv. Pad.","IC inf","IC sup","Real"],"line":{"color":"#506784"},"fill":{"color":"#1F8FFFB4"},"align":["center","center","center","center","center"],"font":{"color":"white","size":15},"height":40},"cells":{"values":[[1.0244,0.4933,1.9001],[0.023,0.0241,0.085],[0.9792,0.4464,1.7371],[1.0697,0.5409,2.0695],[1,0.5,2]],"line":{"color":"#506784"},"fill":{"color":["#1F8FFF58","white","white","white","#1F8FFF58"]},"align":["center","center","center","center","center"],"font":{"color":["white","#506784","#506784","#506784","white"],"size":12},"height":30},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"table"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"hovermode":"closest","showlegend":false},"source":"A","config":{"showSendToCloud":false},"data":[{"columnorder":[1,2,3,4,5],"columnwidth":[80,80,80,80,80],"header":{"values":["Média","Desv. Pad.","IC inf","IC sup","Real"],"line":{"color":"#506784"},"fill":{"color":"#1F8FFFB4"},"align":["center","center","center","center","center"],"font":{"color":"white","size":15},"height":40},"cells":{"values":[[1.0244,0.4933,1.9001],[0.023,0.0241,0.085],[0.9792,0.4464,1.7371],[1.0697,0.5409,2.0695],[1,0.5,2]],"line":{"color":"#506784"},"fill":{"color":["#1F8FFF58","white","white","white","#1F8FFF58"]},"align":["center","center","center","center","center"],"font":{"color":["white","#506784","#506784","#506784","white"],"size":12},"height":30},"type":"table","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>Como se trata de uma amostra simulada é possível comparar as estimativas com os valores reais que geraram a amostra e os valores estão muito próximos da média (todos eles estão incluídos no intervalo de credibilidade).</p>
</div>
</div>
<div id="comparando-com-o-modelo-linear-clássico" class="section level3">
<h3>Comparando com o modelo linear clássico</h3>
<p>Agora que os resultados sob o paradigma bayesiano já foram conferidos será ajustado um modelo de regressão linear simples pelo método dos mínimos quadrados através da função <code>lm()</code> sob o paradigma clássico para comparar com os resultados de um modelo de regressão linear simples sob o paradigma bayesiano utilizando os resultados calculados.</p>
<pre class="r"><code># Reta do modelo classico
plot(x, y)
modelo.classico &lt;- lm(y ~ 1 + x)
a.classico      &lt;- modelo.classico$coefficients[1]
b.classico      &lt;- modelo.classico$coefficients[2]
abline(a        &lt;- a.classico, b = b.classico, col = &quot;blue&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>O modelo estimado para estes dados sob o paradigma da inferência clássica foi o seguinte: <span class="math inline">\(\hat{y} = 1.0245 x + 0,4933\)</span>, o que mostra que as estimativas de <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> foram muito parecidas com as estimativas sob o paradigma da inferência bayesiana.</p>
<pre class="r"><code># Reta do modelo bayesiano
plot(x, y)
a.bayes  &lt;-  mean(results[, 1])
b.bayes  &lt;-  mean(results[, 2])
abline(a = a.bayes, b = b.bayes, col = &quot;red&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>A figura apresenta o gráfico de dispersão entre as variáveis da amostra simulada e as retas dos ajustes de ambos os modelos:</p>
<pre class="r"><code>library(stringr)
library(ggplot2)
library(ggExtra)

# Texto da imagem
text.classico &lt;- str_c(&quot;Modelo Classico: &quot;,&quot;y = &quot;,round(a.classico,4),&quot; x + &quot;,round(b.classico,4))
text.bayes    &lt;- str_c(&quot;Modelo Bayesiano: &quot;,&quot;y = &quot;,round(a.bayes,4),&quot; x + &quot;,round(b.bayes,4))

# Gerando o e ambos:
cbind(y, x) %&gt;%
  as.data.frame %&gt;%
    ggplot(aes(y = y, x = x)) +
    geom_point() +
    geom_smooth(method = &quot;lm&quot;, se = F, col = &quot;red&quot;) +
    theme_classic() +
    geom_abline(slope = b.bayes,
    intercept = a.bayes,
    col = &quot;blue&quot;) +
    labs(title = &quot;&quot;,
    x = &quot;Covariável&quot;,
    y = &quot;Reposta&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Agora que os resultados no algoritmo já foram conferidos e avaliados de maneira satisfatória utilizando os dados simulados, é a vez de fazer o ajuste para dados reais.</p>
</div>
</div>
</div>
<div id="ajuste-do-modelo-para-dados-reais" class="section level1">
<h1>Ajuste do modelo para dados reais</h1>
<p>O conjunto de dados que será utilizado como exemplo foi disponibilizado por <span class="citation">@Ezekiel_cars</span> e hoje faz parte do conjunto de banco de dados nativos do R (a base de dados pode ser obtida ao escrever <code>cars</code> no console). Os dados informam a velocidade dos carros e as distâncias tomadas para parar, esses dados foram registrados na década de 1920 e são de grande utilidade didática até os dias de hoje.</p>
<p>Considere que deseja-se modelar a velocidade dos carros de acordo com as distâncias tomadas para parar, portanto a variável resposta será a velocidade e a variável explicativa do modelo será a distância tomada para parar.</p>
<div id="amostra-utilizada" class="section level2">
<h2>Amostra utilizada</h2>
<pre class="r"><code>y    &lt;-  cars$speed
x    &lt;-  cars$dist
n    &lt;-  nrow(cars)</code></pre>
<p>o valor p para o teste de Shapiro para conferir a suposição de normalidade da variável resposta foi de 0.4576319 enquanto que o valor p para conferir a normalidade da variável explicativa foi de 0.0390997</p>
</div>
<div id="distribuição-a-priori-2" class="section level2">
<h2>Distribuição a priori</h2>
<p>Serão utilizados os mesmos valores que foram propostos na simulação como hiperparametros e chutes iniciais para a cadeia, o código usado foi exatamente o mesmo.</p>
</div>
<div id="resultados-da-cadeia-1" class="section level2">
<h2>Resultados da cadeia</h2>
<p>Definiremos novamente a variável <code>inds</code> que indica os valores após a amostra de aquecimento (ou <em>burn-in</em>), desta vez não haverá a variável <code>real</code> pois não conhecemos os valores reais utilizados para gerar a amostra para conferir se o modelo foi capaz de recuperá-los. Desta vez utilizaremos a variável <code>classico</code>, que guarda os valores obtidos com o ajuste do modelo linear pela abordagem clássica.</p>
<pre class="r"><code># Juntando resultados:
inds     &lt;- seq(burnin, nsim) # Definindo os indices
results  &lt;- cbind(cadeia.b0, cadeia.b1, cadeia.tau) %&gt;% as.data.frame() %&gt;% .[inds, ]
classico &lt;- c(coefficients(lm(cars)), 1 / var(lm(cars)$residuals))
name     &lt;- c(expression(beta[0]), expression(beta[1]), expression(tau))</code></pre>
<div id="histograma-e-densidade-1" class="section level4">
<h4>Histograma e densidade</h4>
<p>A figura abaixo exibe os histogramas com as densidades de três cadeias obtidas ao se iniciar o amostrador em pontos diferentes de todos os parâmetros <span class="math inline">\(\theta\)</span> mas dessa vez sem a linha vermelha que indicava o valor do parâmetro real pois agora ele é desconhecido.</p>
<pre class="r"><code>g1 &lt;- hist_den(results[, 1], name = name[1])
g2 &lt;- hist_den(results[, 2], name = name[2])
g3 &lt;- hist_den(results[, 3], name = name[3])
grid.arrange(g1, g2, g3, ncol = 1)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Nota-se que ambas as cadeias convergiram uma mesma distribuição e que as últimas três cadeias apresentaram valores próximos.</p>
</div>
<div id="cadeias" class="section level4">
<h4>Cadeias</h4>
<p>A figura abaixo apresenta os traços das cadeias dos parâmetros amostrados. Note que há indícios de convergência.</p>
<pre class="r"><code>cadeia(results,name)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
</div>
<div id="autocorrelação-1" class="section level4">
<h4>Autocorrelação</h4>
<p>A Figura abaixo apresenta os gráficos de autocorrelação dos parâmetros amostrados.</p>
<pre class="r"><code>FAC(results)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>É possível notar que apenas nas primeiras defasagens das cadeias das estimativas para os parâmetros <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> se apresentaram de forma autocorrelacionada e que a partir dessa defasagem o gráfico de autocorrelação se apresentou de forma desejável.</p>
</div>
<div id="estimativas-1" class="section level4">
<h4>Estimativas</h4>
<p>Como todas as características da cadeia gerada foram avaliadas de maneira satisfatória agora será possível conferir o ajuste dos parâmetros de maneira mais segura pois já foi constatada a convergência da cadeia</p>
</div>
<div id="comparando-com-o-modelo-linear-clássico-1" class="section level4">
<h4>Comparando com o modelo linear clássico</h4>
<p>Agora que os resultados sob o paradigma bayesiano já foram conferidos novamente será ajustado um modelo de regressão linear simples pelo método dos mínimos quadrados sob o paradigma clássico para comparar com os resultados do um modelo de regressão linear simples sob o paradigma bayesiano utilizando os resultados calculados na seção.</p>
<pre class="r"><code># Reta do modelo classico 
plot(x, y)
modelo.classico &lt;- lm(y ~ 1 + x)
a.classico      &lt;- modelo.classico$coefficients[1]
b.classico      &lt;- modelo.classico$coefficients[2]
abline(a        &lt;- a.classico, b = b.classico, col = &quot;blue&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code># Reta do modelo bayesiano
plot(x, y)
a.bayes &lt;- mean(results[, 1])
b.bayes &lt;- mean(results[, 2])
abline(a = a.bayes, b = b.bayes, col = &quot;red&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>A Tabela abaixo apresenta o resumo a posteriori dos parâmetros estimados da cadeia e note que esta tabela não conta com a coluna dos valores reais como no exemplo anterior e sim as estimativas sob o paradigma clássico.</p>
<pre class="r"><code>coef &lt;- 
  coeficientes(results,real = classico) %&gt;% as.data.frame()

tabela_coeficientes(coef)</code></pre>
<div id="htmlwidget-2" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"visdat":{"11b981cae4251":["function () ","plotlyVisDat"]},"cur_data":"11b981cae4251","attrs":{"11b981cae4251":{"columnorder":[1,2,3,4,5],"columnwidth":[80,80,80,80,80],"header":{"values":["Média","Desv. Pad.","IC inf","IC sup","Real"],"line":{"color":"#506784"},"fill":{"color":"#1F8FFFB4"},"align":["center","center","center","center","center"],"font":{"color":"white","size":15},"height":40},"cells":{"values":[[8.2374,0.1663,0.1083],[0.8481,0.017,0.0214],[6.5848,0.1326,0.0699],[9.9239,0.1997,0.1542],[8.2839,0.1656,0.1025]],"line":{"color":"#506784"},"fill":{"color":["#1F8FFF58","white","white","white","#1F8FFF58"]},"align":["center","center","center","center","center"],"font":{"color":["white","#506784","#506784","#506784","white"],"size":12},"height":30},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"table"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"hovermode":"closest","showlegend":false},"source":"A","config":{"showSendToCloud":false},"data":[{"columnorder":[1,2,3,4,5],"columnwidth":[80,80,80,80,80],"header":{"values":["Média","Desv. Pad.","IC inf","IC sup","Real"],"line":{"color":"#506784"},"fill":{"color":"#1F8FFFB4"},"align":["center","center","center","center","center"],"font":{"color":"white","size":15},"height":40},"cells":{"values":[[8.2374,0.1663,0.1083],[0.8481,0.017,0.0214],[6.5848,0.1326,0.0699],[9.9239,0.1997,0.1542],[8.2839,0.1656,0.1025]],"line":{"color":"#506784"},"fill":{"color":["#1F8FFF58","white","white","white","#1F8FFF58"]},"align":["center","center","center","center","center"],"font":{"color":["white","#506784","#506784","#506784","white"],"size":12},"height":30},"type":"table","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>O modelo estimado sob este paradigma pode ser escrito da seguinte maneira: <span class="math inline">\(\hat{y} = 8,2839 x + 0,1656\)</span>, ou seja, os valores de <span class="math inline">\(\beta_0\)</span> e de <span class="math inline">\(\beta_1\)</span> novamente foram muito próximos dos parâmetros obtidos ao estimar sob o paradigma clássico.</p>
</div>
<div id="comparando-de-forma-visual" class="section level4">
<h4>Comparando de forma visual</h4>
<p>A Figura ilustra o gráfico de dispersão dos dados citados acima, com a intenção de exibir quanto uma variável é afetada por outra, onde no eixo vertical representa a velocidade do carro e no eixo horizontal a distância tomada para parar.</p>
<p>Além do comportamento das variáveis, neste gráfico é exibido também os resultados obtidos do ajuste ao se utilizar o método de mínimos quadrados (representada pela linha em vermelho) para estimar os parâmetros e o ajuste do modelo ao se utilizar o método apresentado acima em (representada pela linha azul).</p>
<pre class="r"><code># Texto da imagem
text.classico &lt;- str_c(&quot;Modelo Classico: &quot;,&quot;y = &quot;,round(a.classico,4),&quot; x + &quot;,round(b.classico,4))
text.bayes    &lt;- str_c(&quot;Modelo Bayesiano: &quot;,&quot;y = &quot;,round(a.bayes,4),&quot; x + &quot;,round(b.bayes,4))

#Gerando o scatter.plot
cbind(y, x) %&gt;%
  as.data.frame %&gt;%
  ggplot(aes(y = y, x = x)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, se = F, col = &quot;red&quot;) +
  theme_classic() +
  geom_abline(slope = b.bayes,
              intercept = a.bayes,
              col = &quot;blue&quot;) +
  labs(title = &quot;Relação entre a Distância e a Velocidade com \nreta do modelo linear clássico vs bayesiano&quot;,
       x = &quot;Distância&quot;,
       y = &quot;Velocidade&quot;)</code></pre>
<p><img src="/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>É possível notar que os coeficientes calculados foram muito parecidos, mesmo apresentando pequenas diferenças decimais no valor dos coeficientes ainda é possível notar que as retas estão basicamente sobrepostas, ou seja, os valores estimados em ambas as abordagens foram praticamente os mesmos.</p>
<p>Apesar dos valores dos ajustes terem apresentado basicamente os mesmo resultados, a maneira de se conferir a qualidade do ajuste é diferente em ambas as abordagens. Enquanto sob o paradigma clássico o ajuste do modelo pode ser checado ao avaliar os pre-supostos quanto à distribuição dos resíduos, como recomenda <span class="citation">@GaussClarice</span>, ao utilizar um método de MCMC faz-se necessário conferir também outros aspectos como por exemplo se houve convergência da cadeias além do comportamento das autocorrelações, vide <span class="citation">@migon</span>.</p>
</div>
</div>
</div>
<div id="conclusão" class="section level1">
<h1>Conclusão</h1>
<p>O uso do algorítmo para simular os dados da implementação do modelo hierárquico bayesiano envolveu diversas etapas. Inicialmente foi necessária a revisão de literatura para a compreensão dos métodos que seriam utilizados na implementação do algoritmo, bem como em seu desenvolvimento. Essa pesquisa funcionou de maneira muito didática, de forma que a cada semana a abordagem pudesse envolver maior grau de complexidade.</p>
<p>Durante o estudo, diversos valores de parâmetros a priori foram selecionados para que fosse possível avaliar a sensibilidade da qualidade da escolha da distribuição a priori. Observou-se que valores elevados para variância a priori (também consideradas como “não informativas” - fazendo uma analogia à modelos clássicos) obtiveram melhores ajustes atribuindo maior importância à informação provinda da amostra.</p>
<p>O estudo com dados simulados facilitou o entendimento do algoritmo pois foi possível notar com facilidade a inadequabilidade das escolhas das prioris, que resultavam em estimativas muito distante do parâmetro populacional que gerou a amostra.</p>
</div>
<div id="referências" class="section level1">
<h1>Referências</h1>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2018-07-28-modelo-bayesiano-do-zero/modelo-bayesiano-do-zero/">modelo bayesiano do zero</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Aprendizado Não Supervisionado</category>
      <category>Bayes</category>
      <category>Inferência Bayesiana</category>
      <category>Estatistica</category>
      <category>Modelagem Estatistica</category>
      <category>Probabilidade</category>
      <category>R</category>
      <category>Simulação</category>
      <category>Teoria</category>
      <category domain="tag">bayes</category>
      <category domain="tag">Estatistica</category>
      <category domain="tag">gomesfellipe</category>
      <category domain="tag">jags</category>
      <category domain="tag">modelagem</category>
      <category domain="tag">modelagem estatistica</category>
      <category domain="tag">modelos generalizados</category>
      <category domain="tag">modelos lineares</category>
      <category domain="tag">probabilidade</category>
      <category domain="tag">R</category>
      <category domain="tag">regression</category>
      <category domain="tag">Teoria</category>
    </item>
    <item>
      <title>Brasil x Argentina, tidytext e Machine Learning</title>
      <link>https://gomesfellipe.github.io/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml/</link>
      <pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml/</guid>
      <description>Aplicando técnincas de Text Mining como pacote tidy text para explorar a rivalidade entre Brasil e Argentina! Veja também como a análise de sentimentos pode ser divertida além de possíveis aplicações de machine learning</description>
      <content:encoded>&lt;![CDATA[
        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="brasil-vs-argentina-e-text-mining" class="section level1">
<h1>Brasil vs Argentina e Text Mining</h1>
<p>A copa do mundo esta ai novamente e como não poderia ser diferente, com ela surgem novos <a href="http://cio.com.br/noticias/2015/10/27/tome-nota-2-5-quintilhoes-de-bytes-sao-criados-todos-os-dias/">quintilhões de bytes todos os dias</a>, saber analisar esses dados é um grande desafio pois a maioria dessa informação se encontra de forma não estruturada e além do desafio de captar esses dados ainda existem mais desafios que podem ser ainda maiores, como o de processá-los e obter respostas deles.</p>
<p>Dada a rivalidade histórica entre Brasil e Argentina achei que seria interessante avaliar como anda o comportamento das pessoas do Brasil nas mídias sociais em relação a esses dois países. Para o post não ficar muito longo, escolhi que iria recolher informações apenas do Twitter devido a praticidade, foram coletados os últimos 4.000 tweets com o termo “brasil” e os últimos “4.000” tweets com o termo “argentina” no Twitter através da sua API com o pacote os <code>twitteR</code> e <code>ROAuth</code>. O código pode ser conferido <a href="https://github.com/gomesfellipe/functions/blob/master/getting_twitter_data.R">neste link</a>.</p>
<p>Análise de textos sempre foi um tema que me interessou muito, no final do ano de 2017 quando era estagiário me pediram para ajudar em uma pesquisa que envolvia a análise de palavras criando algumas nuvens de palavras. Pesquisando sobre técnicas de textmining descobri tantas abordagens diferentes que resolvi juntar tudo que tinha encontrado em uma única função (que será apresentada a seguir) para a confecção dessas nuvens, utilizarei esta função para ter uma primeira impressão dos dados.</p>
<p>Além disso, como seria um problema a tarefa de criar as nuvens de palavras só poderia ser realizada por alguém com conhecimento em R, na época estava começando meus estudo sobre shiny e como treinamento desenvolvi um app que esta hospedado no link: <a href="https://gomesfellipe.shinyapps.io/appwordcloud/" class="uri">https://gomesfellipe.shinyapps.io/appwordcloud/</a> e o código esta aberto e disponível para quem se interessar no meu github <a href="https://github.com/gomesfellipe/appwordcloud/blob/master/appwordcloud.Rmd">neste link</a></p>
<p>Porém, após ler e estudar o livro <a href="https://www.tidytextmining.com/">Text Mining with R - A Tidy Approach</a> por <span class="citation"><a href="#ref-tidytext" role="doc-biblioref">Silge; Robinson</a> (<a href="#ref-tidytext" role="doc-biblioref">2018</a>)</span> hoje em dia eu olho para trás e vejo que poderia ter feito tanto a função quanto o aplicativo de maneira muito mais eficiente portanto esse post trás alguns dos meus estudos sobre esse livro maravilhoso e também algum estudo sobre Machine Learning com o pacote <a href="https://cran.r-project.org/web/packages/caret"><code>caret</code></a></p>
<div id="importando-a-dados" class="section level2">
<h2>Importando a dados</h2>
<p>Como já foi dito, a base de dados foi obtida através da API do twitter e o código pode ser obtido <a href="https://github.com/gomesfellipe/functions/blob/master/getting_twitter_data.R">neste link</a>.</p>
<pre class="r"><code>library(dplyr)
library(kableExtra)
library(magrittr)

base &lt;- read.csv(&quot;original_books.csv&quot;) %&gt;% as_tibble()</code></pre>
</div>
<div id="nuvem-de-palavras-rápida-com-função-customizada" class="section level2">
<h2>Nuvem de palavras rápida com função customizada</h2>
<p>Para uma primeira impressão dos dados, vejamos o que retorna uma nuvem de palavras criada com a função <a href="https://github.com/gomesfellipe/functions/blob/master/wordcloud_sentiment.R"><code>wordcloud_sentiment()</code></a> que desenvolvi antes de conhecer a “A Tidy Approach” para Text Mining:</p>
<pre class="r"><code>devtools::source_url(&quot;https://raw.githubusercontent.com/gomesfellipe/functions/master/wordcloud_sentiment.R&quot;)

# Obtendo nuvem e salvando tabela num objeto com nome teste:
df &lt;- wordcloud_sentiment(base$text,
                      type = &quot;text&quot;,
                      sentiment = F,
                      excludeWords = c(&quot;nao&quot;,letters,LETTERS),
                      ngrams = 2,
                      tf_idf = F,
                      max = 100,
                      freq = 10,
                      horizontal = 0.9,
                      textStemming = F,
                      print=T)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-2-1.png" width="1056" /></p>
<p>Não poderia esquecer, além da nuvem, a função também retorna um dataframe com a frequência das palavras:</p>
<pre class="r"><code>df %&gt;% as_tibble()</code></pre>
<pre><code>## # A tibble: 29,064 x 2
##    words          freq  
##    &lt;chr&gt;          &lt;chr&gt; 
##  1 =              &quot;2795&quot;
##  2 brasil copa    &quot;2061&quot;
##  3 copa mundo     &quot;1959&quot;
##  4 hat trick      &quot;1327&quot;
##  5 = hoje         &quot;1248&quot;
##  6 hoje brasil    &quot;1215&quot;
##  7 mundo          &quot; 852&quot;
##  8 isl ndia       &quot; 820&quot;
##  9 pra copa       &quot; 813&quot;
## 10 estreia brasil &quot; 782&quot;
## # … with 29,054 more rows</code></pre>
<p>E outra função interessante é a de criar uma nuvem a partir de um webscraping muito (muito mesmo) introdutório, para isso foi pegar todo o texto da página sobre a copa do mundo no Wikipédia, veja:</p>
<pre class="r"><code># Obtendo nuvem e salvando tabela num objeto com nome teste:
df_html &lt;- wordcloud_sentiment(&quot;https://pt.wikipedia.org/wiki/Copa_do_Mundo_FIFA&quot;,
                      type = &quot;url&quot;,
                      sentiment = F,
                      excludeWords = c(&quot;nao&quot;,letters,LETTERS),
                      ngrams = 2,
                      tf_idf = F,
                      max = 100,
                      freq = 6,
                      horizontal = 0.9,
                      textStemming = F,
                      print=T)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Essa função é bem “prematura,” existem infinitas maneiras de melhorar ela e não alterei ela ainda por falta de tempo.</p>
</div>
<div id="a-tidy-approach" class="section level2">
<h2>A Tidy Approach</h2>
<p>O formato tidy, em que cada linha corresponde a uma observação e cada coluna à uma variável, veja:</p>
<center>
<img src="http://garrettgman.github.io/images/tidy-1.png" style="width:70.0%" />
</center>
<p>Agora a tarefa será simplificada com a abordagem tidy, além das funções do livro <a href="https://www.tidytextmining.com/">Text Mining with R</a> utilizarei a função <a href="https://github.com/gomesfellipe/functions/blob/master/clean_tweets.R"><code>clean_tweets</code></a> que adaptei inspirado nesse post dessa pagina: <a href="https://sites.google.com/site/miningtwitter/home">Quick guide to mining twitter with R</a> quando estudava sobre textmining.</p>
<div id="arrumando-e-transformando-a-base-de-dados" class="section level3">
<h3>Arrumando e transformando a base de dados</h3>
<p>Utilizando as funções do pacote <code>tidytext</code> em conjunto com os pacotes <code>stringr</code> e <code>abjutils</code>, será possível limpar e arrumar a base de dados.</p>
<p>Além disso serão removidas as stop words de nossa base, com a função <code>stopwords::stopwords("pt")</code> podemos obter as stopwords da nossa língua</p>
<pre class="r"><code>library(stringr)
library(tidytext)
library(abjutils)

devtools::source_url(&quot;https://raw.githubusercontent.com/gomesfellipe/functions/master/clean_tweets.R&quot;)

original_books = base %&gt;% 
  mutate(text = clean_tweets(text) %&gt;% enc2native() %&gt;% rm_accent())

#Removendo stopwords:
excludewords=c(&quot;[:alpha:]&quot;,&quot;[:alnum:]&quot;,&quot;[:digit:]&quot;,&quot;[:xdigit:]&quot;,&quot;[:space:]&quot;,&quot;[:word:]&quot;,
               LETTERS,letters,1:10,
               &quot;hat&quot;,&quot;trick&quot;,&quot;bc&quot;,&quot;de&quot;,&quot;tem&quot;,&quot;twitte&quot;,&quot;fez&quot;,
               &#39;pra&#39;,&quot;vai&quot;,&quot;ta&quot;,&quot;so&quot;,&quot;ja&quot;,&quot;rt&quot;)

stop_words = data_frame(word = c(stopwords::stopwords(&quot;pt&quot;), excludewords))

tidy_books &lt;- original_books %&gt;%
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words)</code></pre>
<p>Portando a base de dados após a limpeza e a remoção das stop words:</p>
<pre class="r"><code>#Palavras mais faladas:
tidy_books %&gt;% count(word, sort = TRUE) </code></pre>
<pre><code>## # A tibble: 3,900 x 2
##    word          n
##    &lt;chr&gt;     &lt;int&gt;
##  1 copa       6993
##  2 brasil     4164
##  3 argentina  3487
##  4 mundo      2030
##  5 hoje       1825
##  6 letras     1562
##  7 messi      1493
##  8 estreia    1107
##  9 est         866
## 10 isl         828
## # … with 3,890 more rows</code></pre>
<pre class="r"><code>#Apos a limpeza, caso precise voltar as frases:
original_books = tidy_books%&gt;%
  group_by(book,line)%&gt;%
  summarise(text=paste(word,collapse = &quot; &quot;))</code></pre>
<div id="palavras-mais-frequentes" class="section level4">
<h4>Palavras mais frequentes</h4>
<p>Vejamos as palavras mais faladas nessa pesquisa:</p>
<pre class="r"><code>library(ggplot2)

tidy_books %&gt;%
  count(word, sort = TRUE) %&gt;%
  filter(n &gt; 400) %&gt;%
  mutate(word = reorder(word, n)) %&gt;%
  
  ggplot(aes(word, n, fill = I(&quot;yellow&quot;), colour = I(&quot;green&quot;))) +
  geom_col(position=&quot;dodge&quot;) +
  xlab(NULL) +
  labs(title = &quot;Frequencia total das palavras pesquisadas&quot;)+
  coord_flip()+ theme(
  panel.background = element_rect(fill = &quot;#74acdf&quot;,
                                colour = &quot;lightblue&quot;,
                                size = 0.5, linetype = &quot;solid&quot;),
  panel.grid.major = element_line(size = 0.5, linetype = &#39;solid&#39;,
                                colour = &quot;white&quot;), 
  panel.grid.minor = element_line(size = 0.25, linetype = &#39;solid&#39;,
                                colour = &quot;white&quot;)
  )</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="palavras-mais-frequentes-para-cada-termo" class="section level4">
<h4>Palavras mais frequentes para cada termo</h4>
<p>Vejamos as nuvens de palavras mais frequentes de acordo com cada um dos termos pesquisados:</p>
<pre class="r"><code>#Criando nuvem de palavra:
library(wordcloud)

par(mfrow=c(1,2))
tidy_books %&gt;%
  filter(book==&quot;br&quot;)%&gt;%
  count(word) %&gt;%
  with(wordcloud(word, n, max.words = 100,random.order = F,min.freq = 15,random.color = F,colors = c(&quot;#009b3a&quot;, &quot;#fedf00&quot;,&quot;#002776&quot;),scale = c(2,1),rot.per = 0.05))

tidy_books %&gt;%
  filter(book==&quot;arg&quot;)%&gt;%
  count(word) %&gt;%
  with(wordcloud(word, n, max.words = 100,min.freq = 15,random.order = F,random.color = F,colors = c(&quot;#75ade0&quot;, &quot;#ffffff&quot;,&quot;#f6b506&quot;),scale = c(2,1),rot.per = 0.05))</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-8-1.png" width="1056" /></p>
<pre class="r"><code>par(mfrow=c(1,1))</code></pre>
</div>
</div>
<div id="análise-de-sentimentos" class="section level3">
<h3>Análise de sentimentos</h3>
<p>A análise de sentimentos utilizando a abordagem tidy foi possível graças ao pacote <a href="https://cran.r-project.org/package=lexiconPT"><code>lexiconPT</code></a>, que esta disponível no CRAN e que conheci ao ler o <a href="https://sillasgonzaga.github.io/2017-09-23-sensacionalista-pt01/">post: “O Sensacionalista e Text Mining: Análise de sentimento usando o lexiconPT”</a> do blog <a href="https://sillasgonzaga.github.io/">Paixão por dados</a> que gosto tanto de acompanhar.</p>
<pre class="r"><code># Analise de sentimentos:
library(lexiconPT)

sentiment = data.frame(word = sentiLex_lem_PT02$term ,
                       polarity = sentiLex_lem_PT02$polarity) %&gt;% 
  mutate(sentiment = if_else(polarity&gt;0,&quot;positive&quot;,if_else(polarity&lt;0,&quot;negative&quot;,&quot;neutro&quot;)),
         word = as.character(word)) %&gt;% 
  as_tibble()


library(tidyr)

book_sentiment &lt;- tidy_books %&gt;%
  inner_join(sentiment) %&gt;%
  count(book,word, index = line , sentiment) %&gt;%
  spread(sentiment, n, fill = 0) %&gt;%
  mutate(sentiment = positive - negative) %T&gt;%
  print</code></pre>
<pre><code>## # A tibble: 2,953 x 7
##    book  word      index negative neutro positive sentiment
##    &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
##  1 arg   abandonar   857        1      0        0        -1
##  2 arg   absurdo     849        1      0        0        -1
##  3 arg   absurdo    1863        1      0        0        -1
##  4 arg   afogado    2275        1      0        0        -1
##  5 arg   afogado    3659        1      0        0        -1
##  6 arg   alegria    1134        0      0        1         1
##  7 arg   almo        186        0      0        1         1
##  8 arg   almo       2828        0      0        1         1
##  9 arg   almo       3433        0      0        1         1
## 10 arg   almo       3569        0      0        1         1
## # … with 2,943 more rows</code></pre>
<p>Cada palavra possui um valor associado a sua polaridade , vejamos como ficou distribuído o número de palavras de cada sentimento de acordo com cada termo escolhido para a pesquisa:</p>
<pre class="r"><code>book_sentiment%&gt;%
  count(sentiment,book)%&gt;%
  arrange(book) %&gt;%
  
  ggplot(aes(x = factor(sentiment),y = n,fill=book))+
  geom_bar(stat=&quot;identity&quot;,position=&quot;dodge&quot;)+
  facet_wrap(~book) +
  theme_bw()+ 
    scale_fill_manual(values=c(&quot;#75ade0&quot;, &quot;#009b3a&quot;))</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div id="comparando-sentimentos-dos-termos-de-pesquisa" class="section level4">
<h4>Comparando sentimentos dos termos de pesquisa</h4>
<p>Para termos associados a palavra “Brasil” no twitter:</p>
<pre class="r"><code># Nuvem de comparação:
library(reshape2)

tidy_books %&gt;%
  filter(book==&quot;br&quot;)%&gt;%
  inner_join(sentiment) %&gt;%
  count(word, sentiment, sort = TRUE) %&gt;%
  acast(word ~ sentiment, value.var = &quot;n&quot;, fill = 0) %&gt;%
  comparison.cloud(colors = c(&quot;red&quot;, &quot;gray80&quot;,&quot;green&quot;),
                   max.words = 200)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Para termos associados a palavra “Argentina” no twitter:</p>
<pre class="r"><code>tidy_books %&gt;%
  filter(book==&quot;arg&quot;)%&gt;%
  inner_join(sentiment) %&gt;%
  count(word, sentiment, sort = TRUE) %&gt;%
  acast(word ~ sentiment, value.var = &quot;n&quot;, fill = 0) %&gt;%
  comparison.cloud(colors = c(&quot;red&quot;, &quot;gray80&quot;,&quot;green&quot;),
                   max.words = 200)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="proporção-de-palavras-positivas-e-negativas-por-texto" class="section level4">
<h4>Proporção de palavras positivas e negativas por texto</h4>
<pre class="r"><code># Proporção de palavras negativas:
bingnegative &lt;- sentiment %&gt;% 
  filter(sentiment == &quot;negative&quot;)

bingpositive &lt;- sentiment %&gt;% 
  filter(sentiment == &quot;positive&quot;)

wordcounts &lt;- tidy_books %&gt;%
  group_by(book, line) %&gt;%
  summarize(words = n())</code></pre>
<div id="para-negativas" class="section level5">
<h5>Para negativas;</h5>
<pre class="r"><code>tidy_books %&gt;%
  semi_join(bingnegative) %&gt;%
  group_by(book, line) %&gt;%
  summarize(negativewords = n()) %&gt;%
  left_join(wordcounts, by = c(&quot;book&quot;, &quot;line&quot;)) %&gt;%
  mutate(ratio = negativewords/words) %&gt;%
  top_n(5) %&gt;%
  ungroup() %&gt;% arrange(desc(ratio)) %&gt;% filter(book==&quot;br&quot;)</code></pre>
<pre><code>## # A tibble: 5 x 5
##   book   line negativewords words ratio
##   &lt;chr&gt; &lt;int&gt;         &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
## 1 br     2003             1     3 0.333
## 2 br     2775             1     3 0.333
## 3 br     2580             2     7 0.286
## 4 br      126             1     4 0.25 
## 5 br     2335             1     4 0.25</code></pre>
<p>A frase mais negativa do brasil e da argentina::</p>
<pre class="r"><code>base %&gt;%
  filter(book==&quot;br&quot;,line==2580) %&gt;% mutate(text = as.character(text))%&gt;% select(text) %&gt;% c() </code></pre>
<pre><code>## $text
## [1] &quot;um medo? \x97 de nois criar expectativa e o Brasil perder a copa https://t.co/0chcNWHh0m&quot;</code></pre>
<pre class="r"><code>base %&gt;%
  filter(book==&quot;arg&quot;,line==572) %&gt;% mutate(text = as.character(text))%&gt;% select(text) %&gt;% c()  </code></pre>
<pre><code>## $text
## [1] &quot;RT @DavidmeMelo: @SantiiSanchez16 @Flamengo Perder a copa para o time mais sujo e mais corrupto da argentina \xe9 assim mesmo https://t.co/zIC\x85&quot;</code></pre>
</div>
<div id="para-positivas" class="section level5">
<h5>Para positivas:</h5>
<pre class="r"><code>tidy_books %&gt;%
  semi_join(bingpositive) %&gt;%
  group_by(book, line) %&gt;%
  summarize(positivewords = n()) %&gt;%
  left_join(wordcounts, by = c(&quot;book&quot;, &quot;line&quot;)) %&gt;%
  mutate(ratio = positivewords/words) %&gt;%
  top_n(5) %&gt;%
  ungroup() %&gt;% arrange(desc(ratio))</code></pre>
<pre><code>## # A tibble: 22 x 5
##    book   line positivewords words ratio
##    &lt;chr&gt; &lt;int&gt;         &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
##  1 arg    2120             3     9 0.333
##  2 br     2374             1     3 0.333
##  3 arg    3272             2     7 0.286
##  4 arg    2301             1     4 0.25 
##  5 br      126             1     4 0.25 
##  6 br      553             2     8 0.25 
##  7 br     1499             2     8 0.25 
##  8 br     2054             2     8 0.25 
##  9 br     2591             1     4 0.25 
## 10 arg    2130             1     5 0.2  
## # … with 12 more rows</code></pre>
<p>A frase mais positiva do brasil e da argentina:</p>
<pre class="r"><code>base %&gt;%
  filter(book==&quot;br&quot;,line==2374) %&gt;% mutate(text = as.character(text))%&gt;% select(text) %&gt;% c() </code></pre>
<pre><code>## $text
## [1] &quot;Tirei Brasil, \xe9 uma honra https://t.co/OgNCot4Wu0&quot;</code></pre>
<pre class="r"><code>base %&gt;%
  filter(book==&quot;arg&quot;,line==2120) %&gt;% mutate(text = as.character(text))%&gt;% select(text) %&gt;% c()  </code></pre>
<pre><code>## $text
## [1] &quot;@_LeoFerreiraH Quero que a Argentina passe para possivelmente enfrentar o Brasil, ganhar da Argentina j\xe1 \xe9 bom, na\x85 https://t.co/bxHJUeGVpc&quot;</code></pre>
</div>
</div>
</div>
</div>
<div id="tf-idf" class="section level2">
<h2>TF-IDF</h2>
<p>Segundo <span class="citation"><a href="#ref-tidytext" role="doc-biblioref">Silge; Robinson</a> (<a href="#ref-tidytext" role="doc-biblioref">2018</a>)</span> no livro <a href="https://www.tidytextmining.com/tfidf.html">tidytextminig</a>:</p>
<blockquote>
<p>The statistic tf-idf is intended to measure how important a word is to a document in a collection (or corpus) of documents, for example, to one novel in a collection of novels or to one website in a collection of websites.</p>
</blockquote>
<p>Traduzido pelo Google tradutor:</p>
<blockquote>
<p>A estatística tf-idf destina-se a medir a importância de uma palavra para um documento em uma coleção (ou corpus) de documentos, por exemplo, para um romance em uma coleção de romances ou para um site em uma coleção de sites.</p>
</blockquote>
<p>Matematicamente:</p>
<p><span class="math display">\[
idf(\text{term}) = \ln{\left(\frac{n_{\text{documents}}}{n_{\text{documents containing term}}}\right)}
\]</span></p>
<p>E que com o pacote <code>tidytext</code> podemos obter usando o comando <code>bind_tf_idf()</code>, veja:</p>
<pre class="r"><code># Obtendo numero de palavras
book_words &lt;- original_books %&gt;%
  unnest_tokens(word, text) %&gt;%
  count(book, word, sort = TRUE) %&gt;%
  ungroup()%&gt;%
  anti_join(stop_words)

total_words &lt;- book_words %&gt;% 
  group_by(book) %&gt;% 
  summarize(total = sum(n))

book_words &lt;- left_join(book_words, total_words)

# tf-idf:
book_words &lt;- book_words %&gt;%
  bind_tf_idf(word, book, n)

book_words %&gt;%
  arrange(desc(tf_idf))</code></pre>
<pre><code>## # A tibble: 4,773 x 7
##    book  word              n total      tf   idf  tf_idf
##    &lt;chr&gt; &lt;chr&gt;         &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1 br    letras         1562 30429 0.0513  0.693 0.0356 
##  2 br    ansioso         688 30429 0.0226  0.693 0.0157 
##  3 arg   classificou     666 40781 0.0163  0.693 0.0113 
##  4 arg   segundo         654 40781 0.0160  0.693 0.0111 
##  5 arg   especialistas   649 40781 0.0159  0.693 0.0110 
##  6 arg   nalti           649 40781 0.0159  0.693 0.0110 
##  7 arg   repito          649 40781 0.0159  0.693 0.0110 
##  8 br    icon            248 30429 0.00815 0.693 0.00565
##  9 arg   ncio            287 40781 0.00704 0.693 0.00488
## 10 arg   penalti         284 40781 0.00696 0.693 0.00483
## # … with 4,763 more rows</code></pre>
<p>O que nos trás algo como: “termos mais relevantes.”</p>
<p>Visualmente:</p>
<pre class="r"><code>book_words %&gt;%
  arrange(desc(tf_idf)) %&gt;%
  mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% 
  group_by(book) %&gt;% 
  top_n(15) %&gt;% 
  ungroup %&gt;%
  
  ggplot(aes(word, tf_idf, fill = book)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = &quot;tf-idf&quot;) +
  facet_wrap(~book, ncol = 2, scales = &quot;free&quot;) +
  coord_flip()+
  theme_bw()+ 
    scale_fill_manual(values=c(&quot;#75ade0&quot;, &quot;#009b3a&quot;))</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
<div id="bi-grams" class="section level2">
<h2>bi grams</h2>
<p>OS bi grams são sequencias de palavras, a seguir será procurada as sequencias de duas palavras, o que nos permite estudar um pouco melhor o contexto do seu uso.</p>
<pre class="r"><code># Bi grams
book_bigrams &lt;- original_books %&gt;%
  unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2)

book_bigrams %&gt;%
  count(bigram, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 15,106 x 3
## # Groups:   book [2]
##    book  bigram                    n
##    &lt;chr&gt; &lt;chr&gt;                 &lt;int&gt;
##  1 br    brasil copa            2039
##  2 br    copa mundo             1459
##  3 br    hoje brasil            1215
##  4 arg   argentina copa         1122
##  5 arg   isl ndia                818
##  6 br    estreia brasil          764
##  7 br    ansioso estreia         684
##  8 br    est ansioso             680
##  9 arg   classificou argentina   660
## 10 arg   copa segundo            649
## # … with 15,096 more rows</code></pre>
<p>Separando as coluna de bi grams:</p>
<pre class="r"><code>bigrams_separated &lt;- book_bigrams %&gt;%
  separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;)

bigrams_filtered &lt;- bigrams_separated %&gt;%
  filter(!word1 %in% stop_words$word) %&gt;%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_counts &lt;- bigrams_filtered %&gt;% 
  count(word1, word2, sort = TRUE)

bigram_counts</code></pre>
<pre><code>## # A tibble: 15,106 x 4
## # Groups:   book [2]
##    book  word1       word2         n
##    &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;     &lt;int&gt;
##  1 br    brasil      copa       2039
##  2 br    copa        mundo      1459
##  3 br    hoje        brasil     1215
##  4 arg   argentina   copa       1122
##  5 arg   isl         ndia        818
##  6 br    estreia     brasil      764
##  7 br    ansioso     estreia     684
##  8 br    est         ansioso     680
##  9 arg   classificou argentina   660
## 10 arg   copa        segundo     649
## # … with 15,096 more rows</code></pre>
<p>Caso seja preciso juntar novamente:</p>
<pre class="r"><code>bigrams_united &lt;- bigrams_filtered %&gt;%
  unite(bigram, word1, word2, sep = &quot; &quot;)

bigrams_united</code></pre>
<pre><code>## # A tibble: 71,208 x 2
## # Groups:   book [2]
##    book  bigram             
##    &lt;chr&gt; &lt;chr&gt;              
##  1 arg   isl ndia           
##  2 arg   ndia pouco         
##  3 arg   pouco mil          
##  4 arg   mil habitantes     
##  5 arg   habitantes montaram
##  6 arg   montaram sele      
##  7 arg   sele est           
##  8 arg   est copa           
##  9 arg   copa fizeram       
## 10 arg   fizeram gol        
## # … with 71,198 more rows</code></pre>
<div id="analisando-bi-grams-com-tf-idf" class="section level3">
<h3>Analisando bi grams com tf-idf</h3>
<p>Também é possível aplicar a transformação <code>tf-idf</code> em bigrams, veja:</p>
<pre class="r"><code>#bi grams com tf idf
bigram_tf_idf &lt;- bigrams_united %&gt;%
  count(book, bigram) %&gt;%
  bind_tf_idf(bigram, book, n) %&gt;%
  arrange(desc(tf_idf))

bigram_tf_idf</code></pre>
<pre><code>## # A tibble: 15,106 x 6
## # Groups:   book [2]
##    book  bigram                    n     tf   idf  tf_idf
##    &lt;chr&gt; &lt;chr&gt;                 &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1 br    hoje brasil            1215 0.0399 0.693 0.0277 
##  2 br    ansioso estreia         684 0.0225 0.693 0.0156 
##  3 br    est ansioso             680 0.0223 0.693 0.0155 
##  4 br    letras letras           620 0.0204 0.693 0.0141 
##  5 arg   classificou argentina   660 0.0162 0.693 0.0112 
##  6 arg   copa segundo            649 0.0159 0.693 0.0110 
##  7 arg   messi repito            649 0.0159 0.693 0.0110 
##  8 arg   repito classificou      649 0.0159 0.693 0.0110 
##  9 arg   segundo especialistas   649 0.0159 0.693 0.0110 
## 10 br    brasil letras           313 0.0103 0.693 0.00713
## # … with 15,096 more rows</code></pre>
</div>
<div id="analisando-contexto-de-palavras-negativas" class="section level3">
<h3>Analisando contexto de palavras negativas:</h3>
<p>Uma das abordagens interessantes ao estudar as bi-grams é a de avaliar o contexto das palavras negativas, veja:</p>
<pre class="r"><code>bigrams_separated %&gt;%
  filter(word1 == &quot;nao&quot;) %&gt;%
  count(word1, word2, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 35 x 4
## # Groups:   book [2]
##    book  word1 word2         n
##    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;
##  1 br    nao   copa         10
##  2 arg   nao   abrir         3
##  3 arg   nao   convoca       3
##  4 arg   nao   ruim          3
##  5 br    nao   acredito      2
##  6 arg   nao   achei         1
##  7 arg   nao   acordem       1
##  8 arg   nao   argentina     1
##  9 arg   nao   assisti       1
## 10 arg   nao   compara       1
## # … with 25 more rows</code></pre>
<pre class="r"><code>not_words &lt;- bigrams_separated %&gt;%
  filter(word1 == &quot;nao&quot;) %&gt;%
  inner_join(sentiment, by = c(word2 = &quot;word&quot;)) %&gt;%
  count(word2, sentiment, sort = TRUE) %&gt;%
  ungroup()

not_words</code></pre>
<pre><code>## # A tibble: 3 x 4
##   book  word2    sentiment     n
##   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;     &lt;int&gt;
## 1 arg   ruim     negative      3
## 2 arg   vencer   positive      1
## 3 br    amistoso positive      1</code></pre>
<p>A palavra não antes de uma palavra “positiva,” como por exemplo “não gosto” pode ser anulada ao somar-se suas polaridades (“não” = - 1, “gosto” = +1 e “não gosto” = -1 + 1) o leva a necessidade de ser tomar um cuidado especial com essas palavras em uma análise de texto mais detalhada, veja de forma visual:</p>
<pre class="r"><code>not_words %&gt;%
  mutate(sentiment=ifelse(sentiment==&quot;positive&quot;,1,ifelse(sentiment==&quot;negative&quot;,-1,0)))%&gt;%
  mutate(contribution = n * sentiment) %&gt;%
  arrange(desc(abs(contribution))) %&gt;%
  head(20) %&gt;%
  mutate(word2 = reorder(word2, contribution)) %&gt;%
  
  ggplot(aes(word2, n * sentiment, fill = n * sentiment &gt; 0)) +
  geom_col() +
  xlab(&quot;Words preceded by \&quot;not\&quot;&quot;) +
  ylab(&quot;Sentiment score * number of occurrences&quot;) +
  coord_flip()+
  theme_bw()</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="machine-learning" class="section level1">
<h1>Machine Learning</h1>
<p>Estava pesquisando sobre algorítimos recomendados para a análise de texto quando encontrei um artigo da data camp chamado: <a href="https://www.datacamp.com/community/tutorials/R-nlp-machine-learning"><em>Lyric Analysis with NLP &amp; Machine Learning with R</em></a>, do qual a autora expõe a seguinte tabela:</p>
<center>
<img src="http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1517331396/MLImage_cygwsb.jpg" style="width:60.0%" />
</center>
<p>Portanto resolvi fazer uma brincadeira e ajustar 4 dos modelos propostos para a tarefa supervisionada de classificação: K-NN, Tress (tentarei o ajuste do algorítimo Random Forest), Logistic Regression (Modelo estatístico) e Naive-Bayes (por meio do cálculo de probabilidades condicionais) para ver se conseguia recuperar a classificação de quais os termos de pesquisa que eu utilizei para obter esses dados</p>
<p>Além de técnicas apresentadas no livro do pacote <code>caret</code>, por <span class="citation"><a href="#ref-caret" role="doc-biblioref">Kuhn</a> (<a href="#ref-caret" role="doc-biblioref">2018</a>)</span>, muito do que apliquei aqui foi baseado no livro “Introdução a mineração de dados” por <span class="citation"><a href="#ref-miner" role="doc-biblioref">Silva; Peres; Boscarioli</a> (<a href="#ref-miner" role="doc-biblioref">2016</a>)</span>, que foi bastante útil na minha introdução sobre o tema Machine Learning.</p>
<p>Vou utilizar uma função chamada <code>plot_pred_type_distribution()</code>,apresentada neste post de titulo: <a href="https://www.r-bloggers.com/illustrated-guide-to-roc-and-auc/">Illustrated Guide to ROC and AUC</a> e fiz uma pequena alteração para que ela funcionasse para o dataset deste post . A função adaptada pode ser encontrada <a href="https://github.com/gomesfellipe/functions/blob/master/plot_pred_type_distribution.R">neste link</a> no meu github e a função original <a href="https://github.com/joyofdata/joyofdata-articles/blob/master/roc-auc/plot_pred_type_distribution.R">neste link do github do autor</a>.</p>
<div id="pacote-caret" class="section level2">
<h2>Pacote caret</h2>
<p>Basicamente o ajuste de todos os modelos envolveram o uso do pacote <code>caret</code> e muitos dos passos aqui foram baseados nas instruções fornecidas no <a href="https://topepo.github.io/caret/index.html">livro do pacote</a>. O pacote facilita bastante o ajuste dos parâmetros no ajuste de modelos.</p>
</div>
<div id="transformar-e-arrumar" class="section level2">
<h2>Transformar e arrumar</h2>
<p>Uma <a href="https://www.kaggle.com/kailex/tidy-xgboost-glmnet-text2vec-lsa">solução do kaggle</a> para o desafio <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge">Toxic Comment Classification Challenge</a> me chamou atenção, do qual o participante da competição criou colunas que sinalizassem os caracteres especiais de cada frase, utilizarei esta técnica para o ajuste e novamente utilizarei o pacote de léxicos do apresentado no <a href="https://sillasgonzaga.github.io/2017-09-23-sensacionalista-pt01/">post do blog Paixão por dados</a></p>
<p>Veja a base transformada e arrumada:</p>
<pre class="r"><code># Ref: https://cfss.uchicago.edu/text_classification.html 
# https://www.r-bloggers.com/illustrated-guide-to-roc-and-auc/
devtools::source_url(&quot;https://raw.githubusercontent.com/gomesfellipe/functions/master/plot_pred_type_distribution.R&quot;)

base &lt;- base %&gt;% 
  mutate(length = str_length(text),
         ncap = str_count(text, &quot;[A-Z]&quot;),
         ncap_len = ncap / length,
         nexcl = str_count(text, fixed(&quot;!&quot;)),
         nquest = str_count(text, fixed(&quot;?&quot;)),
         npunct = str_count(text, &quot;[[:punct:]]&quot;),
         nword = str_count(text, &quot;\\w+&quot;),
         nsymb = str_count(text, &quot;&amp;|@|#|\\$|%|\\*|\\^&quot;),
         nsmile = str_count(text, &quot;((?::|;|=)(?:-)?(?:\\)|D|P))&quot;),
         text = clean_tweets(text) %&gt;% enc2native() %&gt;% rm_accent())%&gt;%
  unnest_tokens(word, text) %&gt;% 
  anti_join(stop_words)%&gt;%
  group_by(book,line,length, ncap, ncap_len, nexcl, nquest, npunct, nword, nsymb, nsmile)%&gt;%
  summarise(text=paste(word,collapse = &quot; &quot;)) %&gt;% 
  select(text,everything())%T&gt;% 
  print()</code></pre>
<pre><code>## # A tibble: 7,995 x 12
## # Groups:   book, line, length, ncap, ncap_len, nexcl, nquest, npunct, nword,
## #   nsymb [7,995]
##    text  book   line length  ncap ncap_len nexcl nquest npunct nword nsymb
##    &lt;chr&gt; &lt;chr&gt; &lt;int&gt;  &lt;int&gt; &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;
##  1 isl … arg       1     NA     7  NA          0      0      6    24     1
##  2 pau … arg       2    108     6   0.0556     0      0      2    20     1
##  3 mess… arg       3     NA    10  NA          0      0      3    24     1
##  4 minu… arg       4     NA     2  NA          0      0      2    24     1
##  5 requ… arg       5    129    23   0.178      0      0     15    21     1
##  6 bras… arg       6     NA    11  NA          0      0     12    20     1
##  7 dupl… arg       7    123    84   0.683      0      0      8    21     1
##  8 mess… arg       8     NA    10  NA          0      0      3    24     1
##  9 mess… arg       9     NA    10  NA          0      0      3    24     1
## 10 mess… arg      10     NA    10  NA          0      0      3    24     1
## # … with 7,985 more rows, and 1 more variable: nsmile &lt;int&gt;</code></pre>
<p>Após arrumar e transformar as informações que serão utilizadas na classificação, será criado um corpus sem a abordagem tidy para obter a matriz de documentos e termos, e depois utilizar a coluna de classificação, veja:</p>
<pre class="r"><code>library(tm)       #Pacote de para text mining
corpus &lt;- Corpus(VectorSource(base$text))

#Criando a matrix de termos:
book_dtm = DocumentTermMatrix(corpus, control = list(minWordLength=2,minDocFreq=3)) %&gt;% 
  weightTfIdf(normalize = T) %&gt;%    # Transformação tf-idf com pacote tm
  removeSparseTerms( sparse = .95)  # obtendo matriz esparsa com pacote tm

#Transformando em matrix, permitindo a manipulacao:
matrix = as.matrix(book_dtm)
dim(matrix)</code></pre>
<pre><code>## [1] 7995   18</code></pre>
<p>Pronto, agora já podemos juntar tudo em um data frame e separa em treino e teste para a classificação dos textos obtidos do twitter:</p>
<pre class="r"><code>#Criando a base de dados:
full=data.frame(cbind(
  base[,&quot;book&quot;],
  matrix,
  base[,-c(1:3)]
  )) %&gt;% na.omit()</code></pre>
</div>
<div id="treino-e-teste" class="section level2">
<h2>Treino e teste</h2>
<p>Será utilizado tanto o método de hold-out e de cross-validation</p>
<pre class="r"><code>set.seed(825)
particao = sample(1:2,nrow(full), replace = T,prob = c(0.7,0.3))

train = full[particao==1,] 
test = full[particao==2,] 

library(caret)</code></pre>
</div>
<div id="ajustando-modelos" class="section level2">
<h2>Ajustando modelos</h2>
<div id="knn" class="section level3">
<h3>KNN</h3>
<p>É uma técnica de aprendizado baseado em instância, isto quer dizer que a classificação de uma observação com a classe desconhecida é realizada a partir da comparação com outras observações cada vez que uma observação é apresentado ao modelo e também é conhecido como “lazy evaluation,” já que um modelo não é induzido previamente.</p>
<p>Diversas medidas de distância podem ser utilizadas, utilizarei aqui a euclideana e além disso a escolha do parâmetro <span class="math inline">\(k\)</span> (de k vizinhos mais próximos) deve ser feita com cuidado pois um <span class="math inline">\(k\)</span> pequeno pode expor o algorítimo a uma alta sensibilidade a um ruído.</p>
<p>Utilizarei aqui o pacote <code>caret</code> como ferramenta para o ajuste deste modelo pois ela permite que eu configure que seja feita a validação cruzada em conjunto com a padronização, pois esses complementos beneficiam no ajuste de modelos que calculam distâncias.</p>
<pre class="r"><code># knn -------
set.seed(825)
antes = Sys.time()
book_knn &lt;- train(book ~.,
                  data=train,
                 method = &quot;knn&quot;,
                 trControl = trainControl(method = &quot;cv&quot;,number = 10), # validacao cruzada
                 preProc = c(&quot;center&quot;, &quot;scale&quot;))                      
time_knn &lt;- Sys.time() - antes 
Sys.time() - antes</code></pre>
<pre><code>## Time difference of 2.465522 secs</code></pre>
<pre class="r"><code>plot(book_knn)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/knn-1.png" width="672" /></p>
<pre class="r"><code>previsao  = predict(book_knn, test)
confusionMatrix(previsao, factor(test$book))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction arg  br
##        arg 105   8
##        br    5 371
##                                          
##                Accuracy : 0.9734         
##                  95% CI : (0.955, 0.9858)
##     No Information Rate : 0.7751         
##     P-Value [Acc &gt; NIR] : &lt;2e-16         
##                                          
##                   Kappa : 0.9245         
##                                          
##  Mcnemar&#39;s Test P-Value : 0.5791         
##                                          
##             Sensitivity : 0.9545         
##             Specificity : 0.9789         
##          Pos Pred Value : 0.9292         
##          Neg Pred Value : 0.9867         
##              Prevalence : 0.2249         
##          Detection Rate : 0.2147         
##    Detection Prevalence : 0.2311         
##       Balanced Accuracy : 0.9667         
##                                          
##        &#39;Positive&#39; Class : arg            
## </code></pre>
<pre class="r"><code>df = cbind(fit = if_else(previsao==&quot;br&quot;,1,0), class = if_else(test$book==&quot;br&quot;,1,0)) %&gt;% as.data.frame()
plot_pred_type_distribution(df,0.5)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/knn-2.png" width="672" /></p>
<p>Como podemos ver, segundo a validação cruzada realizada com o pacote <code>caret</code>, o número 5 de vizinhos mais próximos foi o que apresentou o melhor resultado. Além disso o modelo apresentou uma acurácia de 97,18% e isto parece bom dado que a sensibilidade (taxa de verdadeiros positivos) e a especificidade (taxa de verdadeiros negativos) foram altas também, o que foi reforçado com o gráfico ilustrado da matriz de confusão.</p>
<p>O tempo computacional para o ajuste do modelo foi de:2.46385908126831 segundos</p>
</div>
<div id="random-forest" class="section level3">
<h3>Random Forest</h3>
<p>O modelo de Random Forest tem se tornado muito popular devido ao seu bom desempenho e pela sua alta capacidade de se adaptar aos dados. O modelo funciona através da combinação de várias árvores de decisões e no seu ajuste alguns parâmetros precisam ser levados em conta.</p>
<p>O parâmetro que sera levado em conta para o ajuste será apenas o <code>ntree</code>, que representa o número de árvores ajustadas. Este parâmetro deve ser escolhido com cuidado pois pode ser tão grande quanto você quiser e continua aumentando a precisão até certo ponto porém pode ser mais limitado pelo tempo computacional disponível.</p>
<pre class="r"><code>set.seed(824)
# Random Forest
antes = Sys.time()
book_rf &lt;- train(book ~.,
                  data=train,
                     method = &quot;rf&quot;,trace=F,
                     ntree = 200,
                     trControl = trainControl(method = &quot;cv&quot;,number = 10))
time_rf &lt;- Sys.time() - antes 
Sys.time() - antes</code></pre>
<pre><code>## Time difference of 8.994044 secs</code></pre>
<pre class="r"><code>library(randomForest)
varImpPlot(book_rf$finalModel)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/rf-1.png" width="672" /></p>
<pre class="r"><code>previsao  = predict(book_rf, test)
confusionMatrix(previsao, factor(test$book))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction arg  br
##        arg 110   0
##        br    0 379
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9925, 1)
##     No Information Rate : 0.7751     
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
##                                      
##                   Kappa : 1          
##                                      
##  Mcnemar&#39;s Test P-Value : NA         
##                                      
##             Sensitivity : 1.0000     
##             Specificity : 1.0000     
##          Pos Pred Value : 1.0000     
##          Neg Pred Value : 1.0000     
##              Prevalence : 0.2249     
##          Detection Rate : 0.2249     
##    Detection Prevalence : 0.2249     
##       Balanced Accuracy : 1.0000     
##                                      
##        &#39;Positive&#39; Class : arg        
## </code></pre>
<pre class="r"><code># https://www.r-bloggers.com/illustrated-guide-to-roc-and-auc/
df = cbind(fit = if_else(previsao==&quot;br&quot;,1,0), class = if_else(test$book==&quot;br&quot;,1,0)) %&gt;% as.data.frame()
plot_pred_type_distribution(df,0.5)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/rf-2.png" width="672" /></p>
<p>Segundo o gráfico de importância, parece que as palavras “brasil,” “argentina,” “copa” e “messi” foram as que apresentaram maior impacto do preditor (lembrando que essa medida não é um efeito específico), o que mostra que a presença das palavras que estamos utilizando para classificar tiveram um impacto na classificação bastante superior aos demais.</p>
<p>Quanto a acurácia, o random forest apresentou valor um pouco maior do que o do algorítimo K-NN e além disso apresentou altos valores para a sensibilidade (taxa de verdadeiros positivos) e a especificidade (taxa de verdadeiros negativos), o que foi reforçado com o gráfico ilustrado da matriz de confusão, porém o tempo computacional utilizado para ajustar este modelo foi muito maior, o que leva a questionar se esse pequeno aumento na taxa de acerto vale a pena aumentando tanto no tempo de processamento (outra alternativa seria diminuir o tamanho do número de árvores para ver se melhoraria na qualidade do ajuste).</p>
<p>O tempo computacional para o ajuste do modelo foi de: 8.99299788475037 segundos</p>
</div>
<div id="naive-bayes" class="section level3">
<h3>Naive Bayes</h3>
<p>Este é um algorítimo que trata-se de um classificador estatístico baseado no <strong>Teorema de Bayes</strong> e recebe o nome de ingênuo (<em>naive</em>) porque pressupõe que o valor de um atributo que exerce algum efeito sobre a distribuição da variável resposta é independente do efeito que outros atributos.</p>
<p>O cálculo para a classificação é feito por meio do cálculo de probabilidades condicionais, ou seja, probabilidade de uma observação pertencer a cada classe dado os exemplares existentes no conjunto de dados usado para o treinamento.</p>
<pre class="r"><code># Naive Bayes ----
set.seed(825)
antes = Sys.time()
book_nb &lt;- train(book ~.,
                  data=train,
                 method= &quot;nb&quot;,
                 laplace =1,       
                 trControl = trainControl(method = &quot;cv&quot;,number = 10))
time_nb &lt;- Sys.time() - antes 
Sys.time() - antes</code></pre>
<pre><code>## Time difference of 7.141471 secs</code></pre>
<pre class="r"><code>previsao  = predict(book_nb, test)
confusionMatrix(previsao, factor(test$book))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction arg  br
##        arg 108   6
##        br    2 373
##                                          
##                Accuracy : 0.9836         
##                  95% CI : (0.968, 0.9929)
##     No Information Rate : 0.7751         
##     P-Value [Acc &gt; NIR] : &lt;2e-16         
##                                          
##                   Kappa : 0.9537         
##                                          
##  Mcnemar&#39;s Test P-Value : 0.2888         
##                                          
##             Sensitivity : 0.9818         
##             Specificity : 0.9842         
##          Pos Pred Value : 0.9474         
##          Neg Pred Value : 0.9947         
##              Prevalence : 0.2249         
##          Detection Rate : 0.2209         
##    Detection Prevalence : 0.2331         
##       Balanced Accuracy : 0.9830         
##                                          
##        &#39;Positive&#39; Class : arg            
## </code></pre>
<pre class="r"><code># https://www.r-bloggers.com/illustrated-guide-to-roc-and-auc/
df = cbind(fit = if_else(previsao==&quot;br&quot;,1,0), class = if_else(test$book==&quot;br&quot;,1,0)) %&gt;% as.data.frame()
plot_pred_type_distribution(df,0.5)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/nb-1.png" width="672" /></p>
<p>Apesar a aparente acurácia alta, o valor calculado para a especificidade (verdadeiros negativos) foi elevado o que aponta que o ajuste do modelo não se apresentou de forma eficiente</p>
<p>O tempo computacional foi de 7.1403751373291 segundos</p>
</div>
<div id="glm---logit" class="section level3">
<h3>GLM - Logit</h3>
<p>Este é um modelo estatístico que já abordei aqui no blog no post sobre <a href="https://gomesfellipe.github.io/post/2018-05-26-smarteademachinelearning/smarteademachinelearning/">AED de forma rápida e um pouco de machine learning</a> e seguindo a recomendação do artigo da datacamp vejamos quais resultados obtemos com o ajuste deste modelo:</p>
<pre class="r"><code># Modelo logístico ----
set.seed(825)
antes = Sys.time()
book_glm &lt;- train(book ~.,
                  data=train,
                  method = &quot;glm&quot;,                                         # modelo generalizado
                  family = binomial(link = &#39;logit&#39;),                      # Familia Binomial ligacao logit
                  trControl = trainControl(method = &quot;cv&quot;, number = 10))   # validacao cruzada
time_glm &lt;- Sys.time() - antes 
Sys.time() - antes</code></pre>
<pre><code>## Time difference of 1.378149 secs</code></pre>
<pre class="r"><code>library(ggfortify)

autoplot(book_glm$finalModel, which = 1:6, data = train,
         colour = &#39;book&#39;, label.size = 3,
         ncol = 3) + theme_classic()</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/glm-1.png" width="672" /></p>
<pre class="r"><code>previsao  = predict(book_glm, test)
confusionMatrix(previsao, factor(test$book))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction arg  br
##        arg 109   0
##        br    1 379
##                                           
##                Accuracy : 0.998           
##                  95% CI : (0.9887, 0.9999)
##     No Information Rate : 0.7751          
##     P-Value [Acc &gt; NIR] : &lt;2e-16          
##                                           
##                   Kappa : 0.9941          
##                                           
##  Mcnemar&#39;s Test P-Value : 1               
##                                           
##             Sensitivity : 0.9909          
##             Specificity : 1.0000          
##          Pos Pred Value : 1.0000          
##          Neg Pred Value : 0.9974          
##              Prevalence : 0.2249          
##          Detection Rate : 0.2229          
##    Detection Prevalence : 0.2229          
##       Balanced Accuracy : 0.9955          
##                                           
##        &#39;Positive&#39; Class : arg             
## </code></pre>
<pre class="r"><code>df = cbind(fit = if_else(previsao==&quot;br&quot;,1,0), class = if_else(test$book==&quot;br&quot;,1,0)) %&gt;% as.data.frame()
plot_pred_type_distribution(df,0.5)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/glm-2.png" width="672" /></p>
</div>
</div>
</div>
<div id="comparando-modelos" class="section level1">
<h1>Comparando modelos</h1>
<p>Agora que temos 4 modelos ajustados e cada um apresentando resultados diferentes, vejamos qual deles seria o mais interessante para caso fosse necessário recuperar a classificação dos termos pesquisados através da API, veja a seguir um resumo das medidas obtidas:</p>
<pre class="r"><code># &quot;Dados esses modelos, podemos fazer declarações estatísticas sobre suas diferenças de desempenho? Para fazer isso, primeiro coletamos os resultados de reamostragem usando resamples.&quot; - caret
resamps &lt;- resamples(list(knn = book_knn,
                          rf = book_rf,
                          nb = book_nb,
                          glm = book_glm)) 
summary(resamps)</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = resamps)
## 
## Models: knn, rf, nb, glm 
## Number of resamples: 10 
## 
## Accuracy 
##          Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&#39;s
## knn 0.9553571 0.9821824 0.9823009 0.9831305 0.9889381    1    0
## rf  0.9823009 1.0000000 1.0000000 0.9973451 1.0000000    1    0
## nb  0.9107143 0.9623894 0.9823009 0.9768726 1.0000000    1    0
## glm 0.9910714 0.9911504 1.0000000 0.9964523 1.0000000    1    0
## 
## Kappa 
##          Min.   1st Qu.    Median      Mean   3rd Qu. Max. NA&#39;s
## knn 0.8730734 0.9500663 0.9512773 0.9530901 0.9691458    1    0
## rf  0.9513351 1.0000000 1.0000000 0.9926689 1.0000000    1    0
## nb  0.7791798 0.8998204 0.9525409 0.9398109 1.0000000    1    0
## glm 0.9752868 0.9753544 1.0000000 0.9901350 1.0000000    1    0</code></pre>
<p>Como podemos ver, o modelo que apresentou a menor acurácia e o menor coeficiente kappa foi o Naive Bayes enquanto que o que apresentou as maiores medidas de qualidade do ajuste foi o modelo ajustado com o algorítimo Random Forest e tanto o modelo ajustado pelo algorítimo knn quanto o modelo linear generalizado com função de ligação “logit” também apresentaram acurácia e coeficiente kappa próximos do apresentado no ajuste do Random Forest.</p>
<p>Portanto, apesar dos ajustes, caso dois modelos não apresentem diferença estatisticamente significante e o tempo computacional gasto para o ajuste de ambos for muito diferente pode ser que ser que tenhamos um modelo candidato para:</p>
<pre class="r"><code>c( knn= time_knn,rf = time_rf,nb = time_nb,glm = time_glm)</code></pre>
<pre><code>## Time differences in secs
##      knn       rf       nb      glm 
## 2.463859 8.992998 7.140375 1.377073</code></pre>
<p>O modelo linear generalizado foi o que apresentou o menor tempo computacional e foi o que apresentou o terceiro maior registro para os as medidas de qualidade do ajuste dos modelos, portanto esse modelo será avaliado com mais cuidado em seguida para saber se ele será o modelo selecionado</p>
<p><strong>Obs.:</strong> Sou suspeito para falar mas dentre esses modelos eu teria preferência por este modelo de qualquer maneira por não se tratar de uma “caixa preta,” da qual todos os efeitos de cada parâmetro ajustado podem ser interpretado, além de obter medidas como razões de chance que ajudam bastante na compreensão dos dados.</p>
<p>Comparando de forma visual:</p>
<pre class="r"><code>splom(resamps)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Assim fica mais claro o como o ajuste dos modelos Random Forest, K-NN e GLM se destacaram quando avaliados em relação a acurácia apresentada.</p>
<p>Vejamos a seguir como foi a distribuição dessas medidas de acordo com cada modelo através de boxplots:</p>
<pre class="r"><code>bwplot(resamps)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>Note que além de apresentar os ajustes com menor acurácia (e elevada taxa de falsos negativos) o algorítimo Naive Bayes foi o que apresentou a maior variação interquartil das medidas de qualidade do ajuste do modelo.</p>
<p>Para finalizar a análise visual vamos obter as diferenças entre os modelos com a função <code>diff()</code> e em seguida conferir de maneira visual o comportamento dessas informações:</p>
<pre class="r"><code>difValues &lt;- diff(resamps)

# plot:
bwplot(difValues)</code></pre>
<p><img src="/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>Observe que tanto o modelo logístico quando o ajuste com o algorítimo K-NN apresentaram valores muito próximos dos valores do ajuste do Random Forest e como já vimos o Random Forest foi o modelo que levou maior tempo computacional para ser ajustado, portanto vamos conferir a seguir se existe diferença estatisticamente significante entre os valores obtidos através de cada um dos ajustes e decidir qual dos modelos se apresentou de maneira mais adequada para nosso caso:</p>
<pre class="r"><code>resamps$values %&gt;% 
  select_if(is.numeric) %&gt;% 
  purrr::map(function(x) shapiro.test(x))</code></pre>
<pre><code>## $`knn~Accuracy`
## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.87602, p-value = 0.1174
## 
## 
## $`knn~Kappa`
## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.87418, p-value = 0.1118
## 
## 
## $`rf~Accuracy`
## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.53165, p-value = 8.564e-06
## 
## 
## $`rf~Kappa`
## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.53234, p-value = 8.727e-06
## 
## 
## $`nb~Accuracy`
## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.80077, p-value = 0.01482
## 
## 
## $`nb~Kappa`
## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.81793, p-value = 0.02392
## 
## 
## $`glm~Accuracy`
## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.6429, p-value = 0.0001803
## 
## 
## $`glm~Kappa`
## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.64123, p-value = 0.0001722</code></pre>
<p>Como a hipótese de normalidade não foi rejeitada para nenhuma das amostras de acurácias registradas, vejamos se existe diferença estatisticamente significante entre as médias dessas medidas de qualidade para cada modelo:</p>
<pre class="r"><code>t.test(resamps$values$`rf~Accuracy`,resamps$values$`knn~Accuracy`, paired = T)  </code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  resamps$values$`rf~Accuracy` and resamps$values$`knn~Accuracy`
## t = 3.9961, df = 9, p-value = 0.003129
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.0061678 0.0222614
## sample estimates:
## mean of the differences 
##               0.0142146</code></pre>
<p>Rejeita a hipótese de que as médias das acurácias calculadas para o ajuste do algorítimo Random Forest e K-NN foram iguais</p>
<pre class="r"><code>t.test(resamps$values$`rf~Accuracy`,resamps$values$`glm~Accuracy`, paired = T)  </code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  resamps$values$`rf~Accuracy` and resamps$values$`glm~Accuracy`
## t = 0.43326, df = 9, p-value = 0.675
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.003768926  0.005554640
## sample estimates:
## mean of the differences 
##            0.0008928571</code></pre>
<p>Novamente, rejeita-se a hipótese de que as médias das acurácias calculadas para o ajuste do algorítimo Random Forest e do modelo de logístico foram iguais</p>
<pre class="r"><code>t.test(resamps$values$`knn~Accuracy`,resamps$values$`glm~Accuracy`, paired = T)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  resamps$values$`knn~Accuracy` and resamps$values$`glm~Accuracy`
## t = -4.0077, df = 9, p-value = 0.003074
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.020841197 -0.005802292
## sample estimates:
## mean of the differences 
##             -0.01332174</code></pre>
<p>Já para a comparação entre as médias das acurácias calculadas para o algorítimo K-NN e para o modelo logístico não houve evidências estatísticas para se rejeitas a hipótese de que ambas as médias são iguais, o que nos sugere o modelo logístico como o segundo melhor candidato como modelo de classificação para este problema com estes dados.</p>
<p>Então a escolha ficará a critério do que é mais importante. Caso o tempo computacional fosse uma medida que tivesse mais importância do que a pequena superioridade de acurácia apresentada pelo algorítimo Random Forest, escolheria o modelo logístico, porém como neste caso os 7.61592507362366 segundos a mais para ajustar o modelo não fazem diferença para mim, fico com o modelo Random Forest.</p>
<p>Este post trás alguns dos conceitos que venho estudado e existem muitos tópicos apresentados aqui que podem (e devem) ser estudados com mais profundidade, espero que tenha gostado!</p>
</div>
<div id="referências" class="section level1">
<h1>Referências</h1>
<p>obs.: links mensionados no corpo do texto</p>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-caret" class="csl-entry">
Kuhn, Max. 2018. <em>The Caret Package</em>. <a href="https://topepo.github.io/caret/index.html">https://topepo.github.io/caret/index.html</a>.
</div>
<div id="ref-tidytext" class="csl-entry">
Silge; Robinson, Julia; David. 2018. <em>Text Mining with R</em>. <em>A Tidy Approach</em>. <a href="https://www.tidytextmining.com/">https://www.tidytextmining.com/</a>.
</div>
<div id="ref-miner" class="csl-entry">
Silva; Peres; Boscarioli, Leandro Augusto; Sarajane Marques; Clodis. 2016. <em>Introdução à Mineração de Dados</em>. <em>Com Aplicações Em R</em>. Vol. 3. Elsevier Editora Ltda.
</div>
</div>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2018-06-24-brasil-argentina-tidytext-ml/brasil-argentina-tidytext-ml/">Brasil x Argentina, tidytext e Machine Learning</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Analise Exploratória</category>
      <category>Aprendizado Não Supervisionado</category>
      <category>Data mining</category>
      <category>Estatistica</category>
      <category>Machine Learning</category>
      <category>Modelagem Estatistica</category>
      <category>Prática</category>
      <category>R</category>
      <category>Text Mining</category>
      <category>Análise de Sentimentos</category>
      <category domain="tag">Data Mining</category>
      <category domain="tag">Estatistica</category>
      <category domain="tag">gomesfellipe</category>
      <category domain="tag">twitter</category>
      <category domain="tag">modelagem</category>
      <category domain="tag">Prática</category>
      <category domain="tag">R</category>
      <category domain="tag">text mining</category>
    </item>
    <item>
      <title>AED de forma rápida e um pouco de Machine Learning</title>
      <link>https://gomesfellipe.github.io/post/2018-05-26-smarteademachinelearning/smarteademachinelearning/</link>
      <pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate>
      <author>gomes.fellipe1@gmail.com (Fellipe Carvalho Gomes)</author>
      <guid>https://gomesfellipe.github.io/post/2018-05-26-smarteademachinelearning/smarteademachinelearning/</guid>
      <description>Veja como é possível realizar a AED de forma muito rápida com o pacote SmartEAD, além de uma breve aplicação de técnicas de machine learning e estatística para ilustrar alguns possíveis cenários da analise da dados</description>
      <content:encoded>&lt;![CDATA[
        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/pagedtable/css/pagedtable.css" rel="stylesheet" />
<script src="/rmarkdown-libs/pagedtable/js/pagedtable.js"></script>


<style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
  .col3 {
    columns: 3 100px;
    -webkit-columns: 3 100px;
    -moz-columns: 3 100px;
  }
</style>
<!-- Resumo: Neste post mostro como é possível realizar a AED de forma muito rápida com o pacote SmartEAD, e aplico algumas técnicas de machine learning e estatística para ilustrar alguns possíveis cenários-->
<div id="a-análise-exploratória-dos-dados" class="section level1">
<h1>A análise exploratória dos dados</h1>
<div class="col2">
<p>A análise exploratória dos dados (AED) foi um termo que ganhou bastante popularidade quando Tukey publicou o livro Exploratory Data Analysis em 1977 que tratava uma “busca por conhecimento antes da análise de dados de fato”. Ocorre quando busca-se obter informações ocultas sobre os dados, tais como: variação, anomalias, distribuição, tendências, padrões e relações</p>
<p>Ao iniciar uma análise de dados, começamos pela AED para a partir dai decidir como buscar qual solução para o problema. É importante frisar que a AED e a construção de gráficos <strong>não</strong> são a mesma coisa, mesmo a AED sendo altamente baseada em produção de gráficos como de dispersão, histogramas, boxplots etc.</p>
<p>Por vezes a AED no R pode envolver a produção de longos scripts utilizando funções como as do pacote <code>ggplot2</code> e mesmo sabendo que desejamos sempre criar o gráfico de maneira mais informativa e atraente possível, as vezes precisamos ter uma noção geral dos dados de forma rápida, não necessariamente tão detalhada e customizada de cara.</p>
<p>A vezes queremos apenas ter uma primeira impressão dos dados e em seguida pensar em quais os gráficos mais se adequariam para a entrega dos resultados que mesmo as funções base do R dependendo do caso também envolvem a confecção de longos scripts.</p>
<p>Existem pacotes que auxiliam na hora de se fazer uma rápida análise exploratória, como o <a href="https://github.com/ropenscilabs/skimr">skimr</a> e o <a href="https://github.com/boxuancui/DataExplorer">DataExplorer</a>. Porém estava pesquisando de existiam mais opções para uma rápida abordagem de AED e me deparei com esta <a href="https://cran.r-project.org/web/packages/SmartEDA/vignettes/Report_r1.html">vinheta</a>, por Dayanand, Kiran, Ravi.</p>
<p>Essa vinheta apresenta o pacote <a href="https://cran.r-project.org/web/packages/SmartEDA"><code>SmartEAD</code></a> que trás uma série de funções que auxiliam na AED de forma bem prática. O pacote está disponível no CRAN.</p>
<p>Para testar o pacote foi utilizada uma base de dados do artigo <a href="http://people.stern.nyu.edu/wgreene/Lugano2013/Fair-ExtramaritalAffairs.pdf">A Theory of Extramarital Affairs</a>, publicado pela <a href="http://www.jstor.org/publisher/ucpress">The University of Chicago Press</a>.</p>
<p>Gostei tanto da proposta do pacote que resolvi preparar este post que conta com a explanação de alguns tópicos apresentados pelo autor, algumas explicações da teoria estatística apresentada na análise descritiva e exploratória dos dados e além da aplicação de algumas técnicas estatísticas e de machine learning para o entendimento da base de dados.</p>
</div>
<p></br></p>
</div>
<div id="smarteda" class="section level1">
<h1>SmartEDA</h1>
<p>Como ele pode ajudá-lo a criar uma análise de dados exploratória? O <code>SmartEDA</code> inclui várias funções personalizadas para executar uma análise exploratória inicial em qualquer dado de entrada. A saída gerada pode ser obtida em formato resumido e gráfico e os resultados também podem ser exportados como relatórios.</p>
<p>O pacote SmartEDA ajuda a construir uma boa base de compreensão de dados, algumas de suas funcionalidades são:</p>
<ul>
<li>O pacote SmartEDA fará com que você seja capaz de aplicar diferentes tipos de EDA sem ter que lembre-se dos diferentes nomes dos pacotes R e escrever longos scripts R com esforço manual para preparar o relatório da EDA, permitindo o entendimento dos dados de maneira mais rápida</li>
<li>Não há necessidade de categorizar as variáveis em caractere, numérico, fator etc. As funções do SmartEDA categorizam automaticamente todos os recursos no tipo de dados correto (caractere, numérico, fator etc.) com base nos dados de entrada.</li>
</ul>
<p>O pacote SmartEDA ajuda a obter a análise completa dos dados exploratórios apenas executando a função em vez de escrever um longo código r.</p>
<div id="carregando-o-pacote" class="section level2">
<h2>Carregando o pacote:</h2>
<pre class="r"><code># install.packages(&quot;SmartEDA&quot;)
library(&quot;SmartEDA&quot;)</code></pre>
<p>outros pactes que serão utilizados no post (incluindo um script com algumas funções, que estará disponível no meu github <a href="https://github.com/gomesfellipe/gomesfellipe.github.io/blob/master/post/2018-05-26-smarteademachinelearning/functions.R">neste link</a>).</p>
<pre class="r"><code>library(knitr)        # Para tabelas interativas
library(DT)           # Para tabelas interativas
library(dplyr)        # Para manipulacao de dados
library(plotly)       # Para gerar uma tabela
library(psych)        # para análise fatorial
source(&quot;functions.R&quot;) # script com funcoes customizadas</code></pre>
<div id="base-de-dados-utilizada" class="section level3">
<h3>Base de dados utilizada:</h3>
<div class="col2">
<p>Estava à procura de uma base de dados para testar as funcionalidades do pacote <code>SmartEAD</code> quando um colega de trabalho me mostrou um artigo chamado <a href="http://people.stern.nyu.edu/wgreene/Lugano2013/Fair-ExtramaritalAffairs.pdf">A Theory of Extramarital Affairs</a>, publicado pela <a href="http://www.jstor.org/publisher/ucpress">The University of Chicago Press</a>. Neste artigo é desenvolvido um <a href="https://en.wikipedia.org/wiki/Tobit_model">modelo pelo estimador de Tobit</a> que explica a alocação de um tempo do indivíduo entre o trabalho e dois tipos de atividades de lazer: tempo passou com o cônjuge e tempo gasto com o amante.</p>
<p>Não conhecia o modelo proposto e em uma rápida pesquisa no Google notei que alguns dos dados utilizados nesse artigo estão disponíveis no pacote <a href="ftp://cran.r-project.org/pub/R/web/packages/AER">AER</a> de Econometria Aplicada com R, que contém funções, conjuntos de dados, exemplos, demonstrações e vinhetas para o livro <a href="http://jrsyzx.njau.edu.cn/__local/C/94/F1/35C7CC5EDA214D4AAE7FE2BA0FD_0D3DFF32_3CDD40.pdf?e=.pdf">Applied Econometrics with R</a> e como esses dados já foram tratados e estão “prontos para análise”, resolvi usar essa amostra pela conveniência.</p>
<p>Portanto farei aqui uma análise exploratória e ao final de cada caso (<em>sem variável reposta</em>, <em>com variável resposta numérica</em> e <em>com variável resposta binária</em>), para ter uma breve intuição de como se comportam os dados irei primeiro utilizar um <em>algorítimo de machine learning não supervisionado</em> para o agrupamento das observações (sem considerar q já conhecemos a variável resposta), depois ajustar um* modelo de regressão linear simples* considerando a variável resposta como numérica e por fim o ajuste de um <em>algorítimo de machine learning supervisonado de classificação</em> após discretizar a variável resposta.</p>
<p>A base de dados pode ser conferida a seguir:</p>
</div>
<pre class="r"><code>library(AER)
data(Affairs)
Affairs %&gt;% rmarkdown::paged_table()</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["affairs"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["gender"],"name":[2],"type":["fct"],"align":["left"]},{"label":["age"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["yearsmarried"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["children"],"name":[5],"type":["fct"],"align":["left"]},{"label":["religiousness"],"name":[6],"type":["int"],"align":["right"]},{"label":["education"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["occupation"],"name":[8],"type":["int"],"align":["right"]},{"label":["rating"],"name":[9],"type":["int"],"align":["right"]}],"data":[{"1":"0","2":"male","3":"37.0","4":"10.000","5":"no","6":"3","7":"18","8":"7","9":"4","_rn_":"4"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"no","6":"4","7":"14","8":"6","9":"4","_rn_":"5"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"1","7":"12","8":"1","9":"4","_rn_":"11"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"5","7":"18","8":"6","9":"5","_rn_":"16"},{"1":"0","2":"male","3":"22.0","4":"0.750","5":"no","6":"2","7":"17","8":"6","9":"3","_rn_":"23"},{"1":"0","2":"female","3":"32.0","4":"1.500","5":"no","6":"2","7":"17","8":"5","9":"5","_rn_":"29"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"2","7":"12","8":"1","9":"3","_rn_":"44"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"2","7":"14","8":"4","9":"4","_rn_":"45"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"16","8":"1","9":"2","_rn_":"47"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"4","7":"14","8":"4","9":"5","_rn_":"49"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"2","7":"20","8":"7","9":"2","_rn_":"50"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"4","7":"18","8":"6","9":"4","_rn_":"55"},{"1":"0","2":"male","3":"47.0","4":"15.000","5":"yes","6":"5","7":"17","8":"6","9":"4","_rn_":"64"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"17","8":"5","9":"4","_rn_":"80"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"no","6":"4","7":"14","8":"5","9":"4","_rn_":"86"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"1","7":"17","8":"5","9":"5","_rn_":"93"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"18","8":"4","9":"3","_rn_":"108"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"3","7":"16","8":"5","9":"4","_rn_":"114"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"16","8":"5","9":"5","_rn_":"115"},{"1":"0","2":"female","3":"27.0","4":"10.000","5":"yes","6":"2","7":"14","8":"1","9":"5","_rn_":"116"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"16","8":"5","9":"5","_rn_":"123"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"16","8":"5","9":"5","_rn_":"127"},{"1":"0","2":"female","3":"27.0","4":"10.000","5":"yes","6":"4","7":"16","8":"5","9":"4","_rn_":"129"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"3","7":"14","8":"1","9":"5","_rn_":"134"},{"1":"0","2":"male","3":"37.0","4":"4.000","5":"yes","6":"2","7":"20","8":"6","9":"4","_rn_":"137"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"18","8":"5","9":"5","_rn_":"139"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"no","6":"4","7":"16","8":"1","9":"5","_rn_":"147"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"5","7":"20","8":"6","9":"4","_rn_":"151"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"3","7":"16","8":"5","9":"5","_rn_":"153"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"3","7":"17","8":"5","9":"4","_rn_":"155"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"3","_rn_":"162"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"3","7":"16","8":"5","9":"5","_rn_":"163"},{"1":"0","2":"male","3":"27.0","4":"0.417","5":"no","6":"4","7":"17","8":"6","9":"4","_rn_":"165"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"5","7":"14","8":"5","9":"4","_rn_":"168"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"yes","6":"1","7":"18","8":"6","9":"4","_rn_":"170"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"4","7":"16","8":"5","9":"3","_rn_":"172"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"12","8":"1","9":"4","_rn_":"184"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"no","6":"4","7":"17","8":"5","9":"5","_rn_":"187"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"yes","6":"1","7":"14","8":"3","9":"5","_rn_":"192"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"3","7":"16","8":"1","9":"5","_rn_":"194"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"5","7":"20","8":"6","9":"5","_rn_":"210"},{"1":"0","2":"male","3":"52.0","4":"15.000","5":"yes","6":"5","7":"18","8":"6","9":"3","_rn_":"217"},{"1":"0","2":"female","3":"22.0","4":"0.417","5":"no","6":"5","7":"14","8":"1","9":"4","_rn_":"220"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"2","7":"18","8":"6","9":"1","_rn_":"224"},{"1":"0","2":"female","3":"32.0","4":"7.000","5":"yes","6":"5","7":"17","8":"5","9":"3","_rn_":"227"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"no","6":"3","7":"16","8":"5","9":"5","_rn_":"228"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"18","8":"6","9":"5","_rn_":"239"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"2","7":"18","8":"5","9":"4","_rn_":"241"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"yes","6":"4","7":"16","8":"3","9":"5","_rn_":"245"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"2","7":"20","8":"6","9":"4","_rn_":"249"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"5","7":"14","8":"3","9":"5","_rn_":"262"},{"1":"0","2":"male","3":"32.0","4":"7.000","5":"yes","6":"2","7":"20","8":"6","9":"4","_rn_":"265"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"5","7":"20","8":"6","9":"5","_rn_":"267"},{"1":"0","2":"male","3":"27.0","4":"10.000","5":"yes","6":"4","7":"20","8":"6","9":"4","_rn_":"269"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"no","6":"1","7":"18","8":"5","9":"5","_rn_":"271"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"3","9":"1","_rn_":"277"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"yes","6":"5","7":"16","8":"4","9":"4","_rn_":"290"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"17","8":"1","9":"5","_rn_":"292"},{"1":"0","2":"female","3":"27.0","4":"0.750","5":"no","6":"4","7":"17","8":"5","9":"4","_rn_":"293"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"4","7":"20","8":"6","9":"4","_rn_":"295"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"5","7":"14","8":"7","9":"2","_rn_":"299"},{"1":"0","2":"male","3":"37.0","4":"10.000","5":"yes","6":"3","7":"20","8":"6","9":"4","_rn_":"320"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"2","7":"16","8":"5","9":"5","_rn_":"321"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"no","6":"2","7":"18","8":"4","9":"5","_rn_":"324"},{"1":"0","2":"male","3":"32.0","4":"7.000","5":"no","6":"4","7":"20","8":"6","9":"4","_rn_":"334"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"2","7":"17","8":"3","9":"5","_rn_":"351"},{"1":"0","2":"male","3":"37.0","4":"10.000","5":"yes","6":"4","7":"20","8":"6","9":"4","_rn_":"355"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"3","7":"17","8":"6","9":"5","_rn_":"361"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"5","7":"16","8":"5","9":"5","_rn_":"362"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"2","7":"16","8":"6","9":"4","_rn_":"366"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"no","6":"3","7":"17","8":"5","9":"5","_rn_":"370"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"5","7":"14","8":"4","9":"5","_rn_":"374"},{"1":"0","2":"female","3":"22.0","4":"0.125","5":"no","6":"2","7":"12","8":"5","9":"5","_rn_":"378"},{"1":"0","2":"male","3":"47.0","4":"15.000","5":"yes","6":"4","7":"14","8":"4","9":"3","_rn_":"381"},{"1":"0","2":"male","3":"32.0","4":"15.000","5":"yes","6":"1","7":"14","8":"5","9":"5","_rn_":"382"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"4","7":"16","8":"5","9":"5","_rn_":"383"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"yes","6":"3","7":"16","8":"5","9":"5","_rn_":"384"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"3","7":"17","8":"6","9":"5","_rn_":"400"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"3","7":"16","8":"5","9":"5","_rn_":"403"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"2","7":"14","8":"7","9":"2","_rn_":"409"},{"1":"0","2":"male","3":"17.5","4":"1.500","5":"yes","6":"3","7":"18","8":"6","9":"5","_rn_":"412"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"5","_rn_":"413"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"2","7":"16","8":"3","9":"4","_rn_":"416"},{"1":"0","2":"male","3":"42.0","4":"4.000","5":"no","6":"4","7":"17","8":"3","9":"3","_rn_":"418"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"yes","6":"4","7":"12","8":"1","9":"5","_rn_":"422"},{"1":"0","2":"female","3":"22.0","4":"0.417","5":"no","6":"1","7":"17","8":"6","9":"4","_rn_":"435"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"17","8":"5","9":"5","_rn_":"439"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"3","7":"18","8":"5","9":"2","_rn_":"445"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"yes","6":"3","7":"14","8":"1","9":"5","_rn_":"447"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"3","7":"14","8":"1","9":"4","_rn_":"448"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"14","8":"3","9":"4","_rn_":"449"},{"1":"0","2":"male","3":"37.0","4":"10.000","5":"yes","6":"2","7":"14","8":"5","9":"3","_rn_":"478"},{"1":"0","2":"male","3":"37.0","4":"10.000","5":"yes","6":"4","7":"16","8":"5","9":"4","_rn_":"482"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"5","7":"20","8":"5","9":"3","_rn_":"486"},{"1":"0","2":"male","3":"27.0","4":"0.417","5":"no","6":"1","7":"16","8":"3","9":"4","_rn_":"489"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"5","7":"14","8":"1","9":"5","_rn_":"490"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"3","7":"16","8":"6","9":"1","_rn_":"491"},{"1":"0","2":"male","3":"37.0","4":"10.000","5":"yes","6":"1","7":"16","8":"6","9":"4","_rn_":"492"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"3","7":"17","8":"5","9":"5","_rn_":"503"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"5","_rn_":"508"},{"1":"0","2":"female","3":"27.0","4":"10.000","5":"yes","6":"5","7":"14","8":"1","9":"5","_rn_":"509"},{"1":"0","2":"male","3":"37.0","4":"10.000","5":"yes","6":"2","7":"18","8":"6","9":"4","_rn_":"512"},{"1":"0","2":"female","3":"22.0","4":"0.125","5":"no","6":"4","7":"12","8":"4","9":"5","_rn_":"515"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"5","7":"20","8":"6","9":"5","_rn_":"517"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"18","8":"6","9":"4","_rn_":"532"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"yes","6":"4","7":"14","8":"6","9":"4","_rn_":"533"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"4","7":"18","8":"5","9":"4","_rn_":"535"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"4","7":"20","8":"5","9":"4","_rn_":"537"},{"1":"0","2":"male","3":"32.0","4":"15.000","5":"yes","6":"3","7":"14","8":"6","9":"3","_rn_":"538"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"14","8":"5","9":"4","_rn_":"543"},{"1":"0","2":"female","3":"32.0","4":"7.000","5":"yes","6":"4","7":"17","8":"1","9":"5","_rn_":"547"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"17","8":"6","9":"5","_rn_":"550"},{"1":"0","2":"female","3":"32.0","4":"1.500","5":"no","6":"5","7":"18","8":"5","9":"5","_rn_":"558"},{"1":"0","2":"male","3":"42.0","4":"10.000","5":"yes","6":"5","7":"20","8":"7","9":"4","_rn_":"571"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"no","6":"3","7":"16","8":"5","9":"4","_rn_":"578"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"no","6":"4","7":"20","8":"6","9":"5","_rn_":"583"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"3","9":"2","_rn_":"586"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"no","6":"5","7":"18","8":"6","9":"4","_rn_":"594"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"4","7":"16","8":"1","9":"5","_rn_":"597"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"12","8":"2","9":"4","_rn_":"602"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"2","7":"16","8":"2","9":"5","_rn_":"603"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"5","7":"18","8":"5","9":"4","_rn_":"604"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"17","8":"5","9":"3","_rn_":"612"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"2","7":"16","8":"1","9":"2","_rn_":"613"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"3","7":"16","8":"5","9":"5","_rn_":"621"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"5","7":"20","8":"6","9":"5","_rn_":"627"},{"1":"0","2":"female","3":"22.0","4":"0.125","5":"no","6":"2","7":"14","8":"4","9":"5","_rn_":"630"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"no","6":"4","7":"16","8":"5","9":"5","_rn_":"631"},{"1":"0","2":"male","3":"32.0","4":"1.500","5":"no","6":"2","7":"18","8":"6","9":"5","_rn_":"632"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"no","6":"2","7":"17","8":"6","9":"5","_rn_":"639"},{"1":"0","2":"female","3":"27.0","4":"10.000","5":"yes","6":"4","7":"16","8":"1","9":"3","_rn_":"645"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"18","8":"6","9":"5","_rn_":"647"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"2","7":"16","8":"6","9":"5","_rn_":"648"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"no","6":"2","7":"18","8":"6","9":"3","_rn_":"651"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"3","7":"14","8":"5","9":"3","_rn_":"655"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"18","8":"5","9":"4","_rn_":"667"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"2","7":"18","8":"6","9":"5","_rn_":"670"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"16","8":"1","9":"4","_rn_":"671"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"4","7":"20","8":"5","9":"5","_rn_":"673"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"no","6":"1","7":"20","8":"5","9":"4","_rn_":"701"},{"1":"0","2":"female","3":"27.0","4":"10.000","5":"yes","6":"2","7":"12","8":"1","9":"4","_rn_":"705"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"5","7":"18","8":"6","9":"4","_rn_":"706"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"5","7":"12","8":"5","9":"3","_rn_":"709"},{"1":"0","2":"male","3":"52.0","4":"15.000","5":"yes","6":"2","7":"18","8":"5","9":"4","_rn_":"717"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"no","6":"3","7":"20","8":"6","9":"3","_rn_":"719"},{"1":"0","2":"male","3":"37.0","4":"4.000","5":"yes","6":"1","7":"18","8":"5","9":"4","_rn_":"723"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"4","7":"14","8":"5","9":"4","_rn_":"724"},{"1":"0","2":"female","3":"52.0","4":"15.000","5":"yes","6":"5","7":"12","8":"1","9":"3","_rn_":"726"},{"1":"0","2":"female","3":"57.0","4":"15.000","5":"yes","6":"4","7":"16","8":"6","9":"4","_rn_":"734"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"1","7":"16","8":"5","9":"4","_rn_":"735"},{"1":"0","2":"male","3":"37.0","4":"7.000","5":"yes","6":"4","7":"20","8":"6","9":"3","_rn_":"736"},{"1":"0","2":"male","3":"22.0","4":"0.750","5":"no","6":"2","7":"14","8":"4","9":"3","_rn_":"737"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"yes","6":"2","7":"18","8":"5","9":"3","_rn_":"739"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"3","_rn_":"743"},{"1":"0","2":"male","3":"22.0","4":"0.750","5":"yes","6":"2","7":"14","8":"4","9":"3","_rn_":"745"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"3","_rn_":"747"},{"1":"0","2":"female","3":"52.0","4":"15.000","5":"yes","6":"5","7":"17","8":"1","9":"1","_rn_":"751"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"1","9":"2","_rn_":"752"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"4","7":"14","8":"5","9":"3","_rn_":"754"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"yes","6":"2","7":"16","8":"5","9":"5","_rn_":"760"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"2","7":"18","8":"6","9":"5","_rn_":"763"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"2","7":"18","8":"5","9":"5","_rn_":"774"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"5","7":"18","8":"6","9":"5","_rn_":"776"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"5","7":"12","8":"5","9":"4","_rn_":"779"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"3","7":"17","8":"1","9":"4","_rn_":"784"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"yes","6":"4","7":"17","8":"1","9":"2","_rn_":"788"},{"1":"0","2":"female","3":"57.0","4":"15.000","5":"yes","6":"2","7":"18","8":"5","9":"2","_rn_":"794"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"4","7":"14","8":"5","9":"4","_rn_":"795"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"3","7":"14","8":"3","9":"4","_rn_":"798"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"4","7":"9","8":"2","9":"2","_rn_":"800"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"5","_rn_":"803"},{"1":"0","2":"female","3":"22.0","4":"0.125","5":"no","6":"4","7":"14","8":"4","9":"5","_rn_":"807"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"4","7":"14","8":"1","9":"5","_rn_":"812"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"18","8":"5","9":"4","_rn_":"820"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"2","7":"18","8":"6","9":"5","_rn_":"823"},{"1":"0","2":"male","3":"32.0","4":"0.125","5":"yes","6":"2","7":"18","8":"5","9":"2","_rn_":"830"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"no","6":"3","7":"16","8":"5","9":"4","_rn_":"843"},{"1":"0","2":"female","3":"27.0","4":"10.000","5":"yes","6":"2","7":"16","8":"1","9":"4","_rn_":"848"},{"1":"0","2":"female","3":"32.0","4":"7.000","5":"yes","6":"4","7":"16","8":"1","9":"3","_rn_":"851"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"5","9":"4","_rn_":"854"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"5","7":"17","8":"6","9":"2","_rn_":"856"},{"1":"0","2":"male","3":"32.0","4":"1.500","5":"yes","6":"4","7":"14","8":"6","9":"5","_rn_":"857"},{"1":"0","2":"female","3":"32.0","4":"4.000","5":"yes","6":"3","7":"17","8":"5","9":"3","_rn_":"859"},{"1":"0","2":"female","3":"37.0","4":"7.000","5":"no","6":"4","7":"18","8":"5","9":"5","_rn_":"863"},{"1":"0","2":"female","3":"22.0","4":"0.417","5":"yes","6":"3","7":"14","8":"3","9":"5","_rn_":"865"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"14","8":"1","9":"5","_rn_":"867"},{"1":"0","2":"male","3":"27.0","4":"0.750","5":"no","6":"3","7":"16","8":"5","9":"5","_rn_":"870"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"2","7":"20","8":"5","9":"5","_rn_":"873"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"4","7":"16","8":"4","9":"5","_rn_":"875"},{"1":"0","2":"male","3":"32.0","4":"15.000","5":"yes","6":"1","7":"14","8":"5","9":"5","_rn_":"876"},{"1":"0","2":"male","3":"22.0","4":"0.750","5":"no","6":"3","7":"17","8":"4","9":"5","_rn_":"877"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"17","8":"1","9":"4","_rn_":"880"},{"1":"0","2":"male","3":"27.0","4":"0.417","5":"yes","6":"4","7":"20","8":"5","9":"4","_rn_":"903"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"20","8":"5","9":"4","_rn_":"904"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"14","8":"1","9":"3","_rn_":"905"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"yes","6":"1","7":"18","8":"5","9":"4","_rn_":"908"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"17","8":"5","9":"3","_rn_":"909"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"14","8":"4","9":"5","_rn_":"910"},{"1":"0","2":"male","3":"52.0","4":"15.000","5":"yes","6":"4","7":"14","8":"6","9":"2","_rn_":"912"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"4","7":"17","8":"5","9":"5","_rn_":"914"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"yes","6":"5","7":"14","8":"3","9":"5","_rn_":"915"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"yes","6":"2","7":"14","8":"3","9":"5","_rn_":"916"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"3","7":"16","8":"6","9":"5","_rn_":"920"},{"1":"0","2":"male","3":"27.0","4":"0.750","5":"no","6":"2","7":"18","8":"3","9":"3","_rn_":"921"},{"1":"0","2":"female","3":"22.0","4":"7.000","5":"yes","6":"2","7":"14","8":"5","9":"2","_rn_":"925"},{"1":"0","2":"female","3":"27.0","4":"0.750","5":"no","6":"2","7":"17","8":"5","9":"3","_rn_":"926"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"12","8":"1","9":"2","_rn_":"929"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"1","7":"14","8":"1","9":"5","_rn_":"931"},{"1":"0","2":"female","3":"37.0","4":"10.000","5":"no","6":"2","7":"12","8":"4","9":"4","_rn_":"945"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"18","8":"5","9":"3","_rn_":"947"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"12","8":"3","9":"3","_rn_":"949"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"no","6":"2","7":"18","8":"5","9":"5","_rn_":"950"},{"1":"0","2":"male","3":"52.0","4":"7.000","5":"yes","6":"2","7":"20","8":"6","9":"2","_rn_":"961"},{"1":"0","2":"male","3":"27.0","4":"0.750","5":"no","6":"2","7":"17","8":"5","9":"5","_rn_":"965"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"no","6":"2","7":"17","8":"4","9":"5","_rn_":"966"},{"1":"0","2":"male","3":"42.0","4":"1.500","5":"no","6":"5","7":"20","8":"6","9":"5","_rn_":"967"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"4","7":"17","8":"6","9":"5","_rn_":"987"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"no","6":"4","7":"17","8":"5","9":"3","_rn_":"990"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"yes","6":"1","7":"14","8":"5","9":"4","_rn_":"992"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"5","7":"20","8":"4","9":"5","_rn_":"995"},{"1":"0","2":"female","3":"37.0","4":"10.000","5":"yes","6":"3","7":"16","8":"6","9":"3","_rn_":"1009"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"17","8":"6","9":"5","_rn_":"1021"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"4","7":"17","8":"5","9":"5","_rn_":"1026"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"4","7":"16","8":"5","9":"4","_rn_":"1027"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"3","7":"12","8":"1","9":"4","_rn_":"1030"},{"1":"0","2":"female","3":"22.0","4":"7.000","5":"yes","6":"1","7":"14","8":"3","9":"5","_rn_":"1031"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"4","7":"17","8":"5","9":"4","_rn_":"1034"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"yes","6":"2","7":"16","8":"2","9":"4","_rn_":"1037"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"5","9":"5","_rn_":"1038"},{"1":"0","2":"male","3":"42.0","4":"4.000","5":"yes","6":"3","7":"14","8":"4","9":"5","_rn_":"1039"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"5","7":"14","8":"5","9":"4","_rn_":"1045"},{"1":"0","2":"female","3":"32.0","4":"7.000","5":"yes","6":"4","7":"17","8":"5","9":"5","_rn_":"1046"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"4","7":"18","8":"6","9":"5","_rn_":"1054"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"no","6":"4","7":"18","8":"6","9":"4","_rn_":"1059"},{"1":"0","2":"male","3":"22.0","4":"0.750","5":"no","6":"4","7":"18","8":"6","9":"5","_rn_":"1063"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"4","7":"14","8":"5","9":"3","_rn_":"1068"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"5","7":"18","8":"1","9":"5","_rn_":"1070"},{"1":"0","2":"female","3":"52.0","4":"15.000","5":"yes","6":"5","7":"9","8":"5","9":"5","_rn_":"1072"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"3","7":"14","8":"5","9":"5","_rn_":"1073"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"16","8":"4","9":"4","_rn_":"1077"},{"1":"0","2":"male","3":"32.0","4":"7.000","5":"yes","6":"2","7":"20","8":"5","9":"4","_rn_":"1081"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"18","8":"1","9":"4","_rn_":"1083"},{"1":"0","2":"male","3":"32.0","4":"15.000","5":"yes","6":"1","7":"16","8":"5","9":"5","_rn_":"1084"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"3","7":"18","8":"5","9":"5","_rn_":"1086"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"12","8":"3","9":"4","_rn_":"1087"},{"1":"0","2":"male","3":"22.0","4":"0.750","5":"yes","6":"3","7":"14","8":"2","9":"4","_rn_":"1089"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"3","7":"16","8":"5","9":"3","_rn_":"1096"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"4","7":"14","8":"3","9":"5","_rn_":"1102"},{"1":"0","2":"female","3":"52.0","4":"15.000","5":"yes","6":"3","7":"16","8":"5","9":"4","_rn_":"1103"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"5","7":"20","8":"6","9":"4","_rn_":"1107"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"4","7":"12","8":"2","9":"3","_rn_":"1109"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"2","7":"20","8":"6","9":"4","_rn_":"1115"},{"1":"0","2":"male","3":"32.0","4":"7.000","5":"yes","6":"4","7":"17","8":"5","9":"5","_rn_":"1119"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"17","8":"1","9":"4","_rn_":"1124"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"1","7":"18","8":"6","9":"5","_rn_":"1126"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"yes","6":"3","7":"9","8":"1","9":"4","_rn_":"1128"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"14","8":"1","9":"5","_rn_":"1129"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"2","7":"20","8":"6","9":"4","_rn_":"1130"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"4","7":"9","8":"2","9":"4","_rn_":"1133"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"2","7":"18","8":"1","9":"5","_rn_":"1140"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"yes","6":"3","7":"14","8":"1","9":"5","_rn_":"1143"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"5","9":"3","_rn_":"1146"},{"1":"0","2":"male","3":"32.0","4":"7.000","5":"yes","6":"1","7":"18","8":"6","9":"4","_rn_":"1153"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"14","8":"5","9":"5","_rn_":"1156"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"yes","6":"3","7":"12","8":"1","9":"3","_rn_":"1157"},{"1":"0","2":"male","3":"52.0","4":"15.000","5":"yes","6":"2","7":"14","8":"5","9":"5","_rn_":"1158"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"14","8":"1","9":"1","_rn_":"1160"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"2","7":"14","8":"5","9":"5","_rn_":"1161"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"20","8":"4","9":"5","_rn_":"1166"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"3","7":"18","8":"4","9":"5","_rn_":"1177"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"5","_rn_":"1178"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"no","6":"3","7":"18","8":"5","9":"5","_rn_":"1180"},{"1":"0","2":"female","3":"22.0","4":"0.125","5":"no","6":"2","7":"16","8":"6","9":"3","_rn_":"1187"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"2","7":"20","8":"6","9":"3","_rn_":"1191"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"no","6":"4","7":"18","8":"5","9":"4","_rn_":"1195"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"2","7":"12","8":"5","9":"1","_rn_":"1207"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"yes","6":"5","7":"18","8":"6","9":"3","_rn_":"1208"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"17","8":"5","9":"5","_rn_":"1209"},{"1":"0","2":"male","3":"47.0","4":"15.000","5":"no","6":"4","7":"20","8":"6","9":"4","_rn_":"1211"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"no","6":"1","7":"18","8":"5","9":"5","_rn_":"1215"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"4","_rn_":"1221"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"18","8":"1","9":"4","_rn_":"1226"},{"1":"0","2":"female","3":"32.0","4":"7.000","5":"yes","6":"4","7":"17","8":"5","9":"4","_rn_":"1229"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"14","8":"1","9":"3","_rn_":"1231"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"3","7":"16","8":"1","9":"4","_rn_":"1234"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"no","6":"3","7":"16","8":"4","9":"2","_rn_":"1235"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"3","7":"16","8":"3","9":"5","_rn_":"1242"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"3","7":"16","8":"4","9":"2","_rn_":"1245"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"3","7":"12","8":"1","9":"2","_rn_":"1260"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"18","8":"5","9":"4","_rn_":"1266"},{"1":"0","2":"female","3":"37.0","4":"7.000","5":"yes","6":"3","7":"14","8":"4","9":"4","_rn_":"1271"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"2","7":"16","8":"5","9":"5","_rn_":"1273"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"5","7":"20","8":"5","9":"4","_rn_":"1276"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"4","7":"16","8":"5","9":"3","_rn_":"1280"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"4","7":"16","8":"1","9":"5","_rn_":"1282"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"no","6":"2","7":"17","8":"5","9":"3","_rn_":"1285"},{"1":"0","2":"female","3":"22.0","4":"0.417","5":"no","6":"4","7":"14","8":"5","9":"5","_rn_":"1295"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"no","6":"2","7":"18","8":"5","9":"5","_rn_":"1298"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"18","8":"5","9":"3","_rn_":"1299"},{"1":"0","2":"male","3":"37.0","4":"10.000","5":"yes","6":"5","7":"20","8":"7","9":"4","_rn_":"1304"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"2","7":"14","8":"4","9":"2","_rn_":"1305"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"yes","6":"2","7":"16","8":"5","9":"5","_rn_":"1311"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"yes","6":"2","7":"16","8":"6","9":"4","_rn_":"1314"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"3","7":"18","8":"4","9":"5","_rn_":"1319"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"yes","6":"4","7":"14","8":"3","9":"4","_rn_":"1322"},{"1":"0","2":"female","3":"17.5","4":"0.750","5":"no","6":"2","7":"18","8":"5","9":"4","_rn_":"1324"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"4","7":"20","8":"4","9":"5","_rn_":"1327"},{"1":"0","2":"female","3":"32.0","4":"0.750","5":"no","6":"5","7":"14","8":"3","9":"3","_rn_":"1328"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"17","8":"5","9":"3","_rn_":"1330"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"no","6":"3","7":"14","8":"4","9":"5","_rn_":"1332"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"2","7":"17","8":"3","9":"2","_rn_":"1333"},{"1":"0","2":"female","3":"22.0","4":"7.000","5":"yes","6":"4","7":"14","8":"1","9":"5","_rn_":"1336"},{"1":"0","2":"male","3":"47.0","4":"15.000","5":"yes","6":"5","7":"14","8":"6","9":"5","_rn_":"1341"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"1","7":"16","8":"4","9":"4","_rn_":"1344"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"5","7":"14","8":"1","9":"3","_rn_":"1352"},{"1":"0","2":"male","3":"42.0","4":"4.000","5":"yes","6":"4","7":"18","8":"5","9":"5","_rn_":"1358"},{"1":"0","2":"female","3":"32.0","4":"4.000","5":"yes","6":"2","7":"14","8":"1","9":"5","_rn_":"1359"},{"1":"0","2":"male","3":"52.0","4":"15.000","5":"yes","6":"2","7":"14","8":"7","9":"4","_rn_":"1361"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"16","8":"1","9":"4","_rn_":"1364"},{"1":"0","2":"male","3":"52.0","4":"15.000","5":"yes","6":"4","7":"12","8":"2","9":"4","_rn_":"1368"},{"1":"0","2":"female","3":"22.0","4":"0.417","5":"no","6":"3","7":"17","8":"1","9":"5","_rn_":"1384"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"16","8":"5","9":"5","_rn_":"1390"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"4","7":"20","8":"6","9":"4","_rn_":"1393"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"14","8":"1","9":"5","_rn_":"1394"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"2","7":"16","8":"3","9":"5","_rn_":"1402"},{"1":"0","2":"male","3":"32.0","4":"4.000","5":"no","6":"1","7":"20","8":"6","9":"5","_rn_":"1407"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"3","7":"20","8":"6","9":"4","_rn_":"1408"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"no","6":"2","7":"16","8":"6","9":"5","_rn_":"1412"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"5","7":"14","8":"5","9":"5","_rn_":"1413"},{"1":"0","2":"male","3":"37.0","4":"1.500","5":"yes","6":"4","7":"18","8":"5","9":"3","_rn_":"1416"},{"1":"0","2":"male","3":"32.0","4":"1.500","5":"no","6":"2","7":"18","8":"4","9":"4","_rn_":"1417"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"4","7":"14","8":"1","9":"4","_rn_":"1418"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"4","7":"18","8":"5","9":"4","_rn_":"1419"},{"1":"0","2":"female","3":"27.0","4":"10.000","5":"yes","6":"5","7":"12","8":"1","9":"5","_rn_":"1420"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"3","7":"16","8":"4","9":"5","_rn_":"1423"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"12","8":"4","9":"2","_rn_":"1424"},{"1":"0","2":"female","3":"27.0","4":"0.750","5":"no","6":"4","7":"16","8":"5","9":"5","_rn_":"1432"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"16","8":"1","9":"5","_rn_":"1433"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"16","8":"1","9":"5","_rn_":"1437"},{"1":"0","2":"female","3":"27.0","4":"10.000","5":"yes","6":"2","7":"16","8":"1","9":"5","_rn_":"1438"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"no","6":"2","7":"20","8":"6","9":"5","_rn_":"1439"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"14","8":"1","9":"3","_rn_":"1446"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"yes","6":"2","7":"17","8":"4","9":"4","_rn_":"1450"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"yes","6":"2","7":"14","8":"1","9":"5","_rn_":"1451"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"yes","6":"4","7":"14","8":"2","9":"4","_rn_":"1452"},{"1":"0","2":"male","3":"42.0","4":"0.125","5":"no","6":"4","7":"17","8":"6","9":"4","_rn_":"1453"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"yes","6":"4","7":"18","8":"6","9":"5","_rn_":"1456"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"3","7":"16","8":"6","9":"3","_rn_":"1464"},{"1":"0","2":"female","3":"52.0","4":"15.000","5":"yes","6":"4","7":"14","8":"1","9":"3","_rn_":"1469"},{"1":"0","2":"male","3":"27.0","4":"1.500","5":"no","6":"5","7":"20","8":"5","9":"2","_rn_":"1473"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"2","7":"16","8":"5","9":"5","_rn_":"1481"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"3","7":"17","8":"5","9":"5","_rn_":"1482"},{"1":"0","2":"male","3":"22.0","4":"0.125","5":"no","6":"5","7":"16","8":"4","9":"4","_rn_":"1496"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"4","7":"16","8":"1","9":"5","_rn_":"1497"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"4","7":"12","8":"1","9":"5","_rn_":"1504"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"2","7":"14","8":"5","9":"5","_rn_":"1513"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"14","8":"5","9":"3","_rn_":"1515"},{"1":"0","2":"male","3":"42.0","4":"7.000","5":"yes","6":"2","7":"16","8":"5","9":"5","_rn_":"1534"},{"1":"0","2":"male","3":"22.0","4":"0.750","5":"no","6":"4","7":"16","8":"6","9":"4","_rn_":"1535"},{"1":"0","2":"male","3":"27.0","4":"0.125","5":"no","6":"3","7":"20","8":"6","9":"5","_rn_":"1536"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"3","7":"20","8":"6","9":"5","_rn_":"1540"},{"1":"0","2":"female","3":"22.0","4":"0.417","5":"no","6":"5","7":"14","8":"4","9":"5","_rn_":"1551"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"5","7":"14","8":"1","9":"4","_rn_":"1555"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"3","7":"14","8":"1","9":"5","_rn_":"1557"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"4","7":"17","8":"5","9":"5","_rn_":"1566"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"3","7":"20","8":"6","9":"5","_rn_":"1567"},{"1":"0","2":"female","3":"32.0","4":"7.000","5":"yes","6":"4","7":"17","8":"1","9":"5","_rn_":"1576"},{"1":"0","2":"female","3":"37.0","4":"10.000","5":"yes","6":"4","7":"16","8":"1","9":"5","_rn_":"1584"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"1","7":"18","8":"1","9":"4","_rn_":"1585"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"no","6":"3","7":"14","8":"1","9":"4","_rn_":"1590"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"14","8":"3","9":"2","_rn_":"1594"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"yes","6":"5","7":"18","8":"5","9":"2","_rn_":"1595"},{"1":"0","2":"male","3":"32.0","4":"7.000","5":"yes","6":"2","7":"18","8":"5","9":"5","_rn_":"1603"},{"1":"0","2":"female","3":"27.0","4":"1.500","5":"no","6":"4","7":"17","8":"1","9":"3","_rn_":"1608"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"4","7":"14","8":"5","9":"5","_rn_":"1609"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"yes","6":"4","7":"14","8":"5","9":"4","_rn_":"1615"},{"1":"0","2":"female","3":"32.0","4":"7.000","5":"yes","6":"3","7":"16","8":"1","9":"5","_rn_":"1616"},{"1":"0","2":"female","3":"47.0","4":"15.000","5":"yes","6":"3","7":"16","8":"5","9":"4","_rn_":"1617"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"3","7":"16","8":"1","9":"5","_rn_":"1620"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"yes","6":"2","7":"14","8":"5","9":"5","_rn_":"1621"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"1","7":"16","8":"5","9":"5","_rn_":"1637"},{"1":"0","2":"male","3":"52.0","4":"15.000","5":"yes","6":"4","7":"16","8":"5","9":"5","_rn_":"1638"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"4","7":"20","8":"6","9":"5","_rn_":"1650"},{"1":"0","2":"male","3":"47.0","4":"15.000","5":"yes","6":"4","7":"16","8":"6","9":"4","_rn_":"1654"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"2","7":"14","8":"1","9":"2","_rn_":"1665"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"4","7":"14","8":"4","9":"5","_rn_":"1670"},{"1":"0","2":"female","3":"32.0","4":"10.000","5":"yes","6":"2","7":"16","8":"5","9":"4","_rn_":"1671"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"2","7":"16","8":"5","9":"4","_rn_":"1675"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"16","8":"5","9":"5","_rn_":"1688"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"18","8":"6","9":"4","_rn_":"1691"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"5","7":"14","8":"4","9":"5","_rn_":"1695"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"16","8":"4","9":"4","_rn_":"1698"},{"1":"0","2":"female","3":"57.0","4":"15.000","5":"yes","6":"3","7":"18","8":"5","9":"2","_rn_":"1704"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"3","7":"18","8":"6","9":"2","_rn_":"1705"},{"1":"0","2":"female","3":"32.0","4":"7.000","5":"yes","6":"2","7":"14","8":"1","9":"2","_rn_":"1711"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"no","6":"5","7":"12","8":"4","9":"5","_rn_":"1719"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"1","7":"16","8":"6","9":"5","_rn_":"1723"},{"1":"0","2":"female","3":"22.0","4":"0.750","5":"no","6":"1","7":"14","8":"4","9":"5","_rn_":"1726"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"12","8":"1","9":"5","_rn_":"1749"},{"1":"0","2":"male","3":"22.0","4":"1.500","5":"no","6":"2","7":"18","8":"5","9":"3","_rn_":"1752"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"5","7":"17","8":"2","9":"5","_rn_":"1754"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"4","7":"12","8":"1","9":"5","_rn_":"1758"},{"1":"0","2":"male","3":"42.0","4":"15.000","5":"yes","6":"5","7":"18","8":"5","9":"4","_rn_":"1761"},{"1":"0","2":"male","3":"32.0","4":"1.500","5":"no","6":"2","7":"20","8":"7","9":"3","_rn_":"1773"},{"1":"0","2":"male","3":"57.0","4":"15.000","5":"no","6":"4","7":"9","8":"3","9":"1","_rn_":"1775"},{"1":"0","2":"male","3":"37.0","4":"7.000","5":"no","6":"4","7":"18","8":"5","9":"5","_rn_":"1786"},{"1":"0","2":"male","3":"52.0","4":"15.000","5":"yes","6":"2","7":"17","8":"5","9":"4","_rn_":"1793"},{"1":"0","2":"male","3":"47.0","4":"15.000","5":"yes","6":"4","7":"17","8":"6","9":"5","_rn_":"1799"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"no","6":"2","7":"17","8":"5","9":"4","_rn_":"1803"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"14","8":"5","9":"5","_rn_":"1806"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"no","6":"2","7":"14","8":"3","9":"3","_rn_":"1807"},{"1":"0","2":"male","3":"37.0","4":"7.000","5":"yes","6":"2","7":"20","8":"6","9":"5","_rn_":"1808"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"no","6":"4","7":"12","8":"4","9":"3","_rn_":"1814"},{"1":"0","2":"male","3":"42.0","4":"10.000","5":"yes","6":"4","7":"18","8":"6","9":"4","_rn_":"1815"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"3","7":"14","8":"1","9":"5","_rn_":"1818"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"yes","6":"2","7":"14","8":"1","9":"3","_rn_":"1827"},{"1":"0","2":"female","3":"57.0","4":"15.000","5":"no","6":"4","7":"20","8":"6","9":"5","_rn_":"1834"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"4","9":"3","_rn_":"1835"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"3","7":"18","8":"5","9":"5","_rn_":"1843"},{"1":"0","2":"female","3":"17.5","4":"10.000","5":"no","6":"4","7":"14","8":"4","9":"5","_rn_":"1846"},{"1":"0","2":"male","3":"22.0","4":"4.000","5":"yes","6":"4","7":"16","8":"5","9":"5","_rn_":"1850"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"2","7":"16","8":"1","9":"4","_rn_":"1851"},{"1":"0","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"14","8":"5","9":"1","_rn_":"1854"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"5","7":"14","8":"1","9":"4","_rn_":"1859"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"2","7":"20","8":"5","9":"4","_rn_":"1861"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"4","7":"14","8":"5","9":"5","_rn_":"1866"},{"1":"0","2":"male","3":"22.0","4":"0.125","5":"no","6":"1","7":"16","8":"3","9":"5","_rn_":"1873"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"14","8":"1","9":"4","_rn_":"1875"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"5","7":"16","8":"5","9":"3","_rn_":"1885"},{"1":"0","2":"male","3":"32.0","4":"10.000","5":"yes","6":"4","7":"18","8":"5","9":"4","_rn_":"1892"},{"1":"0","2":"female","3":"32.0","4":"15.000","5":"yes","6":"2","7":"14","8":"3","9":"4","_rn_":"1895"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"3","7":"17","8":"5","9":"5","_rn_":"1896"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"4","7":"17","8":"4","9":"4","_rn_":"1897"},{"1":"0","2":"female","3":"52.0","4":"15.000","5":"yes","6":"5","7":"14","8":"1","9":"5","_rn_":"1899"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"2","7":"12","8":"1","9":"2","_rn_":"1904"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"3","7":"12","8":"1","9":"4","_rn_":"1905"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"2","7":"14","8":"1","9":"4","_rn_":"1908"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"4","7":"14","8":"5","9":"4","_rn_":"1916"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"4","7":"14","8":"3","9":"3","_rn_":"1918"},{"1":"0","2":"male","3":"27.0","4":"7.000","5":"yes","6":"2","7":"20","8":"6","9":"2","_rn_":"1920"},{"1":"0","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"12","8":"3","9":"3","_rn_":"1930"},{"1":"0","2":"male","3":"27.0","4":"4.000","5":"yes","6":"3","7":"16","8":"3","9":"5","_rn_":"1940"},{"1":"0","2":"female","3":"27.0","4":"7.000","5":"yes","6":"3","7":"14","8":"1","9":"4","_rn_":"1947"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"14","8":"4","9":"5","_rn_":"1949"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"4","7":"14","8":"1","9":"4","_rn_":"1951"},{"1":"0","2":"female","3":"22.0","4":"4.000","5":"no","6":"4","7":"14","8":"5","9":"5","_rn_":"1952"},{"1":"0","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"16","8":"4","9":"5","_rn_":"1960"},{"1":"0","2":"male","3":"47.0","4":"15.000","5":"no","6":"4","7":"14","8":"5","9":"4","_rn_":"9001"},{"1":"0","2":"male","3":"37.0","4":"10.000","5":"yes","6":"2","7":"18","8":"6","9":"2","_rn_":"9012"},{"1":"0","2":"male","3":"37.0","4":"15.000","5":"yes","6":"3","7":"17","8":"5","9":"4","_rn_":"9023"},{"1":"0","2":"female","3":"27.0","4":"4.000","5":"yes","6":"2","7":"16","8":"1","9":"4","_rn_":"9029"},{"1":"3","2":"male","3":"27.0","4":"1.500","5":"no","6":"3","7":"18","8":"4","9":"4","_rn_":"6"},{"1":"3","2":"female","3":"27.0","4":"4.000","5":"yes","6":"3","7":"17","8":"1","9":"5","_rn_":"12"},{"1":"7","2":"male","3":"37.0","4":"15.000","5":"yes","6":"5","7":"18","8":"6","9":"2","_rn_":"43"},{"1":"12","2":"female","3":"32.0","4":"10.000","5":"yes","6":"3","7":"17","8":"5","9":"2","_rn_":"53"},{"1":"1","2":"male","3":"22.0","4":"0.125","5":"no","6":"4","7":"16","8":"5","9":"5","_rn_":"67"},{"1":"1","2":"female","3":"22.0","4":"1.500","5":"yes","6":"2","7":"14","8":"1","9":"5","_rn_":"79"},{"1":"12","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"5","9":"2","_rn_":"122"},{"1":"7","2":"female","3":"22.0","4":"1.500","5":"no","6":"2","7":"14","8":"3","9":"4","_rn_":"126"},{"1":"2","2":"male","3":"37.0","4":"15.000","5":"yes","6":"2","7":"18","8":"6","9":"4","_rn_":"133"},{"1":"3","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"12","8":"3","9":"2","_rn_":"138"},{"1":"1","2":"female","3":"37.0","4":"15.000","5":"yes","6":"4","7":"14","8":"4","9":"2","_rn_":"154"},{"1":"7","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"17","8":"1","9":"4","_rn_":"159"},{"1":"12","2":"female","3":"42.0","4":"15.000","5":"yes","6":"5","7":"9","8":"4","9":"1","_rn_":"174"},{"1":"12","2":"male","3":"37.0","4":"10.000","5":"yes","6":"2","7":"20","8":"6","9":"2","_rn_":"176"},{"1":"12","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"14","8":"1","9":"2","_rn_":"181"},{"1":"3","2":"male","3":"27.0","4":"4.000","5":"no","6":"1","7":"18","8":"6","9":"5","_rn_":"182"},{"1":"7","2":"male","3":"37.0","4":"10.000","5":"yes","6":"2","7":"18","8":"7","9":"3","_rn_":"186"},{"1":"7","2":"female","3":"27.0","4":"4.000","5":"no","6":"3","7":"17","8":"5","9":"5","_rn_":"189"},{"1":"1","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"16","8":"5","9":"5","_rn_":"204"},{"1":"1","2":"female","3":"47.0","4":"15.000","5":"yes","6":"5","7":"14","8":"4","9":"5","_rn_":"215"},{"1":"7","2":"female","3":"27.0","4":"4.000","5":"yes","6":"3","7":"18","8":"5","9":"4","_rn_":"232"},{"1":"1","2":"female","3":"27.0","4":"7.000","5":"yes","6":"5","7":"14","8":"1","9":"4","_rn_":"233"},{"1":"12","2":"male","3":"27.0","4":"1.500","5":"yes","6":"3","7":"17","8":"5","9":"4","_rn_":"252"},{"1":"12","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"14","8":"6","9":"2","_rn_":"253"},{"1":"3","2":"female","3":"42.0","4":"15.000","5":"yes","6":"4","7":"16","8":"5","9":"4","_rn_":"274"},{"1":"7","2":"female","3":"27.0","4":"10.000","5":"yes","6":"4","7":"12","8":"7","9":"3","_rn_":"275"},{"1":"1","2":"male","3":"27.0","4":"1.500","5":"no","6":"2","7":"18","8":"5","9":"2","_rn_":"287"},{"1":"1","2":"male","3":"32.0","4":"4.000","5":"no","6":"4","7":"20","8":"6","9":"4","_rn_":"288"},{"1":"1","2":"female","3":"27.0","4":"7.000","5":"yes","6":"3","7":"14","8":"1","9":"3","_rn_":"325"},{"1":"3","2":"female","3":"32.0","4":"10.000","5":"yes","6":"4","7":"14","8":"1","9":"4","_rn_":"328"},{"1":"3","2":"male","3":"27.0","4":"4.000","5":"yes","6":"2","7":"18","8":"7","9":"2","_rn_":"344"},{"1":"1","2":"female","3":"17.5","4":"0.750","5":"no","6":"5","7":"14","8":"4","9":"5","_rn_":"353"},{"1":"1","2":"female","3":"32.0","4":"10.000","5":"yes","6":"4","7":"18","8":"1","9":"5","_rn_":"354"},{"1":"7","2":"female","3":"32.0","4":"7.000","5":"yes","6":"2","7":"17","8":"6","9":"4","_rn_":"367"},{"1":"7","2":"male","3":"37.0","4":"15.000","5":"yes","6":"2","7":"20","8":"6","9":"4","_rn_":"369"},{"1":"7","2":"female","3":"37.0","4":"10.000","5":"no","6":"1","7":"20","8":"5","9":"3","_rn_":"390"},{"1":"12","2":"female","3":"32.0","4":"10.000","5":"yes","6":"2","7":"16","8":"5","9":"5","_rn_":"392"},{"1":"7","2":"male","3":"52.0","4":"15.000","5":"yes","6":"2","7":"20","8":"6","9":"4","_rn_":"423"},{"1":"7","2":"female","3":"42.0","4":"15.000","5":"yes","6":"1","7":"12","8":"1","9":"3","_rn_":"432"},{"1":"1","2":"male","3":"52.0","4":"15.000","5":"yes","6":"2","7":"20","8":"6","9":"3","_rn_":"436"},{"1":"2","2":"male","3":"37.0","4":"15.000","5":"yes","6":"3","7":"18","8":"6","9":"5","_rn_":"483"},{"1":"12","2":"female","3":"22.0","4":"4.000","5":"no","6":"3","7":"12","8":"3","9":"4","_rn_":"513"},{"1":"12","2":"male","3":"27.0","4":"7.000","5":"yes","6":"1","7":"18","8":"6","9":"2","_rn_":"516"},{"1":"1","2":"male","3":"27.0","4":"4.000","5":"yes","6":"3","7":"18","8":"5","9":"5","_rn_":"518"},{"1":"12","2":"male","3":"47.0","4":"15.000","5":"yes","6":"4","7":"17","8":"6","9":"5","_rn_":"520"},{"1":"12","2":"female","3":"42.0","4":"15.000","5":"yes","6":"4","7":"12","8":"1","9":"1","_rn_":"526"},{"1":"7","2":"male","3":"27.0","4":"4.000","5":"no","6":"3","7":"14","8":"3","9":"4","_rn_":"528"},{"1":"7","2":"female","3":"32.0","4":"7.000","5":"yes","6":"4","7":"18","8":"4","9":"5","_rn_":"553"},{"1":"1","2":"male","3":"32.0","4":"0.417","5":"yes","6":"3","7":"12","8":"3","9":"4","_rn_":"576"},{"1":"3","2":"male","3":"47.0","4":"15.000","5":"yes","6":"5","7":"16","8":"5","9":"4","_rn_":"611"},{"1":"12","2":"male","3":"37.0","4":"15.000","5":"yes","6":"2","7":"20","8":"5","9":"4","_rn_":"625"},{"1":"7","2":"male","3":"22.0","4":"4.000","5":"yes","6":"2","7":"17","8":"6","9":"4","_rn_":"635"},{"1":"1","2":"male","3":"27.0","4":"4.000","5":"no","6":"2","7":"14","8":"4","9":"5","_rn_":"646"},{"1":"7","2":"female","3":"52.0","4":"15.000","5":"yes","6":"5","7":"16","8":"1","9":"3","_rn_":"657"},{"1":"1","2":"male","3":"27.0","4":"4.000","5":"no","6":"3","7":"14","8":"3","9":"3","_rn_":"659"},{"1":"1","2":"female","3":"27.0","4":"10.000","5":"yes","6":"4","7":"16","8":"1","9":"4","_rn_":"666"},{"1":"1","2":"male","3":"32.0","4":"7.000","5":"yes","6":"3","7":"14","8":"7","9":"4","_rn_":"679"},{"1":"7","2":"male","3":"32.0","4":"7.000","5":"yes","6":"2","7":"18","8":"4","9":"1","_rn_":"729"},{"1":"3","2":"male","3":"22.0","4":"1.500","5":"no","6":"1","7":"14","8":"3","9":"2","_rn_":"755"},{"1":"7","2":"male","3":"22.0","4":"4.000","5":"yes","6":"3","7":"18","8":"6","9":"4","_rn_":"758"},{"1":"7","2":"male","3":"42.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"4","_rn_":"770"},{"1":"2","2":"female","3":"57.0","4":"15.000","5":"yes","6":"1","7":"18","8":"5","9":"4","_rn_":"786"},{"1":"7","2":"female","3":"32.0","4":"4.000","5":"yes","6":"3","7":"18","8":"5","9":"2","_rn_":"797"},{"1":"1","2":"male","3":"27.0","4":"4.000","5":"yes","6":"1","7":"16","8":"4","9":"4","_rn_":"811"},{"1":"7","2":"male","3":"32.0","4":"7.000","5":"yes","6":"4","7":"16","8":"1","9":"4","_rn_":"834"},{"1":"2","2":"male","3":"57.0","4":"15.000","5":"yes","6":"1","7":"17","8":"4","9":"4","_rn_":"858"},{"1":"7","2":"female","3":"42.0","4":"15.000","5":"yes","6":"4","7":"14","8":"5","9":"2","_rn_":"885"},{"1":"7","2":"male","3":"37.0","4":"10.000","5":"yes","6":"1","7":"18","8":"5","9":"3","_rn_":"893"},{"1":"3","2":"male","3":"42.0","4":"15.000","5":"yes","6":"3","7":"17","8":"6","9":"1","_rn_":"927"},{"1":"1","2":"female","3":"52.0","4":"15.000","5":"yes","6":"3","7":"14","8":"4","9":"4","_rn_":"928"},{"1":"2","2":"female","3":"27.0","4":"7.000","5":"yes","6":"3","7":"17","8":"5","9":"3","_rn_":"933"},{"1":"12","2":"male","3":"32.0","4":"7.000","5":"yes","6":"2","7":"12","8":"4","9":"2","_rn_":"951"},{"1":"1","2":"male","3":"22.0","4":"4.000","5":"no","6":"4","7":"14","8":"2","9":"5","_rn_":"968"},{"1":"3","2":"male","3":"27.0","4":"7.000","5":"yes","6":"3","7":"18","8":"6","9":"4","_rn_":"972"},{"1":"12","2":"female","3":"37.0","4":"15.000","5":"yes","6":"1","7":"18","8":"5","9":"5","_rn_":"975"},{"1":"7","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"17","8":"1","9":"3","_rn_":"977"},{"1":"7","2":"female","3":"27.0","4":"7.000","5":"no","6":"2","7":"17","8":"5","9":"5","_rn_":"981"},{"1":"1","2":"female","3":"32.0","4":"7.000","5":"yes","6":"3","7":"17","8":"5","9":"3","_rn_":"986"},{"1":"1","2":"male","3":"32.0","4":"1.500","5":"yes","6":"2","7":"14","8":"2","9":"4","_rn_":"1002"},{"1":"12","2":"female","3":"42.0","4":"15.000","5":"yes","6":"4","7":"14","8":"1","9":"2","_rn_":"1007"},{"1":"7","2":"male","3":"32.0","4":"10.000","5":"yes","6":"3","7":"14","8":"5","9":"4","_rn_":"1011"},{"1":"7","2":"male","3":"37.0","4":"4.000","5":"yes","6":"1","7":"20","8":"6","9":"3","_rn_":"1035"},{"1":"1","2":"female","3":"27.0","4":"4.000","5":"yes","6":"2","7":"16","8":"5","9":"3","_rn_":"1050"},{"1":"12","2":"female","3":"42.0","4":"15.000","5":"yes","6":"3","7":"14","8":"4","9":"3","_rn_":"1056"},{"1":"1","2":"male","3":"27.0","4":"10.000","5":"yes","6":"5","7":"20","8":"6","9":"5","_rn_":"1057"},{"1":"12","2":"male","3":"37.0","4":"10.000","5":"yes","6":"2","7":"20","8":"6","9":"2","_rn_":"1075"},{"1":"12","2":"female","3":"27.0","4":"7.000","5":"yes","6":"1","7":"14","8":"3","9":"3","_rn_":"1080"},{"1":"3","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"12","8":"1","9":"2","_rn_":"1125"},{"1":"3","2":"male","3":"32.0","4":"10.000","5":"yes","6":"2","7":"14","8":"4","9":"4","_rn_":"1131"},{"1":"12","2":"female","3":"17.5","4":"0.750","5":"yes","6":"2","7":"12","8":"1","9":"3","_rn_":"1138"},{"1":"12","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"18","8":"5","9":"4","_rn_":"1150"},{"1":"2","2":"female","3":"22.0","4":"7.000","5":"no","6":"4","7":"14","8":"4","9":"3","_rn_":"1163"},{"1":"1","2":"male","3":"32.0","4":"7.000","5":"yes","6":"4","7":"20","8":"6","9":"5","_rn_":"1169"},{"1":"7","2":"male","3":"27.0","4":"4.000","5":"yes","6":"2","7":"18","8":"6","9":"2","_rn_":"1198"},{"1":"1","2":"female","3":"22.0","4":"1.500","5":"yes","6":"5","7":"14","8":"5","9":"3","_rn_":"1204"},{"1":"12","2":"female","3":"32.0","4":"15.000","5":"no","6":"3","7":"17","8":"5","9":"1","_rn_":"1218"},{"1":"12","2":"female","3":"42.0","4":"15.000","5":"yes","6":"2","7":"12","8":"1","9":"2","_rn_":"1230"},{"1":"7","2":"male","3":"42.0","4":"15.000","5":"yes","6":"3","7":"20","8":"5","9":"4","_rn_":"1236"},{"1":"12","2":"male","3":"32.0","4":"10.000","5":"no","6":"2","7":"18","8":"4","9":"2","_rn_":"1247"},{"1":"12","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"9","8":"1","9":"1","_rn_":"1259"},{"1":"7","2":"male","3":"57.0","4":"15.000","5":"yes","6":"5","7":"20","8":"4","9":"5","_rn_":"1294"},{"1":"12","2":"male","3":"47.0","4":"15.000","5":"yes","6":"4","7":"20","8":"6","9":"4","_rn_":"1353"},{"1":"2","2":"female","3":"42.0","4":"15.000","5":"yes","6":"2","7":"17","8":"6","9":"3","_rn_":"1370"},{"1":"12","2":"male","3":"37.0","4":"15.000","5":"yes","6":"3","7":"17","8":"6","9":"3","_rn_":"1427"},{"1":"12","2":"male","3":"37.0","4":"15.000","5":"yes","6":"5","7":"17","8":"5","9":"2","_rn_":"1445"},{"1":"7","2":"male","3":"27.0","4":"10.000","5":"yes","6":"2","7":"20","8":"6","9":"4","_rn_":"1460"},{"1":"2","2":"male","3":"37.0","4":"15.000","5":"yes","6":"2","7":"16","8":"5","9":"4","_rn_":"1480"},{"1":"12","2":"female","3":"32.0","4":"15.000","5":"yes","6":"1","7":"14","8":"5","9":"2","_rn_":"1505"},{"1":"7","2":"male","3":"32.0","4":"10.000","5":"yes","6":"3","7":"17","8":"6","9":"3","_rn_":"1543"},{"1":"2","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"18","8":"5","9":"1","_rn_":"1548"},{"1":"7","2":"female","3":"27.0","4":"1.500","5":"no","6":"2","7":"17","8":"5","9":"5","_rn_":"1550"},{"1":"3","2":"female","3":"47.0","4":"15.000","5":"yes","6":"2","7":"17","8":"5","9":"2","_rn_":"1561"},{"1":"12","2":"male","3":"37.0","4":"15.000","5":"yes","6":"2","7":"17","8":"5","9":"4","_rn_":"1564"},{"1":"12","2":"female","3":"27.0","4":"4.000","5":"no","6":"2","7":"14","8":"5","9":"5","_rn_":"1573"},{"1":"2","2":"female","3":"27.0","4":"10.000","5":"yes","6":"4","7":"14","8":"1","9":"5","_rn_":"1575"},{"1":"1","2":"female","3":"22.0","4":"4.000","5":"yes","6":"3","7":"16","8":"1","9":"3","_rn_":"1599"},{"1":"12","2":"male","3":"52.0","4":"7.000","5":"no","6":"4","7":"16","8":"5","9":"5","_rn_":"1622"},{"1":"2","2":"female","3":"27.0","4":"4.000","5":"yes","6":"1","7":"16","8":"3","9":"5","_rn_":"1629"},{"1":"7","2":"female","3":"37.0","4":"15.000","5":"yes","6":"2","7":"17","8":"6","9":"4","_rn_":"1664"},{"1":"2","2":"female","3":"27.0","4":"4.000","5":"no","6":"1","7":"17","8":"3","9":"1","_rn_":"1669"},{"1":"12","2":"female","3":"17.5","4":"0.750","5":"yes","6":"2","7":"12","8":"3","9":"5","_rn_":"1674"},{"1":"7","2":"female","3":"32.0","4":"15.000","5":"yes","6":"5","7":"18","8":"5","9":"4","_rn_":"1682"},{"1":"7","2":"female","3":"22.0","4":"4.000","5":"no","6":"1","7":"16","8":"3","9":"5","_rn_":"1685"},{"1":"2","2":"male","3":"32.0","4":"4.000","5":"yes","6":"4","7":"18","8":"6","9":"4","_rn_":"1697"},{"1":"1","2":"female","3":"22.0","4":"1.500","5":"yes","6":"3","7":"18","8":"5","9":"2","_rn_":"1716"},{"1":"3","2":"female","3":"42.0","4":"15.000","5":"yes","6":"2","7":"17","8":"5","9":"4","_rn_":"1730"},{"1":"1","2":"male","3":"32.0","4":"7.000","5":"yes","6":"4","7":"16","8":"4","9":"4","_rn_":"1731"},{"1":"12","2":"male","3":"37.0","4":"15.000","5":"no","6":"3","7":"14","8":"6","9":"2","_rn_":"1732"},{"1":"1","2":"male","3":"42.0","4":"15.000","5":"yes","6":"3","7":"16","8":"6","9":"3","_rn_":"1743"},{"1":"1","2":"male","3":"27.0","4":"4.000","5":"yes","6":"1","7":"18","8":"5","9":"4","_rn_":"1751"},{"1":"2","2":"male","3":"37.0","4":"15.000","5":"yes","6":"4","7":"20","8":"7","9":"3","_rn_":"1757"},{"1":"7","2":"male","3":"37.0","4":"15.000","5":"yes","6":"3","7":"20","8":"6","9":"4","_rn_":"1763"},{"1":"3","2":"male","3":"22.0","4":"1.500","5":"no","6":"2","7":"12","8":"3","9":"3","_rn_":"1766"},{"1":"3","2":"male","3":"32.0","4":"4.000","5":"yes","6":"3","7":"20","8":"6","9":"2","_rn_":"1772"},{"1":"2","2":"male","3":"32.0","4":"15.000","5":"yes","6":"5","7":"20","8":"6","9":"5","_rn_":"1776"},{"1":"12","2":"female","3":"52.0","4":"15.000","5":"yes","6":"1","7":"18","8":"5","9":"5","_rn_":"1782"},{"1":"12","2":"male","3":"47.0","4":"15.000","5":"no","6":"1","7":"18","8":"6","9":"5","_rn_":"1784"},{"1":"3","2":"female","3":"32.0","4":"15.000","5":"yes","6":"4","7":"16","8":"4","9":"4","_rn_":"1791"},{"1":"7","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"14","8":"3","9":"2","_rn_":"1831"},{"1":"7","2":"female","3":"27.0","4":"7.000","5":"yes","6":"4","7":"16","8":"1","9":"2","_rn_":"1840"},{"1":"12","2":"male","3":"42.0","4":"15.000","5":"yes","6":"3","7":"18","8":"6","9":"2","_rn_":"1844"},{"1":"7","2":"female","3":"42.0","4":"15.000","5":"yes","6":"2","7":"14","8":"3","9":"2","_rn_":"1856"},{"1":"12","2":"male","3":"27.0","4":"7.000","5":"yes","6":"2","7":"17","8":"5","9":"4","_rn_":"1876"},{"1":"3","2":"male","3":"32.0","4":"10.000","5":"yes","6":"4","7":"14","8":"4","9":"3","_rn_":"1929"},{"1":"7","2":"male","3":"47.0","4":"15.000","5":"yes","6":"3","7":"16","8":"4","9":"2","_rn_":"1935"},{"1":"1","2":"male","3":"22.0","4":"1.500","5":"yes","6":"1","7":"12","8":"2","9":"5","_rn_":"1938"},{"1":"7","2":"female","3":"32.0","4":"10.000","5":"yes","6":"2","7":"18","8":"5","9":"4","_rn_":"1941"},{"1":"2","2":"male","3":"32.0","4":"10.000","5":"yes","6":"2","7":"17","8":"6","9":"5","_rn_":"1954"},{"1":"2","2":"male","3":"22.0","4":"7.000","5":"yes","6":"3","7":"18","8":"6","9":"2","_rn_":"1959"},{"1":"1","2":"female","3":"32.0","4":"15.000","5":"yes","6":"3","7":"14","8":"1","9":"5","_rn_":"9010"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Neste post, a análise de dados será feita considerando a variável <code>affairs</code> (Quantas vezes envolvido em caso extraconjugal no último ano (aparentemente em 1977)) e a base de dados conta com as variáveis gênero, idade, anos de casado, se tem crianças, religiosidade, educação, ocupação e como avalia o casamento.</p>
<p>Informações detalhadas podem ser conferidas na tabela a seguir, retirada do artigo apresentado:</p>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/tab.png" /></p>
<p>Obs.: Essa tabela foi feita com o pacote <a href="https://plot.ly/r/"><code>plotly</code></a>, o código pode ser conferido <a href="https://gist.github.com/gomesfellipe/4d1d17ca97ac6dadfabad6baef3c5539">aqui</a>.</p>
</div>
</div>
</div>
<div id="visão-geral-dos-dados" class="section level1">
<h1>Visão geral dos dados</h1>
<p>Entendendo as dimensões do conjunto de dados, nomes de variáveis, resumo geral, variáveis ausentes e tipos de dados de cada variável com a função <code>ExpData()</code>, se o argumento Type = 1, visualização dos dados (os nomes das colunas são “Descrições”, “Obs.”), já se Type = 2, estrutura dos dados (os nomes das colunas são “S.no”, “VarName”, “VarClass”, “VarType”)
:</p>
<pre class="r"><code># Visao geral dos dados - Type = 1
ExpData(data=Affairs, type=1) # O tipo 1 é uma visão geral dos dados</code></pre>
<pre><code>##                                           Descriptions    Value
## 1                                   Sample size (nrow)      601
## 2                              No. of variables (ncol)        9
## 3                    No. of numeric/interger variables        7
## 4                              No. of factor variables        2
## 5                                No. of text variables        0
## 6                             No. of logical variables        0
## 7                          No. of identifier variables        0
## 8                                No. of date variables        0
## 9             No. of zero variance variables (uniform)        0
## 10               %. of variables having complete cases 100% (9)
## 11   %. of variables having &gt;0% and &lt;50% missing cases   0% (0)
## 12 %. of variables having &gt;=50% and &lt;90% missing cases   0% (0)
## 13          %. of variables having &gt;=90% missing cases   0% (0)</code></pre>
<p>Conferindo o nome das variáveis e os tipos de cada uma:</p>
<pre class="r"><code># Estrutura dos dados - Type = 2
ExpData(data=Affairs, type=2) # O tipo 2 é a estrutura dos dados</code></pre>
<pre><code>##   Index Variable_Name Variable_Type Per_of_Missing No_of_distinct_values
## 1     1       affairs       numeric              0                     6
## 2     2        gender        factor              0                     2
## 3     3           age       numeric              0                     9
## 4     4  yearsmarried       numeric              0                     8
## 5     5      children        factor              0                     2
## 6     6 religiousness       integer              0                     5
## 7     7     education       numeric              0                     7
## 8     8    occupation       integer              0                     7
## 9     9        rating       integer              0                     5</code></pre>
<p>Esta função fornece visão geral e estrutura dos quadros de dados.</p>
</div>
<div id="análise-exploratória-dos-dados" class="section level1">
<h1>Análise exploratória dos dados</h1>
<p>As funções a seguir apresentam a saída EDA para 3 casos diferentes de análise exploratória dos dados, são elas:</p>
<ul>
<li><p>A variável de destino não está definida</p></li>
<li><p>A variável alvo é contínua</p></li>
<li><p>A variável de destino é categórica</p></li>
</ul>
<p>Para fins ilustrativos, será feita inicialmente uma análise considerando que não existe variável resposta, em seguida será considerada a variável <code>affairs</code> como variável resposta e por fim, será feita uma transformação nesta variável resposta numérica de forma que ela seja discretizada da seguinte maneira:</p>
<p><span class="math display">\[
1 \text{ se já houve caso extraconjugal} \\
0 \text{ se não houve caso extraconjugal}
\]</span></p>
</div>
<div id="relatório-em-uma-linha" class="section level1">
<h1>Relatório em uma linha</h1>
<p>Caso o interesse seja apenas ter uma noção geral dos dados de forma extremamente rápida, basta rodar a linha de código abaixo:</p>
<pre><code>ExpReport(Affairs,op_file = &quot;teste.html&quot;)</code></pre>
<p>Antes de começar a explanar cada um dos casos, achei que seria legal frisar que além de tudo que será apresentado, existe a opção de se obter um relatório extenso sobre a análise exploratória dos dados em apenas uma linha!</p>
<div id="exemplo-para-o-caso-1-a-variável-de-destino-não-está-definida" class="section level2">
<h2>Exemplo para o caso 1: a variável de destino não está definida</h2>
<p>Para ilustrar o primeiro caso, onde a variável destino não é definida, vamos supor que não existe uma variável alvo na nossa base de dados e estamos interessados em simplesmente obter uma visão geral enquanto pensamos em quais técnicas estatísticas serão utilizadas para avaliar nosso dataset.</p>
<div id="resumo-das-variáveis-numéricas" class="section level3">
<h3>Resumo das variáveis numéricas</h3>
<p>Resumo de de todas as variáveis numéricas:</p>
<pre class="r"><code>ExpNumStat (Affairs, 
            by = &quot;A&quot;,       # Agrupar por A (estatísticas resumidas por Todos), G (estatísticas resumidas por grupo), GA (estatísticas resumidas por grupo e Geral)
            gp = NULL,      # variável de destino, se houver, padrão NULL
            MesofShape = 2, # Medidas de formas (assimetria e curtose).
            Outlier = TRUE, # Calcular o limite inferior, o limite superior e o número de outliers
            round = 2)      # Arredondar</code></pre>
<pre><code>##   Vname Group
## 1     1   All</code></pre>
<p>Podemos ver que não existem variáveis negativas e a única variável que apresentou “zero” foi a variável resposta. Nenhum registro como <code>Inf</code> ou como <code>NA</code> e além das medidas descritivas também podemos notar as medidas de <code>skweness</code> e <code>kurtosis</code>. Alguns comentários sobre essas medidas:</p>
<p>Medidas de forma para dar uma avaliação detalhada dos dados. Explica a quantidade e a direção do desvio.</p>
<ul>
<li><strong>Kurotsis</strong> explica o quão alto e afiado é o pico central (Achatamento).</li>
<li><strong>Skewness</strong> não tem unidades: mas um número, como um escore z (medida da assimetria)</li>
</ul>
<p>Onde:</p>
<p><a href="https://pt.wikipedia.org/wiki/Curtose"><strong>Kurtose</strong></a>:</p>
<p>A curtose é uma medida de forma que caracteriza o achatamento da curva da função de distribuição de probabilidade, Assim:</p>
<ul>
<li>Se o valor da curtose for = 0 (ou 3, pela segunda definição), então tem o mesmo achatamento que a distribuição normal. Chama-se a estas funções de mesocúrticas</li>
<li>Se o valor é &gt; 0 (ou &gt; 3), então a distribuição em questão é mais alta (afunilada) e concentrada que a distribuição normal. Diz-se que esta função probabilidade é leptocúrtica, ou que a distribuição tem caudas pesadas (o significado é que é relativamente fácil obter valores que não se aproximam da média a vários múltiplos do desvio padrão)</li>
<li>Se o valor é &lt; 0 (ou &lt; 3), então a função de distribuição é mais “achatada” que a distribuição normal. Chama-se-lhe platicúrtica</li>
</ul>
<p><a href="https://pt.wikipedia.org/wiki/Obliquidade"><strong>Skewness</strong></a>:</p>
<p>O Skewness mede a assimetria das caudas da distribuição. Distribuições assimétricas que tem uma cauda mais “pesada” que a outra apresentam obliquidade. Distribuições simétricas tem obliquidade zero. Assim:</p>
<ul>
<li>Se v&gt;0, então a distribuição tem uma cauda direita (valores acima da média) mais pesada</li>
<li>Se v&lt;0, então a distribuição tem uma cauda esquerda (valores abaixo da média) mais pesada</li>
<li>Se v=0, então a distribuição é aproximadamente simétrica (na terceira potência do desvio em relação à média).</li>
</ul>
<div id="distribuições-de-variáveis-numéricas" class="section level4">
<h4>Distribuições de variáveis numéricas</h4>
<p>Representação gráfica de todos os recursos numéricos com <strong>gráfico de densidade</strong> (uni variada):</p>
<pre class="r"><code># Nota: Variável excluída (se o valor único da variável for menor ou igual a 10 [im = 10])

ExpNumViz(Affairs,
          Page=c(2,2), # padrão de saída. 
          sample=NULL) # seleção aleatória de plots</code></pre>
<pre><code>## $`0`</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-9-1.png" width="672" /><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
<p>Exibidos os gráficos com as densidades das variáveis numéricas. Como podemos ver a maioria da amostra não registrou caso extraconjugal, a maioria tem de 12 ou mais anos de casado. A média amostral da idade dos indivíduos é de aproximadamente 32 anos apresentando leve assimetria com cauda a direita. As demais variáveis podem ser conferidas visualmente.</p>
</div>
</div>
<div id="resumo-de-variáveis-categóricas" class="section level3">
<h3>Resumo de variáveis categóricas</h3>
<p>Essa função selecionará automaticamente variáveis categóricas e gerará frequência ou tabelas cruzadas com base nas entradas do usuário. A saída inclui contagens, porcentagens, total de linhas e total de colunas.</p>
<p>Frequência para todas as variáveis independentes categóricas:</p>
<pre class="r"><code>ExpCTable(Affairs,
          Target=NULL)</code></pre>
<pre><code>##         Variable  Valid Frequency Percent CumPercent
## 1         gender female       315   52.41      52.41
## 2         gender   male       286   47.59     100.00
## 3         gender  TOTAL       601      NA         NA
## 4       children     no       171   28.45      28.45
## 5       children    yes       430   71.55     100.00
## 6       children  TOTAL       601      NA         NA
## 7        affairs      0       451   75.04      75.04
## 8        affairs      1        34    5.66      80.70
## 9        affairs     12        38    6.32      87.02
## 10       affairs      2        17    2.83      89.85
## 11       affairs      3        19    3.16      93.01
## 12       affairs      7        42    6.99     100.00
## 13       affairs  TOTAL       601      NA         NA
## 14           age   17.5         6    1.00       1.00
## 15           age     22       117   19.47      20.47
## 16           age     27       153   25.46      45.93
## 17           age     32       115   19.13      65.06
## 18           age     37        88   14.64      79.70
## 19           age     42        56    9.32      89.02
## 20           age     47        23    3.83      92.85
## 21           age     52        21    3.49      96.34
## 22           age     57        22    3.66     100.00
## 23           age  TOTAL       601      NA         NA
## 24  yearsmarried  0.125        11    1.83       1.83
## 25  yearsmarried  0.417        10    1.66       3.49
## 26  yearsmarried   0.75        31    5.16       8.65
## 27  yearsmarried    1.5        88   14.64      23.29
## 28  yearsmarried     10        70   11.65      34.94
## 29  yearsmarried     15       204   33.94      68.88
## 30  yearsmarried      4       105   17.47      86.35
## 31  yearsmarried      7        82   13.64      99.99
## 32  yearsmarried  TOTAL       601      NA         NA
## 33 religiousness      1        48    7.99       7.99
## 34 religiousness      2       164   27.29      35.28
## 35 religiousness      3       129   21.46      56.74
## 36 religiousness      4       190   31.61      88.35
## 37 religiousness      5        70   11.65     100.00
## 38 religiousness  TOTAL       601      NA         NA
## 39     education     12        44    7.32       7.32
## 40     education     14       154   25.62      32.94
## 41     education     16       115   19.13      52.07
## 42     education     17        89   14.81      66.88
## 43     education     18       112   18.64      85.52
## 44     education     20        80   13.31      98.83
## 45     education      9         7    1.16      99.99
## 46     education  TOTAL       601      NA         NA
## 47    occupation      1       113   18.80      18.80
## 48    occupation      2        13    2.16      20.96
## 49    occupation      3        47    7.82      28.78
## 50    occupation      4        68   11.31      40.09
## 51    occupation      5       204   33.94      74.03
## 52    occupation      6       143   23.79      97.82
## 53    occupation      7        13    2.16      99.98
## 54    occupation  TOTAL       601      NA         NA
## 55        rating      1        16    2.66       2.66
## 56        rating      2        66   10.98      13.64
## 57        rating      3        93   15.47      29.11
## 58        rating      4       194   32.28      61.39
## 59        rating      5       232   38.60      99.99
## 60        rating  TOTAL       601      NA         NA</code></pre>
<p>Obs.: <code>NA</code> significa <code>Not Applicable</code></p>
</div>
<div id="distribuições-de-variáveis-categóricas" class="section level3">
<h3>Distribuições de variáveis categóricas</h3>
<p>Essa função varre automaticamente cada variável e cria um gráfico de barras para variáveis categóricas.</p>
<p>Gráficos de barra para todas as variáveis categóricas</p>
<pre class="r"><code>ExpCatViz(Affairs,
          fname=NULL, # Nome do arquivo de saida, default é pdf
          clim=10,# categorias máximas a incluir nos gráficos de barras.
          margin=2,# índice, 1 para proporções baseadas em linha e 2 para proporções baseadas em colunas
          Page = c(2,1), # padrao de saida
          sample=4) # seleção aleatória de plot</code></pre>
<pre><code>## $`0`</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-11-1.png" width="672" /><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
</div>
<div id="machine-lerning-usando-algorítimo-não-supervisionado-de-agrupamento" class="section level3">
<h3>Machine Lerning usando algorítimo não supervisionado de agrupamento</h3>
<p>Apenas para efeitos ilustrativos, como estamos supondo que não temos a variável resposta vou remover a coluna <code>affairs</code> do data set e considerarei apenas as variáveis numéricas para fazer uma análise multivariada com o algorítimo de machine learning <a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/kmeans.html"><code>kmeans</code></a>.</p>
<p>A função <a href="https://github.com/gomesfellipe/functions/blob/master/plot_kmeans.R"><code>plot_kmeans()</code></a> pode ser encontrada em <a href="github.com/gomesfellipe">meu github</a> no <a href="https://github.com/gomesfellipe/functions">repositório aberto de funções</a>.</p>
<p>Vejamos os resultados:</p>
<pre class="r"><code>plot_kmeans(Affairs[,-c(1)] %&gt;% select_if(is.numeric) , 2)</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Como podemos observar, foram detectados dois grupos no conjunto de dados. O ideal agora seria fazer uma AED desses clusters identificados e avaliar qual o comportamento dos grupos formados mas como essa variável foi omitida e a seguir discutiremos a avaliação da base diante de da variável resposta, deixo essas análises aos curiosos de plantão.</p>
<p>Mais informações sobre análise multivariava podem ser encontrada no meu post sobre <a href="https://gomesfellipe.github.io/post/2018-01-01-analise-multivariada-em-r/an%C3%A1lise-multivariada-em-r/">Análise Multivariada com r</a> e também em um <a href="https://www.kaggle.com/gomes555/an-lise-multivariada-pca-e-kmeans">kernel que escrevi para a plataforma kaggle</a>.</p>
<p>Além disso disponibilizo uma aplicação Shiny que criei a algum tempo para PCA (Análise de componentes Principais) e tarefa de machine learning com agrupamento <a href="https://gomesfellipe.shinyapps.io/appPCAkmeans/">nenste link</a>.</p>
</div>
</div>
<div id="exemplo-para-o-caso-2-a-variável-de-destino-é-contínua" class="section level2">
<h2>Exemplo para o caso 2: A variável de destino é contínua</h2>
<p>Agora vamos considerar que estamos diante de um desfecho onde a variável alvo é contínua, para isso será considerada a variável <code>affairs</code> como variável alvo.</p>
<div id="resumo-da-variável-dependente-contínua" class="section level3">
<h3>Resumo da variável dependente contínua</h3>
<p>Descrição da variável affairs:</p>
<pre class="r"><code>summary(Affairs[,&quot;affairs&quot;])</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.000   0.000   0.000   1.456   0.000  12.000</code></pre>
</div>
<div id="resumo-das-variáveis-numéricas-1" class="section level3">
<h3>Resumo das variáveis numéricas</h3>
<p>Estatísticas de resumo quando a variável dependente é contínua Preço.</p>
<pre class="r"><code>ExpNumStat(Affairs,
           by=&quot;A&quot;, # Agrupar por A (estatísticas resumidas por Todos), G (estatísticas resumidas por grupo), GA (estatísticas resumidas por grupo e Geral)
           Qnt=seq(0,1,0.1), # padrão NULL. Quantis especificados [c (0,25,0,75) encontrarão os percentis 25 e 75]
           MesofShape=1, # Medidas de formas (assimetria e curtose)
           Outlier=TRUE, # Calcular limite superior , inferior e numero de outliers
           round=2) # Arredondamento</code></pre>
<pre><code>##   Vname Group
## 1     1   All</code></pre>
<pre class="r"><code>#Se a variável de destino for contínua, as estatísticas de resumo adicionarão a coluna de correlação (Correlação entre a variável de destino e todas as variáveis independentes)</code></pre>
<div id="distribuições-de-variáveis-numéricas-1" class="section level4">
<h4>Distribuições de variáveis numéricas</h4>
<p>Representação gráfica de todas as variáveis numéricas com gráficos de dispersão (bivariada)</p>
<p>Gráfico de dispersão entre todas as variáveis numéricas e a variável de destino affairs. Esta trama ajuda a examinar quão bem uma variável alvo está correlacionada com variáveis dependentes.</p>
<p>Variável dependente é affairs (contínuo).</p>
<pre class="r"><code>ExpNumViz(Affairs,
            target=&quot;affairs&quot;, # Variavel alvo
            nlim=4, # a variável numérica com valor exclusivo é maior que 4
            Page=c(2,2), # formato de saida
            sample=NULL) # selecionado aleatoriamente 8 gráficos de dispersão</code></pre>
<pre><code>## $`0`</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-15-1.png" width="672" /><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-15-2.png" width="672" /></p>
</div>
</div>
<div id="resumo-de-variáveis-categóricas-1" class="section level3">
<h3>Resumo de variáveis categóricas</h3>
<p>Resumo de variáveis categóricas de acordo com a frequência para todas as variáveis independentes categóricas por Affairs</p>
<pre class="r"><code>##bin=4, descretized 4 categories based on quantiles
ExpCTable(Affairs, Target=&quot;affairs&quot;)</code></pre>
<pre><code>##         VARIABLE CATEGORY affairs:(-0.012,4] affairs:(4,8] affairs:(8,12] TOTAL
## 1         gender   female                273            22             20   315
## 2         gender     male                248            20             18   286
## 3         gender    TOTAL                521            42             38   601
## 4       children       no                157             7              7   171
## 5       children      yes                364            35             31   430
## 6       children    TOTAL                521            42             38   601
## 7        affairs        0                451             0              0   451
## 8        affairs        1                 34             0              0    34
## 9        affairs       12                  0             0             38    38
## 10       affairs        2                 17             0              0    17
## 11       affairs        3                 19             0              0    19
## 12       affairs        7                  0            42              0    42
## 13       affairs    TOTAL                521            42             38   601
## 14           age     17.5                  4             0              2     6
## 15           age       22                112             4              1   117
## 16           age       27                138             9              6   153
## 17           age       32                 95            11              9   115
## 18           age       37                 71             8              9    88
## 19           age       42                 44             6              6    56
## 20           age       47                 19             1              3    23
## 21           age       52                 17             2              2    21
## 22           age       57                 21             1              0    22
## 23           age    TOTAL                521            42             38   601
## 24  yearsmarried    0.125                 11             0              0    11
## 25  yearsmarried    0.417                 10             0              0    10
## 26  yearsmarried     0.75                 29             0              2    31
## 27  yearsmarried      1.5                 85             2              1    88
## 28  yearsmarried       10                 57             8              5    70
## 29  yearsmarried       15                165            17             22   204
## 30  yearsmarried        4                 94             9              2   105
## 31  yearsmarried        7                 70             6              6    82
## 32  yearsmarried    TOTAL                521            42             38   601
## 33 religiousness        1                 37             5              6    48
## 34 religiousness        2                138            14             12   164
## 35 religiousness        3                105            13             11   129
## 36 religiousness        4                177             6              7   190
## 37 religiousness        5                 64             4              2    70
## 38 religiousness    TOTAL                521            42             38   601
## 39     education       12                 36             2              6    44
## 40     education       14                139             6              9   154
## 41     education       16                108             5              2   115
## 42     education       17                 72             9              8    89
## 43     education       18                 94            11              7   112
## 44     education       20                 67             9              4    80
## 45     education        9                  5             0              2     7
## 46     education    TOTAL                521            42             38   601
## 47    occupation        1                101             6              6   113
## 48    occupation        2                 13             0              0    13
## 49    occupation        3                 39             5              3    47
## 50    occupation        4                 60             4              4    68
## 51    occupation        5                177            12             15   204
## 52    occupation        6                120            13             10   143
## 53    occupation        7                 11             2              0    13
## 54    occupation    TOTAL                521            42             38   601
## 55        rating        1                 11             1              4    16
## 56        rating        2                 43             8             15    66
## 57        rating        3                 80             9              4    93
## 58        rating        4                169            18              7   194
## 59        rating        5                218             6              8   232
## 60        rating    TOTAL                521            42             38   601</code></pre>
<div id="distribuições-de-variáveis-categóricas-1" class="section level4">
<h4>Distribuições de variáveis categóricas</h4>
<p>Essa função varre automaticamente cada variável e cria um gráfico de barras para variáveis categóricas.</p>
<p>Gráficos de barra para todas as variáveis categóricas</p>
<pre class="r"><code>ExpCatViz(Affairs,
          target=&quot;affairs&quot;, # Variavel target
          fname=NULL, # Nome do arquivo de saida, default é pdf
          clim=10,# categorias máximas a incluir nos gráficos de barras.
          margin=2,# índice, 1 para proporções baseadas em linha e 2 para proporções baseadas em colunas
          Page = c(2,1), # padrao de saida
          sample=4) # seleção aleatória de plot</code></pre>
<pre><code>## $`0`</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-17-1.png" width="672" /><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-17-2.png" width="672" /></p>
</div>
</div>
<div id="avaliando-a-correlação-entre-as-variáveis" class="section level3">
<h3>Avaliando a correlação entre as variáveis</h3>
<pre class="r"><code>library(ggplot2)
library(dplyr)
library(GGally)
data(&quot;Affairs&quot;)
#Correlaçoes cruzadas
Affairs%&gt;%
  select(age:rating,affairs)%&gt;%
ggpairs(lower = list(continuous = my_fn,combo=wrap(&quot;facethist&quot;, binwidth=1), 
                                       continuous=wrap(my_bin, binwidth=0.25)),aes(fill=affairs))+theme_bw()</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<pre class="r"><code>ggcorr(Affairs,label = T,nbreaks = 5,label_round = 4)</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
<div id="modelo-de-regressão-linear-usando-stepwiseaic" class="section level3">
<h3>Modelo de regressão linear usando stepwiseAIC</h3>
<p>Por fim, vamos ajustar um modelo de regressão linear para entender quais são as variáveis significativas para explicar a variação da variável resposta e qual o efeito de cada uma dessas variáveis explicativas no nosso desfecho.</p>
<p>Com o R base é possível ajustar um modelo de regressão linear simples utilizando a função <code>lm()</code> e em seguida usar a função <code>step()</code> para utilizar técnicas como <a href="https://en.wikipedia.org/wiki/Stepwise_regression">stepwise</a>, porém como quero utilizar também a técnica de <a href="https://pt.wikipedia.org/wiki/Valida%C3%A7%C3%A3o_cruzada">validação cruzada</a>. Para isso vou utilizar o pacote <a href="https://cran.r-project.org/web/packages/caret/caret.pdf"><code>caret</code></a>, muito famoso por facilitar o ajuste de modelos de machine learning (ou mesmo modelos estatísticos tradicionais).</p>
<p>Além disso estou usando as transformações <a href="https://www.rdocumentation.org/packages/caret/versions/6.0-79/topics/preProcess"><code>center()</code></a>, que subtrai a média dos dados e <a href="https://www.rdocumentation.org/packages/caret/versions/6.0-79/topics/preProcess"><code>scale()</code></a> divide pelo desvio padrão.</p>
<pre class="r"><code>data(&quot;Affairs&quot;)
library(caret)
set.seed(123)
index &lt;- sample(1:2,nrow(Affairs),replace=T,prob=c(0.8,0.2))
train = Affairs[index==1,] %&gt;%as.data.frame()
test = Affairs[index==2,] %&gt;%as.data.frame()

# Setando os parâmetros para o controle do ajuste do modelo:
fitControl &lt;- trainControl(method = &quot;repeatedcv&quot;,         # 10fold cross validation
                     number = 10, repeats=5                         # do 5 repititições of cv
                     )

# Regressão Linear com Stepwise
set.seed(825)
lmFit &lt;- train(affairs ~ ., data = train,
                method = &quot;lmStepAIC&quot;, 
                trControl = fitControl,
                preProc = c(&quot;center&quot;, &quot;scale&quot;),trace=F)
summary(lmFit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = .outcome ~ age + yearsmarried + religiousness + 
##     occupation + rating, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.1452 -1.7819 -0.7601  0.2719 11.3518 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     1.4146     0.1401  10.096  &lt; 2e-16 ***
## age            -0.6890     0.2291  -3.007 0.002779 ** 
## yearsmarried    1.1058     0.2302   4.804 2.09e-06 ***
## religiousness  -0.5121     0.1455  -3.519 0.000475 ***
## occupation      0.3858     0.1445   2.669 0.007858 ** 
## rating         -0.7830     0.1470  -5.326 1.55e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.07 on 474 degrees of freedom
## Multiple R-squared:  0.144,  Adjusted R-squared:  0.135 
## F-statistic: 15.95 on 5 and 474 DF,  p-value: 1.542e-14</code></pre>
<p>Como podemos ver as variáveis Idade, Anos de casado, religiosidade, ocupação e como avaliam o próprio relacionamento se apresentaram significantes</p>
<p>Como o <span class="math inline">\(R^2=0,144\)</span>, conclui-se que <span class="math inline">\(14,4%\)</span> da variação da quantidade de vezes que foi envolvida em caso extraconjugal no último ano é explicada pelo modelo ajustado.</p>
<p>Observando a coluna das estimativas, podemos notar o quanto varia a quantidade de vezes que foi envolvido em caso extraconjugal ao aumentar em 1 unidade cada uma das variáveis explicativas.</p>
<p>Além disso o valor p obtido através da estatística F foi menor do que <span class="math inline">\(\alpha = 0.05\)</span>, o que implica que pelo menos uma das variáveis explicativas tem relação significativa com a variável resposta.</p>
<p>Selecionando apenas as variáveis selecionadas com o ajuste do modelo:</p>
<pre class="r"><code>train=as.data.frame(train[,c(1,3,4,6,8,9)])
test=as.data.frame(test[,c(1,3,4,6,8,9)])</code></pre>
<div id="diagnóstico-do-modelo" class="section level4">
<h4>Diagnóstico do modelo</h4>
<p>Existem varias formas e técnicas de se avaliar o ajuste de um modelo e como o foco deste post é apresentar as utilidades do pacote <code>SmartEAD</code> irei fazer uma avaliação muito breve sobre os resíduos, apresento mais algumas maneiras no post sobre <a href="https://gomesfellipe.github.io/post/2017-12-24-diagnostico-de-modelo/diagnostico-de-modelos/">pacotes do R para avaliar o ajuste de modelos</a>.</p>
<div id="avaliando-residuos" class="section level5">
<h5>Avaliando residuos</h5>
<pre class="r"><code>library(GGally)
# calculate all residuals prior to display
residuals &lt;- lapply(train[2:ncol(train)], function(x) {
  summary(lm(affairs ~ x, data = train))$residuals
})

# add a &#39;fake&#39; column
train$Residual &lt;- seq_len(nrow(train))

# calculate a consistent y range for all residuals
y_range &lt;- range(unlist(residuals))

# plot the data
ggduo(
  train,
  2:6, c(1,7),
  types = list(continuous = lm_or_resid)
)+ theme_bw()</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code>train=train%&gt;%
  select(-Residual)</code></pre>
<p>Neste gráfico é possível observar como se comportam os ajustes de modelos lineares de cada variável explicativa em relação à variável resposta e além disso na segunda linha é possível notar o comportamento dos resíduos no modelo.</p>
<p>Uma das suposições do ajuste de um modelo linear normal é de que <span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span> e visualmente parece que essa condição não deve ser atendida, pois esperaríamos algo como uma “nuvem” aleatória de pontos em torno de zero.</p>
</div>
<div id="residuos-e-medidas-de-influencia" class="section level5">
<h5>Residuos e medidas de influencia</h5>
<p>Além da suposição da normalidade dos resíduos, existem ainda mais detalhes do comportamento desses erros, uma breve apresentação no gráfico a seguir:</p>
<pre class="r"><code>library(ggfortify)

autoplot(lmFit$finalModel, which = 1:6, data = train,
         colour = &#39;affairs&#39;, label.size = 3,
         ncol = 3)+theme_classic()</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Pelo que parece no gráfico com título “Normal Q-Q”, as variáveis associadas à variável resposta com valores acima de 6 se comportam de forma inesperadas quando comparadas com os quantis teóricos.</p>
</div>
</div>
</div>
</div>
<div id="exemplo-para-o-caso-3-a-variável-de-destino-é-categórica" class="section level2">
<h2>Exemplo para o caso 3: a variável de destino é categórica</h2>
<p>Para finalizar a avaliação da base de dados, a Variável alvo será discretizado de tal forma:</p>
<p><span class="math display">\[
1 = \text{se affairs} &gt; 0\\
0 = c.c.
\]</span></p>
<p>Essa transformação será utilizada apenas com fins ilustrativos do algorítimo de árvore de decisões, que está ficando muito comum na ciência de dados como uma tarefa supervisionada de machine learning.</p>
<pre class="r"><code>Affairs = Affairs %&gt;% 
  mutate(daffairs = ifelse(Affairs$affairs!=0,1,0)) %&gt;% 
  mutate(daffairs = as.factor(daffairs))%&gt;% 
  select(-affairs)
levels(Affairs$daffairs) = c(&quot;Não&quot;, &quot;Sim&quot;)</code></pre>
<div id="resumo-das-variáveis-numéricas-2" class="section level3">
<h3>Resumo das variáveis numéricas</h3>
<p>Resumo de todas as variáveis numéricas</p>
<pre class="r"><code>ExpNumStat(Affairs,
           by=&quot;A&quot;, # Agrupar por A (estatísticas resumidas por Todos), G (estatísticas resumidas por grupo), GA (estatísticas resumidas por grupo e Geral)
           gp=&quot;daffairs&quot;, # Variavel alvo
           Qnt=seq(0,1,0.1), # padrão NULL. Quantis especificados [c (0,25,0,75) encontrarão os percentis 25 e 75]
           MesofShape=1, # Medidas de formas (assimetria e curtose)
           Outlier=TRUE, # Calcular limite superior , inferior e numero de outliers
           round=2) # Arredondamento</code></pre>
<pre><code>##   Vname Group
## 1     1   All</code></pre>
<div id="distribuições-de-variáveis-numéricas-2" class="section level4">
<h4>Distribuições de variáveis numéricas</h4>
<p>Box plots para todas as variáveis numéricas vs variável dependente categórica - Comparação bivariada apenas com categorias</p>
<p>Boxplot para todos os atributos numéricos por cada categoria de affair</p>
<pre class="r"><code>ExpNumViz(Affairs, target=&quot;daffairs&quot;) # amostra de variaveis para o resumo</code></pre>
<pre><code>## [[1]]</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre><code>## 
## [[2]]</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-26-2.png" width="672" /></p>
<pre><code>## 
## [[3]]</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-26-3.png" width="672" /></p>
<pre><code>## 
## [[4]]</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-26-4.png" width="672" /></p>
<pre><code>## 
## [[5]]</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-26-5.png" width="672" /></p>
<pre><code>## 
## [[6]]</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-26-6.png" width="672" /></p>
</div>
</div>
<div id="resumo-das-variáveis-categóricas" class="section level3">
<h3>Resumo das variáveis categóricas</h3>
<p>Tabulação cruzada com variável de destino com tabelas customizadas entre todas as variáveis independentes categóricas e a variável de destino <code>daffairs</code>:</p>
<pre class="r"><code>ExpCTable(Affairs,
          Target=&quot;daffairs&quot;, # variavel alvo
          margin=1, # 1 para proporcoes por linha, 2 para colunas
          clim=10, # maximo de categorias consideradas por frequencia/ custom table
          round=2, # arredondar
          per=F) # valores percentuais. Tabela padrão dará contagens.</code></pre>
<pre><code>##         VARIABLE CATEGORY daffairs:Não daffairs:Sim TOTAL
## 1         gender   female          243           72   315
## 2         gender     male          208           78   286
## 3         gender    TOTAL          451          150   601
## 4       children       no          144           27   171
## 5       children      yes          307          123   430
## 6       children    TOTAL          451          150   601
## 7            age     17.5            3            3     6
## 8            age       22          101           16   117
## 9            age       27          117           36   153
## 10           age       32           77           38   115
## 11           age       37           65           23    88
## 12           age       42           38           18    56
## 13           age       47           16            7    23
## 14           age       52           15            6    21
## 15           age       57           19            3    22
## 16           age    TOTAL          451          150   601
## 17  yearsmarried    0.125           10            1    11
## 18  yearsmarried    0.417            9            1    10
## 19  yearsmarried     0.75           28            3    31
## 20  yearsmarried      1.5           76           12    88
## 21  yearsmarried       10           49           21    70
## 22  yearsmarried       15          142           62   204
## 23  yearsmarried        4           78           27   105
## 24  yearsmarried        7           59           23    82
## 25  yearsmarried    TOTAL          451          150   601
## 26 religiousness        1           28           20    48
## 27 religiousness        2          123           41   164
## 28 religiousness        3           86           43   129
## 29 religiousness        4          157           33   190
## 30 religiousness        5           57           13    70
## 31 religiousness    TOTAL          451          150   601
## 32     education       12           31           13    44
## 33     education       14          119           35   154
## 34     education       16           95           20   115
## 35     education       17           62           27    89
## 36     education       18           79           33   112
## 37     education       20           60           20    80
## 38     education        9            5            2     7
## 39     education    TOTAL          451          150   601
## 40    occupation        1           90           23   113
## 41    occupation        2           10            3    13
## 42    occupation        3           32           15    47
## 43    occupation        4           47           21    68
## 44    occupation        5          160           44   204
## 45    occupation        6          104           39   143
## 46    occupation        7            8            5    13
## 47    occupation    TOTAL          451          150   601
## 48        rating        1            8            8    16
## 49        rating        2           33           33    66
## 50        rating        3           66           27    93
## 51        rating        4          146           48   194
## 52        rating        5          198           34   232
## 53        rating    TOTAL          451          150   601</code></pre>
<div id="distribuições-de-variáveis-categóricas-2" class="section level4">
<h4>Distribuições de variáveis categóricas</h4>
<p>Gráfico de barras empilhadas com barras verticais ou horizontais para todas as variáveis categóricas</p>
<pre class="r"><code>ExpCatViz(Affairs,
          target=&quot;daffairs&quot;,
          fname=NULL, # Nome do arquivo de saida, default é pdf
          clim=10,# categorias máximas a incluir nos gráficos de barras.
          margin=2,# índice, 1 para proporções baseadas em linha e 2 para proporções baseadas em colunas
          Page = c(2,1), # padrao de saida
          sample=4) # seleção aleatória de plot</code></pre>
<pre><code>## $`0`</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-28-1.png" width="672" /><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-28-2.png" width="672" /></p>
</div>
</div>
<div id="valor-da-informação" class="section level3">
<h3>Valor da informação</h3>
<p><code>IV</code> é o peso da evidência e valores da informação, <span class="math inline">\(ln(odss) \times(pct0 - pct1)\)</span> onde <span class="math inline">\(pct1 =\frac{\text{&quot;boas observações&quot;}}{\text{&quot;total boas observações&quot;}}\)</span>; <span class="math inline">\(pct0 = \frac{&quot;\text{observações ruins&quot;} }{ \text{&quot;total de observações ruins&quot;}}\)</span> e $odds =  $</p>
<pre class="r"><code>ExpCatStat(Affairs %&gt;% mutate(daffairs = if_else(daffairs==&quot;Não&quot;, 0, 1)) ,
           Target=&quot;daffairs&quot;,
           result = &quot;IV&quot;) %&gt;% 
  select(-one_of(&quot;Target&quot;,&quot;Ref_1&quot;,&quot;Ref_0&quot;))</code></pre>
<pre><code>##           Variable  Class Out_1 Out_0 TOTAL Per_1 Per_0 Odds   WOE   IV
## 1         gender.1 female    72   243   315  0.48  0.54 0.79 -0.12 0.01
## 2         gender.2   male    78   208   286  0.52  0.46 1.27  0.12 0.01
## 3       children.1     no    27   144   171  0.18  0.32 0.47 -0.58 0.08
## 4       children.2    yes   123   307   430  0.82  0.68 2.14  0.19 0.03
## 5            age.1   17.5     3     3     6  0.02  0.01 3.05  0.69 0.01
## 6            age.2     22    16   101   117  0.11  0.22 0.41 -0.69 0.08
## 7            age.3     27    36   117   153  0.24  0.26 0.90 -0.08 0.00
## 8            age.4     32    38    77   115  0.25  0.17 1.65  0.39 0.03
## 9            age.5     37    23    65    88  0.15  0.14 1.08  0.07 0.00
## 10           age.6     42    18    38    56  0.12  0.08 1.48  0.41 0.02
## 11           age.7     47     7    16    23  0.05  0.04 1.33  0.22 0.00
## 12           age.8     52     6    15    21  0.04  0.03 1.21  0.29 0.00
## 13           age.9     57     3    19    22  0.02  0.04 0.46 -0.69 0.01
## 14  yearsmarried.1  0.125     1    10    11  0.01  0.02 0.30 -0.69 0.01
## 15  yearsmarried.2  0.417     1     9    10  0.01  0.02 0.33 -0.69 0.01
## 16  yearsmarried.3   0.75     3    28    31  0.02  0.06 0.31 -1.11 0.04
## 17  yearsmarried.4    1.5    12    76    88  0.08  0.17 0.43 -0.76 0.07
## 18  yearsmarried.5     10    21    49    70  0.14  0.11 1.34  0.24 0.01
## 19  yearsmarried.6     15    62   142   204  0.41  0.31 1.53  0.28 0.03
## 20  yearsmarried.7      4    27    78   105  0.18  0.17 1.05  0.06 0.00
## 21  yearsmarried.8      7    23    59    82  0.15  0.13 1.20  0.14 0.00
## 22 religiousness.1      1    20    28    48  0.13  0.06 2.32  0.77 0.05
## 23 religiousness.2      2    41   123   164  0.27  0.27 1.00  0.00 0.00
## 24 religiousness.3      3    43    86   129  0.29  0.19 1.71  0.43 0.04
## 25 religiousness.4      4    33   157   190  0.22  0.35 0.53 -0.46 0.06
## 26 religiousness.5      5    13    57    70  0.09  0.13 0.66 -0.37 0.01
## 27     education.1     12    13    31    44  0.09  0.07 1.29  0.25 0.00
## 28     education.2     14    35   119   154  0.23  0.26 0.85 -0.13 0.00
## 29     education.3     16    20    95   115  0.13  0.21 0.58 -0.48 0.04
## 30     education.4     17    27    62    89  0.18  0.14 1.38  0.25 0.01
## 31     education.5     18    33    79   112  0.22  0.18 1.33  0.20 0.01
## 32     education.6     20    20    60    80  0.13  0.13 1.00  0.00 0.00
## 33     education.7      9     2     5     7  0.01  0.01 1.21  0.00 0.00
## 34    occupation.1      1    23    90   113  0.15  0.20 0.73 -0.29 0.01
## 35    occupation.2      2     3    10    13  0.02  0.02 0.90  0.00 0.00
## 36    occupation.3      3    15    32    47  0.10  0.07 1.45  0.36 0.01
## 37    occupation.4      4    21    47    68  0.14  0.10 1.40  0.34 0.01
## 38    occupation.5      5    44   160   204  0.29  0.35 0.75 -0.19 0.01
## 39    occupation.6      6    39   104   143  0.26  0.23 1.17  0.12 0.00
## 40    occupation.7      7     5     8    13  0.03  0.02 1.91  0.41 0.00
## 41        rating.1      1     8     8    16  0.05  0.02 3.12  0.92 0.03
## 42        rating.2      2    33    33    66  0.22  0.07 3.57  1.14 0.17
## 43        rating.3      3    27    66    93  0.18  0.15 1.28  0.18 0.01
## 44        rating.4      4    48   146   194  0.32  0.32 0.98  0.00 0.00
## 45        rating.5      5    34   198   232  0.23  0.44 0.37 -0.65 0.14</code></pre>
</div>
<div id="testes-estatísticos" class="section level3">
<h3>Testes estatísticos</h3>
<p>Além de toda a informação visual e das estatísticas descritivas, ainda contamos com alguma função que fornece estatísticas resumidas para todas as colunas de caracteres ou categóricas no data frame</p>
<pre class="r"><code>ExpCatStat(Affairs %&gt;% mutate(daffairs = if_else(daffairs==&quot;Não&quot;, 0, 1)),
           Target=&quot;daffairs&quot;, # variavel alvo
           result = &quot;Stat&quot;) # resumo de estatisticas</code></pre>
<pre><code>##        Variable   Target Unique Chi-squared p-value df IV Value Cramers V
## 1        gender daffairs      2       1.334   0.248  1     0.02      0.05
## 2      children daffairs      2      10.055   0.002  1     0.11      0.13
## 3           age daffairs      9      17.771   0.023  8     0.15      0.17
## 4  yearsmarried daffairs      8      17.177   0.016  7     0.17      0.17
## 5 religiousness daffairs      5      19.354   0.001  4     0.16      0.18
## 6     education daffairs      7       7.057   0.316  6     0.06      0.11
## 7    occupation daffairs      7       6.718   0.348  6     0.04      0.11
## 8        rating daffairs      5      41.433   0.000  4     0.35      0.26
##   Degree of Association    Predictive Power
## 1             Very Weak      Not Predictive
## 2                  Weak Somewhat Predictive
## 3                  Weak Somewhat Predictive
## 4                  Weak Somewhat Predictive
## 5                  Weak Somewhat Predictive
## 6                  Weak      Not Predictive
## 7                  Weak      Not Predictive
## 8              Moderate   Highly Predictive</code></pre>
<p>Os critérios usados para classificação de poder preditivo variável categórico são</p>
<ul>
<li><p>Se o valor da informação for &lt;0,03, então, poder de previsão = “Não Preditivo”</p></li>
<li><p>Se o valor da informação é de 0,3 a 0,1, então o poder preditivo = “um pouco preditivo”</p></li>
<li><p>Se o valor da informação for de 0,1 a 0,3, então, poder preditivo = “Medium Predictive”</p></li>
<li><p>Se o valor da informação for&gt; 0.3, então, poder preditivo = “Altamente Preditivo”</p></li>
</ul>
<p>Nota para a variável <code>rating</code> que segundo essas regras, demonstrou alto poder preditivo.</p>
</div>
<div id="machine-learning-com-random-forest" class="section level3">
<h3>Machine Learning com Random Forest</h3>
<p>O algorítimo supervisionado de machine learning conhecido como <a href="https://www.stat.berkeley.edu/~breiman/RandomForests/">Random Forest</a> é uma grande caixa preta. Apresenta resultados muito robustos pois combina o resultado de várias árvores de decisões e pode ser facilmente aplicada com o pacote <code>caret</code>.</p>
<p><a href="https://topepo.github.io/caret/variable-importance.html">No livro do pacote caret</a> o algorítimo é apresentado da seguinte maneira: “segundo o pacote do R: Para cada árvore, a precisão da previsão na parte fora do saco dos dados é registrada. Então, o mesmo é feito após a permutação de cada variável preditora. A diferença entre as duas precisões é calculada pela média de todas as árvores e normalizada pelo erro padrão. Para a regressão, o MSE é calculado nos dados fora da bolsa para cada árvore e, em seguida, o mesmo é computado após a permutação de uma variável. As diferenças são calculadas e normalizadas pelo erro padrão. Se o erro padrão é igual a 0 para uma variável, a divisão não é feita.”</p>
<p>Não entrarei em muitos detalhes sobre o algorítimo pois esta parte é apenas um demonstrativo dos diferentes cenários de análise exploratória dos dados. Serão comentadas apenas algumas métricas utilizadas.</p>
<p>Ajuste com o algorítimo Random Forest:</p>
<pre class="r"><code>library(caret)
set.seed(1)
index &lt;- sample(1:2,nrow(Affairs),replace=T,prob=c(0.8,0.2))
train = Affairs[index==1,] %&gt;%as.data.frame()
test = Affairs[index==2,] %&gt;%as.data.frame()


# Setando os parâmetros para o controle do ajuste do modelo:
fitControl &lt;- trainControl(method = &quot;repeatedcv&quot;,         # 10fold cross validation
                     number = 10
                     )

# Random Forest
set.seed(825)
antes = Sys.time()
rfFit &lt;- train(daffairs ~ ., data = train,
                method = &quot;rf&quot;, 
                trControl = fitControl,
                trace=F,
                preProc = c(&quot;center&quot;, &quot;scale&quot;))

antes - Sys.time() # Para saber quanto tempo durou o ajuste</code></pre>
<pre><code>## Time difference of -13.38876 secs</code></pre>
<p>Resultados do ajuste:</p>
<pre class="r"><code>rfFit</code></pre>
<pre><code>## Random Forest 
## 
## 484 samples
##   8 predictor
##   2 classes: &#39;Não&#39;, &#39;Sim&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Cross-Validated (10 fold, repeated 1 times) 
## Summary of sample sizes: 436, 436, 435, 435, 435, 436, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##   2     0.7539966  0.1369868
##   5     0.7292942  0.1727691
##   8     0.7231718  0.1613695
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 2.</code></pre>
<p><strong>Accurary e Kappa</strong></p>
<p>Essas são as métricas padrão usadas para avaliar algoritmos em conjuntos de dados de classificação binária.</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Accuracy_and_precision"><strong>Accuray</strong></a>: é a porcentagem de classificar corretamente as instâncias fora de todas as instâncias. É mais útil em uma classificação binária do que problemas de classificação de várias classes, porque pode ser menos claro exatamente como a precisão é dividida entre essas classes (por exemplo, você precisa ir mais fundo com uma matriz de confusão).</li>
<li><a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa"><strong>Kappa ou Kappa de Cohen</strong></a> é como a precisão da classificação, exceto que é normalizado na linha de base da chance aleatória em seu conjunto de dados. É uma medida mais útil para usar em problemas que têm um desequilíbrio nas classes (por exemplo, divisão de 70 a 30 para as classes 0 e 1 e você pode atingir 70% de precisão prevendo que todas as instâncias são para a classe 0).</li>
</ul>
<p>A seguir a “Variable Importance” de cada variável:</p>
<pre class="r"><code>rfImp = varImp(rfFit);rfImp</code></pre>
<pre><code>## rf variable importance
## 
##               Overall
## rating         100.00
## age             94.66
## religiousness   85.77
## education       78.99
## yearsmarried    67.41
## occupation      62.48
## gendermale       6.94
## childrenyes      0.00</code></pre>
<pre class="r"><code>plot(rfImp)</code></pre>
<p><img src="/post/2018-05-26-smarteademachinelearning/smarteademachinelearning_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>A função dimensiona automaticamente as pontuações de importância entre 0 e 100, os escores de importância da variável em Random Forest são medidas agregadas. Eles apenas quantificam o impacto do preditor, não o efeito específico, para isso utilizamos o ajuste um modelo paramétrico onde conseguimos estimar termos estruturais.</p>
<p>É claro que existem muitos adentos a serem feitos tanto na forma como os dados foram apresentados no ajuste do modelo linear e no Random Forest, mas como a finalidade do post continua sendo apresentar o pacote SmartEAD, encerrarei a avaliação por aqui.</p>
<p>Caso alguém queira entender com mais detalhes a avaliação de modelos de machine learning, talvez <a href="https://topepo.github.io/caret/measuring-performance.html">o livro do pacote caret</a> seja uma alternativa interessante para ter uma noção geral.</p>
<blockquote>
<p><em>Todos os modelos estão errados, alguns são úteis - George Box</em></p>
</blockquote>
<p>Não conseguimos nenhum modelo útil que quantificasse as incertezas nas modelagens deste post mas conseguimos executar praticamente todas as funções do pacote <code>SmartEAD</code> e foi muito útil para conhecer a base em poucas linhas, obrigado Dayanand Ubrangala, Kiran R. e Ravi Prasad Kondapalli!</p>
</div>
</div>
</div>

        <p><strong>Leia o post completo em:</strong> <a href="https://gomesfellipe.github.io/post/2018-05-26-smarteademachinelearning/smarteademachinelearning/">AED de forma rápida e um pouco de Machine Learning</a></p>
        <p><em>Este post foi originalmente publicado em <a href="https://gomesfellipe.github.io/">Fellipe Gomes - Data Science Blog</a></em></p>
      ]]></content:encoded>
      <category>Analise Exploratória</category>
      <category>Data mining</category>
      <category>Estatistica</category>
      <category>Modelagem Estatistica</category>
      <category>Prática</category>
      <category>R</category>
      <category>Reports</category>
      <category>Machine Learning</category>
      <category>Analise Mutivariada</category>
      <category>Aprendizado Supervisionado</category>
      <category>Aprendizado Não Supervisionado</category>
      <category domain="tag">analise multivariada</category>
      <category domain="tag">Correlacoes</category>
      <category domain="tag">Data Mining</category>
      <category domain="tag">Estatistica</category>
      <category domain="tag">gomesfellipe</category>
      <category domain="tag">kmeans</category>
      <category domain="tag">modelagem</category>
      <category domain="tag">pca</category>
      <category domain="tag">R</category>
      <category domain="tag">RStudio</category>
    </item>
  </channel>
</rss>