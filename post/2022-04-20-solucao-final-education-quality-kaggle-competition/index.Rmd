---
title: Solu√ß√£o Final - ML Olympiad [2¬∫ lugar]
author: Fellipe Gomes
date: '2022-04-19'
slug: []
categories:
  - R
  - Python
  - Pr√°tica
  - Regress√£o
  - modelo baseado em arvores
  - Machine Learning
  - kaggle
  - catboost
  - Ciencia de dados
  - Aprendizado Supervisionado
  - Analise Explorat√≥ria
tags:
  - regression
  - R
  - Pr√°tica
  - modelagem
  - machine learning
  - kaggle
  - gomesfellipe
  - Data Mining
  - ciencia de dados
  - catboost
description: 'Confira a estrat√©gia aplicada para esta competi√ß√£o'
featured: 'img1.png'
featuredalt: 'Pic 29'
featuredpath: 'date'
linktitle: ''
type: "post"
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
image_preview: 'img1.png'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = F, warning = F, error = F, message = F)
```


# Introdu√ß√£o   

No final de Janeiro desde ano (2022) o [TFUG - TensorFlow Users Group de S√£o Paulo](https://www.meetup.com/TensorFlowSP/events/284607061/) lan√ßou uma competi√ß√£o no Kaggle para prever as notas do enem que tem rela√ß√£o com um dos 17 t√≥picos de Desenvolvimento Sustent√°vel das Na√ß√µes Unidas - *Educa√ß√£o de Qualidade*.

Al√©m de divertido, o desafio foi repleto de possibilidades e bastante desafiador! Todos os competidores que trabalharam duro em pleno m√™s de carnaval est√£o de parab√©ns! üòÖ üòÇ

Aqui est√£o alguns dos pr√™mios recebidos:

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/premio.png){width=80%} 
</center> 

Como nesta competi√ß√£o havia bastante trabalho a ser feito e tivemos apenas 1 m√™s para trabalhar na solu√ß√£o, foi preciso fazer uma boa gest√£o do c√≥digo e do tempo de desenvolvimento.  

Nas se√ß√µes abaixo apresento o racional por tr√°s da minha solu√ß√£o bem como os 5 melhores modelos individuais (para cada nota) que utilizei em um ensemble para chegar ao segundo lugar. 

# Defini√ß√£o do problema de neg√≥cio

O objetivo desta competi√ß√£o consistiu em prever as notas dos alunos(as) nas provas: Ci√™ncias da Natureza, Ci√™ncias Humanas, Linguagens e C√≥digos, Matem√°tica e Reda√ß√£o.

Apesar das notas serem calculadas de maneira independente, a partir de modelos de [TRI (Teoria de Resposta ao Item)](http://portal.mec.gov.br/ultimas-noticias/389-ensino-medio-2092297298/17319-teoria-de-resposta-ao-item-avalia-habilidade-e-minimiza-o-chute) que levam em considera√ß√£o a performance em um caderno espec√≠fico e na dificuldade de cada quest√£o, o mesmo aluno realiza todas as provas em um curto per√≠odo de tempo.

Portanto, esta tarefa pode ser enquadrada como um problema supervisionado de regress√£o com m√∫ltiplos outputs na qual as previs√µes s√£o, de certa forma, dependentes da entrada umas das outras.

A valida√ß√£o da solu√ß√£o foi feita utilizando a m√©trica Mean Columnwise Root Mean Squared Error ‚Äì MCRMSE, que √© basicamente a m√©dia do RMSE calculado sobre as previs√µes de cada nota.

# An√°lise Explorat√≥ria (em R)

Convido o leitor a conferir o [notebook publicado no Kaggle](https://gomesfellipe.github.io/post/2021-11-01-solucao-final-porto-seguro-data-challenge/) com a an√°lise explorat√≥ria completa. Aqui irei trazer apenas alguns dos principais insights que encontrei durante a etapa de an√°lise explorat√≥ria.

## Estrutura da base

Veja a seguir qual a estrutura geral da base de dados:

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/02_df_status.png){width=95%} 
</center>

√â not√≥rio que existem dados faltantes e que parece haver algum padr√£o. Vejamos com mais detalhse:

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/03_missing.png){width=95%} 
</center>

<div class="w3-panel w3-pale-blue w3-border">
&nbsp; üí° Insights!

Existem dados *missing* nas 5 targets que queremos prever e note que existe uma rela√ß√£o tanto entre as provas de Matem√°tica e Ci√™ncias da Natuerza quanto nas de Ci√™ncias Humanas, Linguagens e C√≥digos e Reda√ß√£o, o que parece ocorrer devido a aus√™ncia do aluno incrito em comparecer a realiza√ß√£o da prova no respectivo dia.
</div>

## Ano da base de dados

Essa informa√ß√£o n√£o estava explicitamente dispon√≠vel, mas ap√≥s analisar a idade dos participantes em rela√ß√£o ao ano em que conclu√≠ram o ensino m√©dio, foi poss√≠vel identificar que tratavam-se dos dados de 2019, veja:

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/05_ano_concluiu.png){width=95%} 
</center>

Essa informa√ß√£o poderia ser √∫til na hora de buscar dados externos (permitido nesta competi√ß√£o).

<div class="w3-panel w3-pale-blue w3-border">
&nbsp; üí° Insights!

‚Üí Aten√ß√£o aos outliers: √â no m√≠nimo estranho uma pessoa que formou em 2007 ter 17 anos;

‚Üí Como ningu√©m concluiu a escola no ano de 2019 e a m√©dia das idades vai diminuindo quanto mais pr√≥ximo de 2018, parece que estes dados s√£o de 2019. Essa inform√ß√£o poderia ser √∫til na hora de procurar por bases externas.
</div>

## Target

A primeira decis√£o importante era definir como enquadrar o problema; se seriam m√∫ltiplos modelos independentes ou modelos com sa√≠das dependentes. 

Primeiramente vejamos como eram as distribui√ß√µes das notas por caderno:

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/07_distribuicao_target.png){width=95%} 
</center>

Ao olhar estas distribui√ß√µes foram surgindo v√°rias id√©ias! Cheguei at√© a tentar modelos estat√≠sticos GAM considerando a resposta como uma distribui√ß√£o Beta (transformando as targets no intervalo [0,1]) mas acabou n√£o apresentando bons resultados para a competi√ß√£o.. acho que seria necess√°rio um pouco mais de prepara√ß√£o nos dados.

Apesar das notas do enem serem calculadas via TRI (Teoria de Resposta ao Item) que considera as notas independentes, parece existir alguma correla√ß√£o entre as notas, veja:

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/08_correlacao_notas.png){width=95%} 
</center>

As targets da nota de L√≠nguas e C√≥digos e Ci√™ncias Humanas pareciam possuir uma correla√ß√£o ‚Äúinteressante‚Äù, mas, ap√≥s testar modelos de m√∫ltiplas respostas dependentes para cada dia (com e sem a nota da reda√ß√£o), em nenhum de meus testes superou (de maneira consistente) o desempenho de modelos que considerassem as sa√≠das independentes. Portanto foquei em criar 5 modelos independentes.

# Machine Learning (em Python)

Toda a rotina de pr√©-processamento dos dados, feature engineering, modelagem, ensamble e p√≥s-processamento foi realizada utilizando a linguagem Python para cada uma das 5 notas. Trouxe apenas o modelo final neste post mas, para chegar at√© aqui foram necess√°rio muitos testes!

## Importar dependencias

Carregar pacotes Python:

```{python}
# data prep
import numpy as np 
import pandas as pd 
# pre process
from sklearn.preprocessing import MinMaxScaler
# modeling
from sklearn.model_selection import train_test_split
from catboost import CatBoostRegressor
# plots
import seaborn as sns
import matplotlib.pyplot as plt
```

Confira a baixo as fun√ß√µes desenvolvidas para a solu√ß√£o deste problema

<details>
<summary>(*Clique aqui para expandir as fun√ß√µes*)</summary>

```{python}
def prep_data_questionarios(df):
  '''
  Converte dados de questionario para ordinal
  '''
    # escolaridade pai
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F': 5, 'G': 6, 'H': -1}
    df.loc[:, 'Q001'] = df.loc[:, 'Q001'].map(to_map).astype(int)

    # escolaridade mae
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F': 5, 'G': 6, 'H': -1}
    df.loc[:, 'Q002'] = df.loc[:, 'Q002'].map(to_map).astype(int) 

    # ocupacao pai
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F': -1}
    df.loc[:, 'Q003'] = df.loc[:, 'Q003'].map(to_map).astype(int) 

    # ocupacao mae
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F': -1}
    df.loc[:, 'Q004'] = df.loc[:, 'Q004'].map(to_map).astype(int) 

    # renda da familia
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'I':8,
              'J':9, 'K':10,'L':11, 'M':12, 'N':13, 'O':14, 'P':15, 'Q':16}
    df.loc[:, 'Q006'] = df.loc[:, 'Q006'].map(to_map).astype(int) 

    # empregado domestico
    to_map = {'A':0, 'B':1, 'C':2, 'D':3}
    df.loc[:, 'Q007'] = df.loc[:, 'Q007'].map(to_map).astype(int) 

    # banheiro
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q008'] = df.loc[:, 'Q008'].map(to_map).astype(int) 

    # qnt de quartos
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q009'] = df.loc[:, 'Q009'].map(to_map).astype(int) 

    # qnt de carros
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q010'] = df.loc[:, 'Q010'].map(to_map).astype(int) 

    # qnt de motocicleta
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q011'] = df.loc[:, 'Q011'].map(to_map).astype(int) 

    # qnt de geladeira
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q012'] = df.loc[:, 'Q012'].map(to_map).astype(int) 

    # qnt de freezer
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q013'] = df.loc[:, 'Q013'].map(to_map).astype(int) 

    # qnt de maquina de lavar roupa
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q014'] = df.loc[:, 'Q014'].map(to_map).astype(int) 

    # qnt de maquina de secar roupa
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q015'] = df.loc[:, 'Q015'].map(to_map).astype(int) 

    # qnt de microondas
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q016'] = df.loc[:, 'Q016'].map(to_map).astype(int) 

    # qnt de maquina de lavar louca
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q017'] = df.loc[:, 'Q017'].map(to_map).astype(int) 

    # tem aspirador de po
    to_map = {'A':0, 'B':1}
    df.loc[:, 'Q018'] = df.loc[:, 'Q018'].map(to_map).astype(int) 

    # qtd tv colorida
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q019'] = df.loc[:, 'Q019'].map(to_map).astype(int) 

    # tem dvd
    to_map = {'A':0, 'B':1}
    df.loc[:, 'Q020'] = df.loc[:, 'Q020'].map(to_map).astype(int) 

    # tem tv por assinatura
    to_map = {'A':0, 'B':1}
    df.loc[:, 'Q021'] = df.loc[:, 'Q021'].map(to_map).astype(int) 

    # qtd telefone celular
    to_map = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q022'] = df.loc[:, 'Q022'].map(to_map).astype(int) 

    # qtd telefone fixo
    to_map = {'A':0, 'B':1}
    df.loc[:, 'Q023'] = df.loc[:, 'Q023'].map(to_map).astype(int) 

    # qtd computador
    to_map =  {'A':0, 'B':1, 'C':2, 'D':3, 'E':4}
    df.loc[:, 'Q024'] = df.loc[:, 'Q024'].map(to_map).astype(int) 

    # tem acesso a internet
    to_map =  {'A':0, 'B':1}
    df.loc[:, 'Q025'] = df.loc[:, 'Q025'].map(to_map).astype(int) 
    
    return(df)
  
def fe_questionario(df):
  '''
  Gerar novas features artificiais baseadas nos dados de questionario
  '''
    df.loc[:, "Q021+Q006"] = df["Q021"] + df["Q006"]
    df.loc[:, "Q018+Q006"] = df["Q018"] + df["Q006"]
    df.loc[:, "Q018+Q008"] = df["Q018"] + df["Q008"]
    df.loc[:, "Q010+Q018"] = df["Q010"] + df["Q018"]
    df.loc[:, "Q018+Q024"] = df["Q018"] + df["Q024"]
    
    df.loc[:, "Q018*Q006"] = df["Q018"] * df["Q006"]
    df.loc[:, "Q010*Q018"] = df["Q010"] * df["Q018"]
    
    return df
  
def fe_mun(data):
    '''
    Gerar novas features a partir das localizacoes de municipio
    '''
    for c in list(data.columns[data.dtypes=='category']):
        data.loc[:, c] = data.loc[:, c].astype('object')
    
    data.loc[:, 'FE_MUNICIPIO_PROVA_x_MUNICIPIO_RESIDENCIA'] = np.where(data.NO_MUNICIPIO_PROVA == data.NO_MUNICIPIO_RESIDENCIA , 1, 0)
    data.loc[:, 'FE_MUNICIPIO_PROVA_x_MUNICIPIO_NASCIMENTO'] = np.where(data.NO_MUNICIPIO_PROVA == data.NO_MUNICIPIO_NASCIMENTO , 1, 0)
    data.loc[:, 'FE_MUNICIPIO_PROVA_x_MUNICIPIO_ESC'] = np.where(data.NO_MUNICIPIO_PROVA == data.NO_MUNICIPIO_ESC , 1, 0)
    data.loc[:, 'FE_MUNICIPIO_RESIDENCIA_x_MUNICIPIO_NASCIMENTO'] = np.where(data.NO_MUNICIPIO_RESIDENCIA == data.NO_MUNICIPIO_NASCIMENTO , 1, 0)
    data.loc[:, 'FE_MUNICIPIO_RESIDENCIA_x_MUNICIPIO_ESC'] = np.where(data.NO_MUNICIPIO_RESIDENCIA == data.NO_MUNICIPIO_ESC , 1, 0)
    data.loc[:, 'FE_MUNICIPIO_NASCIMENTO_x_MUNICIPIO_ESC'] = np.where(data.NO_MUNICIPIO_RESIDENCIA == data.NO_MUNICIPIO_ESC , 1, 0)
    
    for c in list(data.columns[data.dtypes=='object']):
        data.loc[:, c] = data.loc[:, c].astype('category')
    
    return data
  
def fe_in(df):
    '''
    Gerar features a partir das indicadoras
    '''
    df.loc[:, 'IN_DEFICIT_ATENCAO+IN_TEMPO_ADICIONAL'] = df["IN_DEFICIT_ATENCAO"] + df["IN_TEMPO_ADICIONAL"]
    df.loc[:, 'IN_LEDOR+IN_TRANSCRICAO'] = df["IN_LEDOR"] + df["IN_TRANSCRICAO"]

    return df
  
def prep_co_escola(df):
    '''
    Converter codigo da escola para categorico
    '''
    df.loc[:, 'CO_ESCOLA'] = [str(x) for x in df.CO_ESCOLA]
    df.loc[:, 'CO_ESCOLA'] = np.where(df['CO_ESCOLA']=='nan', np.nan, df['CO_ESCOLA'])
    df.loc[:, 'CO_ESCOLA'] = df.loc[:, 'CO_ESCOLA'].astype('category')
    
    return df
  
def fe_extra(df):
    '''
    Gerar novas features 
    '''
    df.loc[:, "FE_IDADE_DISCRETA"] = pd.cut(df.NU_IDADE, (0, 15, 18, 23, 36, 60, 120), labels=['ADOLESCENTE','ADOLESCENTE_2', 'JOVEM','JOVEM_2', 'ADULTO', 'IDOSO']).astype('category')
    df.loc[:, 'FE_OCUPACAO_PAIS'] = df.Q003 + df.Q004
    df.loc[:, 'FE_ESCOLARIDADE_PAIS'] = df.Q001 + df.Q002
    df.loc[:, 'FE_RENDA_POR_PESSOA'] = df.Q006 / df.Q005
    df.loc[:, 'FE_CELULAR_POR_PESSOA'] = df.Q022 / df.Q005
    df.loc[:, 'FE_COMPUTADOR_POR_PESSOA'] = df.Q024 / df.Q005
    df.loc[:, 'FE_VISAO_RUIM'] = df[['IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_VISAO_MONOCULAR', 'IN_SURDO_CEGUEIRA']].max(axis=1)
    df.loc[:, 'FE_AUDICAO_RUIM'] = df[['IN_SURDEZ', 'IN_DEFICIENCIA_AUDITIVA', 'IN_SURDO_CEGUEIRA']].max(axis=1)
    df.loc[:, 'FE_TDAH_MAIS_TEMPO'] = df.IN_TEMPO_ADICIONAL + df.IN_DEFICIT_ATENCAO
    df.loc[:, 'FE_TDAH_MEDICADO'] = np.where((df.IN_DEFICIT_ATENCAO==1)&(df.IN_MEDICAMENTOS==1), 1, 0)
    df.loc[:, 'FE_RECURSO_VISAO'] =  df[['IN_BRAILLE', 'IN_AMPLIADA_24', 'IN_AMPLIADA_18', 'IN_LEDOR', 'IN_MAQUINA_BRAILE', 'IN_LAMINA_OVERLAY']].max(axis=1)
    df.loc[:, 'FE_RECURSO_SURDEZ'] =  df[['IN_LIBRAS', 'IN_LEITURA_LABIAL', 'IN_TRANSCRICAO']].max(axis=1)
    acess = ['IN_ACESSO', 'IN_MESA_CADEIRA_RODAS', 'IN_MESA_CADEIRA_SEPARADA', 'IN_APOIO_PERNA', 'IN_CADEIRA_ESPECIAL', 'IN_CADEIRA_CANHOTO', 'IN_CADEIRA_ACOLCHOADA', 'IN_MOBILIARIO_OBESO', 'IN_SALA_INDIVIDUAL', 'IN_SALA_ESPECIAL', 'IN_SALA_ACOMPANHANTE', 'IN_MOBILIARIO_ESPECIFICO', 'IN_MATERIAL_ESPECIFICO']
    df.loc[:, 'FE_ACESSIBILIDADE'] =  df[acess].max(axis=1)

    return df
```

</details>
&nbsp;

Carregar features artificiais extra√≠das atrav√©s de um modelo KNN. N√£o apresentarei o c√≥digo aqui (talvez fique para um pr√≥ximo post) mas a id√©ia √© basicamente a seguinte: 

<div class="w3-panel w3-pale-yellow w3-border">
&nbsp; üß™ Feature Extraction com KNN

Ajuste um `KNeighborsRegressor` encontrando os K-vizinhos mais pr√≥ximos de cada inst√¢ncia out-of-fold via valida√ß√£o cruzada (para evitar data leak) nos dados de treino e depois ajuste um modelo em todos os dados de treino para obter os K-vizinhos mais pr√≥ximos nos dados de teste. 
</div>


Quem sabe no futuro fa√ßo um post compartilhando esta estrat√©gia com mais detalhes.

```{python}
knn_train = pd.read_csv("../input/knn/KNN_feat_train_CH_LC.csv")
knn_test = pd.read_csv("../input/knn/KNN_feat_test_CH_LC.csv")

knn_train_cn_mt = pd.read_csv("../input/knn/KNN_feat_train_CN_MT.csv")
knn_test_cn_mt = pd.read_csv("../input/knn/KNN_feat_test_CN_MT.csv")

knn_train_rd = pd.read_csv("../input/knn/KNN_feat_train_RD.csv")
knn_test_rd = pd.read_csv("../input/knn/KNN_feat_test_RD.csv")
```

## Carregar dados

Importar uma vers√£o do dataset no formato `.parquet` que foi compactada com um truque para otimizar o consumo de mem√≥ria disponibilizada pelos organizadores [neste notebook](https://www.kaggle.com/code/caneiro/mlo-make-parquet).

```{python}
train = pd.read_parquet('train.parquet')
test = pd.read_parquet('test.parquet')
sub = pd.read_csv('../input/qualityeducation/sample_submission.csv')
```

Definir objetos com targets

```{python}
targets = ['NU_NOTA_LC', 'NU_NOTA_CH', 'NU_NOTA_CN',  'NU_NOTA_MT', 'NU_NOTA_REDACAO']
presencas = ['TP_PRESENCA_LC', 'TP_PRESENCA_CH', 'TP_PRESENCA_CN', 'TP_PRESENCA_MT', 'TP_STATUS_REDACAO']
```

<div class="w3-panel w3-pale-yellow w3-border">
&nbsp; ‚ö†Ô∏è Aten√ß√£o:

A feature de presen√ßa √© muito importante no p√≥s-processamento para atribuir nota zero aos alunos que n√£o foram realizar a prova mas n√£o faz sentido mant√™-la nos dados de treino pois ser√° sempre constante.
</div>

### Dados externos

Dados Externos utilizados:

1. [Atlas do Desenvolvimento Humano (ADH)](https://basedosdados.org/dataset/mundo-onu-adh)

Esta base tinha muita informa√ß√£o legal mas sua cobertura temporal estava bastante defasada (1991 - 2010) o que pode adicionar algum ru√≠do ao modelo.

As features selecionadas (sem muito crit√©rio) desta base foram:

```{python}
extra1 = pd.read_csv("municipio.csv")

extra1 = extra1[extra1.ano==2010]

features_extra1 = ['expectativa_vida', 'razao_dependencia', 'expectativa_anos_estudo',
'taxa_analfabetismo_11_a_14', 'taxa_analfabetismo_15_a_17', 'taxa_analfabetismo_18_mais',
'taxa_atraso_0_basico', 'taxa_atraso_0_fundamental', 'taxa_atraso_0_medio',
'taxa_freq_bruta_medio', 'taxa_freq_liquida_medio',
'taxa_freq_medio_18_24', 'taxa_freq_medio_6_14', 'indice_gini','prop_pobreza_extrema', 'prop_pobreza',
'prop_renda_10_ricos', 'prop_renda_20_pobres', 'razao_10_ricos_40_pobres','renda_pc' , 'renda_pc_quintil_1',
'indice_theil', 'prop_trabalhadores_conta_proria', 
'prop_empregadores', 'prop_ocupados_agropecuaria', 'prop_ocupados_comercio',
'prop_ocupados_construcao', 'prop_ocupados_formalizacao', 'prop_ocupados_medio',
'prop_ocupados_servicos', 'prop_ocupados_superior',
'prop_ocupados_renda_0', 'renda_media_ocupados', 'indice_treil_trabalho',
'taxa_ocupados_carteira', 'taxa_agua_encanada', 
'taxa_banheiro_agua_encanada', 'taxa_coleta_lixo', 'taxa_energia_eletrica',
'taxa_agua_esgoto_inadequados', 'taxa_criancas_dom_sem_fund',
'pea', 'indice_escolaridade', 'indice_frequencia_escolar', 
'idhm', 'idhm_e', 'idhm_l', 'idhm_r']
extra1 = extra1[['id_municipio']+features_extra1]

train = pd.merge(train, extra1, how='left', left_on='CO_MUNICIPIO_RESIDENCIA', right_on='id_municipio')
test = pd.merge(test, extra1, how='left', left_on='CO_MUNICIPIO_RESIDENCIA', right_on='id_municipio')
```

2. [Microdados do Censo Escolar da Educaca√ß√£o B√°sica](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/censo-escolar)

Base dispon√≠vel no mesmo site dos dados da competi√ß√£o e que tr√°s informa√ß√µes muito ricas das escolas do Brasil. Infelizmente quase 75% da informa√ß√£o da escola do aluno era missing ent√£o esta base n√£o conseguiu alavancar os ganhos do modelo de maneira consider√°vel.

Nesta base foquei principalmente nas features utilizadas para calcular o IIE (√çndice de Estrutura da Escola) que se baseia nos seguintes componentes:

| Componente 1: \nEstrutura Pedag√≥gica (IEE_Pedag√≥gico):         | Componente 2: \nEstrutura B√°sica (IEE_B√°sico): | Componente 3: \nEstrutura Tecnol√≥gica (IEE_Tecnol√≥gico):                          |
|--------------------------------------------------------------|----------------------------------------------|---------------------------------------------------------------------------------|
| Qualifica√ß√£o do docente (forma√ß√£o acad√™mica dos professores) | √Ågua filtrada (bin√°ria)                      | N√∫mero de computadores por aluno (computadores dispon√≠veis para uso dos alunos) |
| N√∫mero de alunos por sala                                    | Acesso √† rede p√∫blica de energia (bin√°ria)   | N√∫mero de equipamentos multim√≠dia por aluno                                     |
| N√∫mero de funcion√°rios por aluno                             | Acesso √† rede p√∫blica de esgoto (bin√°ria)    | Acesso a internet (bin√°ria)                                                     |
| Quadra de esportes coberta (bin√°ria)                         | Coleta peri√≥dica de lixo (bin√°ria)           | Laborat√≥rio de Ci√™ncias (bin√°ria)                                               |
| Biblioteca (bin√°ria)                                         | Banheiro dentro do pr√©dio (bin√°ria)          | Laborat√≥rio de Inform√°tica (bin√°ria)                                            |

- [Fonte](https://leosalesblog.wordpress.com/2018/02/03/escola-ruim-aluno-ruim-entendendo-a-relacao-entre-estrutura-escolar-e-desempenho-no-enem/)

```{python}
# Importar dados
extra2 = pd.read_csv('microdados_ed_basica_2021.csv', error_bad_lines=False, sep=';', encoding='latin1', dtype={'CO_ORGAO_REGIONAL': 'str'})
extra2 = extra2[extra2.isnull().sum(axis=1) / extra2.shape[1] < .9]

# Tratamento nas features
extra2.loc[:, 'QT_TOTAL_ALUNOS'] = extra2[['QT_MAT_BAS_ND', 'QT_MAT_BAS_BRANCA', 'QT_MAT_BAS_PRETA', 'QT_MAT_BAS_PARDA', 'QT_MAT_BAS_AMARELA', 'QT_MAT_BAS_INDIGENA']].sum(axis=1).fillna(0)
extra2.loc[:, 'QT_TOTAL_PROFESSORES'] = (extra2.QT_DOC_BAS + extra2.QT_DOC_INF + extra2.QT_DOC_INF_CRE + extra2.QT_DOC_INF_PRE + extra2.QT_DOC_FUND + extra2.QT_DOC_FUND_AI + extra2.QT_DOC_FUND_AF + extra2.QT_DOC_MED + extra2.QT_DOC_PROF + extra2.QT_DOC_PROF_TEC + extra2.QT_DOC_EJA + extra2.QT_DOC_EJA_FUND + extra2.QT_DOC_EJA_MED + extra2.QT_DOC_ESP + extra2.QT_DOC_ESP_CC + extra2.QT_DOC_ESP_CE).fillna(0)
extra2.loc[:, 'QT_SALAS_UTILIZADAS'] = (extra2.loc[:, 'QT_TOTAL_ALUNOS'] / extra2.QT_SALAS_UTILIZADAS).fillna(0)
extra2.loc[:, 'QT_COMP_DISP_ALUNO'] = extra2.QT_DESKTOP_ALUNO + extra2.QT_COMP_PORTATIL_ALUNO + extra2.QT_TABLET_ALUNO

# Selecao de faetures importantes
features_extra2 = ['CO_ENTIDADE', 'QT_SALAS_UTILIZADAS', 'QT_TOTAL_PROFESSORES', 'IN_QUADRA_ESPORTES_COBERTA', 'IN_BIBLIOTECA',
       'IN_AGUA_POTAVEL', 'IN_ENERGIA_REDE_PUBLICA', 'IN_ESGOTO_REDE_PUBLICA', 'IN_LIXO_SERVICO_COLETA', 'IN_BANHEIRO',
       'QT_COMP_DISP_ALUNO', 'QT_EQUIP_MULTIMIDIA', 'IN_INTERNET', 'IN_LABORATORIO_CIENCIAS', 'IN_LABORATORIO_INFORMATICA']
extra2 = extra2[features_extra2]

# Remover outliers
for c in list(extra2.iloc[:, 1:].columns):
    trs = extra2.loc[extra2[c]!=88888, c].quantile(.99)
    extra2.loc[(extra2[c]==88888)|(extra2[c]>trs), c] = trs
    
#Normalizar para calcular IEE
scaler = MinMaxScaler()
to_iee = scaler.fit_transform(extra2.iloc[:, 1:])
to_iee = pd.DataFrame(to_iee, columns=extra2.iloc[:, 1:].columns)

# Calcular IEE e componentes
extra2.loc[:, 'COMP1'] = to_iee[['QT_SALAS_UTILIZADAS', 'QT_TOTAL_PROFESSORES', 'IN_QUADRA_ESPORTES_COBERTA', 'IN_BIBLIOTECA']].sum(axis=1)
extra2.loc[:, 'COMP2'] = to_iee[['IN_AGUA_POTAVEL', 'IN_ENERGIA_REDE_PUBLICA', 'IN_ESGOTO_REDE_PUBLICA', 'IN_LIXO_SERVICO_COLETA', 'IN_BANHEIRO']].sum(axis=1)
extra2.loc[:, 'COMP3'] = to_iee[['QT_COMP_DISP_ALUNO', 'QT_EQUIP_MULTIMIDIA', 'IN_INTERNET', 'IN_LABORATORIO_CIENCIAS', 'IN_LABORATORIO_INFORMATICA']].sum(axis=1)
extra2.loc[:, 'IEE'] = extra2.COMP1 + extra2.COMP2 + extra2.COMP3

train = pd.merge(train, extra2, how='left', left_on='CO_ESCOLA', right_on='CO_ENTIDADE').drop('CO_ENTIDADE', axis=1)
test = pd.merge(test, extra2, how='left', left_on='CO_ESCOLA', right_on='CO_ENTIDADE').drop('CO_ENTIDADE', axis=1)
```

## Modelagem

Testei muitos modelos e muitas abordagens (inclusive com finalidade de estudo). Foram modelos estat√≠sticos (GAM considerando a distribui√ß√£o Beta(0,1)), redes neurais (TabNet) e √°rvores mas no final das contas os que tiveram melhor custo/benef√≠cio foram o LightGBM e o CatBoost.

Sobre o tuning, tomei a decis√£o de n√£o investir muito em otimiza√ß√£o autom√°tica de hiperpar√¢metros pois o tempo era curto e os ganhos seriam pequenos comparados com o potencial ganho com a variedade de features que poderiam ser geradas, ent√£o fiz apenas alguns testes manuais conforme via necessidade.

#### Pre processing

A etapa que investi bastante tempo foi para criar novas vari√°veis. A seguir trago algumas features constru√≠das que foram utilizadas em determinados modelos, a partir dos dados dispon√≠veis:

* Renda somada dos pais;
* N√≠vel de ocupa√ß√£o somado dos pais;
* Renda dividido pelo n√∫mero de pessoas na casa;
* Quantidade de celulares por pessoa na casa;
* Quantidade de computadores por pessoa na casa;
* Se a pessoa possui vis√£o ruim (se possui baixa vis√£o, cegueira ou monocular);
* Se a pessoa possui audi√ß√£o ruim (Surdez, defici√™ncia auditiva);
* Se o aluno possui TDAH e toma medicamento controlado;
* Se o aluno possui TDAH e teve mais tempo de prova;
* Se precisou de recurso de vis√£o ou audi√ß√£o (libras, baile, etc);
* Se o munic√≠pio que nasceu √© o mesmo da escola;
* Se o munic√≠pio que fez a prova √© o mesmo da escola;
* Se o munic√≠pio da prova √© o mesmo da resid√™ncia;
* Nota m√©dia dos alunos da respectiva escola nas outras provas (\*);
* Renda m√©dia dos alunos da respectiva escola (\*).

(\*) Estas features precisaram ser calculadas de maneira muito cuidadosa para n√£o causar algum tipo de data leak!

#### Post Processing

Essa base tinha uma pegadinha que fazia muita diferen√ßa no resultado final. Existem duas possibilidades de um aluno tirar zero em uma prova: errar tudo ou n√£o comparecer.

Como temos a informa√ß√£o da presen√ßa do aluno na prova (o que na pr√°tica seria meio estranho) bastava dar zero para os alunos faltantes na hora de prever nos dados de teste para submeter.

### Linguagens e C√≥digos

Definir finalidade de algumas colunas:

```{python}
# colunas que serao dropadas
to_drop = ['IN_PROVA_DEITADO',
            'NU_INSCRICAO',
            'CO_MUNICIPIO_ESC',
            'CO_UF_NASCIMENTO',
            'CO_UF_RESIDENCIA',
            'CO_UF_ESC',
            'CO_UF_PROVA',
            'CO_MUNICIPIO_PROVA',
            'CO_MUNICIPIO_RESIDENCIA',
            'CO_MUNICIPIO_NASCIMENTO']

# definir target e presenca
target = "NU_NOTA_LC"
presenca = "TP_PRESENCA_LC"

# demais notas para dropar (menos ch)
notas = list(set(targets)-set([target, 'NU_NOTA_CH']))
```

Pr√©-processamento nos dados de treino

```{python}
X = train.copy()
X.loc[:, 'knn_feature'] = knn_train.knn_oof
X = X.drop(to_drop, axis=1) 
X = X[X[presenca]==1]
X = X[~X[target].isnull()]

X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X.loc[:, 'FE_RENDA'] = X.loc[:, 'Q006'].map({'A':0, 'B':1000, 'C':1500, 'D':2000,
'E':2500, 'F':3000, 'G':4000, 'H':5000, 'I':6000, 'J':7000,'K':8000,'L':9000,
'M':10000, 'N':12000, 'O':15000, 'P':20000, 'Q':30000}).astype(int) 
X = prep_data_questionarios(X)
X = fe_mun(X)
X = fe_questionario(X)
X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&(~train[target].isnull()), target].astype(np.float64)
```

Pr√©-processamento nos dados de teste

```{python}
X_test = test.copy()
X_test.loc[:, 'knn_feature'] = knn_test.knn_test
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test.loc[:, 'FE_RENDA'] = X_test.loc[:, 'Q006'].map({'A':0, 'B':1000, 'C':1500, 'D':2000,
'E':2500, 'F':3000, 'G':4000, 'H':5000, 'I':6000, 'J':7000, 'K':8000,'L':9000,
'M':10000, 'N':12000, 'O':15000, 'P':20000, 'Q':30000}).astype(int) 
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
X_test = fe_questionario(X_test)
X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)
```

Feature engineering separada para evitar data leak:

```{python}
# calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby('CO_ESCOLA').FE_RENDA.mean()
co_escola_idade_media = X.groupby('CO_ESCOLA').NU_IDADE.mean()
co_escola_nota_ch = X.groupby('CO_ESCOLA').NU_NOTA_CH.mean()
X = X.drop('NU_NOTA_CH', axis=1)

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    'CO_ESCOLA': co_escola_renda_media.index,
    'FE_ESCOLA_RENDA_MEDIA': co_escola_renda_media,
    'FE_IDADE_MEDIA': co_escola_idade_media,
    'FE_NOTA_CH': co_escola_nota_ch
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how='left', on='CO_ESCOLA')
X_test = pd.merge(X_test, co_escola_aux, how='left', on='CO_ESCOLA')

# Codigo da escola para categorico
X.loc[:, 'CO_ESCOLA'] = X.CO_ESCOLA.astype('object').astype('category')
X_test.loc[:, 'CO_ESCOLA'] = X_test.CO_ESCOLA.astype('object').astype('category')

# Features de contagem
X.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, 'FE_COUNT_ESCOLA'] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_ESCOLA'] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
```

Ajustar modelo:

```{python}
cat_feat = X.columns[X.dtypes=='category']
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna("XXX").astype("category")
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna("XXX").astype("category")

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)
    
clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = "RMSE",
                            od_type = "Iter",
                            od_wait = 100,
                            iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/lc_catboost.png){width=95%} 
</center>

Salvar previs√µes:

```{python}
sub.loc[:, 'NU_NOTA_LC'] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_PRESENCA_LC!=1, 'NU_NOTA_LC'] = 0
```

Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:

```{python}
sns.kdeplot(train.loc[:, target], shade=True, color='r', clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color='b', clip=[0,1000])
plt.legend(labels=['train', 'predict'])
plt.title(target)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/lc_pred.png){width=50%} 
</center>

### Ci√™ncias Humanas

Novas features desenvolvidas especificamente para este modelo:

```{python}
def fe_ch(df):
    
    df.loc[:, 'FE_RENDA'] = df.loc[:, 'Q006'].map({'A':0, 'B':1000,
    'C':1500, 'D':2000, 'E':2500, 'F':3000, 'G':4000, 'H':5000, 'I':6000,
    'J':7000, 'K':8000,'L':9000, 'M':10000, 'N':12000, 'O':15000, 
    'P':20000, 'Q':30000}).astype(int) 
    df.loc[:, 'FE_NU_IDADE*TP_ANO_CONCLUIU'] = df.TP_ANO_CONCLUIU * df.NU_IDADE
    df.loc[:, 'FE_Q002+Q024'] = df.loc[:, 'Q002'].map({'A':0, 'B':1, 'C':2, 
    'D':3, 'E':4, 'F': 5, 'G': 6, 'H': -1}).astype(int) + 
    df.loc[:, 'Q024'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4}).astype(int) 
    df.loc[:, 'FE_SCORE'] = (1/df.TP_ANO_CONCLUIU) + np.sqrt(df.NU_IDADE) +
    np.where(df.TP_ESCOLA==3, 1, 0)
    
    return df
```

Definir finalidade de algumas colunas:

```{python}
# colunas que serao dropadas
to_drop = ['IN_PROVA_DEITADO',
           'NU_INSCRICAO',
           'CO_MUNICIPIO_ESC',
           'CO_UF_NASCIMENTO',
           'CO_UF_RESIDENCIA',
           'CO_UF_ESC',
           'CO_UF_PROVA',
           'CO_MUNICIPIO_PROVA',
           'CO_MUNICIPIO_RESIDENCIA',
          'CO_MUNICIPIO_NASCIMENTO']

# definir target e presenca
target = "NU_NOTA_CH"
presenca = "TP_PRESENCA_CH"

# demais notas para dropar (menos lc)
notas = list(set(targets)-set([target, 'NU_NOTA_LC']))
```

Pr√©-processamento nos dados de treino

```{python}
X = train.copy()
X.loc[:, 'knn_feature'] = knn_train.knn_oof
X = X.drop(to_drop, axis=1)
X = X[X[presenca]==1]
X = X[~X[target].isnull()]

X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X = fe_ch(X)
X = prep_data_questionarios(X)
X = fe_mun(X)
X = fe_questionario(X)
#X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&(~train[target].isnull()), target].astype(np.float64)
```

Pr√©-processamento nos dados de teste

```{python}
X_test = test.copy()
X_test.loc[:, 'knn_feature'] = knn_test.knn_test
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test = fe_ch(X_test)
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
X_test = fe_questionario(X_test)
#X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)
```

Feature engineering separada para evitar data leak:

```{python}
# calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby('CO_ESCOLA').FE_RENDA.mean()
co_escola_idade_media = X.groupby('CO_ESCOLA').NU_IDADE.mean()
co_escola_nota_lc = X.groupby('CO_ESCOLA').NU_NOTA_LC.mean()
X = X.drop('NU_NOTA_LC', axis=1)

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    'CO_ESCOLA': co_escola_renda_media.index,
    'FE_ESCOLA_RENDA_MEDIA': co_escola_renda_media,
    'FE_IDADE_MEDIA': co_escola_idade_media,
    'FE_NOTA_LC': co_escola_nota_lc
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how='left', on='CO_ESCOLA')
X_test = pd.merge(X_test, co_escola_aux, how='left', on='CO_ESCOLA')

# Codigo da escola para categorico
X.loc[:, 'CO_ESCOLA'] = X.CO_ESCOLA.astype('object').astype('category')
X_test.loc[:, 'CO_ESCOLA'] = X_test.CO_ESCOLA.astype('object').astype('category')

# Features de contagem
X.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, 'FE_COUNT_ESCOLA'] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_ESCOLA'] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
```

Ajustar modelo:

```{python}
%%time

cat_feat = X.columns[X.dtypes=='category']
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna("XXX").astype("category")
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna("XXX").astype("category")

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)

clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = "RMSE",
                            od_type = "Iter",
                            od_wait = 100,iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/ch_catboost.png){width=95%} 
</center>

Salvar previs√µes:

```{python}
sub.loc[:, 'NU_NOTA_CH'] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_PRESENCA_CH!=1, 'NU_NOTA_CH'] = 0
```

Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:

```{python}
sns.kdeplot(train.loc[:, target], shade=True, color='r', clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color='b', clip=[0,1000])
plt.legend(labels=['train', 'predict'])
plt.title(target)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/ch_pred.png){width=50%} 
</center>

### Ci√™ncias da Natureza

Novas features desenvolvidas especificamente para este modelo:

```{python}
def fe_cn(df):
    df.loc[:, 'FE_RENDA'] = df.loc[:, 'Q006'].map({'A':0, 'B':1000,
    'C':1500, 'D':2000, 'E':2500, 'F':3000, 'G':4000, 'H':5000, 
    'I':6000, 'J':7000, 'K':8000,'L':9000, 'M':10000, 'N':12000, 
    'O':15000, 'P':20000, 'Q':30000}).astype(int) 
    df.loc[:, 'FE_NU_IDADE*TP_ANO_CONCLUIU'] = df.TP_ANO_CONCLUIU * df.NU_IDADE
    df.loc[:, 'FE_Q002+Q024'] = df.loc[:, 'Q002'].map({'A':0, 'B':1, 'C':2,
    'D':3, 'E':4, 'F': 5, 'G': 6, 'H': -1}).astype(int) + 
    df.loc[:, 'Q024'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4}).astype(int) 
    df.loc[:, 'FE_SCORE'] = (1/df.TP_ANO_CONCLUIU) + np.sqrt(df.NU_IDADE) + np.where(df.TP_ESCOLA==3, 1, 0)
    
    df.loc[:, 'FE_UF_ESCOLA'] = df.SG_UF_ESC.map({
      'AM':'Norte', 'RR':'Norte', 'AP':'Norte', 'PA':'Norte', 'TO':'Norte', 'RO':'Norte', 'AC':'Norte',
      'MA':'Nordeste', 'PI':'Nordeste', 'CE':'Nordeste', 'RN':'Nordeste', 'PE':'Nordeste', 'PB':'Nordeste', 'SE':'Nordeste', 'AL':'Nordeste', 'BA':'Nordeste',
      'MT': 'CentroOeste', 'MS': 'CentroOeste', 'GO': 'CentroOeste',
      'SP': 'Sudeste', 'RJ': 'Sudeste', 'ES': 'Sudeste', 'MG': 'Sudeste',
      'PR': 'Sul', 'RS': 'Sul', 'SC': 'Sul'}).astype('category')
    return df
```

Definir finalidade de algumas colunas:

```{python}
# colunas que serao dropadas
to_drop = ['IN_PROVA_DEITADO',
           'NU_INSCRICAO',
           'CO_MUNICIPIO_ESC',
           'CO_UF_NASCIMENTO',
           'CO_UF_RESIDENCIA',
           'CO_UF_ESC',
           'CO_UF_PROVA',
           'CO_MUNICIPIO_PROVA',
           'CO_MUNICIPIO_RESIDENCIA',
          'CO_MUNICIPIO_NASCIMENTO']

# definir target e presenca
target = "NU_NOTA_CN"
presenca = "TP_PRESENCA_CN"

# demais notas para dropar (menos mt)
notas = list(set(targets)-set([target, 'NU_NOTA_MT']))
```

Pr√©-processamento nos dados de treino

```{python}
X = train.copy()
X = X.drop(to_drop, axis=1) 
X = X[X[presenca]==1]
X = X[~X[target].isnull()]

X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X = fe_cn(X)
X = prep_data_questionarios(X)
X = fe_mun(X)
X = fe_questionario(X)
X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&(~train[target].isnull()), target].astype(np.float64)
```

Pr√©-processamento nos dados de teste

```{python}
X_test = test.copy()
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test = fe_cn(X_test)
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
X_test = fe_questionario(X_test)
X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)
```

Feature engineering separada para evitar data leak:

```{python}
# calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby('CO_ESCOLA').FE_RENDA.mean()
co_escola_idade_media = X.groupby('CO_ESCOLA').NU_IDADE.mean()
co_escola_nota_mt = X.groupby('CO_ESCOLA').NU_NOTA_MT.mean()
X = X.drop('NU_NOTA_MT', axis=1)

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    'CO_ESCOLA': co_escola_renda_media.index,
    'FE_ESCOLA_RENDA_MEDIA': co_escola_renda_media,
    'FE_IDADE_MEDIA': co_escola_idade_media,
    'FE_NOTA_MT': co_escola_nota_mt
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how='left', on='CO_ESCOLA')
X_test = pd.merge(X_test, co_escola_aux, how='left', on='CO_ESCOLA')

# Codigo da escola para categorico
X.loc[:, 'CO_ESCOLA'] = X.CO_ESCOLA.astype('object').astype('category')
X_test.loc[:, 'CO_ESCOLA'] = X_test.CO_ESCOLA.astype('object').astype('category')

# Features de contagem
X.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, 'FE_COUNT_ESCOLA'] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_ESCOLA'] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
```

Ajustar modelo:

```{python}
%%time

cat_feat = X.columns[X.dtypes=='category']
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna("XXX").astype("category")
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna("XXX").astype("category")

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)

clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = "RMSE",
                            od_type = "Iter",
                            od_wait = 100,iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/cn_catboost.png){width=95%} 
</center>

Salvar previs√µes:

```{python}
sub.loc[:, 'NU_NOTA_CN'] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_PRESENCA_CN!=1, 'NU_NOTA_CN'] = 0
```

Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:

```{python}
sns.kdeplot(train.loc[:, target], shade=True, color='r', clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color='b', clip=[0,1000])
plt.legend(labels=['train', 'predict'])
plt.title(target)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/cn_pred.png){width=50%} 
</center>

### Matem√°tica

Novas features desenvolvidas especificamente para este modelo:

```{python}
def fe_mt(df):
    
    df.loc[:, 'FE_RENDA'] = df.loc[:, 'Q006'].map({'A':0, 'B':1000, 'C':1500, 'D':2000, 'E':2500, 'F':3000, 'G':4000, 'H':5000, 'I':6000, 'J':7000, 'K':8000,'L':9000, 'M':10000, 'N':12000, 'O':15000, 'P':20000, 'Q':30000}).astype(int) 
    df.loc[:, 'FE_NU_IDADE*TP_ANO_CONCLUIU'] = df.TP_ANO_CONCLUIU * df.NU_IDADE
    df.loc[:, 'FE_Q002+Q024'] = df.loc[:, 'Q002'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F': 5, 'G': 6, 'H': -1}).astype(int) + df.loc[:, 'Q024'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4}).astype(int) 
    df.loc[:, 'FE_SCORE'] = (1/df.TP_ANO_CONCLUIU) + np.sqrt(df.NU_IDADE) + np.where(df.TP_ESCOLA==3, 1, 0)
    
    df.loc[:, 'FE_UF_ESCOLA'] = df.SG_UF_ESC.map({'AM':'Norte', 'RR':'Norte', 'AP':'Norte', 'PA':'Norte', 'TO':'Norte', 'RO':'Norte', 'AC':'Norte',
                'MA':'Nordeste', 'PI':'Nordeste', 'CE':'Nordeste', 'RN':'Nordeste', 'PE':'Nordeste', 'PB':'Nordeste', 'SE':'Nordeste', 'AL':'Nordeste', 'BA':'Nordeste',
                'MT': 'CentroOeste', 'MS': 'CentroOeste', 'GO': 'CentroOeste',
                'SP': 'Sudeste', 'RJ': 'Sudeste', 'ES': 'Sudeste', 'MG': 'Sudeste',
                'PR': 'Sul', 'RS': 'Sul', 'SC': 'Sul'}).astype('category')
    
    
    return df
```

Definir finalidade de algumas colunas:

```{python}
# colunas que serao dropadas
to_drop = ['IN_PROVA_DEITADO',
           'NU_INSCRICAO',
           'CO_MUNICIPIO_ESC',
           'CO_UF_NASCIMENTO',
           'CO_UF_RESIDENCIA',
           'CO_UF_ESC',
           'CO_UF_PROVA',
           'CO_MUNICIPIO_PROVA',
           'CO_MUNICIPIO_RESIDENCIA',
          'CO_MUNICIPIO_NASCIMENTO']

# definir target e presenca
target = "NU_NOTA_MT"
presenca = "TP_PRESENCA_MT"

# demais notas para dropar (menos cn)
notas = list(set(targets)-set([target, 'NU_NOTA_CN']))
```

Pr√©-processamento nos dados de treino

```{python}
X = train.copy()
X = X.drop(to_drop, axis=1) 
X = X[X[presenca]==1]
X = X[~X[target].isnull()]

X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X = fe_mt(X)
X = prep_data_questionarios(X)
X = fe_mun(X)
#X = fe_questionario(X)
#X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&(~train[target].isnull()), target].astype(np.float64)
```

Pr√©-processamento nos dados de teste

```{python}
X_test = test.copy()
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test = fe_mt(X_test)
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
#X_test = fe_questionario(X_test)
#X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)
```

Feature engineering separada para evitar data leak:

```{python}
# calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby('CO_ESCOLA').FE_RENDA.mean()
co_escola_idade_media = X.groupby('CO_ESCOLA').NU_IDADE.mean()
co_escola_nota_cn = X.groupby('CO_ESCOLA').NU_NOTA_CN.mean()
X = X.drop('NU_NOTA_CN', axis=1)

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    'CO_ESCOLA': co_escola_renda_media.index,
    'FE_ESCOLA_RENDA_MEDIA': co_escola_renda_media,
    'FE_IDADE_MEDIA': co_escola_idade_media,
    'FE_NOTA_CN': co_escola_nota_cn
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how='left', on='CO_ESCOLA')
X_test = pd.merge(X_test, co_escola_aux, how='left', on='CO_ESCOLA')

# Codigo da escola para categorico
X.loc[:, 'CO_ESCOLA'] = X.CO_ESCOLA.astype('object').astype('category')
X_test.loc[:, 'CO_ESCOLA'] = X_test.CO_ESCOLA.astype('object').astype('category')

# Features de contagem
X.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, 'FE_COUNT_ESCOLA'] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_ESCOLA'] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
```

Ajustar modelo:

```{python}
%%time

cat_feat = X.columns[X.dtypes=='category']
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna("XXX").astype("category")
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna("XXX").astype("category")

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)
    
clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = "RMSE",
                            od_type = "Iter",
                            od_wait = 100,iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/mt_catboost.png){width=95%} 
</center>

Salvar previs√µes:

```{python}
sub.loc[:, 'NU_NOTA_MT'] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_PRESENCA_CN!=1, 'NU_NOTA_MT'] = 0
```

Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:

```{python}
sns.kdeplot(train.loc[:, target], shade=True, color='r', clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color='b', clip=[0,1000])
plt.legend(labels=['train', 'predict'])
plt.title(target)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/mt_pred.png){width=50%} 
</center>

### Reda√ß√£o

Novas features desenvolvidas especificamente para este modelo:

```{python}
def fe_rd(df):
    
    df.loc[:, 'FE_RENDA'] = df.loc[:, 'Q006'].map({'A':0, 'B':1000, 'C':1500, 'D':2000, 'E':2500, 'F':3000, 'G':4000, 'H':5000, 'I':6000, 'J':7000, 'K':8000,'L':9000, 'M':10000, 'N':12000, 'O':15000, 'P':20000, 'Q':30000}).astype(int) 
    df.loc[:, 'FE_NU_IDADE*TP_ANO_CONCLUIU'] = df.TP_ANO_CONCLUIU * df.NU_IDADE
    df.loc[:, 'FE_Q002+Q024'] = df.loc[:, 'Q002'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F': 5, 'G': 6, 'H': -1}).astype(int) + df.loc[:, 'Q024'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4}).astype(int) 
    df.loc[:, 'FE_SCORE'] = (1/df.TP_ANO_CONCLUIU) + np.sqrt(df.NU_IDADE) + np.where(df.TP_ESCOLA==3, 1, 0)
    
    df.loc[:, 'FE_RENDA_FAMILIA_+_IDADE'] = df.loc[:, 'Q006'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'I':8, 'J':9, 'K':10,'L':11, 'M':12, 'N':13, 'O':14, 'P':15, 'Q':16}).astype(int) + df.NU_IDADE        
    df.loc[:, 'FE_RENDA_FAMILIA_+_ANO_CONCLUIU'] = df.loc[:, 'Q006'].map({'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'I':8, 'J':9, 'K':10,'L':11, 'M':12, 'N':13, 'O':14, 'P':15, 'Q':16}).astype(int)+ df.TP_ANO_CONCLUIU  
    
    return df
```

Definir finalidade de algumas colunas:

```{python}
# colunas que serao dropadas
to_drop = ['IN_PROVA_DEITADO',
           'NU_INSCRICAO',
           'CO_MUNICIPIO_ESC',
           'CO_UF_NASCIMENTO',
           'CO_UF_RESIDENCIA',
           'CO_UF_ESC',
           'CO_UF_PROVA',
           'CO_MUNICIPIO_PROVA',
           'CO_MUNICIPIO_RESIDENCIA',
          'CO_MUNICIPIO_NASCIMENTO']

# definir target e presenca
target = "NU_NOTA_REDACAO"
presenca = "TP_STATUS_REDACAO"

# demais notas para dropar 
notas = list(set(targets)-set([target]))
```

Pr√©-processamento nos dados de treino

```{python}
X = train.copy()
X = X.drop(to_drop, axis=1) 
X = X[X[presenca]==1]
X = X[~X[target].isnull()]


X = X.loc[:, ~X.columns.isin([target]+[presenca]+notas)]
X = fe_rd(X)
X = prep_data_questionarios(X)
X = fe_mun(X)
#X = fe_questionario(X)
X = fe_in(X)
X = prep_co_escola(X)
X = fe_extra(X)

y = train.loc[(train[presenca]==1)&(~train[target].isnull()), target].astype(np.float64)
```

Pr√©-processamento nos dados de teste

```{python}
X_test = test.copy()
X_test = X_test.drop(to_drop, axis=1) 

X_test = X_test.loc[:, ~X_test.columns.isin([presenca])]
X_test = fe_rd(X_test)
X_test = prep_data_questionarios(X_test)
X_test = fe_mun(X_test)
#X_test = fe_questionario(X_test)
X_test = fe_in(X_test)
X_test = prep_co_escola(X_test)
X_test = fe_extra(X_test)
```

Feature engineering separada para evitar data leak:

```{python}
# calcular estatisticas nos dados de treino
co_escola_renda_media = X.groupby('CO_ESCOLA').FE_RENDA.mean()
co_escola_idade_media = X.groupby('CO_ESCOLA').NU_IDADE.mean()

# instanciar objeto com as estatisticas por escola
co_escola_aux = pd.DataFrame({
    'CO_ESCOLA': co_escola_renda_media.index,
    'FE_ESCOLA_RENDA_MEDIA': co_escola_renda_media,
    'FE_IDADE_MEDIA': co_escola_idade_media
}).reset_index(drop=True)

# Concatenar estatisticas nas bases de treino e teste
X = pd.merge(X, co_escola_aux, how='left', on='CO_ESCOLA')
X_test = pd.merge(X_test, co_escola_aux, how='left', on='CO_ESCOLA')

# Codigo da escola para categorico
X.loc[:, 'CO_ESCOLA'] = X.CO_ESCOLA.astype('object').astype('category')
X_test.loc[:, 'CO_ESCOLA'] = X_test.CO_ESCOLA.astype('object').astype('category')

# Features de contagem
X.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_PROVA'] = X_test.NO_MUNICIPIO_PROVA.map({x: y for x, y in zip(X.NO_MUNICIPIO_PROVA.value_counts().index.values, X.NO_MUNICIPIO_PROVA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X.NO_MUNICIPIO_RESIDENCIA.map({x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_RESIDENCIA'] = X_test.NO_MUNICIPIO_RESIDENCIA.map({ x: y for x, y in zip(X.NO_MUNICIPIO_RESIDENCIA.value_counts().index.values, X.NO_MUNICIPIO_RESIDENCIA.value_counts().values)})

X.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X.NO_MUNICIPIO_NASCIMENTO.map({ x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})
X_test.loc[:, 'FE_COUNT_MUNICIPIO_NASCIMENTO'] = X_test.NO_MUNICIPIO_NASCIMENTO.map({x: y for x, y in zip(X.NO_MUNICIPIO_NASCIMENTO.value_counts().index.values, X.NO_MUNICIPIO_NASCIMENTO.value_counts().values)})

X.loc[:, 'FE_COUNT_ESCOLA'] = X.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
X_test.loc[:, 'FE_COUNT_ESCOLA'] = X_test.CO_ESCOLA.map({x: y for x, y in zip(X.CO_ESCOLA.value_counts().index.values, X.CO_ESCOLA.value_counts().values)})
```

Ajustar modelo:

```{python}
%%time

cat_feat = X.columns[X.dtypes=='category']
cat_indices = [X.columns.get_loc(x) for x in cat_feat]

for c in list(cat_feat):
    X.loc[:, c] = X.loc[:, c].astype(object).fillna("XXX").astype("category")
    X_test.loc[:, c] = X_test.loc[:, c].astype(object).fillna("XXX").astype("category")

X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.1, random_state=SEED)

clf = CatBoostRegressor(random_state=314,
                            cat_features=cat_indices,
                            verbose=0,
                            loss_function = "RMSE",
                            od_type = "Iter",
                            od_wait = 100,iterations=3000,
                            use_best_model=True)

clf.fit(X, y, eval_set = (X_eval, y_eval), verbose=False, plot=True)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/redacao_catboost.png){width=95%} 
</center>

Salvar previs√µes:

```{python}
sub.loc[:, 'NU_NOTA_REDACAO'] = clf.predict(X_test)
# alunos que nao foram fazer a prova tiraram zero
sub.loc[test.TP_STATUS_REDACAO!=1, 'NU_NOTA_REDACAO'] = 0
```

Comparar distribui√ß√£o da target nos dados de treino com rela√ß√£o √†s previs√µes do modelo:

```{python}
sns.kdeplot(train.loc[:, target], shade=True, color='r', clip=[0,1000])
sns.kdeplot(sub.loc[:, target], shade=True, color='b', clip=[0,1000])
plt.legend(labels=['train', 'predict'])
plt.title(target)
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/redacao_pred.png){width=50%} 
</center>

# Submiss√£o

Veja a seguir como ficou a distribui√ß√£o das previs√µes comparada √† distribui√ß√£o da target nos dados de treino:

```{python}
plt.figure(figsize=(16, 5))

notas = ['NU_NOTA_CH', 'NU_NOTA_CN', 'NU_NOTA_MT', 'NU_NOTA_LC', 'NU_NOTA_REDACAO']

for i in range(len(notas)):

    plt.subplot(1, 5, i+1)
    sns.kdeplot(train.loc[:, notas[i]], shade=True, color='r', clip=[0,1000])
    sns.kdeplot(sub.loc[:, notas[i]], shade=True, color='b', clip=[0,1000])
    plt.legend(labels=['train', 'predict'])
    plt.title(notas[i])
plt.tight_layout()
plt.show()
```

<center>
![](/post/2022-04-20-solucao-final-education-quality-kaggle-competition/all_pred.png){width=95%} 
</center>

Acredito que talvez um tuning do modelo poderia trazer mais qualidade √†s previs√µes mas com o tempo limitado n√£o pude investir muito nesta etapa. 

# Considera√ß√µes Finais

Em resumo, essas foram as principais id√©ias para a solu√ß√£o da competi√ß√£o e acredito que um dos segredos era focar em feature engineering por 2 motivos:

* A base era muito grande e o processo de tuning seria muito custoso (a n√£o ser que tenha um √≥timo computador a disposi√ß√£o);
* Os atributos n√£o eram an√¥nimos, o que d√° muita informa√ß√£o de contexto.

Agrade√ßo aos organizadores e √† todos os participantes que tornaram esta competi√ß√£o t√£o divertida! Por mais competi√ß√µes como esta, que valorizam a comunidade brasileira de Data Science!

Espero que tenham gostado e at√© logo!

Abra√ßos!

Fellipe Gomes
