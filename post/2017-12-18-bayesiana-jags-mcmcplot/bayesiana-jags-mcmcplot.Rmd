---
title: Ajustando Modelos Bayesianos com JAGS
author: Fellipe Gomes
date: '2017-12-18'
slug: []
categories:
  - Estatistica
  - R
  - Teoria
  - Bayes
  - Inferência Bayesiana
  - Modelagem Estatistica
tags:
  - Estatistica
  - gomesfellipe
  - R
  - jags
  - bayes
  - modelagem
  - modelagem estatistica
description: ''
featured: 'bayes-R-jags.jpg'
featuredalt: 'Pic 5'
featuredpath: 'date'
linktitle: ''
type: post
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, error = F, warning = F)
```

# Inferência bayesiana 

[Imagem da Internet](https://www.flickr.com/photos/mattbuck007/3676624894/in/photolist-6ATEuo-9TK3TW)

Quando estamos falando de Inferência nosso objetivo normalmente é tentar verificar alguma informação sobre uma quantidade desconhecida.

Para isso devemos utilizar **toda** informação disponível, seja ela **objetiva** ou **subjetiva** (isto é, vinda de umam amostra ou de algum conhecimento préveo ou intuitivo)

Segundo o ponto de vista Bayesiano essa informação subjetiva também será incorporada na análise graças ao [teorema de bayes](https://pt.wikipedia.org/wiki/Teorema_de_Bayes).

Como no ponto de vista Bayesiano atribuímos aleatoriedade ao parâmetro, nossa "crença" será representada por uma distribuição de probabilidade (ou modelo probabilístico)

*Teorema de bayes*:
$$
p(\theta|x)=\frac{p(x,\theta)}{p(x)}=\frac{p(x|\theta)p(\theta)}{p(x)}
$$

onde:

  * $p(x|\theta)$: função de verossimilhança (modelo)
  * $p(\theta)$: distribuição a priori
  * $p(x)$: distribuição marginal de $x$.

A estimação muitas vezes envolve o cálculo de integrais nada simples analiticamente porém, alguns algorítimos como o amostrador de Gibbs pode relizar aproximações muito relevantes.

# Modelo linear bayesiano

Para entender como funciona o modelo bayesiano, primeiramente vamos começar com algo bem simples, suponha:

$$
Y_i \sim N(\mu_i,\tau)
$$
onde $\mu$ é definido como $\mu_i= X \mathbf{\beta}$.

Incialmente vamos considerar que não existe relação nenhuma, então utilizaremos a priori:

$$
\beta \sim N(0,\tau_{\beta})
$$ 

onde $\tau$ é conhecido.

Nem sempre é  uma tarefa simples determinar a distribuição posteri de um modelo bayesiano e é neste ponto que o pacote `jags`será bastante útil (existem outras alternativas como o [WinBugs](https://cran.r-project.org/package=R2WinBUGS), [OpenBugs](https://cran.r-project.org/package=R2OpenBUGS), [Stan](https://cran.r-project.org/web/packages/rstan/index.html), mas aqui resolvi trazer apenas o [jags](https://cran.r-project.org/package=rjags) por possuir vantagens bem interessantes.)

# Jags

O pacote [`R2jags`](https://cran.r-project.org/package=R2jags) é exatamente o que seu nome significa: "*Just Another Gibbs Sampler*". Possui as mesmas funcionalidades do nosso querido [OpenBugs](https://cran.r-project.org/package=R2OpenBUGS) possibilitando também que seja utilizado inteiramente dentro do ambiente R. 

Assim como o OpenBugs, ele também trabalha chamando o [software oficial que precisa ser baixado no site](mcmc-jags.sourceforge.net/).

Para começar a utilizar basta baixar o pacote e acessá-lo na biblioteca:

```{r,warning=F}
library(R2jags)
```


# Declarando o modelo

A base de dados que será utilizada para ajustar o modelo será a base nativa do R chamada `trees`:

```{r}
X<-trees[,1:2] #Matriz de variáveis explanatórias
Y<- trees[,3]  #Vetor da variável resposta
p <- ncol(X)   #p é o número de parâmetros do modelo (nesse caso é o número de colunas)
n <- nrow(X)   #n é o número de observações do modelo
```

O modelo deve estar declarado e salvo em um arquivo `.txt` (ou mesmo um outro arquivo `.r`) da seguinte maneira:

```{r,eval=F}
### Declarando o modelo Bayesiano
sink("linreg.txt")
cat("
    model {
    
    # Prioris
    for(j in 1:p)
    {
    beta[j] ~ dnorm(mu.beta, tau.beta)       
    }
    sigma ~ dunif(0, 100)            
    tau <- 1/ (sigma * sigma)
    
    # Verossimilhança
    for (i in 1:n) {
    y[i] ~ dnorm(mu[i], tau)
    mu[i] <- inprod(X[i,], beta)
    }

    }
    ",fill=TRUE)
sink()
```

Uma vez que o modelo esta declarado, é a hora de nomear os parametros da função que fará o ajuste do modelo

```{r}
#Parametros da Priori
mu.beta <- 0
tau.beta <- 0.001

#Set Working Directory
wd <- getwd()

# Junte os dados em uma lista
win.data <- list(X=X,y=Y,p=p,n=n,mu.beta=mu.beta,tau.beta=tau.beta)

# Função de inicialização
inits <- function(){ list(beta=rnorm(p), sigma = rlnorm(1))}

# Os parametros que desejamos estimar
params <- c("beta","sigma","tau")

# Caracteristicas do MCMC
n.burnin <- 500                    #Número de iterações que serão descartadas
n.thin <- 10                       #para economizar memória e tempo de computação se n.iter for grande
n.post <- 5000  
n.chains <- 3                      #Número de cadeias
n.iter <- n.burnin + n.thin*n.post #Número de iterações

```

# Implementando o modelo

Após ter em mãos todos esses resultados, já podemos ajustar o modelo com o comando `jags()`, veja:

```{r}
bayes.mod.fit <-jags(data = win.data,
                     inits = inits,
                     parameters = params,
                     model.file = "linreg.txt",  # O arquivo "linreg.txt" deve estar no mesmo diretório
                     n.iter = n.iter,
                     n.thin=n.thin,
                     n.burnin=n.burnin,
                     n.chains=n.chains,
                     working.directory=wd,DIC = T)

print(bayes.mod.fit, dig = 3)
```

Com os resultados em mãos podemos avaliar o ajuste do modelo, o jags nos fornece os intervalos de credibilidade e o Rhat, que é a convergência da cadeia, a princípio vamos apenas considerar o fato de que quanto mais próximo de 1, melhor são as estimativas.

Não vou me extender neste post com a interpretação do modelo pois o objetivo esta sendo mostrar a funcionalidade do jags em conjunto com o R.

# Diagnósticos do modelo com `mcmcplots`

Para o diagnóstico do modelo podemos utilizar o pacote `mcmcplots` que fornece de maneira bem agradável os resultados gerados pelo amostrador, primeiramente vamos carregar o pacote:

```{r,warning=F}
library(mcmcplots)
```

Em seguida precisar informar para o `R` que o resultado do algorítimo se trata de um objeto mcmc, portanto:

```{r}
bayes.mod.fit.mcmc <- as.mcmc(bayes.mod.fit)
summary(bayes.mod.fit.mcmc)
```

O pacote nos fornece alguns tipos de gráficos para diagnóstico

```{r}
caterplot(bayes.mod.fit.mcmc)                #Observando todas as estimativas
caterplot(bayes.mod.fit.mcmc,parms = params) #Observando as estimativas de todos os parâmetros menos o desvio
denplot(bayes.mod.fit.mcmc)                  #Densidade das estimativas de cada cadeia
traplot(bayes.mod.fit.mcmc,greek = T)        #Avaliando a convergência
```

E por fim, para diagnósticos rápidos, pode produzir arquivos html com traço, densidade e autocorrelação. 

O comando traça tudo em uma página e os arquivos serão exibidos em seu navegador de internet padrão.

```{r,eval=F}
mcmcplot(bayes.mod.fit.mcmc)
```

Vai retornar um relatório resumido para todos os parâmetros como nesta [imagem da internet](https://introndatalab.com/wp-content/uploads/manually/20150405/MCMC%20Plots%20%20result2_files/attack[1,1].png) como:

![](/post/2017-12-18-bayesiana-jags-mcmcplot/bayesiana-jags-mcmcplot_files/imagem1.png)

Como o objetivo do post é trazer a funcionalidade do pacote, vou apenas deixar ilustrado quais são algumas das funções mais comumente utilizadas para avaliar estatísticamente o desempenho dos modelos.

Diagnosticos estatísticos do modelo:

```{r}
#Mais diagnosticos:
gelman.plot(bayes.mod.fit.mcmc)
geweke.diag(bayes.mod.fit.mcmc)
geweke.plot(bayes.mod.fit.mcmc)
raftery.diag(bayes.mod.fit.mcmc)
heidel.diag(bayes.mod.fit.mcmc)
```

# Diagnostico de convergencia rapida: `superdiag`

Uma função muito conveniente para analisar representações numéricas de diagnósticos em um ajuste é o pacote `superdiag` de Tsai, Gill e Rapkin, 2012 que trás uma série de estatísticas para avaliar o desempenho dos ajustes do modelo.

```{r}
library(superdiag)
superdiag(bayes.mod.fit.mcmc, burnin = 100)
```

Para finalizar, outra função que pode ser útil pata atualizando o modelo, se necessário - por exemplo, se não houver convergência ou pouca convergencia:

```{r}
bayes.mod.fit.upd <- update(bayes.mod.fit, n.iter=1000)
bayes.mod.fit.upd <- autojags(bayes.mod.fit)
```

# Muito a estudar

Assim como toda a Estatística, inferência bayesiana não funciona se a teoria não for aplicada corretamente. É uma ferramenta muito poderosa e necessita ser usada com cautela pois demanda bastante o uso de metodologias estatísticas.

Como dizia o tio Ben: "grandes poderes trazem grandes responsabilidades" então vamos tomar cuidado com os resultados que encontramos.

# Referencias

[Uma primeira olhada em estatística bayesiana e linguagem BUGS por Augusto Ribas - blog Recologia](http://recologia.com.br/2012/12/uma-primeira-olhada-em-estatistica-bayesiana-e-linguagem-bugs/)

[John K. Kruschke 2014 Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan.2nd Edition. Academic Press / Elsevier.](http://www.users.csbsju.edu/~mgass/robert.pdf)