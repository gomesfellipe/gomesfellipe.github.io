---
title: Otimizando pipelines que envolvem dados desbalanceados
author: Fellipe Gomes
date: '2021-06-28'
slug: []
categories:
  - Aprendizado Supervisionado
  - Automa√ß√£o
  - Dados Desbalanceados
  - Estatistica
  - Machine Learning
  - modelo baseado em arvores
  - Pr√°tica
  - R
  - randomforest
tags:
  - tunning
  - Tidyverse
  - Tidymodels
  - random forest
  - R
  - Pr√°tica
  - machine learning
  - kaggle
  - imbalanced
  - imbalanced data
  - workflowsets
description: 'Utilizaremos o framework tidymodels para machine learning em R com o aux√≠lio do pacote workflowsets para otimizar pipelines de dados desbalanceados'
featured: 'img1.png'
featuredalt: 'Pic 26'
featuredpath: 'date'
linktitle: ''
type: "post"
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
image_preview: 'img1.png'
---

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 33%;
padding: 10px;
}

.column8 {
float: left;
width: 66%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, error = F, 
                      fig.height = 3,  fig.align = "center")
```

# O problema envolvendo dados desbalanceados
 
A tarefa de classifica√ß√£o com dados desbalanceados √© muito comum na vida real podendo variar desde um leve vi√©s at√© um enorme desequil√≠brio na distribui√ß√£o da classe de interesse. Problemas mais comuns envolvem:

- Detec√ß√£o de fraude;
- Previs√£o de inadimpl√™ncia;
- Identificador de *spam*;
- Busca por anomalias/outliers;
- Detec√ß√£o de poss√≠veis roubos/furtos/vulnerabilidades;
- Previs√£o de *churn*;
- etc

<div class="row">
<div class="column8"> 

Este tipo de tarefa representa um enorme desafio para modelagem preditiva pois a maioria dos algoritmos de machine learning foram projetados sob suposi√ß√£o de haver um n√∫mero igual de exemplos para cada classe de interesse.

E isso √© um grande problema pois normalmente estamos interessados em prever a classe minorit√°ria e para isso √© preciso tomar uma s√©rie de decis√µes, como por exemplo: m√©trica utilizada, m√©todo para valida√ß√£o cruzada, ado√ß√£o (ou n√£o) do uso de m√©todos de reamostragem, quais algoritmos utilizar, qual ser√° o threshold, etc
</div>

<div class="column4">
</br>
![[Via Giphy](https://media.giphy.com/media/JPV8lNtI59zaWyL4pf/giphy.gif)](https://media.giphy.com/media/JPV8lNtI59zaWyL4pf/giphy.gif)
</div>

</div>

Lidar com dados desbalanceados √© um assunto longo portanto tentarei dar mais aten√ß√£o apenas em um *hack* para encontrar a melhor forma de se aplicar o balanceamento dos dados. N√£o pretendo me aprofundar na teoria envolvida na escolha das m√©tricas neste post, caso o leitor deseje se aprofundar sobre a teoria envolvida com classifica√ß√£o que envolve dados desbalanceados, sugiro a leitura do livro: [Imbalanced Classification with Python - Choose Better Metrics, Balance Skewed Classes and Apply Cost-Sensitive Learning](https://machinelearningmastery.com/imbalanced-classification-with-python/) e consultar os links de refer√™ncia no final do post).

# Objetivo 

Utilizaremos neste post o pacote `workflowsets` a fim de otimizar o pipeline de reamostragem da base para lidar com o desbalanceamento dos dados. 

Para efeitos de compara√ß√£o, utilizarei como refer√™ncia o (excelente) [post escrito recentemente pela Julia Silge](https://juliasilge.com/blog/sliced-aircraft/) em seu blog que tamb√©m aborda o problema de dados desbalanceados utilizando um conjunto de dados de uma [competi√ß√£o do Kaggle](https://www.kaggle.com/c/sliced-s01e02-xunyc5). Utilizarei a mesma configura√ß√£o de pr√©-processamento adotado em seu post para que a compara√ß√£o seja justa.

Portanto, nosso objetivo de modelagem ser√° prever se uma colis√£o com animais selvagens resultou em danos a aeronave.

<div class="w3-panel w3-pale-green w3-border">
‚ö†Ô∏è Este dataset √© rico em possibilidades para diferentes tipos de pr√© processamentos e por isso convido o leitor a analis√°-lo com maior profundidade e tamb√©m a compartilhar seus resultados!
</div>

# Depend√™ncias

Primeiro vamos carregar as bibliotecas necess√°rias e algumas fun√ß√µes desenvolvidas para o post

```{r}
library(tidyverse)    # ds toolkit
library(tidymodels)   # ml toolkit
library(baguette)     # bag_tree
library(themis)       # imbalanced
library(workflowsets) # opt pipelines
library(patchwork)    # arrange plots 

doParallel::registerDoParallel()
theme_set(theme_bw())
```

<details>
<summary>(*Clique aqui para ver as fun√ß√µes* `print_table` *e* `conf_mat_plot` *importadas*)</summary>

```{r}
# Para o print de tabelas
print_table <- function(x, round=0, cv=F, wf=F, bm=F, ...){ 
  
  if(round>0) x <- x %>% mutate_if(is.numeric, ~round(.x, round))
  
  if(cv==T){
    columns_spec = list(
      .metric = reactable::colDef(minWidth = 75),
      .estimator = reactable::colDef(minWidth = 70),
      .config = reactable::colDef(minWidth = 120)
    )
  } else if(wf==T){
    columns_spec = list(
      wflow_id = reactable::colDef(minWidth = 100),
      .metric = reactable::colDef(minWidth = 100),
      preprocessor = reactable::colDef(minWidth = 110),
      rank = reactable::colDef(minWidth = 50),
      n = reactable::colDef(minWidth = 50)
    )
  }else if (bm==T){
    columns_spec = list(
      wflow_id = reactable::colDef(minWidth = 130),
      model = reactable::colDef(minWidth = 80)
    )
  }else{
    columns_spec = NULL
  }
  
  reactable::reactable(x, striped = T, bordered = T,
                       highlight = T, pagination = F, resizable = T, 
                       columns = columns_spec, ...)
  
}

# Para plot da matriz de confusao e distribuicoes de probabilidade
conf_mat_plot <- function(x, null_model = FALSE){
  p1 <- 
    x %>%
    select(.pred_class, damaged) %>%
    table() %>% 
    conf_mat() %>% 
    autoplot(type = "heatmap")+
    labs(title = "Matriz de confus√£o")
  
  p2 <- 
    x  %>%
    ggplot() +
    geom_density(aes(x = .pred_damage, fill = damaged), 
                 alpha = 0.5)+
    labs(title = "Distribui√ß√µes de probabilidade previstas",
         subtitle = "por classe")+ 
    scale_x_continuous(limits = 0:1)+
    scale_fill_brewer(palette="Set1")
  
  p1 | p2
} 
```
</details>
&nbsp;

Em seguida vamos importar os dados provenientes da competi√ß√£o Inclass do Kaggle [SLICED s01e02 - Predict whether an aircraft strike with wildlife causes damage](https://www.kaggle.com/c/sliced-s01e02-xunyc5). Para mais informa√ß√µes consulte a [documenta√ß√£o e dicion√°rio dos dados](https://www.kaggle.com/c/sliced-s01e02-xunyc5/data).

```{r}
df <- read_csv("train.csv")
```

Note que carregamos apenas os dados de treino pois os dados de teste n√£o possuem a target.

# Preparar dados

Tratar a vari√°vel target `damaged` e avaliar sua distribui√ß√£o:

```{r}
df <- df %>% 
  mutate(damaged = if_else(damaged==1, "damage", "not_damage") %>% 
           factor(levels = c("damage", "not_damage")))
```

<details>
<summary>(*Clique aqui para ver o c√≥digo do gr√°fico abaixo*)</summary>

```{r}
p1 <- df %>% 
  count(damaged) %>% 
  ggplot(aes(x=rev(damaged), y=n, fill=damaged))+
  geom_bar(stat = "identity")+
  scale_fill_brewer(palette="Set1")+
  theme(legend.position = "bottom")+
  labs(y="N√∫mero de inst√¢ncias", x = "")

p2 <- df %>% 
  count(damaged) %>% 
  arrange(desc(damaged)) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(ypos = cumsum(prop)- 0.5*prop )%>% 
  ggplot(aes(x="", y=prop, fill=damaged)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  theme_void() + 
  theme(legend.position="none") +
  geom_text(aes(y = ypos,
                label = paste(scales::comma(n, big.mark = "."),
                              scales::comma(n/sum(n), big.mark = ".", 
                                            suffix = "%" ),sep = "\n")
                
  ), 
  color = "white", size=6) +
  scale_fill_brewer(palette="Set1")
```
</details>
&nbsp;


```{r, fig.height=4, fig.width=6, fig.align="center"}
p1 + p2 
```

Veja que estamos diante de um problema que existem aproximadamente 9 casos de dano para cada 100 eventos observados.

# Breve an√°lise explorat√≥ria

Vamos iniciar a explorat√≥ria com uma avalia√ß√£o geral dos dados brutos

```{r}
DataExplorer::plot_intro(df, ggtheme = theme_bw(), 
                         theme_config = list(legend.position = "bottom"))
```

Primeira informa√ß√£o que chama aten√ß√£o √© que quase 1/4 desses dados √© faltante. Vamos olhar a estrutura dessa base de maneira mais aprofundada:

```{r}
df %>% 
  sample_frac(0.01) %>% 
  visdat::vis_dat()
```

Parece existir algum padr√£o nos dados faltantes (que coocorrem em diveros atributos). Al√©m disso algumas colunas est√£o quase inteiramente vazias e ser√£o descartadas no processo de modelagem.

Uma vis√£o geral das classes das features categ√≥ricas:

```{r, fig.height=5}
df %>%
  select(-damaged, -id)%>%
  mutate_all(as.factor) %>%
  inspectdf::inspect_cat() %>% 
  inspectdf::show_plot()
```

Algumas features possuem muitas classes e caso seja feita a transforma√ß√£o *one-hot-encoding* (estrat√©gia amplamente utilizada para lidar com features categ√≥ricas) sem algum cuidado, o desempenho da maioria dos modelos de machine learning pode ser prejudicado por tornar a base anal√≠tica muito esparsa.

Uma vis√£o geral das classes das features num√©ricas em rela√ß√£o a target:

```{r, fig.height=4}
num_columns <- c(df %>% select_if(is.numeric) %>% colnames(), 'damaged')
df%>% 
  select_at(num_columns) %>% 
  select(-id) %>%
  gather(key, value, -damaged) %>%
  ggplot(aes(y=damaged, x=value))+
  geom_boxplot()+
  facet_wrap(~key, ncol=5, scales = "free_x")+
  labs(x = "", y="")
```

Parece que algumas features possuem comportamentos diferentes quando avaliados segundo a target. Al√©m disso √© poss√≠vel notar que as features `aircraft_mass`, `distance`, `engine4_position`, `engines`, `height` e `speed` apresentam outliers.

# Modelagem

Finalmente chegamos a modelagem! 

Primeiro vamos definir um esquema de reamostragem (com estratifica√ß√£o) que ser√° utilizado para avaliar os modelos e as m√©tricas de qualidade.

```{r}
set.seed(123)

bird_folds <- vfold_cv(df, v = 5, strata = damaged)
bird_metrics <- metric_set(mn_log_loss, accuracy, sensitivity, specificity)
```

Nossos conjuntos de pipelines necessitar√£o de um pr√©-processador base que ser√° comum a todos como camada inicial. Para isso utilizaremos o mesmo definido no post de refer√™ncia.

```{r}
base_rec <- recipe(damaged ~ ., data = df) %>%
  step_select( damaged, flight_impact, precipitation,
               visibility, flight_phase, engines, incident_year,
               incident_month, species_id, engine_type,
               aircraft_model, species_quantity, height, speed) %>% 
  step_novel(all_nominal_predictors()) %>%
  step_other(all_nominal_predictors(), threshold = 0.01) %>%
  step_unknown(all_nominal_predictors()) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_zv(all_predictors())
```

## Baselines

Para efeitos de compara√ß√£o, vamos ajustar 2 modelos que ser√£o utilizados como baselines para saber se a complexidade que estamos adicionando no modelo est√° realmente trazendo algum ganho na performance do modelo. Os modelos ser√£o:

- Modelo nulo: um modelo que sempre prev√™ a classe majorit√°ria;
- Modelo de base: [Bagged Decision Tree](https://bradleyboehmke.github.io/HOML/bagging.html) sem adicionar pr√©-processamento para compensar o desequil√≠brio de classe.

### Modelo nulo

Avaliando modelo nulo via valida√ß√£o cruzada:

```{r}
null_spec <- null_model(mode = "classification") %>% 
  set_engine("parsnip")

null_wf <-
  workflow() %>%
  add_recipe(base_rec) %>%
  add_model(null_spec)

null_rs <-
  fit_resamples(
    object = null_wf,
    resamples = bird_folds,
    metrics = bird_metrics,
    control = control_resamples(save_pred = TRUE)
  ) 

collect_metrics(null_rs) %>% print_table(round = 5, cv = T) 
```

Qualquer modelo com desempenho pior do que este deve ser descartado. Vejamos a matriz de confus√£o:

```{r}
collect_predictions(null_rs) %>% 
  conf_mat_plot()
```

### Modelo de base

Agora vamos ajusta o modelo *Bagged Decision Tree* sem o pr√©-processamento para compensar o desequil√≠brio de classe:

```{r}
bag_spec <-
  bag_tree(min_n = 10) %>%
  set_engine("rpart", times = 25) %>%
  set_mode("classification")

imb_wf <-
  workflow() %>%
  add_recipe(base_rec) %>%
  add_model(bag_spec)

set.seed(123)
imb_rs <-
  fit_resamples(
    imb_wf,
    resamples = bird_folds,
    metrics = bird_metrics,
    control = control_resamples(save_pred = TRUE)
  )

collect_metrics(imb_rs) %>% print_table(round = 5, cv = T)
```

Apesar do elevado n√∫mero de falsos negativos, este modelo j√° esta com um desempenho razo√°vel em compara√ß√£ao ao modelo nulo e o n√∫mero de verdadeiros positivos j√° √© quase o dobro do n√∫mero de falsos positivos. Veja na matriz de confus√£o abaixo:

```{r}
collect_predictions(imb_rs) %>% 
  conf_mat_plot()
```

## Preparar Pipeline de dados com `workflowsets`

A escolha do m√©todo de amostragem dos dados √© t√£o importante quanto a escolha do modelo preditivo que ser√° utilizado pois o desempenho pode ser enganosamente otimista visto que o algoritmo de bagging n√£o esta usando nenhuma estrat√©gia de subamostragem aleat√≥ria da classe majorit√°ria em cada amostra de bootstrap para equilibrar as duas classes. 

Existem muitos m√©todos para amostragem de dados e n√£o h√° um m√©todo √∫nico que seja melhor em todos os problemas de classifica√ß√£o (assim como n√£o existe o "melhor modelo") portanto, utilizaremos este pacote para testar diferentes m√©todos e tamb√©m tunar seus hiperpar√¢metros.

### Oversampling

Estes m√©todos duplicam ou sintetizam novos dados da classe minorit√°ria. Deve ser usado com cautela pois na vida real pode gerar alguns dados que n√£o condizem com a relidade ou criar tantas inst√¢ncias que acaba consumindo muito mais tempo de processamento.

#### Random Oversampling

Este m√©todo simplesmente duplica aleat√≥riamente exemplos da classe minorit√°ria. Vamos tunar esta propor√ß√£o buscando n√∫meros reais no intervalo [0.5,1].

```{r}
rec_up <- base_rec %>% 
  step_upsample(damaged, over_ratio = tune())

params_up <- rec_up %>% 
  parameters() %>% update(over_ratio = mixture(c(0.5, 1)))
```

#### SMOTE - Synthetic Minority Oversampling Technique

O SMOTE funciona gerando novos dados sint√©tios baseados em exemplos selecionando que est√£o "pr√≥ximos". Vamos tunar tanto a propor√ß√£o de dados que ser√£o gerados quanto a quantidade de vizinhos selecionados, buscando n√∫meros reais e inteiros no intervalo [0.5,1] e [1, 10], respectivamente.

```{r}
rec_smote <- base_rec %>%
  step_dummy(all_nominal_predictors()) %>%
  step_smote(damaged, over_ratio = tune(), 
             neighbors = tune())

params_smote <- rec_smote %>% 
  parameters() %>% update(over_ratio = mixture(c(0.5, 1)),
                          neighbors = neighbors())
```

#### ADASYN - Adaptive Synthetic Sampling

O ADASYN √© uma extens√£o do SMOTE que busca propor melhorias. Vamos tunar os mesmos par√¢metros definidos no SMOTE. 

```{r}
rec_adasyn <- base_rec %>%
  step_dummy(all_nominal_predictors()) %>%
  step_adasyn(damaged, 
              over_ratio = tune(), 
              neighbors = tune())

params_adasyn <- rec_adasyn %>% 
  parameters() %>% update(over_ratio = mixture(c(0.5, 1)),
                          neighbors = neighbors())
```

### Undersampling 

S√£o t√©cnicas que excluem ou selecionam um subconjunto de exemplos da classe majorit√°ria e existem dezenas (se n√£o centenas) desses m√©todos. Neste post utilizaremos s√≥ 3 mas existem outros implementados em outras bibliotecas (em R e em Python).

#### Random Undersampling

Este √© o m√©todo mais simples e envolve a exclus√£o aleat√≥ria de algumas inst√¢ncias da classe majorit√°ria. Vamos tunar esta propor√ß√£o de frequ√™ncias da minorit√°ria para a majorit√°ria.

```{r}
rec_down <- base_rec %>% 
  step_downsample(damaged, under_ratio = tune())

params_down <- rec_down %>% 
  parameters() %>% update(under_ratio = deg_free())
```

#### Near Miss Undersampling

Este algoritmo se baseia em m√©todos de KNN selecionando exemplos da classe majorit√°ria que tem menor dist√¢ncia m√©dia dos k exemplos mais pr√≥ximos. Vamos tunar tanto a propor√ß√£o quanto o n√∫mero de vizinhos utilizados. 

```{r}
rec_nearmiss <- base_rec %>%
  step_dummy(all_nominal_predictors()) %>%
  step_nearmiss(damaged, 
                under_ratio = tune(), 
                neighbors = tune())

params_nearmiss <- rec_nearmiss %>% 
  parameters() %>% update(under_ratio = deg_free(),
                          neighbors = neighbors())
```

#### Tomek Links Undersampling

Este algoritmo que tenta excluir inst√¢ncias que sejam pr√≥ximas e que possuam classes diferentes, buscando diminuir a ambiguidade dos dados. N√£o vamos tunar nenhum hiperpar√¢metro aqui.

```{r}
rec_tomek <- base_rec %>%
  step_dummy(all_nominal_predictors()) %>%
  step_tomek(damaged)
```

### Preparar pipeline de dados

Agora que todos pipelines de dados candidatos est√£o definidos, vamos combinar tudo em um √∫nico objeto com `workflow_set`:

```{r}
chi_models <- 
  workflow_set(
    preproc = list(upsample = rec_up,
                   smote = rec_smote,
                   adasyn = rec_adasyn,
                   downsample = rec_down,
                   nearmiss = rec_nearmiss,
                   tomek = rec_tomek),
    models = list(bag_spec = bag_spec),
    cross = TRUE
  )
```

Utilizar a fun√ß√£o `option_add` para adicionar as informa√ß√µes dos intervalos definidos para cada hiperpar√¢metro:

```{r}
chi_models <- chi_models %>% 
  option_add(param_info = params_up, id = "upsample_bag_spec")  %>% 
  option_add(param_info = params_smote, id = "smote_bag_spec") %>% 
  option_add(param_info = params_adasyn, id = "adasyn_bag_spec") %>% 
  option_add(param_info = params_down, id = "downsample_bag_spec") %>% 
  option_add(param_info = params_nearmiss, id = "nearmiss_bag_spec")
```

Finalmente, vamos ajustar todos os modelos utilizando o m√©todo simples para fazer a busca dos melhores hiperpar√¢metros em grids de 20 valores aleat√≥rios e calcular os scores via valida√ß√£o cruzada (esta parte pode demorar bastante tempo): 

```{r, eval = F}
set.seed(123)
chi_models <- 
  chi_models %>% 
  workflow_map("tune_grid",
               resamples = bird_folds, 
               grid = 20, 
               metrics = bird_metrics,
               control = control_resamples(save_pred = TRUE),
               verbose = TRUE)
```

```{r, eval = F, echo = F}
saveRDS(chi_models, "chi_models.rds")  
```

```{r, echo = F}
chi_models <- readRDS("chi_models.rds")
```

Vejamos os resultados:

```{r}
rank_results(chi_models, rank_metric = "mn_log_loss", select_best = TRUE) %>% 
  select(-.config) %>%
  mutate(wflow_id = str_remove(wflow_id, "_bag_spec")) %>% 
  print_table(round = 5, wf=T, height = 300, filterable = T)
```

Matriz de confus√£o do modelo com menor *logloss*:

```{r}
collect_predictions(chi_models) %>% 
  filter(wflow_id == "tomek_bag_spec") %>% 
  conf_mat_plot()
```

## Benchmark

Comparando os resultados dos modelos ajustados:

<details>
<summary>(*Clique aqui para ver o c√≥digo que cria o objeto* `benchmark`)</summary>

```{r}
benchmark <- bind_rows(
  mutate(collect_metrics(null_rs), wflow_id = "default", model = "null_model") %>% 
    select(.metric, mean, wflow_id, model) %>% 
    spread(.metric, mean)
  ,
  mutate(collect_metrics(imb_rs), wflow_id = "default", model = "bag_tree") %>% 
    select(.metric, mean, wflow_id, model) %>% 
    spread(.metric, mean)
  ,
  rank_results(chi_models, rank_metric = "mn_log_loss", select_best = TRUE) %>% 
    filter(wflow_id=="smote_bag_spec") %>% 
    select(.metric, mean, wflow_id, model) %>% 
    spread(.metric, mean)
  ,
  rank_results(chi_models, rank_metric = "mn_log_loss", select_best = TRUE) %>% 
    filter(rank==1) %>% 
    select(.metric, mean, wflow_id, model) %>% 
    spread(.metric, mean)
) 
```
</details>

```{r}
benchmark  %>%
  print_table(round = 5, bm = T)
```

Como no post da Julia, a logloss e a precis√£o dos modelos que utilizaram m√©todos de balanceamento dos dados pioraram em rela√ß√£o ao modelo de *Bagged Decision Tree* sem o uso desses pipelines. Apesar da piora em rela√ß√£o ao modelo de base nota-se que outros m√©todos como *Tomek Links* e *Adasyn* se sa√≠ram ligeiramente melhores do que o *Smote* (al√©m disso vimos que o *Smote* com sua configura√ß√£o *default* n√£o necessariamente produriz√° os melhores resultados). 

Este tipo de performance √© muito comum e at√© esperado visto que estamos avaliando o modelo atrav√©s de uma √∫nica m√©trica (com os mesmos pontos de corte e com o mesmo algoritmo). Normalmente no mundo real monitoramos diversas m√©tricas e experimentamos mais configura√ß√µes de hiperpar√¢metros de diferentes modelos com diferentes pipelines. 

# Conclus√£o

Assim como n√£o existe melhor modelo, n√£o existe melhor t√©cnica de balanceamento de dados. Portanto, na busca de melhores resultados n√≥s podemos tentar otimizar qual abordagem ser√° uyilizada bem como seus hiperpar√¢metros (em conjunto com os hiperpar√¢metros dos modelos em quest√£o).

Esta abordagem em R √© nova para mim (estou mais acostumado a utilizar em Python com o m√©todo `sklearn.pipeline.Pipeline` em conjunto com a biblioteca [imblearn](https://pypi.org/project/imblearn/)) ent√£o qualquer cr√≠tica e sugest√£o de melhoria ser√° muito bem vinda! Basta entrar em contato ou deixar aqui nos coment√°rios!

Bons estudos e espero que gostem! üöÄ

# Refer√™ncias

- <https://www.tidyverse.org/blog/2021/03/workflowsets-0-0-1/>
- <https://www.kaggle.com/c/sliced-s01e02-xunyc5>
- <https://juliasilge.com/blog/sliced-aircraft/>
- <https://topepo.github.io/caret/subsampling-for-class-imbalances.html>
- <https://machinelearningmastery.com/bagging-and-random-forest-for-imbalanced-classification/>
- <https://machinelearningmastery.com/what-is-imbalanced-classification/>
- <https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/>
- <https://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/>




