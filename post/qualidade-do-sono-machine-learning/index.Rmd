---
title: Prevendo a qualidade do sono utilizando Machine Learning
author: Fellipe Gomes
date: '2021-03-04'
slug: qualidade-do-sono-machine-learning
categories:
  - Tidyverse
  - Tidymodels
  - R
  - Pr√°tica
  - modelo baseado em arvores
  - Machine Learning
  - Aprendizado Supervisionado
  - lightgbm
  - randomforest
  - arvore de decisoes
  - Tunning
  - Dados Desbalanceados
tags:
  - Tidyverse
  - Tidymodels
  - random forest
  - imbalanced data
  - lightgbm
  - R
  - gomesfellipe
  - tunning
  - threshold movel
  - imbalanced
description: 'Utilizaremos dados reais coletados pelo celular para gerar previs√µes a partir de uma pequena base de dados com target desbalanceada'

featured: 'img1.png'
featuredalt: 'Pic 25'
featuredpath: 'date'
linktitle: ''
type: "post"
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
---

<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 33%;
padding: 10px;
}

.column8 {
float: left;
width: 66%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, error = F,
                      fig.align="center", fig.height = 3) 
```

<!-- O que veremos no post? -->

<!-- Aquisi√ß√†o e prepara√ß√£o dos dados -->
<!-- Uso de fontes externas para preencher dados faltantes -->

<!-- - Dados desbalanceados -->
<!-- - Analise exploratoria -->
<!-- Sele√ß√£o de features -->
<!-- - *threshold* m√≥vel -->
<!-- - Random Forest -->
<!-- - Ajustar modelo nulo baseline -->
<!-- - Lightgbm -->
<!-- - Tunning -->
<!-- - Sele√ß√£o de modelos -->
<!-- Early Stopping -->
<!-- Aprendizagem n√£o supervisionada para avaliar em novos dados -->
# Qualidade de sono? ü§®

Sim, exatamente! Neste post analisaremos dados de um *tracking* que venho fazendo desde 2017 com informa√ß√µes relacionadas √† um sono de qualidade.

<div class="row">
<div class="column8"> 

Boas noites de sono nos tornam mais felizes, mais saud√°veis, mais inteligentes, mais dispostos e evita problemas de cansa√ßo, falta de concentra√ß√£o, depress√£o e ansiedade.

Resumindo, a nossa qualidade de vida est√° diretamente ligada √† qualidade do nosso sono, pois ao dormir nosso corpo realiza fun√ß√µes extremamente importantes como por exemplo o fortalecimento do sistema imunol√≥gico, secre√ß√£o e libera√ß√£o de horm√¥nios, consolida√ß√£o da mem√≥ria, entre outras[^1].

</div>

<div class="column4">
![[Via Giphy](https://media.giphy.com/media/mguPrVJAnEHIY/giphy.gif)](https://media.giphy.com/media/mguPrVJAnEHIY/giphy.gif)
</div>

</div>

Alguns fatores podem auxiliar a determinar se uma noite foi bem dormida como por exemplo: a regularidade do hor√°rio de dormir e de acordar, a frequ√™ncia card√≠aca (bpm), n√∫mero de passos dados no dia, tempo na cama, tempo antes de dormir, ronco, tipo de clima etc..

<div class="row">

<div class="column4">
![[Via Gyiphy](https://media.giphy.com/media/xUPJPlFxssGpmLemru/giphy.gif)](https://media.giphy.com/media/xUPJPlFxssGpmLemru/giphy.gif){width=80%}
</div>

<div class="column8">
Felizmente, existe um aplicativo chamado [Sleep Cycle](sleepcycle.com/) que √© capaz de *trackear* todas essas informa√ß√µes durante o uso do app, dentre outras funcionalidades. Desde 2017 tenho acompanhado meu sono atrav√©s dele, principalmente pela funcionalidade de [rastreio dos padr√µes de sono para despertar durante sua fase mais leve, sem um despertador convencional](https://www.sleepcycle.com/how-sleep-cycle-works/) e tenho curtido bastante!
</div>

</div>

A proposta principal do aplicativo √© monitorar os sinais do corpo para nos despertar suavemente quando estivermos no est√°gio de sono mais leve poss√≠vel, pois acordar durante o sono leve √© como acordar naturalmente descansado!

# Como funciona aplicativo Sleep Cycle? ![](https://www.sleepcycle.com/wp-content/uploads/2020/09/sleep_cycle_app_icon-480x480.png){width=3%}

<small>Tradu√ß√£o livre de [*How Sleep Cycle works*](https://www.sleepcycle.com/how-sleep-cycle-works/):</small>

"O funcionamento b√°sico desse aplicativo se baseia que nos mexemos predominantemente durante o sono leve. J√° durante o sono pesado, os m√∫sculos tendem a permanecer relaxados, e em sono REM a movimenta√ß√£o muscular abaixo do pesco√ßo fica paralizada.

Assim sendo √© poss√≠vel selecionar um hor√°rio que gostaria de acordar, como de 6:30 at√© 7:00, e o aplicativo rastrear√° os movimentos na cama para acordar apenas quando entrar em sono leve durnte este per√≠odo.

Dessa forma, estar√≠amos aumentando as chances de acordar mais bem-disposto, j√° que seu sono foi interrompido em uma fase mais leve de descanso."

Vejamos dois gr√°ficos que exemplificam dois dos poss√≠veis cen√°rios de uma noite de sono:

<div class="row">

<div class="column">
<center>
**Exemplo 1 - sono regular**
![[via SleepCycle.com](https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_regular_sleep.png)](https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_regular_sleep.png){width=80%}
</br>
<small>Os picos representam os ciclos do sono, incluindo todas as fases do sono.</small>
</center>
</div>

<div class="column">
<center>  
**Exemplo 2 - sono irregular**
![[via SleepCycle.com](https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_irregular_sleep.png)](https://www.sleepcycle.com/wp-content/uploads/2019/08/sleepcycle_irregular_sleep.png){width=80%}
</br>
<small>Ciclos de sono mais irregulares, onde o usu√°rio provavelmente n√£o dormiu t√£o bem como em nosso primeiro exemplo.</small>
</center>
</div>

</div>

Esta √© a principal informa√ß√£o coletada no aplicativo e que permite um "despertar tranquilo"!

<!-- Agora que j√° entendemos as benef√≠cios de uma noite bem dormida, de onde v√™m os dados, como o app funciona e quantas horas proporcionam uma boa noite de sono, vamos direto ao objetivo deste post! -->

# Objetivo üéØ

Apesar do aplicativo captar diversos dados sobre a noite de sono, o "humor ao acordar" √© uma informa√ß√£o fornecida pelo usu√°rio assim que desativa o alarme, quando a seguinte tela √© exibida:

<div class="row">

<div class="column">
<center>
![](/post/2021-02-28-qualidade-do-sono-machine-learning/mood.jpg){width=80%}
</center>
</div>

<div class="column">
<div class="center">
<br>
<dl>
<dt>Onde:</dt>
<dd>- üòÉ (Bom)</dd>
<dd>- üòë (Ok)</dd>
<dd>- üò° (Mau)</dd>
</dl>
</div>
</div>
</div>

Como houveram diversos dias em que utilizei o aplicativo mas n√£o assinalei o humor (seja por ter desativado o recurso por algum tempo ou simplesmente por ter ignorado üòÖ) vamos trabalhar para responder a seguinte pergunta:

> Qual foi a probabilidade de ter acordado de **mal humor** durante o per√≠odo de *tracking* do app, nos dias cujo esse dado √© faltante?

Onde **mal humor** ser√° a classe positiva da **target**, traduzido nos dados da seguinte forma:

$$
mood=
\begin{cases}
Bom, & \text{se}\  mood = Bom \\
Ruim, & \text{c.c}\ 
\end{cases}
$$

Logo, `mood` ser√° bin√°ria, avaliando se o humor foi `Bom` ou `Ruim` ao acordar, onde `Ruim`  a combina√ß√£o do status üòë (Ok) e üò° (Mau) e ser√° a classe mais importante para controlar os erros de previs√£o. 

Tomei a liberdade de fazer essa transforma√ß√£o pois desde o in√≠cio do uso do app, marco como `Ruim` apenas quando realmente n√£o descansei de forma satisfat√≥ria. Isso pode ter ocorrido por diversos fatores, como por exemplo: acordar ap√≥s um pesadelo; acordar com barulho da rua ou de casa; acordar meio doente ou passando mal e por ai vai..

Por enquanto, estas informa√ß√µes ser√£o suficientes. Vejamos na an√°lise explorat√≥ria como se apresenta a vari√°vel target e quais dados dispon√≠veis para atingir tal objetivo. 

# Explorar dados üîé 


Carregar as depend√™ncias:

```{r}
library(tidyverse)  # datascience toolkit 
library(lubridate)  # manipule date
library(patchwork)  # grid ggplot
library(tidymodels) # machine learning toolkit
library(reactable)  # print tables 
library(treesnip)   # lightgbm

# Definir tema para ggplot
theme_set(theme_bw()) 
```

Vamos carregar fun√ß√µes que foram desenvolvidas ao longo das an√°lises para facilitar tanto na apresenta√ß√£o dos resultados quanto na portabilidade dos c√≥digos (bastando pequenos ajustes para "recicl√°-los" ‚ôªÔ∏è):

<details>
<summary>(*Clique aqui para exibir as fun√ß√µes customizadas*)</summary>

```{r}
# Para o print de tabelas
print_table <- function(x, round=0, evalue_model = F, ...){ 
  
  if(round>0) x <- x %>% mutate_if(is.numeric, ~round(.x, round))
  
  if(evalue_model == T){
    
    reactable::reactable(x, striped = T, bordered = T, 
                         highlight = T, pagination = F,
                         width = 800,
                         defaultColDef = colDef(minWidth = 85),
                         defaultSorted = list(auc_pr = "desc"),
                         columns = list(
                           model = colDef(minWidth = 110),
                           tp = colDef(minWidth = 40),
                           fp = colDef(minWidth = 40),
                           fn = colDef(minWidth = 40),
                           tn = colDef(minWidth = 40)),
                         ...)  
    
  }else{
    reactable::reactable(x, striped = T, bordered = T, width = 800,
                         highlight = T, pagination = F, ...)  
  }
  
  
}

# Graficos de features numericas
plot_num <- function(data, num_feature, 
                     title = NULL, bins = 30, legend = NULL){
  
  if(is.null(title)) title = num_feature
  
  data = data %>% filter(!is.na(mood))
  
  p_shapiro = round(shapiro.test(data$air_pressure_pa)$p.value, 5)
  
  p1 <- 
    data %>% 
    ggplot(aes_string(x = num_feature, fill = "mood"))+
    geom_histogram(aes(y=..density..), bins = bins, alpha = 0.5,
                   show.legend = ifelse(!is.null(legend), T, F))+
    geom_density(alpha = 0.5,
                 show.legend = ifelse(!is.null(legend), T, F))+
    labs(y = "", x= "", title = title)+
    scale_fill_viridis_d(end = 0.8, direction = 1)
  
  if(!is.null(legend)){
    p1 = p1 + theme(legend.position = legend)
  }
  
  p2 <- 
    data %>% 
    ggplot(aes_string(x = num_feature))+
    geom_boxplot(aes(y = "", color = mood), 
                 show.legend = F)+
    labs(y = "", x= "", 
         caption = paste0("Shapiro-Wilk normality test: ",
                          ifelse(p_shapiro == 0, "P<0.05", p_shapiro) ))+
    scale_color_viridis_d(end = 0.8, direction = 1)
  
  p1 / p2  + plot_layout(heights = c(4/5, 1/5))
}  

# Graficos de features categoricas
plot_cat <- function(data, cat_feature, title = NULL, label = TRUE, legend = NULL){
  
  data = data %>% filter(!is.na(mood))
  
  valor_p = round(chisq.test(data %>% pull(cat_feature), 
                             data$mood, 
                             simulate.p.value = T)$p.value, 5)
  
  to_plot = data %>%
    count(!!as.name(cat_feature), mood) %>% 
    group_by(!!as.name(cat_feature)) 
  
  final_plot = to_plot %>% 
    mutate(prop = n/sum(n),
           lab = paste0(round(prop*100, 2), "%")) %>% 
    ggplot()+
    geom_bar(aes_string(x = cat_feature, y = "n", fill = "mood"),
             stat = "identity", alpha = 0.7, 
             position = position_dodge2(0.9),
             show.legend = ifelse(!is.null(legend), T, F))+
    scale_fill_viridis_d(end = 0.8, direction = 1)+
    labs(title = title, y = "",
         caption = paste0("Pearson's Chi-squared test: ", valor_p))
  
  if(label == TRUE){
    final_plot = final_plot+
      geom_label(aes_string(x = cat_feature, y = "n", label = "lab"),
                 position = position_dodge2(0.9), show.legend = F)  
  }
  
  if(!is.null(legend)){
    final_plot = final_plot + theme(legend.position = legend)
  }
  
  return(final_plot)
  
}

# Grafico interativo de features temporais
plot_dygraph <- function(x, order.by, feature, title = NULL){
  x %>%  
    xts::xts(order.by = order.by) %>% 
    .[,feature] %>%
    dygraphs::dygraph(main = title) %>% 
    dygraphs::dyRangeSelector()
}

# Calcula o ponto de corte que maximiza a funcao f beta
threshold_max <- function(x){
  
  fbeta <- function(precision, recall){ 
    (beta+1)*(precision*recall)/(beta*(precision+recall))
  }
  
  # https://machinelearningmastery.com/fbeta-measure-for-machine-learning/
  # F05: + precision - recall
  # F1 : + precision + recall
  # F2 : - precision + recall 
  beta = 0.5
  
  x  %>%
    pr_curve(mood, .pred_Ruim) %>% 
    mutate(fbeta = fbeta(precision, recall) ) %>% 
    filter(fbeta == max(fbeta, na.rm = T))
}

# Plot da matriz de confusao e da funcao das funcoes de densidade estimadas
conf_mat_plot <- function(x, null_model = FALSE){
  trs <- threshold_max(x)$.threshold
  
  if(null_model==FALSE){
    x <- x %>% 
      mutate(.pred_class = ifelse(.pred_Ruim >= trs, "Ruim", "Bom") %>%
               factor(levels = c("Ruim", "Bom"), ordered = TRUE))  
  }
  
  p1 <- 
    x %>%
    select(.pred_class, mood) %>%
    table() %>% 
    conf_mat() %>% 
    autoplot(type = "heatmap")+
    labs(title = "Matriz de Confusao",
         subtitle = paste0("Threshold max F0.5: ", round(trs, 4)))
  
  p2 <- 
    x  %>%
    ggplot() +
    geom_density(aes(x = .pred_Ruim, fill = mood), 
                 alpha = 0.5)+
    labs(title = "Distribui√ß√µes de probabilidade previstas",
         subtitle = "por classe")+ 
    scale_x_continuous(limits = 0:1)+
    geom_vline(aes(xintercept = trs, color = "threshold max F0.5"), linetype = 2) +
    scale_color_manual(name = "", values = c(`threshold max F0.5` =  "red"))+
    scale_fill_viridis_d(end = 0.7, direction = 1)
  
  p1 | p2
} 

# Conjunto de metricas utilizadas para avaliar os modelos
evalue_model <- function(x, model = "", null_model=FALSE){
  
  trs <- threshold_max(x)$.threshold
  
  if(null_model==FALSE){
    x <- x %>%
      mutate(.pred_class = ifelse(.pred_Ruim >= trs, "Ruim", "Bom") %>% 
               factor(levels = c("Ruim", "Bom"), ordered = TRUE))
  }
  
  cm <- x %>% 
    select(.pred_class, mood) %>% 
    table() 
  
  tibble(
    model = model,
    tp = cm[1,1],
    fp = cm[1,2],
    fn = cm[2,1],
    tn = cm[2,2],
    auc_roc   = yardstick::roc_auc(x, mood, `.pred_Ruim`)$.estimate,
    auc_pr    = yardstick::pr_auc(x, mood, `.pred_Ruim`)$.estimate,
    logloss   = yardstick::mn_log_loss_vec(x$mood, x$.pred_Ruim),
    f1        = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 1),
    f05       = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 0.5),
    f2        = yardstick::f_meas_vec(x$mood, x$.pred_class, beta = 2),
    precision = yardstick::precision_vec(x$mood, x$.pred_class),
    recall    = yardstick::recall_vec(x$mood, x$.pred_class),
    trs_fbeta = trs
  ) 
}  

plot_auc <- function(x){
  
  p1 <-  
    x %>% 
    group_by(model) %>%
    roc_curve(mood, .pred_Ruim) %>%
    ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +
    geom_line(size = 1, alpha = 0.5, show.legend = F) +
    geom_abline(lty = 2, alpha = 0.5, color = "gray50", size = 1.3)+
    labs(title = "AUC")+
    scale_color_viridis_d(direction = 1)
  
  p2 <- 
    x %>%
    group_by(model) %>%
    pr_curve(mood, .pred_Ruim) %>%
    ggplot(aes(x = recall, y = precision, color = model)) +
    geom_line(size = 1.15, alpha = 0.5) +
    # geom_abline(slope = -1, intercept = 1, lty = 2, alpha = 0.5, color = "gray50", size = 1.2)+
    labs(title = "PR AUC")+
    theme(legend.position = "right")+
    scale_color_viridis_d(direction = 1)
  
  (p1 | p2)
}
```
</details>
&nbsp;

Importar os dados obtidos no app [SleepCycle](https://www.sleepcycle.com/) e padronizar nomes das colunas:

```{r}
sleep <- read_csv2("sleepdata.csv") %>% janitor::clean_names(case = "snake")
```

A seguir, uma tabela com uma descri√ß√£o do conte√∫do de cada coluna:

<!-- <div class="fold s"> -->

<details>
<summary>(*C√≥digo do objeto `dic`*)</summary>

```{r}
dic <- 
  tibble(
    `Coluna` = sleep %>% colnames(),
    `Descri√ß√£o curta` = 
      c("Inicio",
        "Fim",
        "Qualidade do Sono",
        "Regularidade",
        "Humor",
        "Frequ√™ncia card√≠aca (bpm)",
        "Passos",
        "Modo de alarme",
        "Press√£o do Ar (Pa)",
        "Cidade",
        "Movimentos por hora",
        "Tempo na cama (segundos)",
        "Tempo adormecido (segundos)",
        "Tempo antes de dormir (segundos)",
        "In√≠cio da janela",
        "Fim da janela",
        "Ronco",
        "Hora do ronco",
        "Temperatura (¬∞C)",
        "Tipo de clima",
        "Notas"),
    `Descri√ß√£o detalhada` = 
      c("In√≠cio do monitoramento",
        "Fim do monitoramento",
        "Qualidade do sono √© baseada em: tempo que passa a dormir, movimentos durante a noite e momentos em que est√° totalmente desperto",
        "Informa sobre a regularidade do hor√°rio de dormir e de acordar durante um per√≠odo de tempo. Quanto maior, mais regular tem sido o hor√°rio de acordar e dormir e isso pode resultar em um sono melhor",
        "Humor informado no app ao acordar:    
        \U0001F603 (Bom), \U0001F611 (Ok), \U0001F621 (Mau), \U00026D4 (N√£o informado)",
        "-",
        "Quantos passos d√° por dia (bom a partir de 10.000 passos por dia)",
        "Alarme ligado ou apenas monitoramento",
        "-",
        "-",
        "-",
        "-",
        "-",
        "-",
        "In√≠cio do modo soneca",
        "Fim do modo soneca",
        "Detector de ru√≠dos (pode captar outros barulhos que n√£o seja ronco)",
        "-",
        "-",
        "-",
        "Alguma nota ao acordar"
      ),
    Target = c(rep("",4), "üéØ", rep("", 16))
  )
```

</details>
<!-- &nbsp; -->

```{r}
dic %>% print_table(columns = list(Target = colDef(minWidth = 35)))
```

&nbsp;

## Limpeza e prepara√ß√£o dos dados

Vamos realizar uma limpeza inicial, preparando os dados para possibilitar as an√°lise em um objeto `tibble` minimamente arrumado:

```{r}
sleep <- sleep %>% 
  # fix target
  mutate(mood = case_when(mood == "Bom" ~ "Bom",
                          mood == "Mau" ~ "Ruim",
                          mood == "Ok" ~ "Ruim",
                          is.na(mood) ~ NA_character_),
         mood = factor(mood, levels = c("Ruim", "Bom"), ordered = TRUE)) %>% 
  # fix window
  mutate_at(c("window_start", "window_stop"), 
            ~ifelse(is.na(.x), end, .x)) %>% 
  # fix string %
  mutate_at(c("sleep_quality", "regularity"),
            ~ .x %>% str_remove("%") %>% as.numeric() ) %>% 
  # fix heart_rate_bpm e criar bug indicator 
  mutate(heart_rate_bug = ifelse(heart_rate_bpm == 0, "sim", "nao")) %>% 
  mutate(heart_rate_bpm = ifelse(heart_rate_bpm == 0, 
                                 NA_integer_, heart_rate_bpm)) %>% 
  # fix dados de soneca
  mutate(snore_time = as.numeric(snore_time),
         did_snore = ifelse(did_snore == TRUE, "sim", "nao")) %>% 
  # fix para numerico
  mutate_at(c("time_before_sleep_seconds", 
              "time_asleep_seconds", 
              "time_in_bed_seconds"),
            ~as.numeric(.x) ) %>% 
  # fix movements_per_hour para double
  mutate(movements_per_hour = as.double(movements_per_hour)) %>% 
  # fix weather_type
  mutate(weather_type = 
           factor(weather_type, 
                  levels = c("No weather", "Rain", "Rainy showers", "Cloudy",
                             "Partly cloudy", "Fair", "Sunny"),
                  ordered = TRUE))  %>% 
  mutate_at(c("weather_temperature_c", "air_pressure_pa"),
            ~ as.numeric(.x) %>% if_else(. == 0, NA_real_, .)) %>% 
  # remover unused columns
  select(-one_of(c("city", "notes"))) %>% 
  select(mood, everything()) %>% 
  arrange(end)
```

Qual a estrutura geral dos dados? Ser√° que existe algum padr√£o nos dados ausentes?

```{r}
sleep %>% 
  arrange(end) %>% 
  mutate(Date = as.Date(end))%>%
  # complete(Date = seq.Date(min(Date), max(Date), by="day"))  %>%  
  visdat::vis_dat() 
```

Os dados ausentes ocorrem tanto espalhados (`heart_rate_bpm`) quanto em sequ√™ncia (`air_pressure_pa`, `weather_temperature_c`, `mood`) portando, adotaremos as seguintes estrat√©gias para inputar dados ausentes:

1. `air_pressure_pa`: Ser√° obtidos no site [data.rio/datasets](https://www.data.rio/datasets/dados-hor%C3%A1rios-do-monitoramento-da-qualidade-do-ar-monitorar?selectedAttribute=Pres) e caso ainda exista dados ausentes, ser√° preenchido com as m√©dias m√≥veis dos √∫ltimos 7 dias;
2. `weather_temperature_c`: Mesma estrat√©gia do item (1);
3. `heart_rate_bpm`: C√°lculo das m√©dias m√≥veis dos √∫ltimos 7 dias;
4. `mood`: Como √© a *target*, as inst√¢ncias aonde `is.na(mood)` ser√£o retidas para estima√ß√£o ap√≥s o ajuste do modelo.

## Imputar dados de fontes externas

O preenchimento das features `air_pressure_pa`, `weather_temperature_c` ser√£o realizados a partir do download de dados p√∫blicos do Rio de Janeiro no link: [data.rio/datasets](https://www.data.rio/datasets/dados-hor%C3%A1rios-do-monitoramento-da-qualidade-do-ar-monitorar?selectedAttribute=Pres). Para obter este dado utilizaremos a fun√ß√£o `get_rj_data()` desenvolvida para este post, que est√° omitida mas para quem tiver interesse basta conferir clicando no item abaixo:

<details>
<summary>(*C√≥digo da fun√ß√£o `get_rj_data()`*)</summary>
```{r}
get_rj_data <- function(){ 
  
  if(!file.exists("rj_data.rds")){ 
    
    url <- "https://opendata.arcgis.com/datasets/5b1bf5c3e5114564bbf9b7a372b85e17_2.csv?outSR=%7B%22latestWkid%22%3A4326%2C%22wkid%22%3A4326%7D"
    
    download.file(url, "rj_data.csv")
    
    rj_data <- readr::read_csv("rj_data.csv")
    
    saveRDS(rj_data, "rj_data.rds")
    
  }else{
    rj_data <- readRDS("rj_data.rds")
  }
  
  # preparar dados de pressao atmosferica e temperatura no periodo desejado
  rj_data <- rj_data %>% 
    mutate(Data = ymd_hms(Data)) %>% 
    filter(Data >= min(sleep$start) &  Data <= max(sleep$start)) %>% 
    group_by(Data = as.Date(Data)) %>% 
    summarise(air_pressure_pa = mean(Pres/10, rm.na=T),
              weather_temperature_c = mean(Temp, rm.na=T))
  
  return(rj_data)
  
}
```
</details>
<!-- &nbsp; -->

Com acesso aos dados, hora de combinar as bases e preencher os dados faltantes:

```{r}
sleep <- sleep %>% 
  mutate(Data = as.Date(start)) %>%
  # to numeric
  mutate_at(c("weather_temperature_c", "air_pressure_pa"),
            ~ as.numeric(.x) %>% if_else(. == 0, NA_real_, .)) %>% 
  # join Rio data
  left_join(get_rj_data() , by = c("Data")) %>% 
  # fill with new data
  mutate(air_pressure_pa = ifelse(is.na(air_pressure_pa.x),
                                  air_pressure_pa.y,
                                  air_pressure_pa.x)) %>%
  mutate(weather_temperature_c = ifelse(is.na(weather_temperature_c.x),
                                        weather_temperature_c.y, 
                                        weather_temperature_c.x)) %>%
  # remove aux columns
  select(-air_pressure_pa.x, -air_pressure_pa.y,
         -weather_temperature_c.x, -weather_temperature_c.y,
         -Data)
```

## Insights

Nesta se√ß√£o vamos responder algumas perguntas com dados!

### `start` e `end`

Qual a m√©dia mensal de horas dormidas e que horas costumo acordar, em m√©dia, mensalmente ao longo desses anos?

<details>
<summary>(*C√≥digo para gr√°fco abaixo*)</summary>
```{r}
dy1 <- sleep %>% 
  complete(start = seq.Date(min(as.Date(start)), max(as.Date(start)), by="day")) %>%
  mutate(dif_sleep_hours = as.numeric(end - start)/60) %>% 
  mutate(dif_sleep_hours = zoo::rollmean(dif_sleep_hours, k =  30, fill = NA)) %>%
  plot_dygraph(order.by = .$start, feature =  'dif_sleep_hours')

dy2 <- sleep %>% 
  complete(start = seq.Date(min(as.Date(start)), max(as.Date(start)), by="day")) %>%
  mutate(end_hour = hour(end)) %>% 
  mutate(end_hour = zoo::rollmean(end_hour, k =  30, fill = NA)) %>%
  plot_dygraph(order.by = .$start, feature =  'end_hour')
```
</details>
&nbsp;&nbsp;

<div class="row">
<div class="column">
<center>
**Tempo dormindo (em horas)**
</br>
<small>M√©dia m√≥vel 30 dias</small>
```{r, fig.height=2, fig.width=3,echo = F}
dy1
```
</br>
<small>O tempo que passa dormindo parece variar (em m√©dia) em torno de 6 √† 7 horas</small>
</center>
</div>

<div class="column">
<center>  
**Hora que acorda**
</br>
<small>M√©dia m√≥vel 30 dias</small>
```{r, fig.height=2, fig.width=3,echo = F}
dy2
```
</br>
<small>O pico no in√≠cio no gr√°fico corresponde ao pen√∫ltimo semestre da facultado. No final de 2017 comecei a trabalhare passei a acordar mais cedo  </small>
</center>
</div>

</div>



<div class="w3-panel w3-sand w3-border">
‚ö†Ô∏è Note que existem alguns espa√ßos vazios, que correspondem aos dias que o app n√£o foi utilizado.
</div>


### `window_start` e `window_stop`

Quanto tempo costumo usar o modo "soneca" ao longo da semana? E aos finais de semana?

<details>
<summary>(*C√≥digo para gr√°fco abaixo*)</summary>
```{r}
p <- sleep %>% 
  mutate(mood = ifelse(is.na(mood), "NA", as.character(mood)) %>% 
           factor(levels = c("Ruim", "NA", "Bom"))) %>% 
  mutate(nap_minutes = (window_stop - window_start) / 30,
         final_de_semana = lubridate::wday(start) %in% c(1, 7)) %>% 
  count(mood, final_de_semana, nap_minutes) %>% 
  group_by(mood, final_de_semana) %>% 
  mutate(
    fnap_minutes = case_when(
      nap_minutes == 0 ~ "Sem modo soneca",
      nap_minutes == 20 ~ "20 minutos",
      nap_minutes == 30 ~ "30 minutos",
      nap_minutes == 60 ~ "1 hora"),
    fnap_minutes = reorder(fnap_minutes, nap_minutes),
    final_de_semana = ifelse(final_de_semana == T, "Final de semena", "Dia de semana"),
    label = paste0( n, " (", round(n/sum(n)*100, 2), "%)")
  ) %>% 
  ggplot(aes(x = fnap_minutes, y = n, label = label, fill = mood))+
  geom_bar(stat = "identity", alpha = 0.8)+
  scale_fill_viridis_d(end = 0.7, direction = 1)+
  # ggrepel::geom_label_repel(aes(label = label))+
  labs(x = "", y = "")+
  facet_wrap(~final_de_semana)+
  theme(axis.text.x = element_text(angle = 30, hjust=1))
```
</details>
&nbsp;

```{r}
p %>% plotly::ggplotly() %>% plotly::config(displayModeBar = F)
```

Como era de se esperar, os dias em que `mood=="Ruim"` ocorrem mais quando o modo soneca n√£o √© ativado pois acaba mesmo sendo menos prop√≠cio a voltar a dormir. Outro detalhe √© que muitas vezes usei o soneca por um tempo muito prolongado! (üò± pelo menos `mood=="Bom"` na maioria desses casos!)

J√° nos finais de semana, ocorre pouqu√≠ssimo `mood== "Ruim"` e praticamente n√£o h√° uso do alarme e quando h√°, n√£o utiliza soneca. 

### `weather_type` e `alarm_mode` 

Ser√° que o humor ao acordar esta relacionado com o tipo de clima ou com o modo utilizado no alarme?

```{r}
p1 <- plot_cat(sleep, cat_feature="weather_type", 
               title = "Tipo de clima", label = F)+ 
  theme(axis.text.x = element_text(angle = 30, hjust=1))

p2 <- plot_cat(sleep, cat_feature="alarm_mode", 
               title = "Modo de alarme", label = F, legend = "right")

p1 | p2
```

Nota-se que n√£o existem evid√™ncias estatisticas para afimar que essas features (sozinhas) est√£o associadas √† target, por√©m como ser√£o utilizados modelos baseados em √°rvores que experimentam diversas combina√ß√µes de features, vamos manter na base e deixar o modelo decidir como usar.

### `sleep_quality` e `time_in_bed_seconds`

A qualidade de sono e o tempo da cama est√£o normalmente distribu√≠dos em torno de uma m√©dia?

```{r, fig.height=3}
p1 <- sleep %>% plot_num("sleep_quality")
p2 <- sleep %>% plot_num("time_in_bed_seconds", legend = "right")

p1 | p2
```

Existem alguns registros em que o tempo na cama √© menor que 10.000 segundos (~3horas) o que corresponde aos pequenos cochilos que registrei no app. N√£o foram muitos registros mas talvez seja √∫til na modelagem pois existem ocorr√™ncias de humor (`mood`) `Bom` e `Ruim` ali.

Como a correla√ß√£o de spearman entre estas duas feautures √© muito alta (`r round(cor(sleep$sleep_quality, sleep$time_in_bed_seconds), 4)`) √© poss√≠vel notar que baixa qualidade do sono esta altamente correlacionada com o tempo na cama.

Mais uma pergunta sobre estas features: Como a m√©dia mensal da qualidade do sono e do tempo na cama em horas est√£o distribu√≠dos ao longo do tempo? 

<details>
<summary>(*C√≥digo para gr√°fco abaixo*)</summary>
```{r}
dy1 <- sleep %>% 
  complete(start = seq.Date(min(as.Date(start)),
                            max(as.Date(start)), by="day")) %>%
  mutate(sleep_quality = zoo::rollmean(sleep_quality, k =  30, fill = NA)) %>%
  plot_dygraph(order.by = .$start, feature =  'sleep_quality')

dy2 <- sleep %>% 
  complete(start = seq.Date(min(as.Date(start)), 
                            max(as.Date(start)), by="day")) %>%
  mutate(time_in_bed_seconds = 
           zoo::rollmean(time_in_bed_seconds, k =  30, fill = NA)) %>%
  mutate(time_in_bed_seconds = time_in_bed_seconds / 60 / 60) %>% 
  plot_dygraph(order.by = .$start, feature =  'time_in_bed_seconds')
```
</details>
&nbsp;&nbsp;

<div class="row">
<div class="column">
<center>
**Qualidade do sono**
</br>
<small>M√©dia m√≥vel 30 dias</small>
```{r, fig.height=2, fig.width=3, echo = F}
dy1
```
</br>
<small>Parece que a qualidade do sono vem aumentando desde final de 2019, mantendo um patamar semlhante ao final e 2018.</small>
</center>
</div>

<div class="column">
<center>  
**Tempo na cama em horas**
</br>
<small>M√©dia m√≥vel 30 dias</small>
```{r, fig.height=2, fig.width=3, echo = F}
dy2
```
</br>
<small>O tempo na cama varia entre 6 √† 7 horas (Apesar de alguns picos em 2020, provavelmente por conta da pandemia do corona virus quando estabeleceu-se o home office)</small>
</center>
</div>

</div>

## Reter dados 

Antes de iniciar o processo de modelagem, ser√° necess√°rio reter dados aonde `mood` √© `NA`, pois faremos as previs√µes nestes dados apenas ap√≥s o ajuste e sele√ß√£o do modelo final.

```{r}
new_sleep <- sleep %>% filter(is.na(mood))
sleep <- sleep %>% filter(!is.na(mood))
```

# Modelagem üöÄ

Hora de criar alguns modelos para estimar a probabilidade das classes da target: `mood`.

Como estamos diante de um cen√°rio onde os dados est√£o desbalanceados, ser√° necess√°rio tomar algumas decis√µes muito importantes (sim, cientistas de dados precisam tomar decis√µes o tempo inteiro). 
<div class="row">
<div class="column8">
<div class="center">
<span>
<div>
Neste caso, as quest√µes s√£o as seguintes:

1. Qual a classe mais importante?
2. Qual a m√©trica ser√° utilizada para selecionar os modelos?
3. Qual ser√° o *threshold*? 
4. Qual ser√° estrat√©gia para lidar com o desbalanceamento?
5. Quais m√©tricas ser√£o monitoradas? 

</div>
</span>
</div>
</div>

<div class="column4">
</br>
![[Via Giphy](https://media.giphy.com/media/XeH1MFu4x3etVsllUN/giphy.gif)](https://media.giphy.com/media/XeH1MFu4x3etVsllUN/giphy.gif)

</div>
</div>
A classe mais importante para nossa previs√£o √© a positiva, ou seja, `mood=="Ruim"`. Sendo assim desejamos **evitar falsos positivos**. 

A m√©trica utilizada para selecionar os modelos ser√° a [**logloss**](https://www.kaggle.com/dansbecker/what-is-log-loss). Esta √© uma m√©trica probabilistica que foca na incerteza que o modelo tem nas previs√µes e penaliza as previs√µes que est√£o erradas[^2].

Ap√≥s calibrar a probabilidade, estabeleceremos um ponto de corte que **maximizar a medida F-Beta**, (que √© uma abstra√ß√£o da medida *F1*, m√©dia harm√¥nica entre *Precision* e *Recall*) onde *Beta = 0.5*. Essa medida tem o efeito de aumentar a import√¢ncia da *Precision* e diminui a import√¢ncia do *Recall*. [^3]

Parra lidar com o desbalanceamento da *target*, utilizaremos o m√©todo de *undersampling* chamado ** *Tomek Links* **[^4]. Este m√©todo faz uma amostragem da classe majorit√°ria de forma "mais esperta" que uma simples amostragem aleat√≥ria. 

Por fim, a principal m√©trica que ser√° monitorada ser√° a ***AUC-PR***[^5] (*Area Under Precision Recall Curve*). Ela √© uma esp√©cie de *AUC* que c√°lculada a √°rea sobre a *Precision* x *Recall*. Essa m√©trica √© prefer√≠vel neste caso pois foca maisn na classe positiva e a *ROC AUC* tente a superestimar os valores nesse caso.

## Amostragem

Para preparar os dados para modelagem vamos dividir os dados em treino (70%) e teste (30%).

```{r}
set.seed(123456789)

# treino e teste
sleep_split <- initial_split(data = sleep, strata = mood, prop = 0.7)
sleep_train <- training(sleep_split)
sleep_test  <- testing(sleep_split)
```

Al√©m disso, vamos dividir o conjunto de treino em `r pull(filter(count(sleep_test, mood), mood=="Ruim"), n)/2` folds para obter resultados de valida√ß√£o cruzada. Este valor corresponde metade da quantidade em que `mood=="Ruim"` nos dados teste.

```{r}
set.seed(123456789)
k_fold <- sleep_test %>% count(mood) %>% filter(mood=="Ruim") %>% pull(n)

sleep_folds <- sleep_train %>% 
  rsample::vfold_cv(v = round(k_fold/2), repeats = 10, strata = mood)
```

A decis√£o de utilizar o valor de `k` como metade do tamanho da classe minorit√°ria foi uma decis√£o pessoal, n√£o sei se √© √≥tima mas foi conveniente neste caso.

Como ficou dividido:

<details>
<summary>(*C√≥digo para tabela abaixo*)</summary>
```{r, eval = T}
tab <- 
  full_join(sleep_train %>% count(mood) %>% mutate(prop = n/sum(n)*100),
            sleep_test %>% count(mood) %>% mutate(prop = n/sum(n)*100),
            by = "mood") %>% 
  print_table(round = 2,
              columns = list(
                n.x = colDef(name = "N"),
                prop.x = colDef(name = "(%)", align = "left"),
                n.y = colDef(name = "N"),
                prop.y = colDef(name = "(%)", align = "left")
              ), 
              columnGroups = list(
                colGroup(name = "Train", columns = c("n.x", "prop.x")),
                colGroup(name = "Test", columns = c("n.y", "prop.y"))
              ))
```
</details>
&nbsp;

```{r}
tab
```

<div class="w3-panel w3-pale-red w3-border">
‚ò†Ô∏è A quantidade reduzida de dados para teste reflete a baixa quantidade de dados no geral! 
</div>

## Engenharia de recursos

Hora de criar o objeto que vai conter todos os passos do pr√©-processamento necess√°rio! Esse passo √© muito importante pois algumas estat√≠sticas precisam ser calculadas nos dados de treino isoladamente para n√£o "dar pistas" para modelo sobre as informa√ß√µes contidas nos dados de teste, comprometendo o desempenho do modelo em novos dados.

De forma semelhante (mas n√£o igual) ao `sklearn.pipeline.Pipeline`, dispon√≠vel para Python, na linguagem R existe o pacote `recipes` que permite a cria√ß√£o de "receitas" com a fun√ß√£o `recipe()` e que pode ser utilizada em um `workflow()` para treinar o modelo na sequ√™ncia.

Sendo assim, algumas das opera√ß√µes realizadas no pr√©processamento do modelo:

- Criar feature: `ano`;
- Criar feature: `mes`;
- Criar feature: `dia da semana`;
- Criar feature: `dia do mes`;
- Criar feature: `hora que acordou`;
- Criar feature: `final de semana`;
- Criar feature: `tempo dormindo`;;
- Criar feature: `tempo de soneca`
- Criar feature: `quarentena`;
- Inputar m√©dia movel semanal para preencher as features de `weather_temperature_c` e `air_pressure_pa` no RJ;
- Transformar categ√≥ricas em dummy;
- Remover colunas com dados inv√°lidos para modelo (timestamp);
- Preencher os dados faltantes de `heart_rate_bpm` utilizando o algor√≠tmo `knn` com 2 vizinhos mais pr√≥ximos;
- Aplicar o algoritmo *Tomek Links*, que √© um m√©todo de *undersampling*. 

Caso queira saber mais sobre m√©todos de *undersampling* para tratar dados desbalanceados sugiro a leitura [deste excelente post](https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/)! (Os c√≥digos est√£o em Python por√©m a explica√ß√£o da teoria √© o que importa neste caso)

Preparar objeto `recipe` que cont√©m um conjunto de etapas para pr√©-processamento de dados:

```{r}
sleep_recipe <- 
  recipe(mood~., data = sleep_train) %>%
  step_ordinalscore(weather_type) %>% 
  step_mutate(
    ano = factor(year(end)),
    mes = month(end),
    dia_semana = wday(end) %>% ifelse(. == 7, 0, .),
    dia_mes = mday(end),
    end_hour = hour(end),
    final_de_semana = 
      ifelse(lubridate::wday(start) %in% c(1, 7),  "sim", "nao") %>% as.factor(),
    dif_sleep_hours = as.numeric(end - start)/60,
    dif_nap = as.numeric(window_stop - window_start) / 60,
    quarentena = ifelse(start > dmy("20/03/2020"), "sim", "nao") %>% as.factor(),
    nap_minutes = (window_stop - window_start) / 30
  ) %>% 
  step_mutate_at(c("weather_temperature_c", "air_pressure_pa"),
                 fn = ~ imputeTS::na_ma(.x, k = 7, weighting = "simple")) %>% 
  step_dummy(all_nominal(), -all_outcomes())  %>% 
  step_mutate_at(starts_with("ano"), # Fix 2018 nos novos dados
                 fn = ~ ifelse(is.na(.x), 0, .x)) %>% 
  step_rm(start, end, window_start, window_stop)%>%
  step_knnimpute(heart_rate_bpm, neighbors = 2) %>% 
  themis::step_tomek(mood) %>%
  prep()

# bake(sleep_recipe, new_data = NULL)
```

Finalmente! ü•µ

Com os dados devidamente preparados, vamos ligar as turbinas e partir para modelagem!

```{r}
doParallel::registerDoParallel(4)
```

## Modelo Nulo (Baseline)

Este n√£o √© o tipo de modelo que serve para resolver problemas reais mas pode servir como um bom baseline ("pior que isso n√£o fica") pois ele vai prever apenas a classe majorit√°ria, e com base nisso, poderemos comparar as m√©tricas de performance do ajuste para saber se nossos modelos est√£o (no m√≠nimo) performando melhor que um modelo que classifica unicamente 1 classe,

```{r}
null_model <- null_model(mode = "classification") %>% 
  set_engine("parsnip")
```

Definir o objeto `workflow`:

```{r}
null_wflow_bas <- workflow() %>% 
  add_recipe(sleep_recipe) %>% 
  add_model(null_model) 
```

Realizar ajuste final nos dados de treino:

```{r}
null_final_fit_bas <- null_wflow_bas %>% last_fit(sleep_split) 
```

Coletar previs√µes nos dados de teste:

```{r}
null_test_preds_bas <- collect_predictions(null_final_fit_bas)
```

Avaliar desempenho do modelo nos dados de teste:

```{r}
null_test_preds_bas %>% 
  mutate(mood = factor(mood, levels = c("Ruim", "Bom"), ordered = TRUE)) %>%
  conf_mat_plot(null_model = T)
```

Modelo nulo pronto! Vamos para a modelagem propriamente dita!

## √Årvore de decis√µes

Este algor√≠timo √© um √≥timo ponto de partida pois possui alta explicabilidade, gerando um plot intuitivo e muito f√°cil de interpretar. As *features* que aparecem no topo s√£o as mais importantes e cada n√≥ seguinte √© gerado a partir de regras que otimizam a divis√£o dos dados daquele ramo.

Existem recursos interessantes ao trabalhar com √°rvores, como determinar uma regra de parada ou ainda deixar a √°rvore crescer e depois realizar a poda. Primeiramente vamos ajusta uma √°rvore de decis√µes *default* e em seguida realizar algum tipo de tunning para tentar obter resultados melhores.

<!-- `gini`: -->
<!-- Se selecionarmos dois itens de uma populacao aleatoriamente, entao eles devem ser da mesma classe e a probabilidade para isto √© 1 se a popula√ß√£o √© pura. -->

### Default

Os par√¢metros *default* foram definidos baseados na documenta√ß√£o oficial do pacote `rpart` em <https://cran.r-project.org/web/packages/rpart/rpart.pdf> e o *de/para* para defini√ß√£o dos par√¢metros na p√°gina do pacote `parsnip` em <https://parsnip.tidymodels.org/reference/decision_tree.html>

```{r}
tree_model_bas <- decision_tree(
  cost_complexity = 0.01, # cp
  tree_depth = 30,        # maxdepth
  min_n = 20              # minsplit
) %>% 
  set_engine("rpart") %>%
  set_mode("classification")
```

Definir o objeto `workflow`:

```{r}
tree_wflow_bas <- workflow() %>% 
  add_recipe(sleep_recipe) %>% 
  add_model(tree_model_bas) 
```

Ajustar modelo via valida√ß√£o cruzada:

```{r, eval = F}
tree_res_bas <- fit_resamples(
  tree_wflow_bas,
  sleep_folds,
  metrics = metric_set(pr_auc, roc_auc, mn_log_loss),
  control = control_resamples(save_pred = TRUE)
)
# Salvar "cache" da otimizacao 
saveRDS(tree_res_bas, "tree_res_bas.rds")
```

```{r, echo = F}
tree_res_bas <- readRDS("tree_res_bas.rds")
```

Finalizar o modelo:

```{r}
# Finalizar workflow com parametros selecionados (default nesse caso)
tree_final_wflow_bas <- 
  finalize_workflow(
    tree_wflow_bas,
    select_best(tree_res_bas, metric = 'mn_log_loss') 
  )

# Realizar ajuste final nos dados de treino
tree_final_fit_bas <- tree_final_wflow_bas %>% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
tree_test_preds_bas <- collect_predictions(tree_final_fit_bas)
```

Vejamos como ficou o modelo baseline:

<details>
<summary>(*C√≥digo do objeto `tre_model_bas`*)</summary>
```{r, fig.height=4}
tre_model_bas <- 
  tree_final_fit_bas$.workflow[[1]] %>% 
  pull_workflow_fit()
```
</details>
&nbsp;

```{r}
rattle::fancyRpartPlot(tre_model_bas$fit, sub = NULL, cex = 0.6)
```

Note que o modelo *default* se baseia nas features `time_before_sleep_seconds` e `steps`. Talvez, com outra combina√ß√£o de par√¢metros seja poss√≠vel conseguir um modelo uma √°rvore um pouco maior com resultado igual/melhor.

Como s√£o apenas duas features, √© poss√≠vel visualizar os regras de classifica√ß√£o a partir de um gr√°fio de dispers√£o

```{r}
sleep_train %>%
  ggplot(aes(time_before_sleep_seconds, steps)) +
  parttree::geom_parttree(data = tre_model_bas$fit, alpha = 0.3) +
  geom_jitter(aes(color = mood), alpha = 0.7) +
  scale_color_viridis_d(end = 0.8, direction = 1)
```

Vamos avaliar desempenho do modelo nos dados de teste:

```{r}
tree_test_preds_bas %>% 
  mutate(mood = factor(mood, levels = c("Ruim", "Bom"), ordered = TRUE)) %>% 
  conf_mat_plot()
```

O modelo n√£o esta muito bom... mas tamb√©m n√£o esta muito ruim para come√ßar! üòÖ

Coram 5/8 acertos para classe de interesse, vamos tentar fazer o tunning deste modelo!

### Tunning

Definir o modelo que ser√° utilizado:

```{r}
tree_model_tun <- decision_tree(
  min_n = tune(),
  cost_complexity = tune(), 
  tree_depth = tune()
) %>%
  set_engine("rpart") %>%
  set_mode("classification")
# tree_model_tun %>% translate()
```

Definir o objeto `workflow`:

```{r}
tree_wflow_tun <- workflow() %>% 
  add_recipe(sleep_recipe) %>% 
  add_model(tree_model_tun) 
```

O grid utilizado foi alterado para tentar previnir que a √°rvore tenha apenas o n√≥ raiz pois o grid default, combinado com o *threshold*, estava gerando um "cotoco".

- `min_n`: [1, 5]
- `cost_complexity`: (transformed scale): [-10, -1]
- `tree_depth`: [10, 20]

Definir um grid aleat√≥rio para otimiza√ß√£o dos hiperpar√¢metros:

```{r}
tree_params <- 
  tree_model_tun %>% 
  parameters() %>%
  update(
    min_n = min_n(c(1, 5)), 
    cost_complexity = cost_complexity(),
    tree_depth = tree_depth(c(10, 20)) 
  )

tree_grid <-grid_regular(tree_params, levels = 3)
```

Ajustar modelo:

```{r, eval = F}
tree_res_tun <- 
  tree_wflow_tun %>% 
  tune_grid(
    resamples = sleep_folds,
    grid = tree_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
# saveRDS(tree_res_tun, "tree_res_tun.rds")
```

```{r, echo = F}
tree_res_tun <- readRDS("tree_res_tun.rds")
```

Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:

<details>
<summary>(*C√≥digo do gr√°fico*)</summary>
```{r}
id_best_model <- 
  show_best(tree_res_tun, metric = 'mn_log_loss') %>%
  slice(1) %>% 
  pull(.config)

plot_tree_tun <- 
  tree_res_tun %>% 
  collect_metrics() %>% 
  mutate(best_model = if_else(.config == id_best_model, 
                              "BestModel", "Try")
         # cost_complexity = log(cost_complexity)-10
  ) %>% 
  select(.metric, mean, best_model,
         cost_complexity:min_n) %>%
  pivot_longer(cost_complexity:min_n,
               values_to = "value",
               names_to = "parameter"
  ) %>% 
  mutate(parameter = case_when(
    parameter == "cost_complexity" ~ "Cost-Complexity Parameter",
    parameter == "tree_depth" ~ "Tree Depth",
    parameter == "min_n" ~ "Minimal Node Size",
    
  ))%>% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == 'BestModel'), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c("red", "black"))+
      facet_grid(.metric~parameter, scales = "free") +
      labs(x = NULL, y = NULL)
  }
# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(tree_res_tun)
```
</details>
&nbsp;

```{r, fig.height = 4}
plot_tree_tun %>% 
  plotly::ggplotly()%>% 
  plotly::layout(showlegend = FALSE) %>% 
  plotly::config(displayModeBar = F)
```

5 Melhores resultados:

```{r}
show_best(tree_res_tun, metric = 'mn_log_loss') %>% 
  select(-.estimator, -n, -.config)
```

Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:

```{r}
# finalizar workflow definindo modelo final
tree_final_wflow_tun <- 
  finalize_workflow(
    tree_wflow_tun,
    select_best(tree_res_tun, metric = 'mn_log_loss') )

# Realizar ajuste final nos dados de treino
tree_final_fit_tun <- tree_final_wflow_tun %>% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
tree_test_preds_tun <- collect_predictions(tree_final_fit_tun)
```

Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o *tunning* final:

<details>
<summary>(*C√≥digo do gr√°fico*)</summary>
```{r, fig.height=4}
tre_model_tun <- pull_workflow_fit(tree_final_fit_tun$.workflow[[1]])
```
</details>
&nbsp;

```{r}
rattle::fancyRpartPlot(tre_model_tun$fit, sub = NULL, cex = 0.6)
```

Avaliar desempenho do modelo nos dados de teste:

```{r}
tree_test_preds_tun %>% 
  mutate(mood = factor(mood, levels = c("Ruim", "Bom"), ordered = TRUE)) %>%
  conf_mat_plot()
```

```{r, echo = F}
bind_rows(
  evalue_model(x = tree_test_preds_bas, model = "tree default"),
  evalue_model(tree_test_preds_tun, model = "tree tunning")) %>% 
  print_table(round = 4, evalue_model = TRUE)
```

Ao comparar o modelo default com o modelo ap√≥s o *tunning* √© poss√≠vel notar que o n√∫mero de verdadeiros positivos foi menor por√©m o n√∫mero de fasos positivos tbm foi menor devido ao elevado `trs_fbeta` encontrado (maximizando F0.5).

No geral, o modelo tunado ficou pior que o modelo default mas como o modelo de √°rvore de deci√µes costuma ser bem inst√°vel, ainda mais em um cen√°rio de dados desbalanceados vamos apenas guardar estes resultados e dar mais um passo, combinando diversas √°rvore de decis√µes!

## Random Forest

O *Random Forest* √© um algoritmo que (de forma simplificada) realiza bootstrap em cima de √°rvores de decis√µes (modelos que utilizamos anteriormente) construindo modelos de √°rvores de decis√µes em diferentes amostras com diferentes combina√ß√µes de *features* e assim uma previs√£o final √© feita ap√≥s uma "vota√ß√£o entre os modelos".

### Default

Os par√¢metros *default* foram definidos baseados na documenta√ß√£o oficial do pacote `ranger` em <https://cran.r-project.org/web/packages/ranger/ranger.pdf> e o *de/para* para defini√ß√£o dos par√¢metros na p√°gina do pacote `parsnip` em <https://parsnip.tidymodels.org/reference/rand_forest.html>

```{r}
# raiz quadrada do numero de features 
n_col = ncol(juice(sleep_recipe))

rf_model_bas <- rand_forest(
  mtry = sqrt(n_col) %>% floor(), # mtry
  trees = 500,                    # num.trees
  min_n = 1                       # min.node.size 
) %>% 
  set_engine("ranger", num.threads = 4, importance = "permutation") %>% 
  set_mode("classification")
```

Definir o objeto `workflow`:

```{r}
rf_wflow_bas <- workflow() %>% 
  add_recipe(sleep_recipe) %>% 
  add_model(rf_model_bas) 
```

Ajustar modelo via valida√ß√£o cruzada:

```{r}
rf_res_bas <- fit_resamples(
  rf_wflow_bas,
  sleep_folds,
  metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
  control = control_resamples(save_pred = TRUE)
)
```

Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:

```{r}
# Finalizar workflow com parametros selecionados (default nesse caso)
rf_final_wflow_bas <- 
  finalize_workflow(
    rf_wflow_bas,
    select_best(rf_res_bas, metric = 'mn_log_loss') )

# Realizar ajuste final nos dados de treino
rf_final_fit_bas <- rf_final_wflow_bas %>% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
rf_test_preds_bas <- collect_predictions(rf_final_fit_bas)
```

Avaliar desempenho do modelo nos dados de teste:

```{r}
rf_test_preds_bas %>% 
  mutate(mood = factor(mood, levels = c("Ruim", "Bom"), ordered = TRUE)) %>%
  conf_mat_plot()
```

Este modelo n√£o fez nenhuma previs√£o de falso positivo! Por√©m note que o `trs_fbeta` ficou bastante alto, o que deve ter ocorrido como reflexo do elevado `logloss` que indicaria que a incerteza que o modelo tem nas previs√µes esta alta.

### Tunning

Definir o modelo que ser√° utilizado:

```{r}
rf_model_tun <- rand_forest(
  mtry = tune(),
  trees = tune(), 
  min_n = tune()
) %>% 
  set_engine("ranger", num.threads = 4, importance = "permutation") %>% 
  set_mode("classification")
# tree_model %>% translate()
```

Definir o objeto `workflow`:

```{r}
rf_wflow_tun <- workflow() %>% 
  add_recipe(sleep_recipe) %>% 
  add_model(rf_model_tun) 
```

O grid utilizado tentar√° valores superiores e inferiores ao n√∫mero de √°rvores *default* do algoritmo e vamos incluir o valor 1 ao `min_n` pois √°rvores mais longas neste m√©todo podem ser √∫teis. O `mtry` ser√° calculado baseado nas informa√ß√µes do dataset de treino.

- `trees`: [100, 900]
- `min_n`: [1, 40]
- `mtry`: [1, 20]

Definir t√©cnica de otimiza√ß√£o de hiperpar√¢metros 

```{r}
rf_grid <-grid_max_entropy(
  trees() %>% range_set(c(100, 900)), # Default Range: [1, 2000]
  min_n() %>% range_set(c(1, 40)),    # Default Range: [2, 40]
  finalize(mtry(), sleep_train),
  size = 30)
```

Ajustar modelo:

```{r, eval = F}
rf_res_tun <- 
  rf_wflow_tun %>% 
  tune_grid(
    resamples = sleep_folds,
    grid = rf_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
saveRDS(rf_res_tun, "rf_res_tun.rds")
```

```{r, echo = F}
rf_res_tun <- readRDS("rf_res_tun.rds")
```

Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:

<details>
<summary>(*C√≥digo do gr√°fico*)</summary>
```{r}
id_best_model <- 
  show_best(rf_res_tun, metric = 'mn_log_loss') %>%
  slice(1) %>% 
  pull(.config)

plot_rf_tun <- 
  rf_res_tun %>% 
  collect_metrics() %>% 
  mutate(best_model = if_else(.config == id_best_model, 
                              "BestModel", "Try")) %>% 
  select(.metric, mean, best_model,
         mtry:min_n) %>%
  pivot_longer(mtry:min_n,
               values_to = "value",
               names_to = "parameter"
  ) %>% 
  mutate(parameter = case_when(
    parameter == "mtry" ~ "Randomly Selected Predictors",
    parameter == "min_n" ~ "Minimal Node Size",
    parameter == "trees" ~ "# Trees"
  )) %>% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == 'BestModel'), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c("red", "black"))+
      facet_grid(.metric~parameter, scales = "free") +
      labs(x = NULL, y = NULL)
  }
# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(rf_res_tun)
```
</details>
&nbsp;

```{r, fig.height = 4}
plot_rf_tun %>% 
  plotly::ggplotly()%>% 
  plotly::layout(showlegend = FALSE) %>% 
  plotly::config(displayModeBar = F)
```

Melhores resultados:

```{r}
show_best(rf_res_tun, metric = 'mn_log_loss') %>% 
  select(-.estimator, -n, -.config)
```

Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:

```{r}
# finalizar workflow definindo modelo final
rf_final_wflow_tun <- 
  finalize_workflow(
    rf_wflow_tun,
    select_best(rf_res_tun, metric = 'mn_log_loss') )

# Realizar ajuste final nos dados de treino
rf_final_fit_tun <- rf_final_wflow_tun %>% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
rf_test_preds_tun <- collect_predictions(rf_final_fit_tun)
```

Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o *tunning* final:

Avaliar desempenho do modelo nos dados de teste:

```{r}
rf_test_preds_tun %>% 
  mutate(mood = factor(mood, levels = c("Ruim", "Bom"), ordered = TRUE)) %>%
  conf_mat_plot()
```

```{r, echo = F}
bind_rows(
  evalue_model(rf_test_preds_bas, model = "rf default"),
  evalue_model(rf_test_preds_tun, model = "rf tunning")) %>% 
  print_table(round = 4, evalue_model = TRUE)
```

Note que apesar do maior n√∫mero de Verdadeiros Positivos, este modelo apresentou um Falso Positivo. Parece estranho pois √© exatamente o que queriamos evitar por√©m √© poss√≠vel notar que o `logloss` foi bem inferior e o `trs_fbeta` est√° bem mais razoavel agora.

Importancia de cada *feature* conforme o modelo:

```{r}
vip::vip(pull_workflow_fit(rf_final_fit_tun$.workflow[[1]]))
```

Diferente do modelo baseado em 1 unica √°rvore de decis√µes, a *feature* `steps` n√£o foi t√£o importante assim. A `time_asleep_seconds` foi a mais importante mas com a ordem de grandeza muito pr√≥xima de `time_before_sleep_seconds`.

*Random Forest* √© um excelente modelo e poder√≠amos investir mais tempo tentando otimizando sua performance mas para este post acho que j√° esta suficiente. Vamos para o pr√≥ximo modelo! üòç

## LightGBM

Este modelo consiste em um m√©todo de *boosting*. Tamb√©m √© baseado nos modelos de √°rvore de decis√µes, mas, diferentemente do *Random Forest*, suas √°rvores s√£o calculadas em sequ√™ncia, "aprendendo" com o erro das √°rvores anteriores.

A mec√¢nica do *LightGBM* √© um pouco diferente do *XGBoost.* N√£o entrarei em detalhes sobre a teoria neste post at√© porque a documenta√ß√£o oficial no github em <https://github.com/microsoft/LightGBM> √© bastante rica, e seus recursos s√£o muito bem apresentados neste link: <https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst>

Links √∫teis para consulta ao trabalhar com este algoritmo:

- Documenta√ß√£o oficial: <https://lightgbm.readthedocs.io/en/latest/>
- Excelente post: <https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/>
- Documenta√ß√£o oficial do pacote `treesnip`: <https://curso-r.github.io/treesnip/articles/working-with-lightgbm-catboost.html>
- Reposit√≥rio no github do pacote `treesnip`: <https://github.com/curso-r/treesnip>
- √ìtimo link para consulta dos par√¢metros: <https://sites.google.com/view/lauraepp/parameters>

### Default

Os par√¢metros *default* foram definidos baseados na documenta√ß√£o oficial do pacote `lightgbm` em <https://lightgbm.readthedocs.io/en/latest/> e o *de/para* para defini√ß√£o dos par√¢metros na p√°gina do (incr√≠vel ü§©) pacote `treesnip` em <https://github.com/curso-r/treesnip/blob/master/R/lightgbm.R>

```{r}

lgbm_model_bas <- parsnip::boost_tree(
  mode = "classification",
  trees = 100,       # num_iterations
  learn_rate = 0.1,  # fixo
  min_n = 20,        # min_data_in_leaf
  tree_depth = 6,    # max_depth
  sample_size = 1,   # bagging_fraction
  mtry = 1,          # feature_fraction
  loss_reduction = 0 # min_gain_to_split
) %>%  
  set_engine("lightgbm",
             nthread = 4,
             importance = "permutation") %>% 
  set_mode("classification")
```

Definir o objeto `workflow`:

```{r}
lgbm_wflow_bas <- workflow() %>% 
  add_recipe(sleep_recipe) %>% 
  add_model(lgbm_model_bas) 
```

Ajustar modelo via valida√ß√£o cruzada:

```{r, eval = F}
lgbm_res_bas <- fit_resamples(
  lgbm_wflow_bas,
  sleep_folds,
  metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
  control = control_resamples(save_pred = TRUE)
)
saveRDS(lgbm_res_bas, "lgbm_res_bas.rds")
```

```{r, echo = F}
lgbm_res_bas <- readRDS("lgbm_res_bas.rds")
```

Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:

```{r}
# Finalizar workflow com parametros selecionados (default nesse caso)
lgbm_final_wflow_bas <- 
  finalize_workflow(
    lgbm_wflow_bas,
    select_best(lgbm_res_bas, metric = 'mn_log_loss') )

# Realizar ajuste final nos dados de treino
lgbm_final_fit_bas <- lgbm_final_wflow_bas %>% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
lgbm_test_preds_bas <- collect_predictions(lgbm_final_fit_bas)
```

Avaliar desempenho do modelo nos dados de teste:

```{r}
lgbm_test_preds_bas %>% 
  mutate(mood = factor(mood, levels = c("Ruim", "Bom"), ordered = TRUE)) %>%
  conf_mat_plot()
```

### Tunning

Para o tunning vamos utilizar uma estrat√©gia um pouco diferente. Vamos fixar o n√∫mero de √°rvores `trees` e a taxa de aprendizado `learning_rate` pois vamos separar mais uma pequena parte dos dados para usar o recurso `early_stopping`. Esta op√ß√£o basicamente "trava" o crescimento da √°rvore caso o modelo n√£o melhore a performance a partir da n-√©sima itera√ß√£o.

```{r}
lgbm_model_tun <- parsnip::boost_tree(
  mode = "classification",
  trees = 700,             # autotune com early stopping
  learn_rate = 0.01,       # early stopping
  min_n = tune(),          # min_data_in_leaf
  tree_depth = tune(),     # max_depth
  sample_size = 1,         # bagging_fraction, n funciona com goss
  mtry = tune(),           # feature_fraction
  loss_reduction = tune()  # min_gain_to_split
) %>%  
  set_engine("lightgbm", nthread = 4, 
             # parametros para early stopping
             early_stop = 30,
             validation = .20,
             eval_metric = "mn_log_loss",
             importance = "permutation"
             # feature_fraction = tune("feature_fraction")
  ) %>% 
  set_mode("classification")
# tree_model %>% translate()
```

Definir o objeto `workflow`:

```{r}
lgbm_wflow_tun <- workflow() %>% 
  add_recipe(sleep_recipe) %>% 
  add_model(lgbm_model_tun) 
```

Definir grid para otimiza√ß√£o de hiperpar√¢metros baseados nas sugest√µes de [github/Laurae2](https://github.com/Laurae2) em uma [issue](https://github.com/microsoft/LightGBM/issues/695) no reposit√≥rio [oficial](https://github.com/microsoft/LightGBM/issues/695) do modelo

```{r}
lightgbm_params <- 
  dials::parameters(
    # learn_rate(),           # learning_rate
    # trees()                 # num_iterations
    min_n(),                  # min_data_in_leaf
    tree_depth(c(2, 63)),     # max_depth
    # sample_prop(c(0.4, 1)), # bagging_fraction (vai para sample_size)
    mtry(),                   # feature_fraction
    loss_reduction()          # min_gain_to_split
  ) 

lgbm_grid <- lightgbm_params %>% 
  finalize(sleep_train) %>% 
  grid_max_entropy(size = 30)
```

```{r, echo = F, eval = F}
lgbm_grid2 <- 
  expand.grid(learn_rate = c(0.005, 0.01, 0.02, 0.03, 0.05, 0.1),
              trees = seq(500, 900, 100) )
```

Ajustar modelo:

```{r, eval = F}
lgbm_res_tun <- 
  lgbm_wflow_tun %>% 
  tune_grid(
    resamples = sleep_folds,
    grid = lgbm_grid,
    metrics = metric_set(roc_auc, mn_log_loss, pr_auc),
    control = control_grid(save_pred = TRUE)
  )

# Salvar cache da otimizacao 
saveRDS(lgbm_res_tun, "lgbm_res_tun.rds")
```

```{r, echo = F}
lgbm_res_tun <- readRDS("lgbm_res_tun_final.rds")
```

Impacto de cada hiperpar√¢metro no resultado das m√©tricas c√°lculadas para cada modelo:

<details>
<summary>(*C√≥digo do gr√°fico*)</summary>
```{r}
id_best_model <- 
  show_best(lgbm_res_tun, metric = 'mn_log_loss')[1, ] %>% 
  pull(.config)

plot_lgbm_tun <- 
  lgbm_res_tun %>% 
  collect_metrics() %>% 
  mutate(best_model = if_else(.config == id_best_model, 
                              "BestModel", "Try")) %>% 
  select(.metric, mean, best_model,
         mtry:loss_reduction) %>%
  pivot_longer(mtry:loss_reduction,
               values_to = "value",
               names_to = "parameter"
  ) %>% {
    ggplot(., aes(value, mean, color = best_model)) +
      geom_point(alpha = 0.6, show.legend = FALSE) +
      geom_point(data = subset(., best_model == 'BestModel'), 
                 size = 4, shape = 3)+
      scale_color_manual(values = c("red", "black"))+
      facet_grid(.metric~parameter, scales = "free") +
      labs(x = NULL, y = NULL)
  }

# Codigo para mesmo grafico sem cor para melhor modelo:
# autoplot(lgbm_res_tun)
```
</details>
&nbsp;

```{r, fig.height=4}
plot_lgbm_tun %>% 
  plotly::ggplotly()%>% 
  plotly::layout(showlegend = FALSE) %>% 
  plotly::config(displayModeBar = F)
```

Melhores resultados:

```{r}
show_best(lgbm_res_tun, metric = 'mn_log_loss') %>% 
  select(-.estimator, -n, -.config)
```

Finalizar o modelo com o conjunto de par√¢metros encontrados no processo de otimiza√ß√£o:

```{r}
# finalizar workflow definindo modelo final
lgbm_final_wflow_tun <- 
  finalize_workflow(
    lgbm_wflow_tun,
    select_best(lgbm_res_tun, metric = 'mn_log_loss') )

# Realizar ajuste final nos dados de treino
lgbm_final_fit_tun <- lgbm_final_wflow_tun %>% last_fit(sleep_split) 

# Coletar previs√µes nos dados de teste
lgbm_test_preds_tun <- collect_predictions(lgbm_final_fit_tun)
```

Vejamos como ficou foi o ajuste do modelo utilizando a configura√ß√£o obtida no ap√≥s o *tunning* final:

Avaliar desempenho do modelo nos dados de teste:

```{r}
lgbm_test_preds_tun %>% 
  mutate(mood = factor(mood, levels = c("Ruim", "Bom"), ordered = TRUE)) %>%
  conf_mat_plot()
```

```{r, echo = F}
bind_rows(
  evalue_model(lgbm_test_preds_bas, model = "lgbm default"),
  evalue_model(lgbm_test_preds_tun, model = "lgbm tunning")) %>% 
  print_table(round = 4, evalue_model = TRUE)
```

Que maravilha! Modelos acertaram mais a classe de interesse do que os anteriores (apesar do *default* ainda apresentar alta propor√ß√£o de falsos positivos). Note ainda que o LightGBM ap√≥s o *tunning* apresentou as melhores m√©tricas no geral (melhor AUC-PR, menor *logloss* e um bom equil√≠brio no *trade-off* de *Precision* x *Recall*).

Vejamos quais as *features* mais importantes no ajuste do modelo:

```{r}
lgbm_imp_tun <- lightgbm::lgb.importance(lgbm_final_fit_tun$.workflow[[1]]$fit$fit$fit, percentage = T)

lgbm_imp_tun%>% 
  mutate(Feature = reorder(Feature, Gain)) %>% 
  ggplot(aes(x = Feature, y = Gain))+
  geom_bar(stat = "identity")+
  labs(y = "Importance", x= "")+
  coord_flip()
```

# Sele√ß√£o do modelo ü§î

<!-- Curva Roc e Precision-Recall Curve: -->

<!-- ```{r} -->
<!-- bind_rows( -->
<!--   # null_res_bas %>% unnest(.predictions) %>% mutate(model = "null baseline"),   -->
<!--   tree_res_bas %>% unnest(.predictions) %>% mutate(model = "rpart baseline"),   -->
<!--   tree_res_tun %>% unnest(.predictions) %>% mutate(model = "rpart tunning"), -->
<!--   rf_res_bas %>% unnest(.predictions) %>% mutate(model = "rf baseline"), -->
<!--   rf_res_tun %>% unnest(.predictions) %>% mutate(model = "rf tunning"), -->
<!--   lgbm_res_bas %>% unnest(.predictions) %>% mutate(model = "lgbm baseline"), -->
<!--   lgbm_res_tun %>% unnest(.predictions) %>% mutate(model = "lgbm tunning") -->
<!-- ) %>%   -->
<!--   plot_auc() +  -->
<!--   plot_annotation(title = 'Resultados nos dados de treino', -->
<!--                   theme = theme(plot.title = element_text(hjust = 0.4))) -->
<!-- ``` -->

Comparar os modelos de forma visual com os gr√°ficos da ROC AUC e da PR AUC:

<details>
<summary>(*C√≥digo do gr√°fico*)</summary>
```{r}
auc_plots <- 
  bind_rows(
    null_test_preds_bas %>% mutate(model = "null baseline"),
    tree_test_preds_bas %>% mutate(model = "rpart default"),
    tree_test_preds_tun %>% mutate(model = "rpart tunning"),
    rf_test_preds_bas %>% mutate(model = "rf default"),
    rf_test_preds_tun %>% mutate(model = "rf tunning"),
    lgbm_test_preds_bas %>% mutate(model = "lgbm default"),
    lgbm_test_preds_tun %>% mutate(model = "lgbm tunning")
  ) %>% 
  plot_auc() + 
  plot_annotation(title = 'Resultados nos dados de teste',
                  theme = theme(plot.title = element_text(hjust = 0.4)))
``` 
</details>
&nbsp;

```{r}
auc_plots
```

Apenas olhando o gr√°fico n√£o da para fazer uma an√°lise conclusiva, vejamos as medidas de qualidade (ordenado por `auc_pr`):

<details>
<summary>(*C√≥digo da tabela*)</summary>
```{r}
test_results <- 
  bind_rows(
    evalue_model(null_test_preds_bas, model = "null baseline", null_model = TRUE),
    evalue_model(tree_test_preds_bas, model = "rpart default"),
    evalue_model(tree_test_preds_tun, model = "rpart tunning"),
    evalue_model(rf_test_preds_bas, model = "rf default"),
    evalue_model(rf_test_preds_tun, model = "rf tunning"),
    evalue_model(lgbm_test_preds_bas, model = "lgbm default"),
    evalue_model(lgbm_test_preds_tun, model = "lgbm tunning")
  ) %>% print_table(round = 4, evalue_model = T)   
```
</details>
&nbsp;

```{r}
test_results
```

O modelo LightGBM ap√≥s o processo de tunning foi o que apresentou as melhores medidas no geral. Note que o LightGBM com os par√¢metro default ficou pior do que o modelo nulo üò±! Isso mostra como o processo de tunning pode ser importante. Al√©m disso note que o modelo `rf baseline` apresentou o segundo maior AUC-PR mas o pior logloss (note que o `threshold` est√° muito alto e as demais m√©tricas n√£o ficaram muito boas).

Portanto, apenas os modelos *LightGBM* e *Random Forest* apresentaram resultados melhores que um modelo nulo (sempre estima a classe majorit√°ria) e como o LightGBM foi o mais satisfat√≥rio, este ser√° o modelo selecionado. üòé

# Previs√£o em dados novos üí´

Obter as previs√µes nos novos dados: 

```{r}
trs_final <- evalue_model(lgbm_test_preds_tun, model = "lgbm tunning")$trs_fbeta

final <- 
  predict(lgbm_final_fit_tun$.workflow[[1]], new_sleep, type = "prob") %>% 
  mutate(.pred_class = ifelse(.pred_Ruim >= trs_final, "Ruim", "Bom")) 

# new_sleep %>% filter(final$.pred_class == "Ruim")
```

Comparar a quantidade de previs√µes de cada classe com o conjunto de treino/teste:

<details>
<summary>(*C√≥digo para tabela abaixo*)</summary>
```{r, eval = T}
tab <- 
  full_join(sleep_train %>% count(mood) %>% mutate(prop = n/sum(n)*100),
            sleep_test %>% count(mood) %>% mutate(prop = n/sum(n)*100),
            by = "mood") %>% 
  full_join(final %>% 
              count(mood = .pred_class) %>% mutate(prop = n/sum(n)*100)) %>% 
  print_table(round = 2,
              columns = list(
                n.x = colDef(name = "N"),
                prop.x = colDef(name = "(%)", align = "left"),
                n.y = colDef(name = "N"),
                prop.y = colDef(name = "(%)", align = "left"),
                n = colDef(name = "N"),
                prop = colDef(name = "(%)", align = "left")
              ), 
              columnGroups = list(
                colGroup(name = "Train", columns = c("n.x", "prop.x")),
                colGroup(name = "Test", columns = c("n.y", "prop.y")),
                colGroup(name = "New Data", columns = c("n", "prop"))
              ))
```
</details>
&nbsp;&nbsp;

```{r}
tab
```

<details>
<summary>(*C√≥digo do c√°lculo das medidas abaixo*)</summary>
```{r}
# ref: https://en.wikipedia.org/wiki/Sensitivity_and_specificity

# Obter medidas da matriz de confusao
tp = evalue_model(lgbm_test_preds_tun, model = "lgbm tunning")$tp
tn = evalue_model(lgbm_test_preds_tun, model = "lgbm tunning")$tn
fn = evalue_model(lgbm_test_preds_tun, model = "lgbm tunning")$fn
fp = evalue_model(lgbm_test_preds_tun, model = "lgbm tunning")$fn

# true positive rate
tpr = tp / (tp + fn)
# false negative rate
fnr = 1 - tpr
#false positive rate
fpr = fp / (fp + tn)
```
</details>
&nbsp;&nbsp;

Como nosso modelo foi otimizado para ser menos "alarmista" (com uma Taxa de Falso Positivo: `r paste0(round(fpr*100, 2), "%")`) √© poss√≠vel que o modelo tenha deixado passar alguns dias em que `mood=="Ruim"` (Taxa de Falso Negativo: `r paste0(round(fnr*100, 2), "%")`). N√£o vejo isto como um grande problema pois dado a pequena quantidade de dados dispon√≠veis at√© que o resultado para a classe de interesse estava bem razo√°vel (Taxa de Verdadeiro Positivo: `r paste0(round(tpr*100, 2), "%")`).

Para n√£o alongar aida mais o post com an√°lise explorat√≥ria das previs√µes, vamos comparar como foram as previs√µes nestes novos dados em rela√ß√£o aos dados utilizados para treinar o modelo e ver se, pelo menos visualmente, o modelo esteja conseguindo prever de semelhante ao padr√£o de dados conhecidos.

A t√©cnica [UMAP](https://cran.r-project.org/web/packages/umap/vignettes/umap.html) ser√° utilizada com a finalidade de reduzir a dimensionalidade para visualiza√ß√£o:

<details>
<summary>(*C√≥digo para gr√°fico abaixo*)</summary>
```{r}
# Treinar UMAP: 
sleep_umap <-  juice(sleep_recipe) %>% select(-mood) %>% umap::umap()

# Aplicar em novos dados:
new_data <- bake(sleep_recipe, new_sleep) %>% select(-mood)
new_data_umap <- predict(sleep_umap, new_data)

# Preparar plot comparando treino com novos dados:
umap_plot <-
  bind_rows(
    sleep_umap$layout %>% 
      as_tibble() %>% 
      bind_cols(juice(sleep_recipe) %>% select(mood))  %>% 
      bind_cols(dataset =  "Train")
    ,
    new_data_umap %>% 
      as_tibble() %>% 
      mutate(mood = factor(final$.pred_class,
                           levels = c("Ruim", "Bom")))  %>% 
      bind_cols(dataset =  "New Data")
  ) %>%
  mutate(dataset = factor(dataset, levels = c("New Data", "Train"))) %>% {
    ggplot(., aes(x = V1, y = V2, color = mood, shape = mood))+
      geom_point(show.legend = F)+
      geom_point(aes(x = V1, y = V2, color = mood), 
                 data = subset(., mood == 'Ruim'), 
                 size = 2, shape = 3)+
      labs(x = "", y = "", 
           title = "UMAP (Uniform Manifold Approximation and Projection)")+
      scale_color_viridis_d(end = 0.8, direction = 1)+
      # scale_size_manual(values=c(2,5))+
      theme(legend.position = "bottom")+
      facet_wrap(~dataset)
  }
```
</details>
&nbsp;&nbsp;

```{r}
umap_plot %>% 
  plotly::ggplotly()%>% 
  plotly::layout(showlegend = FALSE) %>% 
  plotly::config(displayModeBar = F)
```

Parece que o modelo fez previs√µes nos novos dados em um padr√£o espec√≠fico dos dados (√† direita) enquanto que nos dados de treino podemos observar alguma informa√ß√£o da classe `Ruim` na massa de dados √† esquerda. Isso pode estar acontecendo devido ao foco que demos para minimizar falsos positivos. √â uma boa indica√ß√£o para analisar melhor o padr√£o que o modelo esta aprendendo em rela√ß√£o aos falsos negativos.

```{r, eval = F, echo = F}
## RASCUNHO
library(Rtsne)

# iris_matrix <- as.matrix(iris_unique[,1:4])
set.seed(42) # Set a seed if you want reproducible results

datasets <- list(
  train = juice(sleep_recipe),
  # test = bake(sleep_recipe, sleep_test),
  new_data = bake(sleep_recipe, new_sleep) %>% 
    mutate(mood = factor(final$.pred_class,
                         levels = c("Ruim", "Bom")))
) 

tsne_out <- map(datasets, Rtsne) # Run TSNE


tsne_plot <- pmap_df(
  list(tsne_out, datasets, names(datasets)),
  function(.x, .y, .z){
    tibble(x = .x$Y[,1], y = .x$Y[,2], col = .y$mood, dataset = .z)
  })


tsne_plot %>% 
  ggplot() + 
  geom_point(aes(x=x, y=y, color=col))+
  facet_wrap(~dataset)+
  theme(legend.position = "bottom")


g1 | g2
```

# Conclus√£o üçª

Apesar da pequena quantidade dados dados dispon√≠veis, conseguimos ajustar um modelo razo√°vel para prever a qualidade de sono em dias que n√£o foram registrados!

<div class="row">
<div class="column8">
Utilizamos diversas t√©cnicas de *Machine Leaning* combinadas em dados reais (que n√£o s√£o nada comportados) e, obviamente, para colocar um modelo em produ√ß√£o na vida real seria necess√°rio aplicar mais uma s√©rie de an√°lises, al√©m de entender como o modelo est√° funcionando, aplicando t√©cnicas de [XAI](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence) (Explainable AI) mas isso pode ser assunto para um futuro *post*, hora de dormir! üò¥

Espero que este pequeno "*case*" seja √∫til para voc√™! Para mim foi √≥timo combinar a pr√°tica do uso do pacote `tidymodels` para resolver um problema com dados reais com um estudo que me trouxe mais auto-conhecmento e um monte de *insights* pessoais. 


</div>

<div class="column4">
![[Via Giphy](https://media.giphy.com/media/U7Lvtcuqh4WZy/giphy.gif)](https://media.giphy.com/media/U7Lvtcuqh4WZy/giphy.gif)
</div>

</div>


---

# Refer√™ncias üß≥

- <https://juliasilge.com/blog/wind-turbine/>
- <https://juliasilge.com/blog/hotels-recipes/> 
- <https://juliasilge.com/blog/xgboost-tune-volleyball/>
- <http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/>
- <https://machinelearningmastery.com/imbalanced-classification-with-python/>
- <https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/>
- <https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/>
- <https://machinelearningmastery.com/fbeta-measure-for-machine-learning/>
- <https://sites.google.com/view/lauraepp/parameters>
- <https://github.com/microsoft/LightGBM/issues/695>


[^1]: <https://www.usp.br/espacoaberto/?materia=a-importancia-de-dormir-bem>
[^2]: <https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/>
[^3]: <https://machinelearningmastery.com/fbeta-measure-for-machine-learning/>
[^4]: <https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/>
[^5]: <https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/>